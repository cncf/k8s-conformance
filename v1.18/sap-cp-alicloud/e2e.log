Conformance test: not doing test setup.
I0427 16:09:44.100931    7398 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0427 16:09:44.101094    7398 e2e.go:124] Starting e2e run "45bd2b45-dba0-4fb7-82c0-cc3940290997" on Ginkgo node 1
{"msg":"Test Suite starting","total":277,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1588003782 - Will randomize all specs
Will run 277 of 4992 specs

Apr 27 16:09:44.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:44.316: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 27 16:09:44.345: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
Apr 27 16:09:44.394: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 27 16:09:44.394: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Apr 27 16:09:44.394: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 27 16:09:44.407: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 27 16:09:44.407: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-disk-plugin-alicloud' (0 seconds elapsed)
Apr 27 16:09:44.407: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 27 16:09:44.407: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr 27 16:09:44.408: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Apr 27 16:09:44.408: INFO: e2e test version: v1.18.2
Apr 27 16:09:44.411: INFO: kube-apiserver version: v1.18.2
Apr 27 16:09:44.411: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:09:44.418: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:44.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
Apr 27 16:09:44.458: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr 27 16:09:44.479: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 16:09:44.599: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-855'
Apr 27 16:09:49.711: INFO: stderr: ""
Apr 27 16:09:49.711: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Apr 27 16:09:49.715: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-855'
Apr 27 16:09:54.900: INFO: stderr: ""
Apr 27 16:09:54.900: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:54.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-855" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":277,"completed":1,"skipped":15,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:54.914: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 27 16:09:55.077: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7274 /api/v1/namespaces/watch-7274/configmaps/e2e-watch-test-watch-closed 858d4c3d-2b35-4fc2-ba84-4733e790720a 6150 0 2020-04-27 16:09:55 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:09:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:09:55.078: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7274 /api/v1/namespaces/watch-7274/configmaps/e2e-watch-test-watch-closed 858d4c3d-2b35-4fc2-ba84-4733e790720a 6151 0 2020-04-27 16:09:55 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:09:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 27 16:09:55.095: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7274 /api/v1/namespaces/watch-7274/configmaps/e2e-watch-test-watch-closed 858d4c3d-2b35-4fc2-ba84-4733e790720a 6152 0 2020-04-27 16:09:55 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:09:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:09:55.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7274 /api/v1/namespaces/watch-7274/configmaps/e2e-watch-test-watch-closed 858d4c3d-2b35-4fc2-ba84-4733e790720a 6153 0 2020-04-27 16:09:55 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-04-27 16:09:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:09:55.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7274" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":277,"completed":2,"skipped":35,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:09:55.105: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:09:55.841: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:09:57.854: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:09:59.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:01.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:03.860: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:05.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:07.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:09.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:11.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:10:13.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723600595, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:10:16.869: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:10:17.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8966" for this suite.
STEP: Destroying namespace "webhook-8966-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":277,"completed":3,"skipped":74,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:10:17.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6312
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:10:17.262: INFO: (0) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 11.007215ms)
Apr 27 16:10:17.307: INFO: (1) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 44.803844ms)
Apr 27 16:10:17.315: INFO: (2) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.559935ms)
Apr 27 16:10:17.322: INFO: (3) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.80981ms)
Apr 27 16:10:17.328: INFO: (4) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.701668ms)
Apr 27 16:10:17.336: INFO: (5) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.905833ms)
Apr 27 16:10:17.343: INFO: (6) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.017051ms)
Apr 27 16:10:17.351: INFO: (7) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.023932ms)
Apr 27 16:10:17.357: INFO: (8) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.763344ms)
Apr 27 16:10:17.364: INFO: (9) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.900034ms)
Apr 27 16:10:17.371: INFO: (10) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.574024ms)
Apr 27 16:10:17.384: INFO: (11) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 12.559572ms)
Apr 27 16:10:17.391: INFO: (12) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.802816ms)
Apr 27 16:10:17.398: INFO: (13) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.10395ms)
Apr 27 16:10:17.404: INFO: (14) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.565681ms)
Apr 27 16:10:17.411: INFO: (15) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.808124ms)
Apr 27 16:10:17.418: INFO: (16) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.520445ms)
Apr 27 16:10:17.425: INFO: (17) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.6933ms)
Apr 27 16:10:17.432: INFO: (18) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.81538ms)
Apr 27 16:10:17.438: INFO: (19) /api/v1/nodes/izgw873bmqhhfhflh483llz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.670551ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:10:17.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6312" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":277,"completed":4,"skipped":105,"failed":0}
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:10:17.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-1e1a2b73-c8fb-476f-b4eb-076beec23e3c in namespace container-probe-2004
Apr 27 16:10:19.614: INFO: Started pod test-webserver-1e1a2b73-c8fb-476f-b4eb-076beec23e3c in namespace container-probe-2004
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:10:19.619: INFO: Initial restart count of pod test-webserver-1e1a2b73-c8fb-476f-b4eb-076beec23e3c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:14:20.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2004" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":5,"skipped":110,"failed":0}
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:14:20.263: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-bbsp
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:14:20.427: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bbsp" in namespace "subpath-9369" to be "Succeeded or Failed"
Apr 27 16:14:20.433: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.097258ms
Apr 27 16:14:22.438: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0109422s
Apr 27 16:14:24.443: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 4.016260755s
Apr 27 16:14:26.448: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 6.021523374s
Apr 27 16:14:28.454: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 8.026779583s
Apr 27 16:14:30.459: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 10.031876214s
Apr 27 16:14:32.464: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 12.037062669s
Apr 27 16:14:34.469: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 14.042011375s
Apr 27 16:14:36.474: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 16.047013845s
Apr 27 16:14:38.479: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 18.052024722s
Apr 27 16:14:40.484: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 20.056982271s
Apr 27 16:14:42.489: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Running", Reason="", readiness=true. Elapsed: 22.06254067s
Apr 27 16:14:44.495: INFO: Pod "pod-subpath-test-projected-bbsp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.067810045s
STEP: Saw pod success
Apr 27 16:14:44.495: INFO: Pod "pod-subpath-test-projected-bbsp" satisfied condition "Succeeded or Failed"
Apr 27 16:14:44.499: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-subpath-test-projected-bbsp container test-container-subpath-projected-bbsp: <nil>
STEP: delete the pod
Apr 27 16:14:44.593: INFO: Waiting for pod pod-subpath-test-projected-bbsp to disappear
Apr 27 16:14:44.597: INFO: Pod pod-subpath-test-projected-bbsp no longer exists
STEP: Deleting pod pod-subpath-test-projected-bbsp
Apr 27 16:14:44.598: INFO: Deleting pod "pod-subpath-test-projected-bbsp" in namespace "subpath-9369"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:14:44.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9369" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":277,"completed":6,"skipped":114,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:14:44.615: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Apr 27 16:14:44.773: INFO: Waiting up to 5m0s for pod "var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5" in namespace "var-expansion-2121" to be "Succeeded or Failed"
Apr 27 16:14:44.777: INFO: Pod "var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933353ms
Apr 27 16:14:46.782: INFO: Pod "var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009628173s
Apr 27 16:14:48.788: INFO: Pod "var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015128743s
STEP: Saw pod success
Apr 27 16:14:48.788: INFO: Pod "var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5" satisfied condition "Succeeded or Failed"
Apr 27 16:14:48.792: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:14:48.816: INFO: Waiting for pod var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5 to disappear
Apr 27 16:14:48.820: INFO: Pod var-expansion-d1457bd3-ae02-416e-bf8a-9c31ca1d40f5 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:14:48.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2121" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":277,"completed":7,"skipped":131,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:14:48.834: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5069
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-bc3ebbc1-85e9-4f0d-8456-cac6247eeb0c
STEP: Creating a pod to test consume configMaps
Apr 27 16:14:48.995: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c" in namespace "projected-5069" to be "Succeeded or Failed"
Apr 27 16:14:49.000: INFO: Pod "pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.607025ms
Apr 27 16:14:51.008: INFO: Pod "pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012932464s
STEP: Saw pod success
Apr 27 16:14:51.008: INFO: Pod "pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c" satisfied condition "Succeeded or Failed"
Apr 27 16:14:51.013: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:14:51.033: INFO: Waiting for pod pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c to disappear
Apr 27 16:14:51.037: INFO: Pod pod-projected-configmaps-f416071a-e4b2-40be-a168-89e34906261c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:14:51.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5069" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":8,"skipped":142,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:14:51.050: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-936f9692-dfc5-4d72-b851-0c3bd5b78415
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:14:51.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2558" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":277,"completed":9,"skipped":217,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:14:51.210: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-67e31e8b-1d55-4ff7-a093-fa790799c8c0
STEP: Creating a pod to test consume configMaps
Apr 27 16:14:51.371: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11" in namespace "projected-2154" to be "Succeeded or Failed"
Apr 27 16:14:51.375: INFO: Pod "pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11": Phase="Pending", Reason="", readiness=false. Elapsed: 3.958815ms
Apr 27 16:14:53.380: INFO: Pod "pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009115274s
STEP: Saw pod success
Apr 27 16:14:53.380: INFO: Pod "pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11" satisfied condition "Succeeded or Failed"
Apr 27 16:14:53.384: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:14:53.406: INFO: Waiting for pod pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11 to disappear
Apr 27 16:14:53.410: INFO: Pod pod-projected-configmaps-bc51d148-fbd8-4b7a-9f40-e8e0a11afb11 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:14:53.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2154" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":10,"skipped":226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:14:53.424: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:04.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8815" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":277,"completed":11,"skipped":250,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:04.626: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-517950a4-d192-4130-a0dc-02c974c1abda
STEP: Creating a pod to test consume secrets
Apr 27 16:15:04.786: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930" in namespace "projected-7308" to be "Succeeded or Failed"
Apr 27 16:15:04.790: INFO: Pod "pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127615ms
Apr 27 16:15:06.795: INFO: Pod "pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00932996s
STEP: Saw pod success
Apr 27 16:15:06.796: INFO: Pod "pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930" satisfied condition "Succeeded or Failed"
Apr 27 16:15:06.800: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:15:06.820: INFO: Waiting for pod pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930 to disappear
Apr 27 16:15:06.824: INFO: Pod pod-projected-secrets-bd6a284e-201f-4239-ac6b-03288fc8e930 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:06.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7308" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":12,"skipped":251,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:06.836: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8589
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:15:06.981: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:07.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8589" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":277,"completed":13,"skipped":263,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:07.542: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 16:15:07.744: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3576'
Apr 27 16:15:08.212: INFO: stderr: ""
Apr 27 16:15:08.212: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 16:15:09.217: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:15:09.217: INFO: Found 0 / 1
Apr 27 16:15:10.218: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:15:10.218: INFO: Found 1 / 1
Apr 27 16:15:10.218: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 27 16:15:10.223: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:15:10.223: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 16:15:10.223: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod agnhost-master-n44h5 --namespace=kubectl-3576 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 27 16:15:10.311: INFO: stderr: ""
Apr 27 16:15:10.311: INFO: stdout: "pod/agnhost-master-n44h5 patched\n"
STEP: checking annotations
Apr 27 16:15:10.315: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:15:10.316: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:10.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3576" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":277,"completed":14,"skipped":270,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:10.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:15:10.640: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91" in namespace "downward-api-5147" to be "Succeeded or Failed"
Apr 27 16:15:10.645: INFO: Pod "downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91": Phase="Pending", Reason="", readiness=false. Elapsed: 4.284316ms
Apr 27 16:15:12.650: INFO: Pod "downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009246147s
STEP: Saw pod success
Apr 27 16:15:12.650: INFO: Pod "downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91" satisfied condition "Succeeded or Failed"
Apr 27 16:15:12.654: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91 container client-container: <nil>
STEP: delete the pod
Apr 27 16:15:12.675: INFO: Waiting for pod downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91 to disappear
Apr 27 16:15:12.679: INFO: Pod downwardapi-volume-2b44b49a-a69f-484c-91ff-4c6afb8b6d91 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:12.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5147" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":277,"completed":15,"skipped":275,"failed":0}
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:12.691: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:15:12.836: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:16.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2487" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":277,"completed":16,"skipped":277,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:16.032: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:15:18.350: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:18.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8497" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":17,"skipped":298,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:18.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr 27 16:15:19.076: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:19.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0427 16:15:19.076545    7398 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2209" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":277,"completed":18,"skipped":302,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:19.086: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 27 16:15:22.275: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:15:23.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2616" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":277,"completed":19,"skipped":311,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:15:23.308: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7688
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 27 16:15:23.469: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8001 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:15:23.469: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8001 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 27 16:15:33.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8069 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:33 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:15:33.480: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8069 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:33 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 27 16:15:43.491: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8138 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:15:43.492: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8138 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 27 16:15:53.507: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8182 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:15:53.507: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-a 3038bd5e-e797-4e7e-9ed3-78acfd7f6d4d 8182 0 2020-04-27 16:15:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-04-27 16:15:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 27 16:16:03.516: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-b 9013a0fb-266a-44dc-b7cb-724ecb94e7cb 8221 0 2020-04-27 16:16:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:16:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:16:03.516: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-b 9013a0fb-266a-44dc-b7cb-724ecb94e7cb 8221 0 2020-04-27 16:16:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:16:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 27 16:16:13.524: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-b 9013a0fb-266a-44dc-b7cb-724ecb94e7cb 8264 0 2020-04-27 16:16:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:16:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:16:13.524: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7688 /api/v1/namespaces/watch-7688/configmaps/e2e-watch-test-configmap-b 9013a0fb-266a-44dc-b7cb-724ecb94e7cb 8264 0 2020-04-27 16:16:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-04-27 16:16:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:23.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7688" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":277,"completed":20,"skipped":326,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:23.540: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 16:16:23.694: INFO: Waiting up to 5m0s for pod "pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e" in namespace "emptydir-2097" to be "Succeeded or Failed"
Apr 27 16:16:23.699: INFO: Pod "pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020218ms
Apr 27 16:16:25.703: INFO: Pod "pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008477588s
STEP: Saw pod success
Apr 27 16:16:25.703: INFO: Pod "pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e" satisfied condition "Succeeded or Failed"
Apr 27 16:16:25.707: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e container test-container: <nil>
STEP: delete the pod
Apr 27 16:16:25.728: INFO: Waiting for pod pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e to disappear
Apr 27 16:16:25.732: INFO: Pod pod-70936e26-4b65-452e-9ae6-581c3a1b2a0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:25.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2097" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":21,"skipped":351,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:25.745: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:16:25.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6" in namespace "projected-4797" to be "Succeeded or Failed"
Apr 27 16:16:25.903: INFO: Pod "downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.971831ms
Apr 27 16:16:27.908: INFO: Pod "downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00902835s
STEP: Saw pod success
Apr 27 16:16:27.908: INFO: Pod "downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6" satisfied condition "Succeeded or Failed"
Apr 27 16:16:27.912: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6 container client-container: <nil>
STEP: delete the pod
Apr 27 16:16:27.943: INFO: Waiting for pod downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6 to disappear
Apr 27 16:16:27.947: INFO: Pod downwardapi-volume-c1bac551-c894-49a8-a4d4-b41c956c7ad6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:16:27.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4797" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":277,"completed":22,"skipped":401,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:16:27.961: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-12408423-5eaf-4189-8dca-a85643d363fe in namespace container-probe-5207
Apr 27 16:16:30.131: INFO: Started pod liveness-12408423-5eaf-4189-8dca-a85643d363fe in namespace container-probe-5207
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:16:30.136: INFO: Initial restart count of pod liveness-12408423-5eaf-4189-8dca-a85643d363fe is 0
Apr 27 16:16:40.165: INFO: Restart count of pod container-probe-5207/liveness-12408423-5eaf-4189-8dca-a85643d363fe is now 1 (10.029293284s elapsed)
Apr 27 16:17:02.223: INFO: Restart count of pod container-probe-5207/liveness-12408423-5eaf-4189-8dca-a85643d363fe is now 2 (32.087139436s elapsed)
Apr 27 16:17:22.275: INFO: Restart count of pod container-probe-5207/liveness-12408423-5eaf-4189-8dca-a85643d363fe is now 3 (52.139751291s elapsed)
Apr 27 16:17:40.322: INFO: Restart count of pod container-probe-5207/liveness-12408423-5eaf-4189-8dca-a85643d363fe is now 4 (1m10.186579179s elapsed)
Apr 27 16:18:44.485: INFO: Restart count of pod container-probe-5207/liveness-12408423-5eaf-4189-8dca-a85643d363fe is now 5 (2m14.349390274s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:44.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5207" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":277,"completed":23,"skipped":455,"failed":0}
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:44.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2403
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Apr 27 16:18:44.665: INFO: Waiting up to 5m0s for pod "client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2" in namespace "containers-2403" to be "Succeeded or Failed"
Apr 27 16:18:44.669: INFO: Pod "client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040771ms
Apr 27 16:18:46.674: INFO: Pod "client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009001584s
STEP: Saw pod success
Apr 27 16:18:46.674: INFO: Pod "client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2" satisfied condition "Succeeded or Failed"
Apr 27 16:18:46.678: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2 container test-container: <nil>
STEP: delete the pod
Apr 27 16:18:46.796: INFO: Waiting for pod client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2 to disappear
Apr 27 16:18:46.800: INFO: Pod client-containers-e1745dba-b665-4eab-b2b9-5677f8389da2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:46.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2403" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":277,"completed":24,"skipped":457,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:46.813: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:18:46.961: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8194'
Apr 27 16:18:47.194: INFO: stderr: ""
Apr 27 16:18:47.194: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Apr 27 16:18:47.194: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8194'
Apr 27 16:18:47.432: INFO: stderr: ""
Apr 27 16:18:47.432: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 16:18:48.438: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:18:48.438: INFO: Found 0 / 1
Apr 27 16:18:49.438: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:18:49.438: INFO: Found 1 / 1
Apr 27 16:18:49.438: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 16:18:49.442: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:18:49.442: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 16:18:49.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod agnhost-master-dclvv --namespace=kubectl-8194'
Apr 27 16:18:49.541: INFO: stderr: ""
Apr 27 16:18:49.541: INFO: stdout: "Name:         agnhost-master-dclvv\nNamespace:    kubectl-8194\nPriority:     0\nNode:         izgw82palggheybhhd1s46z/10.250.31.184\nStart Time:   Mon, 27 Apr 2020 16:18:47 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.24/32\n              cni.projectcalico.org/podIPs: 100.64.1.24/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.24\nIPs:\n  IP:           100.64.1.24\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://e0b9f1f60c2c82da0b5084bb105d2a592c179733bc68e9d2542d0df021189e12\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 27 Apr 2020 16:18:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-sxplm (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-sxplm:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-sxplm\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                              Message\n  ----    ------     ----       ----                              -------\n  Normal  Scheduled  <unknown>  default-scheduler                 Successfully assigned kubectl-8194/agnhost-master-dclvv to izgw82palggheybhhd1s46z\n  Normal  Pulled     2s         kubelet, izgw82palggheybhhd1s46z  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s         kubelet, izgw82palggheybhhd1s46z  Created container agnhost-master\n  Normal  Started    1s         kubelet, izgw82palggheybhhd1s46z  Started container agnhost-master\n"
Apr 27 16:18:49.542: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc agnhost-master --namespace=kubectl-8194'
Apr 27 16:18:49.646: INFO: stderr: ""
Apr 27 16:18:49.646: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-8194\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-master-dclvv\n"
Apr 27 16:18:49.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service agnhost-master --namespace=kubectl-8194'
Apr 27 16:18:49.740: INFO: stderr: ""
Apr 27 16:18:49.740: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-8194\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                100.111.185.134\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.64.1.24:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 27 16:18:49.748: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node izgw82palggheybhhd1s46z'
Apr 27 16:18:49.878: INFO: stderr: ""
Apr 27 16:18:49.878: INFO: stdout: "Name:               izgw82palggheybhhd1s46z\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecs.sn2ne.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=izgw82palggheybhhd1s46z\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    topology.diskplugin.csi.alibabacloud.com/zone=eu-central-1b\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"diskplugin.csi.alibabacloud.com\":\"i-gw82palggheybhhd1s46\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"node.kubernetes.io/role\":\"node\",\"worker.garden.sapcloud.io/group\":\"worker-1\",\"worker.gard...\n                    projectcalico.org/IPv4Address: 10.250.31.184/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 27 Apr 2020 15:53:24 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  izgw82palggheybhhd1s46z\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 27 Apr 2020 16:18:45 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ReadonlyFilesystem            False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Mon, 27 Apr 2020 16:17:51 +0000   Mon, 27 Apr 2020 15:54:36 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  NetworkUnavailable            False   Mon, 27 Apr 2020 15:56:48 +0000   Mon, 27 Apr 2020 15:56:48 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Mon, 27 Apr 2020 16:18:47 +0000   Mon, 27 Apr 2020 15:53:23 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Mon, 27 Apr 2020 16:18:47 +0000   Mon, 27 Apr 2020 15:53:23 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Mon, 27 Apr 2020 16:18:47 +0000   Mon, 27 Apr 2020 15:53:23 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Mon, 27 Apr 2020 16:18:47 +0000   Mon, 27 Apr 2020 15:53:53 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.31.184\n  Hostname:    izgw82palggheybhhd1s46z\nCapacity:\n  cpu:                2\n  ephemeral-storage:  33136428Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8169084Ki\n  pods:               110\nAllocatable:\n  cpu:                1920m\n  ephemeral-storage:  32235117134\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             6873143085\n  pods:               110\nSystem Info:\n  Machine ID:                 20191113202807502603996947022342\n  System UUID:                1db976bb-b5d5-4974-bf69-0eb97f0230b5\n  Boot ID:                    1fa83759-6a7f-439a-8f3f-7b5d2024d909\n  Kernel Version:             4.19.78-coreos\n  OS Image:                   Container Linux by CoreOS 2247.6.0 (Rhyolite)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.3\n  Kubelet Version:            v1.18.2\n  Kube-Proxy Version:         v1.18.2\nPodCIDR:                      100.64.1.0/24\nPodCIDRs:                     100.64.1.0/24\nProviderID:                   eu-central-1.i-gw82palggheybhhd1s46\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                   CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                   ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-bfbll                                      250m (13%)    800m (41%)  100Mi (1%)       700Mi (10%)    22m\n  kube-system                 calico-node-vertical-autoscaler-74d4897db8-9bzm5       10m (0%)      10m (0%)    50Mi (0%)        50Mi (0%)      26m\n  kube-system                 calico-typha-deploy-784665cc66-hqzfs                   200m (10%)    500m (26%)  100Mi (1%)       700Mi (10%)    26m\n  kube-system                 calico-typha-horizontal-autoscaler-6fdd5d8746-2w9c9    10m (0%)      10m (0%)    50Mi (0%)        50Mi (0%)      26m\n  kube-system                 csi-disk-plugin-alicloud-hzxms                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         25m\n  kube-system                 kube-proxy-r447h                                       20m (1%)      0 (0%)      64Mi (0%)        0 (0%)         25m\n  kube-system                 node-exporter-k58cv                                    5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     25m\n  kube-system                 node-problem-detector-m6qcf                            20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     25m\n  kubectl-8194                agnhost-master-dclvv                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                515m (26%)  1545m (80%)\n  memory             394Mi (6%)  1700Mi (25%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From                                      Message\n  ----     ------                   ----               ----                                      -------\n  Normal   Starting                 25m                kubelet, izgw82palggheybhhd1s46z          Starting kubelet.\n  Normal   NodeHasSufficientMemory  25m                kubelet, izgw82palggheybhhd1s46z          Node izgw82palggheybhhd1s46z status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    25m                kubelet, izgw82palggheybhhd1s46z          Node izgw82palggheybhhd1s46z status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     25m                kubelet, izgw82palggheybhhd1s46z          Node izgw82palggheybhhd1s46z status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  25m                kubelet, izgw82palggheybhhd1s46z          Updated Node Allocatable limit across pods\n  Normal   NodeReady                24m                kubelet, izgw82palggheybhhd1s46z          Node izgw82palggheybhhd1s46z status is now: NodeReady\n  Normal   Starting                 24m                kube-proxy, izgw82palggheybhhd1s46z       Starting kube-proxy.\n  Warning  DockerStart              24m (x2 over 24m)  systemd-monitor, izgw82palggheybhhd1s46z  Starting Docker Application Container Engine...\n"
Apr 27 16:18:49.879: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-8194'
Apr 27 16:18:50.039: INFO: stderr: ""
Apr 27 16:18:50.039: INFO: stdout: "Name:         kubectl-8194\nLabels:       e2e-framework=kubectl\n              e2e-run=45bd2b45-dba0-4fb7-82c0-cc3940290997\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:50.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8194" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":277,"completed":25,"skipped":473,"failed":0}
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:50.052: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:18:50.211: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:18:53.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1799" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":277,"completed":26,"skipped":476,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:18:53.098: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6465.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6465.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6465.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6465.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6465.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6465.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:19:11.849: INFO: DNS probes using dns-6465/dns-test-2a26f947-00de-4aee-834f-d18e061336c3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:11.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6465" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":277,"completed":27,"skipped":488,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:11.870: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Apr 27 16:19:12.114: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Apr 27 16:19:12.231: INFO: stderr: ""
Apr 27 16:19:12.231: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:12.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3865" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":277,"completed":28,"skipped":500,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:12.242: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-ec677852-957a-42d6-8506-1622516d86d1
STEP: Creating secret with name secret-projected-all-test-volume-23ac9325-d0ce-4b95-895d-c777463d260e
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 27 16:19:12.407: INFO: Waiting up to 5m0s for pod "projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778" in namespace "projected-2962" to be "Succeeded or Failed"
Apr 27 16:19:12.411: INFO: Pod "projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778": Phase="Pending", Reason="", readiness=false. Elapsed: 4.732987ms
Apr 27 16:19:14.416: INFO: Pod "projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009712031s
STEP: Saw pod success
Apr 27 16:19:14.416: INFO: Pod "projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778" satisfied condition "Succeeded or Failed"
Apr 27 16:19:14.421: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 27 16:19:14.441: INFO: Waiting for pod projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778 to disappear
Apr 27 16:19:14.446: INFO: Pod projected-volume-08a29ac5-fc3a-4801-a5ca-d5874dc61778 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:14.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2962" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":277,"completed":29,"skipped":512,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:14.458: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-621
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:14.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-621" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":277,"completed":30,"skipped":524,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:14.644: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:19:14.798: INFO: Waiting up to 5m0s for pod "downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea" in namespace "downward-api-5325" to be "Succeeded or Failed"
Apr 27 16:19:14.802: INFO: Pod "downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.78451ms
Apr 27 16:19:16.807: INFO: Pod "downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008849941s
STEP: Saw pod success
Apr 27 16:19:16.807: INFO: Pod "downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea" satisfied condition "Succeeded or Failed"
Apr 27 16:19:16.811: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:19:16.834: INFO: Waiting for pod downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea to disappear
Apr 27 16:19:16.838: INFO: Pod downward-api-8c64908f-3f3f-427a-bdd8-a8313e05b5ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:16.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5325" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":277,"completed":31,"skipped":543,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:16.851: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-894
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr 27 16:19:16.998: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr 27 16:19:30.350: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:19:33.849: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:46.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-894" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":277,"completed":32,"skipped":551,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:46.296: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3330
STEP: Creating secret with name secret-test-682bcbbd-5950-4768-a540-99007c7d54ac
STEP: Creating a pod to test consume secrets
Apr 27 16:19:46.610: INFO: Waiting up to 5m0s for pod "pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2" in namespace "secrets-6371" to be "Succeeded or Failed"
Apr 27 16:19:46.614: INFO: Pod "pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.950637ms
Apr 27 16:19:48.619: INFO: Pod "pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008859591s
STEP: Saw pod success
Apr 27 16:19:48.619: INFO: Pod "pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2" satisfied condition "Succeeded or Failed"
Apr 27 16:19:48.623: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:19:48.645: INFO: Waiting for pod pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2 to disappear
Apr 27 16:19:48.649: INFO: Pod pod-secrets-5e3e184b-318b-4fcf-b30c-33433257a2f2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:19:48.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6371" for this suite.
STEP: Destroying namespace "secret-namespace-3330" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":277,"completed":33,"skipped":570,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:19:48.666: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-170
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-170
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-170
Apr 27 16:19:48.826: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:19:58.832: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 27 16:19:58.837: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:19:59.642: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:19:59.642: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:19:59.642: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:19:59.647: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:20:09.653: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:20:09.653: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:20:09.672: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:09.672: INFO: ss-0  izgw82palggheybhhd1s46z  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:09.672: INFO: 
Apr 27 16:20:09.672: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 27 16:20:10.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995319957s
Apr 27 16:20:11.684: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989521023s
Apr 27 16:20:12.690: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983722569s
Apr 27 16:20:13.695: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977850285s
Apr 27 16:20:14.701: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97187759s
Apr 27 16:20:15.708: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966100604s
Apr 27 16:20:16.713: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.959834163s
Apr 27 16:20:17.719: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953983169s
Apr 27 16:20:18.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.27916ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-170
Apr 27 16:20:19.731: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:20:20.253: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:20:20.253: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:20:20.253: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:20:20.253: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:20:20.778: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 16:20:20.778: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:20:20.778: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:20:20.778: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:20:26.270: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 27 16:20:26.270: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:20:26.270: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:20:26.275: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:20:26.275: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:20:26.275: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 27 16:20:26.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:20:26.829: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:20:26.829: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:20:26.829: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:20:26.829: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:20:27.405: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:20:27.406: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:20:27.406: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:20:27.406: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-170 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:20:27.902: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:20:27.902: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:20:27.902: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:20:27.902: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:20:27.907: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 27 16:20:37.918: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:20:37.918: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:20:37.918: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:20:37.933: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:37.933: INFO: ss-0  izgw82palggheybhhd1s46z  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:37.933: INFO: ss-1  izgw873bmqhhfhflh483llz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:37.933: INFO: ss-2  izgw82palggheybhhd1s46z  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:37.933: INFO: 
Apr 27 16:20:37.933: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:20:38.939: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:38.939: INFO: ss-0  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:38.939: INFO: ss-1  izgw873bmqhhfhflh483llz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:38.939: INFO: ss-2  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:38.939: INFO: 
Apr 27 16:20:38.939: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 27 16:20:39.945: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:39.945: INFO: ss-0  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:39.945: INFO: ss-2  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:39.945: INFO: 
Apr 27 16:20:39.945: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 27 16:20:40.950: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:40.950: INFO: ss-0  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:40.950: INFO: ss-2  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:40.950: INFO: 
Apr 27 16:20:40.950: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 27 16:20:41.956: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:41.956: INFO: ss-0  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:41.956: INFO: ss-2  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:41.956: INFO: 
Apr 27 16:20:41.956: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 27 16:20:42.961: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:42.961: INFO: ss-0  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:42.961: INFO: ss-2  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:42.961: INFO: 
Apr 27 16:20:42.961: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 27 16:20:43.967: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Apr 27 16:20:43.967: INFO: ss-0  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:19:48 +0000 UTC  }]
Apr 27 16:20:43.967: INFO: ss-2  izgw82palggheybhhd1s46z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-27 16:20:09 +0000 UTC  }]
Apr 27 16:20:43.967: INFO: 
Apr 27 16:20:43.967: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 27 16:20:44.972: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.960670328s
Apr 27 16:20:45.977: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.955333485s
Apr 27 16:20:46.982: INFO: Verifying statefulset ss doesn't scale past 0 for another 950.494249ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-170
Apr 27 16:20:47.988: INFO: Scaling statefulset ss to 0
Apr 27 16:20:48.003: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:20:48.007: INFO: Deleting all statefulset in ns statefulset-170
Apr 27 16:20:48.012: INFO: Scaling statefulset ss to 0
Apr 27 16:20:48.026: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:20:48.030: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:20:48.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-170" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":277,"completed":34,"skipped":571,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:20:48.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:20:48.247: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:20:50.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:20:52.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:20:54.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:20:56.253: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:20:58.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:00.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:02.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:04.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:06.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:08.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:10.252: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:12.253: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = false)
Apr 27 16:21:14.253: INFO: The status of Pod test-webserver-dbddb2d9-735a-4b53-9311-6ac7535fcb54 is Running (Ready = true)
Apr 27 16:21:14.257: INFO: Container started at 2020-04-27 16:20:49 +0000 UTC, pod became ready at 2020-04-27 16:21:13 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:14.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1161" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":277,"completed":35,"skipped":578,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:14.272: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d
Apr 27 16:21:14.431: INFO: Pod name my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d: Found 0 pods out of 1
Apr 27 16:21:19.436: INFO: Pod name my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d: Found 1 pods out of 1
Apr 27 16:21:19.436: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d" are running
Apr 27 16:21:19.440: INFO: Pod "my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d-wbcj5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:21:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:21:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:21:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 16:21:14 +0000 UTC Reason: Message:}])
Apr 27 16:21:19.440: INFO: Trying to dial the pod
Apr 27 16:21:24.544: INFO: Controller my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d: Got expected result from replica 1 [my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d-wbcj5]: "my-hostname-basic-20f49944-b826-4ef6-a62b-b39c8c9b292d-wbcj5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:24.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8059" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":36,"skipped":644,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:24.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:21:24.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95" in namespace "downward-api-7270" to be "Succeeded or Failed"
Apr 27 16:21:24.745: INFO: Pod "downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95": Phase="Pending", Reason="", readiness=false. Elapsed: 4.371513ms
Apr 27 16:21:26.750: INFO: Pod "downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009725573s
Apr 27 16:21:28.755: INFO: Pod "downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014915315s
STEP: Saw pod success
Apr 27 16:21:28.755: INFO: Pod "downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95" satisfied condition "Succeeded or Failed"
Apr 27 16:21:28.759: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95 container client-container: <nil>
STEP: delete the pod
Apr 27 16:21:28.876: INFO: Waiting for pod downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95 to disappear
Apr 27 16:21:28.880: INFO: Pod downwardapi-volume-d9102e83-ae12-4564-8bdc-afcf1c153d95 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:28.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7270" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":37,"skipped":667,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:28.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1247
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 27 16:21:29.046: INFO: Waiting up to 5m0s for pod "pod-675ec035-3c35-428b-92f9-506e828f0800" in namespace "emptydir-1247" to be "Succeeded or Failed"
Apr 27 16:21:29.051: INFO: Pod "pod-675ec035-3c35-428b-92f9-506e828f0800": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125883ms
Apr 27 16:21:31.056: INFO: Pod "pod-675ec035-3c35-428b-92f9-506e828f0800": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009483572s
STEP: Saw pod success
Apr 27 16:21:31.056: INFO: Pod "pod-675ec035-3c35-428b-92f9-506e828f0800" satisfied condition "Succeeded or Failed"
Apr 27 16:21:31.060: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-675ec035-3c35-428b-92f9-506e828f0800 container test-container: <nil>
STEP: delete the pod
Apr 27 16:21:31.082: INFO: Waiting for pod pod-675ec035-3c35-428b-92f9-506e828f0800 to disappear
Apr 27 16:21:31.086: INFO: Pod pod-675ec035-3c35-428b-92f9-506e828f0800 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:31.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1247" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":38,"skipped":684,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:31.099: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Apr 27 16:21:31.247: INFO: namespace kubectl-3564
Apr 27 16:21:31.247: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3564'
Apr 27 16:21:31.520: INFO: stderr: ""
Apr 27 16:21:31.520: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Apr 27 16:21:32.525: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:21:32.525: INFO: Found 0 / 1
Apr 27 16:21:33.526: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:21:33.526: INFO: Found 1 / 1
Apr 27 16:21:33.526: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 27 16:21:33.531: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 27 16:21:33.531: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 27 16:21:33.531: INFO: wait on agnhost-master startup in kubectl-3564 
Apr 27 16:21:33.531: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs agnhost-master-vw4sg agnhost-master --namespace=kubectl-3564'
Apr 27 16:21:33.722: INFO: stderr: ""
Apr 27 16:21:33.722: INFO: stdout: "Paused\n"
STEP: exposing RC
Apr 27 16:21:33.722: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3564'
Apr 27 16:21:33.823: INFO: stderr: ""
Apr 27 16:21:33.823: INFO: stdout: "service/rm2 exposed\n"
Apr 27 16:21:33.828: INFO: Service rm2 in namespace kubectl-3564 found.
STEP: exposing service
Apr 27 16:21:35.836: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3564'
Apr 27 16:21:35.977: INFO: stderr: ""
Apr 27 16:21:35.977: INFO: stdout: "service/rm3 exposed\n"
Apr 27 16:21:35.981: INFO: Service rm3 in namespace kubectl-3564 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:21:37.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3564" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":277,"completed":39,"skipped":696,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:21:38.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1475
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-d562
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:21:38.183: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-d562" in namespace "subpath-1475" to be "Succeeded or Failed"
Apr 27 16:21:38.187: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943691ms
Apr 27 16:21:40.192: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 2.009062788s
Apr 27 16:21:42.197: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 4.01423288s
Apr 27 16:21:44.202: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 6.019121564s
Apr 27 16:21:46.208: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 8.02561007s
Apr 27 16:21:48.213: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 10.030351176s
Apr 27 16:21:50.218: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 12.035601926s
Apr 27 16:21:52.224: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 14.040929666s
Apr 27 16:21:54.229: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 16.046775475s
Apr 27 16:21:56.235: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 18.051953175s
Apr 27 16:21:58.240: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Running", Reason="", readiness=true. Elapsed: 20.057080253s
Apr 27 16:22:00.245: INFO: Pod "pod-subpath-test-configmap-d562": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.062741629s
STEP: Saw pod success
Apr 27 16:22:00.245: INFO: Pod "pod-subpath-test-configmap-d562" satisfied condition "Succeeded or Failed"
Apr 27 16:22:00.250: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-subpath-test-configmap-d562 container test-container-subpath-configmap-d562: <nil>
STEP: delete the pod
Apr 27 16:22:00.273: INFO: Waiting for pod pod-subpath-test-configmap-d562 to disappear
Apr 27 16:22:00.277: INFO: Pod pod-subpath-test-configmap-d562 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-d562
Apr 27 16:22:00.277: INFO: Deleting pod "pod-subpath-test-configmap-d562" in namespace "subpath-1475"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:00.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1475" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":277,"completed":40,"skipped":749,"failed":0}
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:00.294: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-8660
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8660 to expose endpoints map[]
Apr 27 16:22:00.456: INFO: successfully validated that service multi-endpoint-test in namespace services-8660 exposes endpoints map[] (4.182278ms elapsed)
STEP: Creating pod pod1 in namespace services-8660
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8660 to expose endpoints map[pod1:[100]]
Apr 27 16:22:02.490: INFO: successfully validated that service multi-endpoint-test in namespace services-8660 exposes endpoints map[pod1:[100]] (2.027386349s elapsed)
STEP: Creating pod pod2 in namespace services-8660
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8660 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 27 16:22:06.566: INFO: Unexpected endpoints: found map[0cfaafe1-73d1-44c9-a7ef-9793dc058041:[100]], expected map[pod1:[100] pod2:[101]] (4.068833524s elapsed, will retry)
Apr 27 16:22:10.621: INFO: successfully validated that service multi-endpoint-test in namespace services-8660 exposes endpoints map[pod1:[100] pod2:[101]] (8.124469801s elapsed)
STEP: Deleting pod pod1 in namespace services-8660
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8660 to expose endpoints map[pod2:[101]]
Apr 27 16:22:10.636: INFO: successfully validated that service multi-endpoint-test in namespace services-8660 exposes endpoints map[pod2:[101]] (8.546941ms elapsed)
STEP: Deleting pod pod2 in namespace services-8660
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8660 to expose endpoints map[]
Apr 27 16:22:10.646: INFO: successfully validated that service multi-endpoint-test in namespace services-8660 exposes endpoints map[] (4.187203ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:10.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8660" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":277,"completed":41,"skipped":750,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:10.671: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9691
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:22:10.819: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:12.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9691" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":277,"completed":42,"skipped":783,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:12.123: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:14.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6116" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":43,"skipped":822,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:14.369: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-5849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Apr 27 16:22:14.524: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Apr 27 16:22:15.094: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Apr 27 16:22:17.137: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:19.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:21.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:23.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:25.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:27.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:29.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:31.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:33.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601335, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:22:42.466: INFO: Waited 7.3174511s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:22:43.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5849" for this suite.
•{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":277,"completed":44,"skipped":832,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:22:43.250: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-6b374758-fd2c-4a0d-a140-e1e0681e06da in namespace container-probe-6511
Apr 27 16:22:45.437: INFO: Started pod liveness-6b374758-fd2c-4a0d-a140-e1e0681e06da in namespace container-probe-6511
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:22:45.442: INFO: Initial restart count of pod liveness-6b374758-fd2c-4a0d-a140-e1e0681e06da is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:46.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6511" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":277,"completed":45,"skipped":838,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:46.100: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5795
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:26:46.728: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:26:48.742: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601606, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601606, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601606, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601606, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:26:51.755: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:26:51.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3622-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:26:53.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5795" for this suite.
STEP: Destroying namespace "webhook-5795-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":277,"completed":46,"skipped":860,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:26:53.338: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 27 16:26:53.651: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6957 /api/v1/namespaces/watch-6957/configmaps/e2e-watch-test-label-changed a024e5d8-ed16-4ed5-98f1-cf8b82d9534e 11956 0 2020-04-27 16:26:53 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:26:53 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:26:53.651: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6957 /api/v1/namespaces/watch-6957/configmaps/e2e-watch-test-label-changed a024e5d8-ed16-4ed5-98f1-cf8b82d9534e 11957 0 2020-04-27 16:26:53 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:26:53 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:26:53.651: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6957 /api/v1/namespaces/watch-6957/configmaps/e2e-watch-test-label-changed a024e5d8-ed16-4ed5-98f1-cf8b82d9534e 11958 0 2020-04-27 16:26:53 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:26:53 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 27 16:27:03.686: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6957 /api/v1/namespaces/watch-6957/configmaps/e2e-watch-test-label-changed a024e5d8-ed16-4ed5-98f1-cf8b82d9534e 12011 0 2020-04-27 16:26:53 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:27:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:27:03.687: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6957 /api/v1/namespaces/watch-6957/configmaps/e2e-watch-test-label-changed a024e5d8-ed16-4ed5-98f1-cf8b82d9534e 12012 0 2020-04-27 16:26:53 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:27:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:27:03.687: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6957 /api/v1/namespaces/watch-6957/configmaps/e2e-watch-test-label-changed a024e5d8-ed16-4ed5-98f1-cf8b82d9534e 12013 0 2020-04-27 16:26:53 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-04-27 16:27:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:03.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6957" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":277,"completed":47,"skipped":869,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:03.699: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-56e0887e-01eb-4560-b7ec-edd65ef411f7
STEP: Creating a pod to test consume secrets
Apr 27 16:27:03.866: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393" in namespace "projected-7648" to be "Succeeded or Failed"
Apr 27 16:27:03.870: INFO: Pod "pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067309ms
Apr 27 16:27:05.875: INFO: Pod "pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009080661s
STEP: Saw pod success
Apr 27 16:27:05.875: INFO: Pod "pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393" satisfied condition "Succeeded or Failed"
Apr 27 16:27:05.879: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:27:05.995: INFO: Waiting for pod pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393 to disappear
Apr 27 16:27:05.999: INFO: Pod pod-projected-secrets-df0a0b39-db1e-4b53-9d37-c7892a211393 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:05.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7648" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":48,"skipped":873,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:06.012: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:08.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5257" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":277,"completed":49,"skipped":880,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:08.223: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:24.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4464" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":277,"completed":50,"skipped":902,"failed":0}

------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:24.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5653
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:24.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5653" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":277,"completed":51,"skipped":902,"failed":0}
S
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:24.599: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr 27 16:27:27.273: INFO: Successfully updated pod "adopt-release-gfpf2"
STEP: Checking that the Job readopts the Pod
Apr 27 16:27:27.274: INFO: Waiting up to 15m0s for pod "adopt-release-gfpf2" in namespace "job-1829" to be "adopted"
Apr 27 16:27:27.278: INFO: Pod "adopt-release-gfpf2": Phase="Running", Reason="", readiness=true. Elapsed: 3.927313ms
Apr 27 16:27:29.283: INFO: Pod "adopt-release-gfpf2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009393576s
Apr 27 16:27:29.283: INFO: Pod "adopt-release-gfpf2" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr 27 16:27:29.795: INFO: Successfully updated pod "adopt-release-gfpf2"
STEP: Checking that the Job releases the Pod
Apr 27 16:27:29.795: INFO: Waiting up to 15m0s for pod "adopt-release-gfpf2" in namespace "job-1829" to be "released"
Apr 27 16:27:29.799: INFO: Pod "adopt-release-gfpf2": Phase="Running", Reason="", readiness=true. Elapsed: 4.030982ms
Apr 27 16:27:31.804: INFO: Pod "adopt-release-gfpf2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009208231s
Apr 27 16:27:31.804: INFO: Pod "adopt-release-gfpf2" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:31.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1829" for this suite.
•{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":277,"completed":52,"skipped":903,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:31.817: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:43.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2243" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":277,"completed":53,"skipped":922,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:43.019: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:43.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9449" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":277,"completed":54,"skipped":933,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:43.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 16:27:49.871: INFO: Successfully updated pod "pod-update-11b5e83c-65e9-4a58-9728-a1410866b660"
STEP: verifying the updated pod is in kubernetes
Apr 27 16:27:49.879: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:49.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-516" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":277,"completed":55,"skipped":935,"failed":0}
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:49.891: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:27:52.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5205" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":277,"completed":56,"skipped":941,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:27:52.082: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9393
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:27:52.229: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:27:55.714: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9393 create -f -'
Apr 27 16:28:01.173: INFO: stderr: ""
Apr 27 16:28:01.173: INFO: stdout: "e2e-test-crd-publish-openapi-5610-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 16:28:01.173: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9393 delete e2e-test-crd-publish-openapi-5610-crds test-cr'
Apr 27 16:28:01.267: INFO: stderr: ""
Apr 27 16:28:01.267: INFO: stdout: "e2e-test-crd-publish-openapi-5610-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 27 16:28:01.267: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9393 apply -f -'
Apr 27 16:28:01.545: INFO: stderr: ""
Apr 27 16:28:01.546: INFO: stdout: "e2e-test-crd-publish-openapi-5610-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 27 16:28:01.546: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9393 delete e2e-test-crd-publish-openapi-5610-crds test-cr'
Apr 27 16:28:01.633: INFO: stderr: ""
Apr 27 16:28:01.633: INFO: stdout: "e2e-test-crd-publish-openapi-5610-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr 27 16:28:01.633: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-5610-crds'
Apr 27 16:28:01.794: INFO: stderr: ""
Apr 27 16:28:01.794: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5610-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:05.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9393" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":277,"completed":57,"skipped":967,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:05.301: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:28:07.486: INFO: Waiting up to 5m0s for pod "client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e" in namespace "pods-7618" to be "Succeeded or Failed"
Apr 27 16:28:07.491: INFO: Pod "client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.19951ms
Apr 27 16:28:09.497: INFO: Pod "client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010373595s
Apr 27 16:28:11.502: INFO: Pod "client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e": Phase="Running", Reason="", readiness=true. Elapsed: 4.015797276s
Apr 27 16:28:13.507: INFO: Pod "client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020867007s
STEP: Saw pod success
Apr 27 16:28:13.507: INFO: Pod "client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e" satisfied condition "Succeeded or Failed"
Apr 27 16:28:13.512: INFO: Trying to get logs from node izgw873bmqhhfhflh483llz pod client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e container env3cont: <nil>
STEP: delete the pod
Apr 27 16:28:13.536: INFO: Waiting for pod client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e to disappear
Apr 27 16:28:13.541: INFO: Pod client-envvars-df70ac1c-11c3-4b8e-82ce-a0dc84ffa00e no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:13.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7618" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":277,"completed":58,"skipped":1013,"failed":0}

------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:13.553: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5077
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Apr 27 16:28:13.709: INFO: Waiting up to 5m0s for pod "var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963" in namespace "var-expansion-5077" to be "Succeeded or Failed"
Apr 27 16:28:13.713: INFO: Pod "var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075673ms
Apr 27 16:28:15.718: INFO: Pod "var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009234998s
STEP: Saw pod success
Apr 27 16:28:15.718: INFO: Pod "var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963" satisfied condition "Succeeded or Failed"
Apr 27 16:28:15.722: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:28:15.742: INFO: Waiting for pod var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963 to disappear
Apr 27 16:28:15.746: INFO: Pod var-expansion-0bbefc92-f65d-4cb7-9bff-fe0563dc6963 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:15.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5077" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":277,"completed":59,"skipped":1013,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:15.759: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Apr 27 16:28:15.906: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-5753 -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 27 16:28:15.997: INFO: stderr: ""
Apr 27 16:28:15.997: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Apr 27 16:28:15.997: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 27 16:28:15.997: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5753" to be "running and ready, or succeeded"
Apr 27 16:28:16.001: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126457ms
Apr 27 16:28:18.006: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009227831s
Apr 27 16:28:18.006: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 27 16:28:18.006: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr 27 16:28:18.006: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-5753'
Apr 27 16:28:18.110: INFO: stderr: ""
Apr 27 16:28:18.110: INFO: stdout: "I0427 16:28:16.816782       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/psx 517\nI0427 16:28:17.017004       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/m29t 559\nI0427 16:28:17.217095       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/ns7 215\nI0427 16:28:17.416958       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/2jv 215\nI0427 16:28:17.617106       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/724b 513\nI0427 16:28:17.817048       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/rd8 329\nI0427 16:28:18.016910       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/grt7 241\n"
STEP: limiting log lines
Apr 27 16:28:18.110: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-5753 --tail=1'
Apr 27 16:28:23.215: INFO: stderr: ""
Apr 27 16:28:23.215: INFO: stdout: "I0427 16:28:23.017018       1 logs_generator.go:76] 31 PUT /api/v1/namespaces/ns/pods/jtc 311\n"
Apr 27 16:28:23.215: INFO: got output "I0427 16:28:23.017018       1 logs_generator.go:76] 31 PUT /api/v1/namespaces/ns/pods/jtc 311\n"
STEP: limiting log bytes
Apr 27 16:28:23.215: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-5753 --limit-bytes=1'
Apr 27 16:28:23.309: INFO: stderr: ""
Apr 27 16:28:23.309: INFO: stdout: "I"
Apr 27 16:28:23.309: INFO: got output "I"
STEP: exposing timestamps
Apr 27 16:28:23.309: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-5753 --tail=1 --timestamps'
Apr 27 16:28:23.404: INFO: stderr: ""
Apr 27 16:28:23.404: INFO: stdout: "2020-04-27T16:28:23.217018045Z I0427 16:28:23.216913       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/fxqd 322\n"
Apr 27 16:28:23.404: INFO: got output "2020-04-27T16:28:23.217018045Z I0427 16:28:23.216913       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/fxqd 322\n"
STEP: restricting to a time range
Apr 27 16:28:25.904: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-5753 --since=1s'
Apr 27 16:28:26.064: INFO: stderr: ""
Apr 27 16:28:26.064: INFO: stdout: "I0427 16:28:25.216921       1 logs_generator.go:76] 42 PUT /api/v1/namespaces/kube-system/pods/xmm 576\nI0427 16:28:25.416943       1 logs_generator.go:76] 43 GET /api/v1/namespaces/kube-system/pods/t4wt 565\nI0427 16:28:25.616922       1 logs_generator.go:76] 44 PUT /api/v1/namespaces/default/pods/mvh 229\nI0427 16:28:25.816910       1 logs_generator.go:76] 45 GET /api/v1/namespaces/default/pods/wm6 499\nI0427 16:28:26.016913       1 logs_generator.go:76] 46 GET /api/v1/namespaces/ns/pods/84ql 267\n"
Apr 27 16:28:26.064: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-5753 --since=24h'
Apr 27 16:28:26.165: INFO: stderr: ""
Apr 27 16:28:26.165: INFO: stdout: "I0427 16:28:16.816782       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/psx 517\nI0427 16:28:17.017004       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/m29t 559\nI0427 16:28:17.217095       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/ns7 215\nI0427 16:28:17.416958       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/2jv 215\nI0427 16:28:17.617106       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/724b 513\nI0427 16:28:17.817048       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/rd8 329\nI0427 16:28:18.016910       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/grt7 241\nI0427 16:28:18.216918       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/7sj 489\nI0427 16:28:18.416920       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/bpnn 264\nI0427 16:28:18.617046       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/gv6x 265\nI0427 16:28:18.816954       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/s68g 579\nI0427 16:28:19.016909       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/hd6 421\nI0427 16:28:19.216915       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/tqh 461\nI0427 16:28:19.416918       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/t9w5 574\nI0427 16:28:19.616913       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/zxck 499\nI0427 16:28:19.816971       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/t2vt 404\nI0427 16:28:20.016921       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/l88 475\nI0427 16:28:20.216920       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/jnsv 409\nI0427 16:28:20.417020       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/xk4 333\nI0427 16:28:20.616917       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/kwh 279\nI0427 16:28:20.816990       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/6gk9 454\nI0427 16:28:21.016962       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/hml 386\nI0427 16:28:21.216909       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/fwf 284\nI0427 16:28:21.416912       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/6pb 370\nI0427 16:28:21.616941       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/mqt 578\nI0427 16:28:21.816902       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/default/pods/ptg9 366\nI0427 16:28:22.016908       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/8ws 379\nI0427 16:28:22.216910       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/tdk2 323\nI0427 16:28:22.417013       1 logs_generator.go:76] 28 GET /api/v1/namespaces/ns/pods/n4zx 439\nI0427 16:28:22.616914       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/default/pods/8lc 422\nI0427 16:28:22.816908       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/kube-system/pods/v7l 318\nI0427 16:28:23.017018       1 logs_generator.go:76] 31 PUT /api/v1/namespaces/ns/pods/jtc 311\nI0427 16:28:23.216913       1 logs_generator.go:76] 32 POST /api/v1/namespaces/ns/pods/fxqd 322\nI0427 16:28:23.416908       1 logs_generator.go:76] 33 GET /api/v1/namespaces/kube-system/pods/s82 410\nI0427 16:28:23.616918       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/ns/pods/qnq 448\nI0427 16:28:23.816918       1 logs_generator.go:76] 35 PUT /api/v1/namespaces/kube-system/pods/94n 510\nI0427 16:28:24.016956       1 logs_generator.go:76] 36 GET /api/v1/namespaces/default/pods/gqs 463\nI0427 16:28:24.216916       1 logs_generator.go:76] 37 POST /api/v1/namespaces/default/pods/m9hk 595\nI0427 16:28:24.416920       1 logs_generator.go:76] 38 GET /api/v1/namespaces/kube-system/pods/g4f 533\nI0427 16:28:24.616916       1 logs_generator.go:76] 39 PUT /api/v1/namespaces/ns/pods/xcgm 544\nI0427 16:28:24.816916       1 logs_generator.go:76] 40 GET /api/v1/namespaces/kube-system/pods/bcb 546\nI0427 16:28:25.016957       1 logs_generator.go:76] 41 POST /api/v1/namespaces/kube-system/pods/t79n 572\nI0427 16:28:25.216921       1 logs_generator.go:76] 42 PUT /api/v1/namespaces/kube-system/pods/xmm 576\nI0427 16:28:25.416943       1 logs_generator.go:76] 43 GET /api/v1/namespaces/kube-system/pods/t4wt 565\nI0427 16:28:25.616922       1 logs_generator.go:76] 44 PUT /api/v1/namespaces/default/pods/mvh 229\nI0427 16:28:25.816910       1 logs_generator.go:76] 45 GET /api/v1/namespaces/default/pods/wm6 499\nI0427 16:28:26.016913       1 logs_generator.go:76] 46 GET /api/v1/namespaces/ns/pods/84ql 267\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Apr 27 16:28:26.165: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-5753'
Apr 27 16:28:34.900: INFO: stderr: ""
Apr 27 16:28:34.900: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:34.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5753" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":277,"completed":60,"skipped":1063,"failed":0}

------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:34.913: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1839
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-228e78e5-45ad-4132-9243-6d3a2009dcf4
STEP: Creating secret with name s-test-opt-upd-5a15e802-e2f8-4f15-9e4a-3943429479e5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-228e78e5-45ad-4132-9243-6d3a2009dcf4
STEP: Updating secret s-test-opt-upd-5a15e802-e2f8-4f15-9e4a-3943429479e5
STEP: Creating secret with name s-test-opt-create-9428a5b1-bb2b-4f9e-8a02-dacc065967b4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:41.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1839" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":61,"skipped":1063,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:41.509: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9050
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:28:41.664: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-98a923d5-58f7-44df-9fb7-89094d2a4507" in namespace "security-context-test-9050" to be "Succeeded or Failed"
Apr 27 16:28:41.670: INFO: Pod "alpine-nnp-false-98a923d5-58f7-44df-9fb7-89094d2a4507": Phase="Pending", Reason="", readiness=false. Elapsed: 5.600133ms
Apr 27 16:28:43.675: INFO: Pod "alpine-nnp-false-98a923d5-58f7-44df-9fb7-89094d2a4507": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011194373s
Apr 27 16:28:45.680: INFO: Pod "alpine-nnp-false-98a923d5-58f7-44df-9fb7-89094d2a4507": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016116642s
Apr 27 16:28:45.680: INFO: Pod "alpine-nnp-false-98a923d5-58f7-44df-9fb7-89094d2a4507" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:28:45.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9050" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":62,"skipped":1128,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:28:45.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5621
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:28:45.861: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:03.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5621" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":277,"completed":63,"skipped":1132,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:03.071: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:29:03.217: INFO: Creating deployment "webserver-deployment"
Apr 27 16:29:03.223: INFO: Waiting for observed generation 1
Apr 27 16:29:05.233: INFO: Waiting for all required pods to come up
Apr 27 16:29:05.241: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 27 16:29:07.255: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 27 16:29:07.263: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 27 16:29:07.272: INFO: Updating deployment webserver-deployment
Apr 27 16:29:07.272: INFO: Waiting for observed generation 2
Apr 27 16:29:09.281: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 27 16:29:09.285: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 27 16:29:09.289: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 16:29:09.301: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 27 16:29:09.301: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 27 16:29:09.305: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 27 16:29:09.312: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 27 16:29:09.312: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 27 16:29:09.321: INFO: Updating deployment webserver-deployment
Apr 27 16:29:09.321: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 27 16:29:09.328: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 27 16:29:09.332: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:29:09.341: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-557 /apis/apps/v1/namespaces/deployment-557/deployments/webserver-deployment 93b7a6cf-b060-4415-bbd6-2739599c57e3 13095 3 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00539d5d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-04-27 16:29:07 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 16:29:09 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 27 16:29:09.349: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-557 /apis/apps/v1/namespaces/deployment-557/replicasets/webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 13084 3 2020-04-27 16:29:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 93b7a6cf-b060-4415-bbd6-2739599c57e3 0xc00539db07 0xc00539db08}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 98 55 97 54 99 102 45 98 48 54 48 45 52 52 49 53 45 98 98 100 54 45 50 55 51 57 53 57 57 99 53 55 101 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00539db98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:29:09.349: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 27 16:29:09.349: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-557 /apis/apps/v1/namespaces/deployment-557/replicasets/webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 13083 3 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 93b7a6cf-b060-4415-bbd6-2739599c57e3 0xc00539dbf7 0xc00539dbf8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 51 98 55 97 54 99 102 45 98 48 54 48 45 52 52 49 53 45 98 98 100 54 45 50 55 51 57 53 57 57 99 53 55 101 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00539dc68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:29:09.361: INFO: Pod "webserver-deployment-6676bcd6d4-4rl4l" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-4rl4l webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-4rl4l a719ecea-be37-4d96-aafe-9b53ad1ec008 13077 0 2020-04-27 16:29:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.63/32 cni.projectcalico.org/podIPs:100.64.1.63/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eafc7 0xc0053eafc8}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:,StartTime:2020-04-27 16:29:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.362: INFO: Pod "webserver-deployment-6676bcd6d4-8d764" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-8d764 webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-8d764 7486042c-2c2e-4022-a706-9b8e17430557 13081 0 2020-04-27 16:29:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.64/32 cni.projectcalico.org/podIPs:100.64.1.64/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eb1f7 0xc0053eb1f8}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:,StartTime:2020-04-27 16:29:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.362: INFO: Pod "webserver-deployment-6676bcd6d4-gvw9r" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-gvw9r webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-gvw9r 2097d8f1-e686-4d7a-a795-5af790b5d189 13117 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eb407 0xc0053eb408}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.362: INFO: Pod "webserver-deployment-6676bcd6d4-hrbbh" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hrbbh webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-hrbbh 1483049a-3b4b-401b-92a3-702314e6c480 13091 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eb570 0xc0053eb571}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.362: INFO: Pod "webserver-deployment-6676bcd6d4-q8pv4" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-q8pv4 webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-q8pv4 bc4e9a91-301e-4642-883c-70775ea07256 13066 0 2020-04-27 16:29:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.0.23/32 cni.projectcalico.org/podIPs:100.64.0.23/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eb6e0 0xc0053eb6e1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.185,PodIP:,StartTime:2020-04-27 16:29:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.362: INFO: Pod "webserver-deployment-6676bcd6d4-stbmt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-stbmt webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-stbmt 95d274c0-f5ea-4333-bbae-53bc46f12716 13102 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eb897 0xc0053eb898}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.362: INFO: Pod "webserver-deployment-6676bcd6d4-v76lk" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-v76lk webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-v76lk 592a7e4c-af16-4ed0-8bc6-ce6debf38168 13076 0 2020-04-27 16:29:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.1.62/32 cni.projectcalico.org/podIPs:100.64.1.62/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053eb9e0 0xc0053eb9e1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:,StartTime:2020-04-27 16:29:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.363: INFO: Pod "webserver-deployment-6676bcd6d4-vvgnp" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vvgnp webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-vvgnp 7ec44898-1b49-47e7-8c14-1602917be627 13100 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053ebbe7 0xc0053ebbe8}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.363: INFO: Pod "webserver-deployment-6676bcd6d4-wkpsh" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-wkpsh webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-wkpsh f3a4f599-3118-47fa-a7a0-115e423246e7 13115 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053ebd30 0xc0053ebd31}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.363: INFO: Pod "webserver-deployment-6676bcd6d4-wp857" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-wp857 webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-wp857 10271051-4e16-40b1-acff-6d1fa3a46166 13105 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053ebe60 0xc0053ebe61}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.363: INFO: Pod "webserver-deployment-6676bcd6d4-xflrv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-xflrv webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-xflrv 62cad204-4785-43a2-a8e0-821419ac10fd 13068 0 2020-04-27 16:29:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:100.64.0.24/32 cni.projectcalico.org/podIPs:100.64.0.24/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0053ebf97 0xc0053ebf98}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:08 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.185,PodIP:,StartTime:2020-04-27 16:29:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.363: INFO: Pod "webserver-deployment-6676bcd6d4-xjz8t" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-xjz8t webserver-deployment-6676bcd6d4- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-6676bcd6d4-xjz8t da58378a-6917-4112-a8cb-3615913c4954 13118 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 3bea496d-b103-4e7f-95d2-21717eecc7d9 0xc0054d4147 0xc0054d4148}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 98 101 97 52 57 54 100 45 98 49 48 51 45 52 101 55 102 45 57 53 100 50 45 50 49 55 49 55 101 101 99 99 55 100 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.363: INFO: Pod "webserver-deployment-84855cf797-29v9b" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-29v9b webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-29v9b 15a9b4c5-7b56-435b-8465-f55eb7eecc6f 13092 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d4280 0xc0054d4281}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.364: INFO: Pod "webserver-deployment-84855cf797-2h8qm" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2h8qm webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-2h8qm f0865ffc-e8b1-45a5-a176-334ee8f9a97f 13000 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.58/32 cni.projectcalico.org/podIPs:100.64.1.58/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d43c0 0xc0054d43c1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.58,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://97ee1552c8e374dc726b6da36724ef39b0b3b0240517260be14c51d9d1adc6f2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.364: INFO: Pod "webserver-deployment-84855cf797-6gd7d" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6gd7d webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-6gd7d 7ea0d302-f506-4140-b915-4e04f1a8a3b8 12995 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.21/32 cni.projectcalico.org/podIPs:100.64.0.21/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d4590 0xc0054d4591}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.185,PodIP:100.64.0.21,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b865231a8c1904d3b79d76e113d45e7dc459f50be8ef36b1978257b39d17d4f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.364: INFO: Pod "webserver-deployment-84855cf797-92hj6" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-92hj6 webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-92hj6 2e789746-1373-46e6-8023-cb2141d3bc75 13103 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d47a0 0xc0054d47a1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.364: INFO: Pod "webserver-deployment-84855cf797-b4nsn" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-b4nsn webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-b4nsn fc6f4f19-c1fa-405a-a2e8-81dfb9ab354b 13113 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d48c0 0xc0054d48c1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.364: INFO: Pod "webserver-deployment-84855cf797-dhxrv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dhxrv webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-dhxrv 531b4372-3e60-4249-914a-c9636596f4f2 13109 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d4a27 0xc0054d4a28}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.364: INFO: Pod "webserver-deployment-84855cf797-kqnhr" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-kqnhr webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-kqnhr b1f4e57b-83c9-4a6b-a42e-74f0acade056 12992 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.20/32 cni.projectcalico.org/podIPs:100.64.0.20/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d4b97 0xc0054d4b98}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 50 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.185,PodIP:100.64.0.20,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fb1cba0b0b81ee4b4c4fa6e6d8cc46dbaddfb8cebdbb16bd0e02014e1b9b0ab8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-kt99w" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-kt99w webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-kt99w 2e2020e4-f505-49de-8f7b-06d858b76421 13088 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d4db0 0xc0054d4db1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-l9xx9" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-l9xx9 webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-l9xx9 7bd6a9dc-7784-4d34-bfaf-2387110c4407 13116 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d4ef0 0xc0054d4ef1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-ljvf8" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-ljvf8 webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-ljvf8 2680e81e-3369-4e47-b3aa-49a836e34dfc 13098 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d5077 0xc0054d5078}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-nsnx4" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-nsnx4 webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-nsnx4 224ea551-d9ab-4100-b3ca-4d939230fe74 13013 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.60/32 cni.projectcalico.org/podIPs:100.64.1.60/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d51d0 0xc0054d51d1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 54 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.60,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a513b759c815b895f6360a0447be0123efc492df6f7521e7954607b4937a782f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-qbfdp" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qbfdp webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-qbfdp 26dcb092-210e-4b5f-a991-8c6015db9126 13112 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d53f0 0xc0054d53f1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-qptm7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-qptm7 webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-qptm7 db5c9ce8-a13a-4922-b8be-963911d747ca 13108 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d5507 0xc0054d5508}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.365: INFO: Pod "webserver-deployment-84855cf797-rq2vc" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rq2vc webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-rq2vc 29d56a1c-2f4d-4cae-9106-2097a56af93d 13110 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d5690 0xc0054d5691}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.366: INFO: Pod "webserver-deployment-84855cf797-tb5dp" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-tb5dp webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-tb5dp 6a75207b-ba92-48bd-9ded-8f5516e777c2 13016 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.57/32 cni.projectcalico.org/podIPs:100.64.1.57/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d57b7 0xc0054d57b8}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 53 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.57,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6c38b8fe1de061efd945628cc509114a31aacbe6dc1eb6b8c2f1e50dbd4ab9bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.366: INFO: Pod "webserver-deployment-84855cf797-thndt" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-thndt webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-thndt 3adcc4fd-8d08-415c-bf04-668c4dca8d38 12989 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.0.22/32 cni.projectcalico.org/podIPs:100.64.0.22/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d5a30 0xc0054d5a31}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 48 46 50 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.185,PodIP:100.64.0.22,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9095649edf25e0eca1b941989e8af07ed79d1ed014bc59f4f1aa8055d89af340,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.22,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.366: INFO: Pod "webserver-deployment-84855cf797-vc4m7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-vc4m7 webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-vc4m7 cecc8c99-5217-4b9a-b29d-b62a3bc24d1b 13111 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d5c30 0xc0054d5c31}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.366: INFO: Pod "webserver-deployment-84855cf797-x9l5l" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-x9l5l webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-x9l5l 660a823c-e20b-49a2-af22-5d577737a650 13010 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.59/32 cni.projectcalico.org/podIPs:100.64.1.59/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054d5df0 0xc0054d5df1}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 53 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.59,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3dc1270489519b9b9b7409ec5e585a46f61eaef59b0af5a50c09d50b6e7eefc9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.366: INFO: Pod "webserver-deployment-84855cf797-xwn6s" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xwn6s webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-xwn6s c127b507-bcc3-4d62-8324-a69c619bf6e4 13020 0 2020-04-27 16:29:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:100.64.1.55/32 cni.projectcalico.org/podIPs:100.64.1.55/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054fa010 0xc0054fa011}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 53 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.55,StartTime:2020-04-27 16:29:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6c985937025477d6c8ff57fe23450ca9c89bb78941f28b765e1810122a27837f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.55,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:29:09.366: INFO: Pod "webserver-deployment-84855cf797-zrktx" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zrktx webserver-deployment-84855cf797- deployment-557 /api/v1/namespaces/deployment-557/pods/webserver-deployment-84855cf797-zrktx 96cca324-f72e-46d0-97c8-919f00410a5e 13114 0 2020-04-27 16:29:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 04393ae6-bf5e-41dd-a465-4e2f870f949b 0xc0054fa220 0xc0054fa221}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 51 57 51 97 101 54 45 98 102 53 101 45 52 49 100 100 45 97 52 54 53 45 52 101 50 102 56 55 48 102 57 52 57 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rsck7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rsck7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rsck7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw873bmqhhfhflh483llz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:09.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-557" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":277,"completed":64,"skipped":1164,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:09.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-de0511bd-5d7c-4de6-97a4-c6620a36433e
STEP: Creating a pod to test consume configMaps
Apr 27 16:29:09.558: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983" in namespace "projected-8239" to be "Succeeded or Failed"
Apr 27 16:29:09.564: INFO: Pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983": Phase="Pending", Reason="", readiness=false. Elapsed: 5.9637ms
Apr 27 16:29:11.569: INFO: Pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010482388s
Apr 27 16:29:13.573: INFO: Pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015247805s
Apr 27 16:29:15.579: INFO: Pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020830939s
Apr 27 16:29:17.584: INFO: Pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.025772743s
STEP: Saw pod success
Apr 27 16:29:17.584: INFO: Pod "pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983" satisfied condition "Succeeded or Failed"
Apr 27 16:29:17.588: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:29:17.697: INFO: Waiting for pod pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983 to disappear
Apr 27 16:29:17.701: INFO: Pod pod-projected-configmaps-0bb408a4-4285-4266-8b42-63d97870f983 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:17.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8239" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":65,"skipped":1181,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:17.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:23.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3987" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":277,"completed":66,"skipped":1194,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:23.084: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:29:23.242: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 27 16:29:28.247: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:29:28.247: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 27 16:29:30.253: INFO: Creating deployment "test-rollover-deployment"
Apr 27 16:29:30.262: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 27 16:29:32.271: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 27 16:29:32.280: INFO: Ensure that both replica sets have 1 created replica
Apr 27 16:29:32.288: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 27 16:29:32.297: INFO: Updating deployment test-rollover-deployment
Apr 27 16:29:32.297: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 27 16:29:34.307: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 27 16:29:34.316: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 27 16:29:34.325: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:29:34.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601774, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:29:36.335: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:29:36.335: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601774, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:29:38.339: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:29:38.339: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601774, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:29:40.336: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:29:40.336: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601774, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:29:42.336: INFO: all replica sets need to contain the pod-template-hash label
Apr 27 16:29:42.336: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601774, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723601770, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 27 16:29:44.335: INFO: 
Apr 27 16:29:44.335: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:29:44.348: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9679 /apis/apps/v1/namespaces/deployment-9679/deployments/test-rollover-deployment 1878d2c1-b38d-4916-95f6-6514685514bb 13579 2 2020-04-27 16:29:30 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:29:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:29:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005781778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:29:30 +0000 UTC,LastTransitionTime:2020-04-27 16:29:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-04-27 16:29:44 +0000 UTC,LastTransitionTime:2020-04-27 16:29:30 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:29:44.353: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-9679 /apis/apps/v1/namespaces/deployment-9679/replicasets/test-rollover-deployment-84f7f6f64b 8d1325e6-5bf0-42b5-b793-f3d275cbf91e 13572 2 2020-04-27 16:29:32 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 1878d2c1-b38d-4916-95f6-6514685514bb 0xc005781ef7 0xc005781ef8}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:29:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 56 55 56 100 50 99 49 45 98 51 56 100 45 52 57 49 54 45 57 53 102 54 45 54 53 49 52 54 56 53 53 49 52 98 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005781fa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:29:44.353: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 27 16:29:44.353: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9679 /apis/apps/v1/namespaces/deployment-9679/replicasets/test-rollover-controller 52491bfa-6bf7-40b7-b291-572aaf047813 13578 2 2020-04-27 16:29:23 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 1878d2c1-b38d-4916-95f6-6514685514bb 0xc005781c57 0xc005781c58}] []  [{e2e.test Update apps/v1 2020-04-27 16:29:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:29:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 56 55 56 100 50 99 49 45 98 51 56 100 45 52 57 49 54 45 57 53 102 54 45 54 53 49 52 54 56 53 53 49 52 98 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005781d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:29:44.353: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-9679 /apis/apps/v1/namespaces/deployment-9679/replicasets/test-rollover-deployment-5686c4cfd5 011598d6-dfb1-42d9-beee-13b407409ff4 13489 2 2020-04-27 16:29:30 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 1878d2c1-b38d-4916-95f6-6514685514bb 0xc005781d87 0xc005781d88}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:29:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 56 55 56 100 50 99 49 45 98 51 56 100 45 52 57 49 54 45 57 53 102 54 45 54 53 49 52 54 56 53 53 49 52 98 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005781e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:29:44.358: INFO: Pod "test-rollover-deployment-84f7f6f64b-pdfhj" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-pdfhj test-rollover-deployment-84f7f6f64b- deployment-9679 /api/v1/namespaces/deployment-9679/pods/test-rollover-deployment-84f7f6f64b-pdfhj cfb37803-e90b-4ddb-837b-0ffc0664f1b7 13503 0 2020-04-27 16:29:32 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:100.64.1.79/32 cni.projectcalico.org/podIPs:100.64.1.79/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b 8d1325e6-5bf0-42b5-b793-f3d275cbf91e 0xc0057cc647 0xc0057cc648}] []  [{kube-controller-manager Update v1 2020-04-27 16:29:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 100 49 51 50 53 101 54 45 53 98 102 48 45 52 50 98 53 45 98 55 57 51 45 102 51 100 50 55 53 99 98 102 57 49 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:29:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:29:34 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 55 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-m4xtk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-m4xtk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-m4xtk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:29:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.79,StartTime:2020-04-27 16:29:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:29:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://64b17b71032d6450f7fa2efbce26345e154ced2ca841f008c12c0dac5f3e7731,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:29:44.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9679" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":277,"completed":67,"skipped":1240,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:29:44.371: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 16:29:50.566: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:29:50.571: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:29:52.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:29:52.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:29:54.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:29:54.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:29:56.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:29:56.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:29:58.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:29:58.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:30:00.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:30:00.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:30:02.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:30:02.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:30:04.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:30:04.576: INFO: Pod pod-with-prestop-http-hook still exists
Apr 27 16:30:06.571: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 27 16:30:06.576: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:06.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6376" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":277,"completed":68,"skipped":1294,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:06.603: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9034
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 16:30:06.754: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9034'
Apr 27 16:30:06.979: INFO: stderr: ""
Apr 27 16:30:06.979: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:30:06.979: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:07.060: INFO: stderr: ""
Apr 27 16:30:07.060: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-cxtpf "
Apr 27 16:30:07.060: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:07.137: INFO: stderr: ""
Apr 27 16:30:07.137: INFO: stdout: ""
Apr 27 16:30:07.137: INFO: update-demo-nautilus-7s9zs is created but not running
Apr 27 16:30:12.137: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:12.218: INFO: stderr: ""
Apr 27 16:30:12.218: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-cxtpf "
Apr 27 16:30:12.219: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:12.304: INFO: stderr: ""
Apr 27 16:30:12.304: INFO: stdout: "true"
Apr 27 16:30:12.304: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:12.387: INFO: stderr: ""
Apr 27 16:30:12.387: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:12.387: INFO: validating pod update-demo-nautilus-7s9zs
Apr 27 16:30:12.482: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:12.482: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:12.482: INFO: update-demo-nautilus-7s9zs is verified up and running
Apr 27 16:30:12.482: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-cxtpf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:12.572: INFO: stderr: ""
Apr 27 16:30:12.573: INFO: stdout: "true"
Apr 27 16:30:12.573: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-cxtpf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:12.653: INFO: stderr: ""
Apr 27 16:30:12.653: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:12.653: INFO: validating pod update-demo-nautilus-cxtpf
Apr 27 16:30:12.748: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:12.748: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:12.748: INFO: update-demo-nautilus-cxtpf is verified up and running
STEP: scaling down the replication controller
Apr 27 16:30:12.750: INFO: scanned /root for discovery docs: <nil>
Apr 27 16:30:12.750: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9034'
Apr 27 16:30:13.849: INFO: stderr: ""
Apr 27 16:30:13.849: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:30:13.849: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:13.931: INFO: stderr: ""
Apr 27 16:30:13.931: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-cxtpf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 16:30:18.931: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:19.018: INFO: stderr: ""
Apr 27 16:30:19.018: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-cxtpf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 16:30:24.018: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:24.105: INFO: stderr: ""
Apr 27 16:30:24.105: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-cxtpf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 27 16:30:29.106: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:29.186: INFO: stderr: ""
Apr 27 16:30:29.186: INFO: stdout: "update-demo-nautilus-7s9zs "
Apr 27 16:30:29.186: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:29.265: INFO: stderr: ""
Apr 27 16:30:29.265: INFO: stdout: "true"
Apr 27 16:30:29.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:29.344: INFO: stderr: ""
Apr 27 16:30:29.344: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:29.344: INFO: validating pod update-demo-nautilus-7s9zs
Apr 27 16:30:29.354: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:29.354: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:29.354: INFO: update-demo-nautilus-7s9zs is verified up and running
STEP: scaling up the replication controller
Apr 27 16:30:29.356: INFO: scanned /root for discovery docs: <nil>
Apr 27 16:30:29.356: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9034'
Apr 27 16:30:30.456: INFO: stderr: ""
Apr 27 16:30:30.456: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:30:30.456: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:30.541: INFO: stderr: ""
Apr 27 16:30:30.541: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-p69p5 "
Apr 27 16:30:30.541: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:30.625: INFO: stderr: ""
Apr 27 16:30:30.625: INFO: stdout: "true"
Apr 27 16:30:30.625: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:30.707: INFO: stderr: ""
Apr 27 16:30:30.707: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:30.707: INFO: validating pod update-demo-nautilus-7s9zs
Apr 27 16:30:30.716: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:30.716: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:30.716: INFO: update-demo-nautilus-7s9zs is verified up and running
Apr 27 16:30:30.716: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p69p5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:30.798: INFO: stderr: ""
Apr 27 16:30:30.798: INFO: stdout: ""
Apr 27 16:30:30.798: INFO: update-demo-nautilus-p69p5 is created but not running
Apr 27 16:30:35.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9034'
Apr 27 16:30:35.884: INFO: stderr: ""
Apr 27 16:30:35.884: INFO: stdout: "update-demo-nautilus-7s9zs update-demo-nautilus-p69p5 "
Apr 27 16:30:35.884: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:35.967: INFO: stderr: ""
Apr 27 16:30:35.967: INFO: stdout: "true"
Apr 27 16:30:35.967: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7s9zs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:36.046: INFO: stderr: ""
Apr 27 16:30:36.046: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:36.046: INFO: validating pod update-demo-nautilus-7s9zs
Apr 27 16:30:36.055: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:36.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:36.056: INFO: update-demo-nautilus-7s9zs is verified up and running
Apr 27 16:30:36.056: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p69p5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:36.135: INFO: stderr: ""
Apr 27 16:30:36.135: INFO: stdout: "true"
Apr 27 16:30:36.136: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p69p5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9034'
Apr 27 16:30:36.213: INFO: stderr: ""
Apr 27 16:30:36.213: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:30:36.213: INFO: validating pod update-demo-nautilus-p69p5
Apr 27 16:30:36.310: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:30:36.310: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:30:36.310: INFO: update-demo-nautilus-p69p5 is verified up and running
STEP: using delete to clean up resources
Apr 27 16:30:36.310: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9034'
Apr 27 16:30:36.393: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:30:36.393: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 16:30:36.393: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9034'
Apr 27 16:30:36.478: INFO: stderr: "No resources found in kubectl-9034 namespace.\n"
Apr 27 16:30:36.478: INFO: stdout: ""
Apr 27 16:30:36.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-9034 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:30:36.562: INFO: stderr: ""
Apr 27 16:30:36.562: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:36.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9034" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":277,"completed":69,"skipped":1364,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:36.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-e31da85e-6d65-4bbe-89fe-d1c5397a2eb1
STEP: Creating a pod to test consume secrets
Apr 27 16:30:36.737: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3" in namespace "projected-151" to be "Succeeded or Failed"
Apr 27 16:30:36.741: INFO: Pod "pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.795716ms
Apr 27 16:30:38.746: INFO: Pod "pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008957606s
STEP: Saw pod success
Apr 27 16:30:38.746: INFO: Pod "pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3" satisfied condition "Succeeded or Failed"
Apr 27 16:30:38.750: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:30:38.770: INFO: Waiting for pod pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3 to disappear
Apr 27 16:30:38.774: INFO: Pod pod-projected-secrets-c213f34d-442f-4687-a491-cd7dcf42cab3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:38.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-151" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":70,"skipped":1368,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:38.786: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:30:38.941: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04" in namespace "projected-6712" to be "Succeeded or Failed"
Apr 27 16:30:38.946: INFO: Pod "downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.658495ms
Apr 27 16:30:40.950: INFO: Pod "downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008971894s
STEP: Saw pod success
Apr 27 16:30:40.950: INFO: Pod "downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04" satisfied condition "Succeeded or Failed"
Apr 27 16:30:40.954: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04 container client-container: <nil>
STEP: delete the pod
Apr 27 16:30:40.974: INFO: Waiting for pod downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04 to disappear
Apr 27 16:30:40.978: INFO: Pod downwardapi-volume-79c500e4-03ef-4e6e-a924-8e85b311ee04 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:30:40.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6712" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":71,"skipped":1375,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:30:40.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-556
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:03.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-556" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":277,"completed":72,"skipped":1405,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:03.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8256
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:07.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8256" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":277,"completed":73,"skipped":1418,"failed":0}

------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:07.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:31:07.701: INFO: Creating deployment "test-recreate-deployment"
Apr 27 16:31:07.706: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 27 16:31:07.715: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 27 16:31:09.725: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 27 16:31:09.729: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 27 16:31:09.738: INFO: Updating deployment test-recreate-deployment
Apr 27 16:31:09.738: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:31:09.772: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2911 /apis/apps/v1/namespaces/deployment-2911/deployments/test-recreate-deployment 09300f25-c890-4c89-a246-e214fba70524 14177 2 2020-04-27 16:31:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-04-27 16:31:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:31:09 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005843cf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-27 16:31:09 +0000 UTC,LastTransitionTime:2020-04-27 16:31:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-04-27 16:31:09 +0000 UTC,LastTransitionTime:2020-04-27 16:31:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 27 16:31:09.777: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-2911 /apis/apps/v1/namespaces/deployment-2911/replicasets/test-recreate-deployment-d5667d9c7 38bbf49a-2768-458e-9d94-bc05b6520912 14176 1 2020-04-27 16:31:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 09300f25-c890-4c89-a246-e214fba70524 0xc0057ae200 0xc0057ae201}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:31:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 57 51 48 48 102 50 53 45 99 56 57 48 45 52 99 56 57 45 97 50 52 54 45 101 50 49 52 102 98 97 55 48 53 50 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0057ae278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:31:09.777: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 27 16:31:09.777: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-2911 /apis/apps/v1/namespaces/deployment-2911/replicasets/test-recreate-deployment-74d98b5f7c 64af0db2-11db-48cc-bb33-6b04351615dd 14169 2 2020-04-27 16:31:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 09300f25-c890-4c89-a246-e214fba70524 0xc0057ae107 0xc0057ae108}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:31:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 57 51 48 48 102 50 53 45 99 56 57 48 45 52 99 56 57 45 97 50 52 54 45 101 50 49 52 102 98 97 55 48 53 50 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0057ae198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:31:09.781: INFO: Pod "test-recreate-deployment-d5667d9c7-5qvrd" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-5qvrd test-recreate-deployment-d5667d9c7- deployment-2911 /api/v1/namespaces/deployment-2911/pods/test-recreate-deployment-d5667d9c7-5qvrd 9c7b4459-1681-44fd-92d7-529d4b98e11a 14173 0 2020-04-27 16:31:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 38bbf49a-2768-458e-9d94-bc05b6520912 0xc0057ae770 0xc0057ae771}] []  [{kube-controller-manager Update v1 2020-04-27 16:31:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 56 98 98 102 52 57 97 45 50 55 54 56 45 52 53 56 101 45 57 100 57 52 45 98 99 48 53 98 54 53 50 48 57 49 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q4wlm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q4wlm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q4wlm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:31:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:09.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2911" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":74,"skipped":1418,"failed":0}
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:09.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-472
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:31:09.948: INFO: Waiting up to 5m0s for pod "downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666" in namespace "downward-api-472" to be "Succeeded or Failed"
Apr 27 16:31:09.952: INFO: Pod "downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666": Phase="Pending", Reason="", readiness=false. Elapsed: 3.97959ms
Apr 27 16:31:11.957: INFO: Pod "downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009155316s
STEP: Saw pod success
Apr 27 16:31:11.957: INFO: Pod "downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666" satisfied condition "Succeeded or Failed"
Apr 27 16:31:11.961: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666 container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:31:11.981: INFO: Waiting for pod downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666 to disappear
Apr 27 16:31:11.985: INFO: Pod downward-api-5a1bbff1-377a-47df-8c0c-112304fc9666 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:11.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-472" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":277,"completed":75,"skipped":1425,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:11.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 16:31:12.167: INFO: Waiting up to 5m0s for pod "pod-db971c17-8834-49a0-9326-3a7a00dd4aa5" in namespace "emptydir-4787" to be "Succeeded or Failed"
Apr 27 16:31:12.171: INFO: Pod "pod-db971c17-8834-49a0-9326-3a7a00dd4aa5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.825668ms
Apr 27 16:31:14.176: INFO: Pod "pod-db971c17-8834-49a0-9326-3a7a00dd4aa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008739449s
STEP: Saw pod success
Apr 27 16:31:14.176: INFO: Pod "pod-db971c17-8834-49a0-9326-3a7a00dd4aa5" satisfied condition "Succeeded or Failed"
Apr 27 16:31:14.180: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-db971c17-8834-49a0-9326-3a7a00dd4aa5 container test-container: <nil>
STEP: delete the pod
Apr 27 16:31:14.200: INFO: Waiting for pod pod-db971c17-8834-49a0-9326-3a7a00dd4aa5 to disappear
Apr 27 16:31:14.205: INFO: Pod pod-db971c17-8834-49a0-9326-3a7a00dd4aa5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:14.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4787" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":76,"skipped":1437,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:14.217: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 16:31:14.370: INFO: Waiting up to 5m0s for pod "pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb" in namespace "emptydir-8392" to be "Succeeded or Failed"
Apr 27 16:31:14.374: INFO: Pod "pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.459823ms
Apr 27 16:31:16.379: INFO: Pod "pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009303826s
STEP: Saw pod success
Apr 27 16:31:16.379: INFO: Pod "pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb" satisfied condition "Succeeded or Failed"
Apr 27 16:31:16.384: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb container test-container: <nil>
STEP: delete the pod
Apr 27 16:31:16.403: INFO: Waiting for pod pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb to disappear
Apr 27 16:31:16.407: INFO: Pod pod-ffcb6078-c76b-4e91-b0ec-1ddc62107bfb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:16.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8392" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":77,"skipped":1437,"failed":0}
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:16.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6271
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-6271/configmap-test-1496917d-2ee1-4cb6-94ed-a36cfdd7edd2
STEP: Creating a pod to test consume configMaps
Apr 27 16:31:16.576: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4" in namespace "configmap-6271" to be "Succeeded or Failed"
Apr 27 16:31:16.580: INFO: Pod "pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.896878ms
Apr 27 16:31:18.585: INFO: Pod "pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008743146s
STEP: Saw pod success
Apr 27 16:31:18.585: INFO: Pod "pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4" satisfied condition "Succeeded or Failed"
Apr 27 16:31:18.589: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4 container env-test: <nil>
STEP: delete the pod
Apr 27 16:31:18.612: INFO: Waiting for pod pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4 to disappear
Apr 27 16:31:18.615: INFO: Pod pod-configmaps-3d360fc0-2662-43a5-9625-5e66c9a6afe4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:18.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6271" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":78,"skipped":1443,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:18.628: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2487
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-318b46f5-91c8-4f2f-9138-a2a57df2b4b8
STEP: Creating configMap with name cm-test-opt-upd-07037e6b-b9a5-4df2-b225-0f749a492e94
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-318b46f5-91c8-4f2f-9138-a2a57df2b4b8
STEP: Updating configmap cm-test-opt-upd-07037e6b-b9a5-4df2-b225-0f749a492e94
STEP: Creating configMap with name cm-test-opt-create-68f9366a-4200-4e69-8a94-fe546a2fe8ab
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:23.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2487" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":79,"skipped":1477,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:23.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-2155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:23.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2155" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":277,"completed":80,"skipped":1487,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:23.378: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Apr 27 16:31:24.056: INFO: created pod pod-service-account-defaultsa
Apr 27 16:31:24.056: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 27 16:31:24.062: INFO: created pod pod-service-account-mountsa
Apr 27 16:31:24.062: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 27 16:31:24.068: INFO: created pod pod-service-account-nomountsa
Apr 27 16:31:24.068: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 27 16:31:24.073: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 27 16:31:24.073: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 27 16:31:24.078: INFO: created pod pod-service-account-mountsa-mountspec
Apr 27 16:31:24.078: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 27 16:31:24.084: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 27 16:31:24.084: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 27 16:31:24.089: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 27 16:31:24.089: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 27 16:31:24.094: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 27 16:31:24.095: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 27 16:31:24.100: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 27 16:31:24.100: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:24.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4012" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":277,"completed":81,"skipped":1507,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:24.112: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7479
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:31:24.259: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr 27 16:31:27.765: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 create -f -'
Apr 27 16:31:28.195: INFO: stderr: ""
Apr 27 16:31:28.195: INFO: stdout: "e2e-test-crd-publish-openapi-1108-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 16:31:28.196: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 delete e2e-test-crd-publish-openapi-1108-crds test-foo'
Apr 27 16:31:28.284: INFO: stderr: ""
Apr 27 16:31:28.284: INFO: stdout: "e2e-test-crd-publish-openapi-1108-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 27 16:31:28.284: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 apply -f -'
Apr 27 16:31:28.574: INFO: stderr: ""
Apr 27 16:31:28.574: INFO: stdout: "e2e-test-crd-publish-openapi-1108-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 27 16:31:28.574: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 delete e2e-test-crd-publish-openapi-1108-crds test-foo'
Apr 27 16:31:28.665: INFO: stderr: ""
Apr 27 16:31:28.665: INFO: stdout: "e2e-test-crd-publish-openapi-1108-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr 27 16:31:28.665: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 create -f -'
Apr 27 16:31:28.890: INFO: rc: 1
Apr 27 16:31:28.890: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 apply -f -'
Apr 27 16:31:29.102: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr 27 16:31:29.102: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 create -f -'
Apr 27 16:31:29.749: INFO: rc: 1
Apr 27 16:31:29.749: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7479 apply -f -'
Apr 27 16:31:29.903: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr 27 16:31:29.903: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1108-crds'
Apr 27 16:31:30.128: INFO: stderr: ""
Apr 27 16:31:30.128: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1108-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr 27 16:31:30.129: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1108-crds.metadata'
Apr 27 16:31:30.279: INFO: stderr: ""
Apr 27 16:31:30.279: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1108-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 27 16:31:30.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1108-crds.spec'
Apr 27 16:31:30.486: INFO: stderr: ""
Apr 27 16:31:30.486: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1108-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 27 16:31:30.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1108-crds.spec.bars'
Apr 27 16:31:30.629: INFO: stderr: ""
Apr 27 16:31:30.629: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1108-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr 27 16:31:30.629: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1108-crds.spec.bars2'
Apr 27 16:31:30.833: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:34.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7479" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":277,"completed":82,"skipped":1520,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:34.315: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3281
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 16:31:34.473: INFO: Waiting up to 5m0s for pod "pod-29bb760f-a834-49f1-bc14-87437f9bd454" in namespace "emptydir-3281" to be "Succeeded or Failed"
Apr 27 16:31:34.476: INFO: Pod "pod-29bb760f-a834-49f1-bc14-87437f9bd454": Phase="Pending", Reason="", readiness=false. Elapsed: 3.658386ms
Apr 27 16:31:36.482: INFO: Pod "pod-29bb760f-a834-49f1-bc14-87437f9bd454": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008914715s
STEP: Saw pod success
Apr 27 16:31:36.482: INFO: Pod "pod-29bb760f-a834-49f1-bc14-87437f9bd454" satisfied condition "Succeeded or Failed"
Apr 27 16:31:36.486: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-29bb760f-a834-49f1-bc14-87437f9bd454 container test-container: <nil>
STEP: delete the pod
Apr 27 16:31:36.506: INFO: Waiting for pod pod-29bb760f-a834-49f1-bc14-87437f9bd454 to disappear
Apr 27 16:31:36.510: INFO: Pod pod-29bb760f-a834-49f1-bc14-87437f9bd454 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:36.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3281" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":83,"skipped":1523,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:36.523: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:31:36.682: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c" in namespace "downward-api-4518" to be "Succeeded or Failed"
Apr 27 16:31:36.685: INFO: Pod "downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.82273ms
Apr 27 16:31:38.691: INFO: Pod "downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009094518s
STEP: Saw pod success
Apr 27 16:31:38.691: INFO: Pod "downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c" satisfied condition "Succeeded or Failed"
Apr 27 16:31:38.695: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c container client-container: <nil>
STEP: delete the pod
Apr 27 16:31:38.714: INFO: Waiting for pod downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c to disappear
Apr 27 16:31:38.718: INFO: Pod downwardapi-volume-d5c8db47-32b6-4cf1-a51d-11e4c3a4f81c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:38.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4518" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":84,"skipped":1586,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:38.730: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 27 16:31:38.907: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8750 /api/v1/namespaces/watch-8750/configmaps/e2e-watch-test-resource-version 5f864d63-cb62-4f8d-a064-07f6c71d713a 14572 0 2020-04-27 16:31:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 16:31:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 27 16:31:38.907: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8750 /api/v1/namespaces/watch-8750/configmaps/e2e-watch-test-resource-version 5f864d63-cb62-4f8d-a064-07f6c71d713a 14573 0 2020-04-27 16:31:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-04-27 16:31:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:38.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8750" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":277,"completed":85,"skipped":1598,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:38.917: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9322
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 27 16:31:39.069: INFO: Waiting up to 5m0s for pod "pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf" in namespace "emptydir-9322" to be "Succeeded or Failed"
Apr 27 16:31:39.073: INFO: Pod "pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.18376ms
Apr 27 16:31:41.078: INFO: Pod "pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009132772s
STEP: Saw pod success
Apr 27 16:31:41.078: INFO: Pod "pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf" satisfied condition "Succeeded or Failed"
Apr 27 16:31:41.082: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf container test-container: <nil>
STEP: delete the pod
Apr 27 16:31:41.103: INFO: Waiting for pod pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf to disappear
Apr 27 16:31:41.107: INFO: Pod pod-e06237b1-0b0e-405b-b3ef-45e976cc3fcf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:41.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9322" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":86,"skipped":1601,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:41.120: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-1497/configmap-test-d2b10992-5d3d-485e-a9b4-554acb610d52
STEP: Creating a pod to test consume configMaps
Apr 27 16:31:41.279: INFO: Waiting up to 5m0s for pod "pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d" in namespace "configmap-1497" to be "Succeeded or Failed"
Apr 27 16:31:41.283: INFO: Pod "pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307211ms
Apr 27 16:31:43.288: INFO: Pod "pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009039227s
STEP: Saw pod success
Apr 27 16:31:43.288: INFO: Pod "pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d" satisfied condition "Succeeded or Failed"
Apr 27 16:31:43.292: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d container env-test: <nil>
STEP: delete the pod
Apr 27 16:31:43.312: INFO: Waiting for pod pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d to disappear
Apr 27 16:31:43.315: INFO: Pod pod-configmaps-12f28899-db75-4010-be1c-e5d762eaef2d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:43.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1497" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":277,"completed":87,"skipped":1659,"failed":0}
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:43.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4968
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-9b6c1073-992b-40f3-8aff-fad26e605453-6879
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:43.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4968" for this suite.
STEP: Destroying namespace "nspatchtest-9b6c1073-992b-40f3-8aff-fad26e605453-6879" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":277,"completed":88,"skipped":1661,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:43.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 16:31:43.798: INFO: Waiting up to 5m0s for pod "pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230" in namespace "emptydir-2485" to be "Succeeded or Failed"
Apr 27 16:31:43.803: INFO: Pod "pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230": Phase="Pending", Reason="", readiness=false. Elapsed: 4.707483ms
Apr 27 16:31:45.807: INFO: Pod "pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009361946s
Apr 27 16:31:47.812: INFO: Pod "pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013950834s
STEP: Saw pod success
Apr 27 16:31:47.812: INFO: Pod "pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230" satisfied condition "Succeeded or Failed"
Apr 27 16:31:47.816: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230 container test-container: <nil>
STEP: delete the pod
Apr 27 16:31:47.836: INFO: Waiting for pod pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230 to disappear
Apr 27 16:31:47.839: INFO: Pod pod-3ba23a24-1425-4a8e-a1bb-4cc34c4cd230 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:47.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2485" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":89,"skipped":1662,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:47.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2388
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-5dec67dd-08e3-47d7-a93a-769349c304b3
STEP: Creating a pod to test consume configMaps
Apr 27 16:31:48.012: INFO: Waiting up to 5m0s for pod "pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d" in namespace "configmap-2388" to be "Succeeded or Failed"
Apr 27 16:31:48.016: INFO: Pod "pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.45197ms
Apr 27 16:31:50.021: INFO: Pod "pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009344427s
STEP: Saw pod success
Apr 27 16:31:50.021: INFO: Pod "pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d" satisfied condition "Succeeded or Failed"
Apr 27 16:31:50.025: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:31:50.046: INFO: Waiting for pod pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d to disappear
Apr 27 16:31:50.049: INFO: Pod pod-configmaps-78730390-9235-47b7-a520-f56c4fc17e7d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:50.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2388" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":277,"completed":90,"skipped":1686,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:50.062: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:31:50.217: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642" in namespace "projected-2922" to be "Succeeded or Failed"
Apr 27 16:31:50.222: INFO: Pod "downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828076ms
Apr 27 16:31:52.227: INFO: Pod "downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010097378s
STEP: Saw pod success
Apr 27 16:31:52.227: INFO: Pod "downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642" satisfied condition "Succeeded or Failed"
Apr 27 16:31:52.231: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642 container client-container: <nil>
STEP: delete the pod
Apr 27 16:31:52.252: INFO: Waiting for pod downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642 to disappear
Apr 27 16:31:52.256: INFO: Pod downwardapi-volume-aa72df16-56f5-4489-8b82-c98c08dbc642 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:52.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2922" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":91,"skipped":1722,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:52.268: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:31:52.421: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9" in namespace "downward-api-4651" to be "Succeeded or Failed"
Apr 27 16:31:52.425: INFO: Pod "downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.86025ms
Apr 27 16:31:54.430: INFO: Pod "downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008647223s
STEP: Saw pod success
Apr 27 16:31:54.430: INFO: Pod "downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9" satisfied condition "Succeeded or Failed"
Apr 27 16:31:54.434: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9 container client-container: <nil>
STEP: delete the pod
Apr 27 16:31:54.454: INFO: Waiting for pod downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9 to disappear
Apr 27 16:31:54.458: INFO: Pod downwardapi-volume-ec4e363f-e851-451b-8ebe-75587a881cf9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:54.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4651" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":92,"skipped":1759,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:54.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-2270/secret-test-8d0d0bf8-0a97-4317-8ba0-aabf48430db1
STEP: Creating a pod to test consume secrets
Apr 27 16:31:54.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c" in namespace "secrets-2270" to be "Succeeded or Failed"
Apr 27 16:31:54.636: INFO: Pod "pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.174885ms
Apr 27 16:31:56.641: INFO: Pod "pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009345197s
STEP: Saw pod success
Apr 27 16:31:56.641: INFO: Pod "pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c" satisfied condition "Succeeded or Failed"
Apr 27 16:31:56.645: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c container env-test: <nil>
STEP: delete the pod
Apr 27 16:31:56.708: INFO: Waiting for pod pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c to disappear
Apr 27 16:31:56.712: INFO: Pod pod-configmaps-a1d00633-e9a8-4829-9db9-5ba0c22fb83c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:31:56.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2270" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":277,"completed":93,"skipped":1763,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:31:56.724: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-5069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Apr 27 16:31:56.870: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 16:32:56.910: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:32:56.914: INFO: Starting informer...
STEP: Starting pods...
Apr 27 16:32:57.135: INFO: Pod1 is running on izgw82palggheybhhd1s46z. Tainting Node
Apr 27 16:33:01.162: INFO: Pod2 is running on izgw82palggheybhhd1s46z. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr 27 16:33:14.899: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 27 16:33:27.742: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:33:27.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-5069" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":277,"completed":94,"skipped":1769,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:33:27.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:33:33.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9363" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":277,"completed":95,"skipped":1787,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:33:33.726: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-e944433b-b744-41fe-b8b6-2b37dcbab13b
STEP: Creating a pod to test consume configMaps
Apr 27 16:33:33.887: INFO: Waiting up to 5m0s for pod "pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519" in namespace "configmap-4390" to be "Succeeded or Failed"
Apr 27 16:33:33.891: INFO: Pod "pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519": Phase="Pending", Reason="", readiness=false. Elapsed: 4.216622ms
Apr 27 16:33:35.896: INFO: Pod "pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009244055s
STEP: Saw pod success
Apr 27 16:33:35.896: INFO: Pod "pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519" satisfied condition "Succeeded or Failed"
Apr 27 16:33:35.900: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:33:36.022: INFO: Waiting for pod pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519 to disappear
Apr 27 16:33:36.026: INFO: Pod pod-configmaps-39ff0d99-88e7-45cb-9bdd-f69228d7c519 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:33:36.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4390" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":277,"completed":96,"skipped":1808,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:33:36.039: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:33:36.458: INFO: Pod name wrapped-volume-race-cd69ac34-ee2b-40dc-a126-d281feecc399: Found 0 pods out of 5
Apr 27 16:33:41.473: INFO: Pod name wrapped-volume-race-cd69ac34-ee2b-40dc-a126-d281feecc399: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cd69ac34-ee2b-40dc-a126-d281feecc399 in namespace emptydir-wrapper-2187, will wait for the garbage collector to delete the pods
Apr 27 16:33:43.567: INFO: Deleting ReplicationController wrapped-volume-race-cd69ac34-ee2b-40dc-a126-d281feecc399 took: 7.839689ms
Apr 27 16:33:43.667: INFO: Terminating ReplicationController wrapped-volume-race-cd69ac34-ee2b-40dc-a126-d281feecc399 pods took: 100.290198ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:33:53.886: INFO: Pod name wrapped-volume-race-c090ecf0-d323-4465-a344-548a6abd7401: Found 0 pods out of 5
Apr 27 16:33:58.900: INFO: Pod name wrapped-volume-race-c090ecf0-d323-4465-a344-548a6abd7401: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c090ecf0-d323-4465-a344-548a6abd7401 in namespace emptydir-wrapper-2187, will wait for the garbage collector to delete the pods
Apr 27 16:33:58.986: INFO: Deleting ReplicationController wrapped-volume-race-c090ecf0-d323-4465-a344-548a6abd7401 took: 7.455046ms
Apr 27 16:33:59.087: INFO: Terminating ReplicationController wrapped-volume-race-c090ecf0-d323-4465-a344-548a6abd7401 pods took: 100.35825ms
STEP: Creating RC which spawns configmap-volume pods
Apr 27 16:34:05.005: INFO: Pod name wrapped-volume-race-fde4ddbb-cf72-4613-ab20-1acf29399f9c: Found 0 pods out of 5
Apr 27 16:34:10.020: INFO: Pod name wrapped-volume-race-fde4ddbb-cf72-4613-ab20-1acf29399f9c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fde4ddbb-cf72-4613-ab20-1acf29399f9c in namespace emptydir-wrapper-2187, will wait for the garbage collector to delete the pods
Apr 27 16:34:10.107: INFO: Deleting ReplicationController wrapped-volume-race-fde4ddbb-cf72-4613-ab20-1acf29399f9c took: 7.467209ms
Apr 27 16:34:10.207: INFO: Terminating ReplicationController wrapped-volume-race-fde4ddbb-cf72-4613-ab20-1acf29399f9c pods took: 100.287493ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:24.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2187" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":277,"completed":97,"skipped":1850,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:24.251: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:34:24.783: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:34:26.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602064, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602064, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602064, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602064, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:34:29.811: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:40.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2031" for this suite.
STEP: Destroying namespace "webhook-2031-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":277,"completed":98,"skipped":1980,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:40.414: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:34:40.814: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:34:40.830: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:34:40.835: INFO: 
Logging pods the kubelet thinks is on node izgw82palggheybhhd1s46z before test
Apr 27 16:34:40.855: INFO: csi-disk-plugin-alicloud-hzxms from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 16:34:40.855: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 16:34:40.855: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 16:34:40.855: INFO: node-exporter-k58cv from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.855: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:34:40.855: INFO: calico-node-xjxjf from kube-system started at 2020-04-27 16:33:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.855: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:34:40.855: INFO: kube-proxy-r447h from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.855: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:34:40.855: INFO: node-problem-detector-m6qcf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.855: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:34:40.855: INFO: 
Logging pods the kubelet thinks is on node izgw873bmqhhfhflh483llz before test
Apr 27 16:34:40.932: INFO: coredns-5cb857d789-5cvkp from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:34:40.932: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-qp9pw from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:34:40.932: INFO: vpn-shoot-6f75686cfb-ntkwh from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:34:40.932: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-dtlrp from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:34:40.932: INFO: calico-node-p7gsw from kube-system started at 2020-04-27 16:33:54 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:34:40.932: INFO: csi-disk-plugin-alicloud-9szgk from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 16:34:40.932: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 16:34:40.932: INFO: calico-typha-vertical-autoscaler-5b477c88cf-ltrk8 from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:34:40.932: INFO: coredns-5cb857d789-x7mvm from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:34:40.932: INFO: kubernetes-dashboard-6b586c4cb4-nqch8 from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:34:40.932: INFO: calico-node-vertical-autoscaler-74d4897db8-m2vrd from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:34:40.932: INFO: node-exporter-gjwg5 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:34:40.932: INFO: metrics-server-7ff88f9d88-zmzhg from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:34:40.932: INFO: blackbox-exporter-5dc75b79b7-xshtf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:34:40.932: INFO: node-problem-detector-9ntf8 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:34:40.932: INFO: calico-typha-deploy-784665cc66-b2n69 from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:34:40.932: INFO: addons-nginx-ingress-controller-6cf77756b5-rwfsq from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:34:40.932: INFO: dashboard-metrics-scraper-76c7b697bc-zfk9z from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:34:40.932: INFO: kube-proxy-v48zq from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:34:40.932: INFO: calico-kube-controllers-77dcb8f688-44xhb from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:34:40.932: INFO: 	Container calico-kube-controllers ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-14bedbfd-7ba1-42a0-85f5-8581b4fe5117 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-14bedbfd-7ba1-42a0-85f5-8581b4fe5117 off the node izgw82palggheybhhd1s46z
STEP: verifying the node doesn't have the label kubernetes.io/e2e-14bedbfd-7ba1-42a0-85f5-8581b4fe5117
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:49.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7526" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":277,"completed":99,"skipped":1982,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:49.064: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9713
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Apr 27 16:34:49.224: INFO: Waiting up to 5m0s for pod "client-containers-cd599509-e423-4191-abbb-7a741280b2bf" in namespace "containers-9713" to be "Succeeded or Failed"
Apr 27 16:34:49.229: INFO: Pod "client-containers-cd599509-e423-4191-abbb-7a741280b2bf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.145666ms
Apr 27 16:34:51.234: INFO: Pod "client-containers-cd599509-e423-4191-abbb-7a741280b2bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009696516s
STEP: Saw pod success
Apr 27 16:34:51.234: INFO: Pod "client-containers-cd599509-e423-4191-abbb-7a741280b2bf" satisfied condition "Succeeded or Failed"
Apr 27 16:34:51.238: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod client-containers-cd599509-e423-4191-abbb-7a741280b2bf container test-container: <nil>
STEP: delete the pod
Apr 27 16:34:51.263: INFO: Waiting for pod client-containers-cd599509-e423-4191-abbb-7a741280b2bf to disappear
Apr 27 16:34:51.267: INFO: Pod client-containers-cd599509-e423-4191-abbb-7a741280b2bf no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:51.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9713" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":277,"completed":100,"skipped":2018,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:51.281: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-d6b7c1b8-5c81-48b1-8f86-280faad463f6
STEP: Creating a pod to test consume secrets
Apr 27 16:34:51.443: INFO: Waiting up to 5m0s for pod "pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1" in namespace "secrets-5928" to be "Succeeded or Failed"
Apr 27 16:34:51.447: INFO: Pod "pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.086053ms
Apr 27 16:34:53.452: INFO: Pod "pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008966923s
STEP: Saw pod success
Apr 27 16:34:53.452: INFO: Pod "pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1" satisfied condition "Succeeded or Failed"
Apr 27 16:34:53.456: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1 container secret-env-test: <nil>
STEP: delete the pod
Apr 27 16:34:53.477: INFO: Waiting for pod pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1 to disappear
Apr 27 16:34:53.481: INFO: Pod pod-secrets-feb40ca9-33f0-4836-96d6-0cd8cd3f0ce1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:34:53.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5928" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":277,"completed":101,"skipped":2029,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:34:53.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-78a4301f-bf92-4609-8c8b-ea1921d86821 in namespace container-probe-678
Apr 27 16:34:55.745: INFO: Started pod busybox-78a4301f-bf92-4609-8c8b-ea1921d86821 in namespace container-probe-678
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:34:55.749: INFO: Initial restart count of pod busybox-78a4301f-bf92-4609-8c8b-ea1921d86821 is 0
Apr 27 16:35:43.878: INFO: Restart count of pod container-probe-678/busybox-78a4301f-bf92-4609-8c8b-ea1921d86821 is now 1 (48.128745373s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:43.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-678" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":102,"skipped":2032,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:43.900: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5230
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-70c6c757-5c0e-45b2-832c-67cc94c04fb7
STEP: Creating secret with name s-test-opt-upd-8f6d123a-214a-4851-ac76-9fabe52af270
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-70c6c757-5c0e-45b2-832c-67cc94c04fb7
STEP: Updating secret s-test-opt-upd-8f6d123a-214a-4851-ac76-9fabe52af270
STEP: Creating secret with name s-test-opt-create-93236cf7-e53c-43ba-9cdf-94fd310ece7f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:35:48.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5230" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":103,"skipped":2043,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:35:48.531: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-7302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Apr 27 16:35:48.678: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 27 16:36:48.717: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:36:48.722: INFO: Starting informer...
STEP: Starting pod...
Apr 27 16:36:48.734: INFO: Pod is running on izgw82palggheybhhd1s46z. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr 27 16:36:48.750: INFO: Pod wasn't evicted. Proceeding
Apr 27 16:36:48.750: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr 27 16:38:03.768: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:03.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-7302" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":277,"completed":104,"skipped":2049,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:03.783: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7390
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-2a2f32f2-2500-45fb-809b-4bbbb9cd1c47
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:08.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7390" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":105,"skipped":2078,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:08.177: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2250
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 16:38:12.879: INFO: Successfully updated pod "annotationupdatef3311752-e82e-4bc4-b55f-272d092d4cde"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:14.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2250" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":106,"skipped":2088,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:14.943: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:38:15.132: INFO: Number of nodes with available pods: 0
Apr 27 16:38:15.132: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:16.145: INFO: Number of nodes with available pods: 0
Apr 27 16:38:16.145: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:17.145: INFO: Number of nodes with available pods: 2
Apr 27 16:38:17.145: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 27 16:38:17.171: INFO: Number of nodes with available pods: 1
Apr 27 16:38:17.171: INFO: Node izgw873bmqhhfhflh483llz is running more than one daemon pod
Apr 27 16:38:18.184: INFO: Number of nodes with available pods: 1
Apr 27 16:38:18.184: INFO: Node izgw873bmqhhfhflh483llz is running more than one daemon pod
Apr 27 16:38:19.185: INFO: Number of nodes with available pods: 2
Apr 27 16:38:19.185: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8133, will wait for the garbage collector to delete the pods
Apr 27 16:38:19.255: INFO: Deleting DaemonSet.extensions daemon-set took: 6.77831ms
Apr 27 16:38:19.856: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.368226ms
Apr 27 16:38:33.761: INFO: Number of nodes with available pods: 0
Apr 27 16:38:33.761: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:38:33.767: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8133/daemonsets","resourceVersion":"17491"},"items":null}

Apr 27 16:38:33.772: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8133/pods","resourceVersion":"17491"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:33.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8133" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":277,"completed":107,"skipped":2096,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:33.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-1a75b561-7071-424b-b1cf-565d4e8fb9f6
STEP: Creating a pod to test consume configMaps
Apr 27 16:38:33.961: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d" in namespace "configmap-9230" to be "Succeeded or Failed"
Apr 27 16:38:33.965: INFO: Pod "pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.415077ms
Apr 27 16:38:35.971: INFO: Pod "pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00965306s
STEP: Saw pod success
Apr 27 16:38:35.971: INFO: Pod "pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d" satisfied condition "Succeeded or Failed"
Apr 27 16:38:35.975: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:38:35.999: INFO: Waiting for pod pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d to disappear
Apr 27 16:38:36.003: INFO: Pod pod-configmaps-b5ddffb3-0c40-46ac-b73b-b89e06ebd34d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:36.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9230" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":108,"skipped":2098,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:36.017: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-6613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:38:36.463: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:38:39.487: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:39.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:41.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6613" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":277,"completed":109,"skipped":2118,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:41.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Apr 27 16:38:41.552: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3060" to be "Succeeded or Failed"
Apr 27 16:38:41.556: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.250936ms
Apr 27 16:38:43.612: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059906533s
STEP: Saw pod success
Apr 27 16:38:43.612: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Apr 27 16:38:43.617: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 27 16:38:43.723: INFO: Waiting for pod pod-host-path-test to disappear
Apr 27 16:38:43.727: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:43.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3060" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":110,"skipped":2157,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:43.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1628
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:38:43.921: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:38:47.920: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1628 create -f -'
Apr 27 16:38:48.390: INFO: stderr: ""
Apr 27 16:38:48.390: INFO: stdout: "e2e-test-crd-publish-openapi-5669-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 16:38:48.390: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1628 delete e2e-test-crd-publish-openapi-5669-crds test-cr'
Apr 27 16:38:48.523: INFO: stderr: ""
Apr 27 16:38:48.523: INFO: stdout: "e2e-test-crd-publish-openapi-5669-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 27 16:38:48.523: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1628 apply -f -'
Apr 27 16:38:48.752: INFO: stderr: ""
Apr 27 16:38:48.752: INFO: stdout: "e2e-test-crd-publish-openapi-5669-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 27 16:38:48.752: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1628 delete e2e-test-crd-publish-openapi-5669-crds test-cr'
Apr 27 16:38:48.879: INFO: stderr: ""
Apr 27 16:38:48.879: INFO: stdout: "e2e-test-crd-publish-openapi-5669-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 16:38:48.879: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-5669-crds'
Apr 27 16:38:49.126: INFO: stderr: ""
Apr 27 16:38:49.126: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5669-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:38:52.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1628" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":277,"completed":111,"skipped":2165,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:38:52.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4127
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 16:38:52.812: INFO: Number of nodes with available pods: 0
Apr 27 16:38:52.812: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:53.825: INFO: Number of nodes with available pods: 0
Apr 27 16:38:53.825: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:54.825: INFO: Number of nodes with available pods: 2
Apr 27 16:38:54.825: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 27 16:38:54.852: INFO: Number of nodes with available pods: 1
Apr 27 16:38:54.852: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:55.865: INFO: Number of nodes with available pods: 1
Apr 27 16:38:55.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:56.864: INFO: Number of nodes with available pods: 1
Apr 27 16:38:56.864: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:57.865: INFO: Number of nodes with available pods: 1
Apr 27 16:38:57.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:58.865: INFO: Number of nodes with available pods: 1
Apr 27 16:38:58.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:38:59.865: INFO: Number of nodes with available pods: 1
Apr 27 16:38:59.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:00.864: INFO: Number of nodes with available pods: 1
Apr 27 16:39:00.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:01.866: INFO: Number of nodes with available pods: 1
Apr 27 16:39:01.866: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:02.865: INFO: Number of nodes with available pods: 1
Apr 27 16:39:02.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:03.865: INFO: Number of nodes with available pods: 1
Apr 27 16:39:03.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:04.865: INFO: Number of nodes with available pods: 1
Apr 27 16:39:04.865: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:05.864: INFO: Number of nodes with available pods: 1
Apr 27 16:39:05.864: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:39:06.865: INFO: Number of nodes with available pods: 2
Apr 27 16:39:06.866: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4127, will wait for the garbage collector to delete the pods
Apr 27 16:39:06.931: INFO: Deleting DaemonSet.extensions daemon-set took: 6.598696ms
Apr 27 16:39:07.031: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.292023ms
Apr 27 16:39:14.936: INFO: Number of nodes with available pods: 0
Apr 27 16:39:14.936: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:39:14.940: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4127/daemonsets","resourceVersion":"17858"},"items":null}

Apr 27 16:39:14.944: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4127/pods","resourceVersion":"17858"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:14.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4127" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":277,"completed":112,"skipped":2167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:14.971: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1982
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Apr 27 16:39:15.123: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:39:33.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1982" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":277,"completed":113,"skipped":2190,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:39:33.162: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7625
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7625, will wait for the garbage collector to delete the pods
Apr 27 16:39:37.382: INFO: Deleting Job.batch foo took: 6.642702ms
Apr 27 16:39:37.482: INFO: Terminating Job.batch foo pods took: 100.339197ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:14.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7625" for this suite.
•{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":277,"completed":114,"skipped":2241,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:15.000: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:15.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1487" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":277,"completed":115,"skipped":2260,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:15.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:40:15.656: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:40:17.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602415, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602415, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602415, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602415, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:40:20.685: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:33.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1732" for this suite.
STEP: Destroying namespace "webhook-1732-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":277,"completed":116,"skipped":2285,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:33.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3841
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:40:33.409: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 27 16:40:36.412: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3841 create -f -'
Apr 27 16:40:36.873: INFO: stderr: ""
Apr 27 16:40:36.873: INFO: stdout: "e2e-test-crd-publish-openapi-9772-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:40:36.873: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3841 delete e2e-test-crd-publish-openapi-9772-crds test-cr'
Apr 27 16:40:36.970: INFO: stderr: ""
Apr 27 16:40:36.971: INFO: stdout: "e2e-test-crd-publish-openapi-9772-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 27 16:40:36.971: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3841 apply -f -'
Apr 27 16:40:37.296: INFO: stderr: ""
Apr 27 16:40:37.296: INFO: stdout: "e2e-test-crd-publish-openapi-9772-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 27 16:40:37.296: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3841 delete e2e-test-crd-publish-openapi-9772-crds test-cr'
Apr 27 16:40:37.384: INFO: stderr: ""
Apr 27 16:40:37.384: INFO: stdout: "e2e-test-crd-publish-openapi-9772-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 27 16:40:37.384: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-9772-crds'
Apr 27 16:40:37.607: INFO: stderr: ""
Apr 27 16:40:37.607: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9772-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:41.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3841" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":277,"completed":117,"skipped":2285,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:41.089: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1130
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:57.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1130" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":277,"completed":118,"skipped":2287,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:57.337: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-8689e7e6-5765-42bc-adf7-6b4e51a99879
STEP: Creating a pod to test consume secrets
Apr 27 16:40:57.498: INFO: Waiting up to 5m0s for pod "pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7" in namespace "secrets-3609" to be "Succeeded or Failed"
Apr 27 16:40:57.502: INFO: Pod "pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.956104ms
Apr 27 16:40:59.507: INFO: Pod "pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009012249s
STEP: Saw pod success
Apr 27 16:40:59.507: INFO: Pod "pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7" satisfied condition "Succeeded or Failed"
Apr 27 16:40:59.511: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:40:59.630: INFO: Waiting for pod pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7 to disappear
Apr 27 16:40:59.634: INFO: Pod pod-secrets-510b42e3-2ba2-4a4c-bb51-83a40d7174e7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:40:59.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3609" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":119,"skipped":2312,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:40:59.646: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:40:59.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb" in namespace "projected-2421" to be "Succeeded or Failed"
Apr 27 16:40:59.806: INFO: Pod "downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129509ms
Apr 27 16:41:01.811: INFO: Pod "downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009693929s
STEP: Saw pod success
Apr 27 16:41:01.811: INFO: Pod "downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb" satisfied condition "Succeeded or Failed"
Apr 27 16:41:01.816: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb container client-container: <nil>
STEP: delete the pod
Apr 27 16:41:01.837: INFO: Waiting for pod downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb to disappear
Apr 27 16:41:01.841: INFO: Pod downwardapi-volume-fc1a50b7-0852-4113-8e5f-21b4ad88c4bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:01.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2421" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":120,"skipped":2346,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:01.854: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-wjj2
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:41:02.018: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wjj2" in namespace "subpath-7689" to be "Succeeded or Failed"
Apr 27 16:41:02.022: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.952091ms
Apr 27 16:41:04.027: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 2.009072034s
Apr 27 16:41:06.033: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 4.014414155s
Apr 27 16:41:08.038: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 6.019606566s
Apr 27 16:41:10.043: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 8.025082428s
Apr 27 16:41:12.049: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 10.030556796s
Apr 27 16:41:14.054: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 12.035806559s
Apr 27 16:41:16.060: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 14.041395545s
Apr 27 16:41:18.065: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 16.046453503s
Apr 27 16:41:20.070: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 18.051482295s
Apr 27 16:41:22.075: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Running", Reason="", readiness=true. Elapsed: 20.056786376s
Apr 27 16:41:24.080: INFO: Pod "pod-subpath-test-configmap-wjj2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.061539449s
STEP: Saw pod success
Apr 27 16:41:24.080: INFO: Pod "pod-subpath-test-configmap-wjj2" satisfied condition "Succeeded or Failed"
Apr 27 16:41:24.084: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-subpath-test-configmap-wjj2 container test-container-subpath-configmap-wjj2: <nil>
STEP: delete the pod
Apr 27 16:41:24.114: INFO: Waiting for pod pod-subpath-test-configmap-wjj2 to disappear
Apr 27 16:41:24.118: INFO: Pod pod-subpath-test-configmap-wjj2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wjj2
Apr 27 16:41:24.118: INFO: Deleting pod "pod-subpath-test-configmap-wjj2" in namespace "subpath-7689"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:24.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7689" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":277,"completed":121,"skipped":2380,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:24.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-aa718e1d-3de6-4118-b5e6-1f284cd43a48
STEP: Creating a pod to test consume configMaps
Apr 27 16:41:24.296: INFO: Waiting up to 5m0s for pod "pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7" in namespace "configmap-8948" to be "Succeeded or Failed"
Apr 27 16:41:24.300: INFO: Pod "pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387692ms
Apr 27 16:41:26.305: INFO: Pod "pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009516284s
STEP: Saw pod success
Apr 27 16:41:26.306: INFO: Pod "pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7" satisfied condition "Succeeded or Failed"
Apr 27 16:41:26.310: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:41:26.333: INFO: Waiting for pod pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7 to disappear
Apr 27 16:41:26.337: INFO: Pod pod-configmaps-557811eb-da23-4b2b-b45f-492db0ae6ba7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:26.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8948" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":122,"skipped":2412,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:26.351: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1539
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr 27 16:41:26.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:41:29.483: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:42.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1539" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":277,"completed":123,"skipped":2418,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:42.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:41:42.842: INFO: Waiting up to 5m0s for pod "downward-api-263bcb5f-840a-477d-a81a-142dac98746b" in namespace "downward-api-6185" to be "Succeeded or Failed"
Apr 27 16:41:42.846: INFO: Pod "downward-api-263bcb5f-840a-477d-a81a-142dac98746b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102157ms
Apr 27 16:41:44.852: INFO: Pod "downward-api-263bcb5f-840a-477d-a81a-142dac98746b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009583222s
STEP: Saw pod success
Apr 27 16:41:44.852: INFO: Pod "downward-api-263bcb5f-840a-477d-a81a-142dac98746b" satisfied condition "Succeeded or Failed"
Apr 27 16:41:44.857: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downward-api-263bcb5f-840a-477d-a81a-142dac98746b container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:41:44.880: INFO: Waiting for pod downward-api-263bcb5f-840a-477d-a81a-142dac98746b to disappear
Apr 27 16:41:44.884: INFO: Pod downward-api-263bcb5f-840a-477d-a81a-142dac98746b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:44.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6185" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":277,"completed":124,"skipped":2427,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:44.896: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9708
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-9708
I0427 16:41:45.071134    7398 runners.go:190] Created replication controller with name: externalname-service, namespace: services-9708, replica count: 2
Apr 27 16:41:48.121: INFO: Creating new exec pod
I0427 16:41:48.121697    7398 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:41:51.148: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9708 execpodv27dv -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 16:41:51.559: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 16:41:51.559: INFO: stdout: ""
Apr 27 16:41:51.560: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9708 execpodv27dv -- /bin/sh -x -c nc -zv -t -w 2 100.106.64.213 80'
Apr 27 16:41:52.063: INFO: stderr: "+ nc -zv -t -w 2 100.106.64.213 80\nConnection to 100.106.64.213 80 port [tcp/http] succeeded!\n"
Apr 27 16:41:52.063: INFO: stdout: ""
Apr 27 16:41:52.064: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9708 execpodv27dv -- /bin/sh -x -c nc -zv -t -w 2 10.250.31.184 32186'
Apr 27 16:41:52.539: INFO: stderr: "+ nc -zv -t -w 2 10.250.31.184 32186\nConnection to 10.250.31.184 32186 port [tcp/32186] succeeded!\n"
Apr 27 16:41:52.539: INFO: stdout: ""
Apr 27 16:41:52.540: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9708 execpodv27dv -- /bin/sh -x -c nc -zv -t -w 2 10.250.31.185 32186'
Apr 27 16:41:53.032: INFO: stderr: "+ nc -zv -t -w 2 10.250.31.185 32186\nConnection to 10.250.31.185 32186 port [tcp/32186] succeeded!\n"
Apr 27 16:41:53.032: INFO: stdout: ""
Apr 27 16:41:53.032: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:41:53.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9708" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":277,"completed":125,"skipped":2432,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:41:53.062: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1281
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1281 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1281;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1281 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1281;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1281.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1281.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1281.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1281.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1281.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1281.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1281.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 236.161.106.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.106.161.236_udp@PTR;check="$$(dig +tcp +noall +answer +search 236.161.106.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.106.161.236_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1281 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1281;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1281 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1281;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1281.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1281.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1281.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1281.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1281.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1281.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1281.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1281.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1281.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 236.161.106.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.106.161.236_udp@PTR;check="$$(dig +tcp +noall +answer +search 236.161.106.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.106.161.236_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:41:57.344: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.390: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.397: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.404: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.411: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.418: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.425: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.432: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.879: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.887: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.894: INFO: Unable to read jessie_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.901: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.908: INFO: Unable to read jessie_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.915: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.922: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:57.930: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:41:58.293: INFO: Lookups using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1281 wheezy_tcp@dns-test-service.dns-1281 wheezy_udp@dns-test-service.dns-1281.svc wheezy_tcp@dns-test-service.dns-1281.svc wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1281 jessie_tcp@dns-test-service.dns-1281 jessie_udp@dns-test-service.dns-1281.svc jessie_tcp@dns-test-service.dns-1281.svc jessie_udp@_http._tcp.dns-test-service.dns-1281.svc jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc]

Apr 27 16:42:03.301: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.307: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.314: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.321: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.328: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.335: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.342: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.348: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.751: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.758: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.765: INFO: Unable to read jessie_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.772: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.785: INFO: Unable to read jessie_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.792: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.799: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:03.806: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:04.167: INFO: Lookups using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1281 wheezy_tcp@dns-test-service.dns-1281 wheezy_udp@dns-test-service.dns-1281.svc wheezy_tcp@dns-test-service.dns-1281.svc wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1281 jessie_tcp@dns-test-service.dns-1281 jessie_udp@dns-test-service.dns-1281.svc jessie_tcp@dns-test-service.dns-1281.svc jessie_udp@_http._tcp.dns-test-service.dns-1281.svc jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc]

Apr 27 16:42:08.331: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.338: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.345: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.354: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.361: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.375: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.382: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.786: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.793: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.801: INFO: Unable to read jessie_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.812: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.819: INFO: Unable to read jessie_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.826: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.833: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:08.840: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:09.198: INFO: Lookups using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1281 wheezy_tcp@dns-test-service.dns-1281 wheezy_udp@dns-test-service.dns-1281.svc wheezy_tcp@dns-test-service.dns-1281.svc wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1281 jessie_tcp@dns-test-service.dns-1281 jessie_udp@dns-test-service.dns-1281.svc jessie_tcp@dns-test-service.dns-1281.svc jessie_udp@_http._tcp.dns-test-service.dns-1281.svc jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc]

Apr 27 16:42:13.301: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.308: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.314: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.321: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.327: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.334: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.341: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.348: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.753: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.760: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.767: INFO: Unable to read jessie_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.774: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.780: INFO: Unable to read jessie_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.787: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.793: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:13.800: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:14.146: INFO: Lookups using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1281 wheezy_tcp@dns-test-service.dns-1281 wheezy_udp@dns-test-service.dns-1281.svc wheezy_tcp@dns-test-service.dns-1281.svc wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1281 jessie_tcp@dns-test-service.dns-1281 jessie_udp@dns-test-service.dns-1281.svc jessie_tcp@dns-test-service.dns-1281.svc jessie_udp@_http._tcp.dns-test-service.dns-1281.svc jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc]

Apr 27 16:42:18.301: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.347: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.354: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.362: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.369: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.376: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.383: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.391: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.835: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.842: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.849: INFO: Unable to read jessie_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.856: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.863: INFO: Unable to read jessie_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.870: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.877: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:18.883: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:19.242: INFO: Lookups using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1281 wheezy_tcp@dns-test-service.dns-1281 wheezy_udp@dns-test-service.dns-1281.svc wheezy_tcp@dns-test-service.dns-1281.svc wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1281 jessie_tcp@dns-test-service.dns-1281 jessie_udp@dns-test-service.dns-1281.svc jessie_tcp@dns-test-service.dns-1281.svc jessie_udp@_http._tcp.dns-test-service.dns-1281.svc jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc]

Apr 27 16:42:23.301: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.308: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.315: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.322: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.329: INFO: Unable to read wheezy_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.336: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.343: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.350: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.754: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.762: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.769: INFO: Unable to read jessie_udp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.776: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281 from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.782: INFO: Unable to read jessie_udp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.789: INFO: Unable to read jessie_tcp@dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.796: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:23.803: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc from pod dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7: the server could not find the requested resource (get pods dns-test-bb805114-ac1e-484b-89b9-4324e83787a7)
Apr 27 16:42:24.161: INFO: Lookups using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1281 wheezy_tcp@dns-test-service.dns-1281 wheezy_udp@dns-test-service.dns-1281.svc wheezy_tcp@dns-test-service.dns-1281.svc wheezy_udp@_http._tcp.dns-test-service.dns-1281.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1281.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1281 jessie_tcp@dns-test-service.dns-1281 jessie_udp@dns-test-service.dns-1281.svc jessie_tcp@dns-test-service.dns-1281.svc jessie_udp@_http._tcp.dns-test-service.dns-1281.svc jessie_tcp@_http._tcp.dns-test-service.dns-1281.svc]

Apr 27 16:42:30.108: INFO: DNS probes using dns-1281/dns-test-bb805114-ac1e-484b-89b9-4324e83787a7 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:30.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1281" for this suite.
•{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":277,"completed":126,"skipped":2456,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:30.158: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7560
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr 27 16:42:30.317: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:42:33.839: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:46.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7560" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":277,"completed":127,"skipped":2514,"failed":0}
SS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:46.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:47.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-432" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":277,"completed":128,"skipped":2516,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:47.054: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 16:42:48.224: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:42:48.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5142" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":277,"completed":129,"skipped":2531,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:42:48.250: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Apr 27 16:42:48.402: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Apr 27 16:42:48.402: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-686'
Apr 27 16:42:48.647: INFO: stderr: ""
Apr 27 16:42:48.647: INFO: stdout: "service/agnhost-slave created\n"
Apr 27 16:42:48.647: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Apr 27 16:42:48.647: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-686'
Apr 27 16:42:48.868: INFO: stderr: ""
Apr 27 16:42:48.869: INFO: stdout: "service/agnhost-master created\n"
Apr 27 16:42:48.869: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 27 16:42:48.869: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-686'
Apr 27 16:42:49.091: INFO: stderr: ""
Apr 27 16:42:49.091: INFO: stdout: "service/frontend created\n"
Apr 27 16:42:49.092: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 27 16:42:49.092: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-686'
Apr 27 16:42:49.356: INFO: stderr: ""
Apr 27 16:42:49.356: INFO: stdout: "deployment.apps/frontend created\n"
Apr 27 16:42:49.357: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 16:42:49.357: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-686'
Apr 27 16:42:49.573: INFO: stderr: ""
Apr 27 16:42:49.573: INFO: stdout: "deployment.apps/agnhost-master created\n"
Apr 27 16:42:49.574: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 27 16:42:49.574: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-686'
Apr 27 16:42:49.844: INFO: stderr: ""
Apr 27 16:42:49.844: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Apr 27 16:42:49.844: INFO: Waiting for all frontend pods to be Running.
Apr 27 16:42:54.895: INFO: Waiting for frontend to serve content.
Apr 27 16:42:54.991: INFO: Trying to add a new entry to the guestbook.
Apr 27 16:42:55.123: INFO: Verifying that added entry can be retrieved.
Apr 27 16:42:55.171: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
Apr 27 16:43:00.182: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-686'
Apr 27 16:43:00.271: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:43:00.271: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:43:00.271: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-686'
Apr 27 16:43:00.402: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:43:00.402: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:43:00.402: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-686'
Apr 27 16:43:00.533: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:43:00.533: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:43:00.533: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-686'
Apr 27 16:43:00.659: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:43:00.659: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:43:00.660: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-686'
Apr 27 16:43:00.785: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:43:00.785: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 27 16:43:00.785: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-686'
Apr 27 16:43:00.909: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:43:00.909: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:00.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-686" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":277,"completed":130,"skipped":2540,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:00.922: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4053
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-75138809-a2e9-435c-91b7-29d6edd8b8ca
STEP: Creating a pod to test consume secrets
Apr 27 16:43:01.082: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae" in namespace "projected-4053" to be "Succeeded or Failed"
Apr 27 16:43:01.086: INFO: Pod "pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.962128ms
Apr 27 16:43:03.091: INFO: Pod "pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009157865s
STEP: Saw pod success
Apr 27 16:43:03.091: INFO: Pod "pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae" satisfied condition "Succeeded or Failed"
Apr 27 16:43:03.095: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:43:03.116: INFO: Waiting for pod pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae to disappear
Apr 27 16:43:03.120: INFO: Pod pod-projected-secrets-0f5eefac-c429-42f6-882d-f22a6394f1ae no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:03.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4053" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":131,"skipped":2562,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:03.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Apr 27 16:43:03.295: INFO: Waiting up to 5m0s for pod "var-expansion-596782cf-1ef8-43c8-acea-610323b9545e" in namespace "var-expansion-2976" to be "Succeeded or Failed"
Apr 27 16:43:03.299: INFO: Pod "var-expansion-596782cf-1ef8-43c8-acea-610323b9545e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194588ms
Apr 27 16:43:05.304: INFO: Pod "var-expansion-596782cf-1ef8-43c8-acea-610323b9545e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009504709s
STEP: Saw pod success
Apr 27 16:43:05.304: INFO: Pod "var-expansion-596782cf-1ef8-43c8-acea-610323b9545e" satisfied condition "Succeeded or Failed"
Apr 27 16:43:05.309: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod var-expansion-596782cf-1ef8-43c8-acea-610323b9545e container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:43:05.330: INFO: Waiting for pod var-expansion-596782cf-1ef8-43c8-acea-610323b9545e to disappear
Apr 27 16:43:05.333: INFO: Pod var-expansion-596782cf-1ef8-43c8-acea-610323b9545e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:05.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2976" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":277,"completed":132,"skipped":2577,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:05.346: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:43:05.493: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:43:05.508: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:43:05.512: INFO: 
Logging pods the kubelet thinks is on node izgw82palggheybhhd1s46z before test
Apr 27 16:43:05.530: INFO: node-exporter-k58cv from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.530: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:43:05.530: INFO: calico-node-xjxjf from kube-system started at 2020-04-27 16:33:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.530: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:43:05.530: INFO: kube-proxy-r447h from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.530: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:43:05.530: INFO: node-problem-detector-m6qcf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.530: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:43:05.530: INFO: csi-disk-plugin-alicloud-hzxms from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 16:43:05.530: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 16:43:05.530: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 16:43:05.530: INFO: 
Logging pods the kubelet thinks is on node izgw873bmqhhfhflh483llz before test
Apr 27 16:43:05.607: INFO: addons-nginx-ingress-controller-6cf77756b5-rwfsq from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:43:05.607: INFO: dashboard-metrics-scraper-76c7b697bc-zfk9z from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:43:05.607: INFO: kube-proxy-v48zq from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:43:05.607: INFO: calico-kube-controllers-77dcb8f688-44xhb from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:43:05.607: INFO: coredns-5cb857d789-5cvkp from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:43:05.607: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-qp9pw from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:43:05.607: INFO: vpn-shoot-6f75686cfb-ntkwh from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:43:05.607: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-dtlrp from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:43:05.607: INFO: calico-node-p7gsw from kube-system started at 2020-04-27 16:33:54 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:43:05.607: INFO: csi-disk-plugin-alicloud-9szgk from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 16:43:05.607: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 16:43:05.607: INFO: calico-typha-vertical-autoscaler-5b477c88cf-ltrk8 from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:43:05.607: INFO: coredns-5cb857d789-x7mvm from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:43:05.607: INFO: kubernetes-dashboard-6b586c4cb4-nqch8 from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:43:05.607: INFO: calico-node-vertical-autoscaler-74d4897db8-m2vrd from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:43:05.607: INFO: node-exporter-gjwg5 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:43:05.607: INFO: metrics-server-7ff88f9d88-zmzhg from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:43:05.607: INFO: blackbox-exporter-5dc75b79b7-xshtf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:43:05.607: INFO: node-problem-detector-9ntf8 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:43:05.607: INFO: calico-typha-deploy-784665cc66-b2n69 from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:43:05.607: INFO: agnhost-slave-85bc7468c4-wrk4z from kubectl-686 started at 2020-04-27 16:42:49 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:05.607: INFO: 	Container slave ready: false, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609bad932029e26], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1609bad932556998], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:06.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7089" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":277,"completed":133,"skipped":2578,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:06.654: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8891
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:43:06.803: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:13.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8891" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":277,"completed":134,"skipped":2585,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:13.428: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:13.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3796" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":277,"completed":135,"skipped":2598,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:13.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-66af0de3-2e99-468a-89ac-622078d8f6fc
STEP: Creating a pod to test consume configMaps
Apr 27 16:43:14.236: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca" in namespace "projected-7392" to be "Succeeded or Failed"
Apr 27 16:43:14.314: INFO: Pod "pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca": Phase="Pending", Reason="", readiness=false. Elapsed: 77.8409ms
Apr 27 16:43:16.319: INFO: Pod "pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.082891688s
STEP: Saw pod success
Apr 27 16:43:16.319: INFO: Pod "pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca" satisfied condition "Succeeded or Failed"
Apr 27 16:43:16.324: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:43:16.345: INFO: Waiting for pod pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca to disappear
Apr 27 16:43:16.349: INFO: Pod pod-projected-configmaps-e449a007-c6ad-4e27-abec-bd4e2d2293ca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:16.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7392" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":136,"skipped":2629,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:16.363: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-326
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:43:16.814: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:43:18.827: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602596, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602596, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602596, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602596, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:43:21.841: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr 27 16:43:23.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-326 to-be-attached-pod -i -c=container1'
Apr 27 16:43:24.259: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:24.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-326" for this suite.
STEP: Destroying namespace "webhook-326-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":277,"completed":137,"skipped":2679,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:24.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:43:24.797: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:43:27.821: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:27.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4562" for this suite.
STEP: Destroying namespace "webhook-4562-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":277,"completed":138,"skipped":2683,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:27.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-4ff5a46b-c960-4d30-9bb5-f564c7bee9b3
STEP: Creating a pod to test consume secrets
Apr 27 16:43:28.041: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d" in namespace "projected-8302" to be "Succeeded or Failed"
Apr 27 16:43:28.045: INFO: Pod "pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.273382ms
Apr 27 16:43:30.051: INFO: Pod "pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009802948s
STEP: Saw pod success
Apr 27 16:43:30.051: INFO: Pod "pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d" satisfied condition "Succeeded or Failed"
Apr 27 16:43:30.055: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 27 16:43:30.080: INFO: Waiting for pod pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d to disappear
Apr 27 16:43:30.085: INFO: Pod pod-projected-secrets-a72ad19b-3517-4777-9fc8-013d8fd1f74d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:30.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8302" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":139,"skipped":2712,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:30.098: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-0a3fe83f-96a6-4184-bed3-8d7c0724fdd8
STEP: Creating a pod to test consume configMaps
Apr 27 16:43:30.258: INFO: Waiting up to 5m0s for pod "pod-configmaps-2373de51-3060-4435-b3da-ce609035931c" in namespace "configmap-9576" to be "Succeeded or Failed"
Apr 27 16:43:30.263: INFO: Pod "pod-configmaps-2373de51-3060-4435-b3da-ce609035931c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.455541ms
Apr 27 16:43:32.268: INFO: Pod "pod-configmaps-2373de51-3060-4435-b3da-ce609035931c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009423737s
STEP: Saw pod success
Apr 27 16:43:32.268: INFO: Pod "pod-configmaps-2373de51-3060-4435-b3da-ce609035931c" satisfied condition "Succeeded or Failed"
Apr 27 16:43:32.272: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-2373de51-3060-4435-b3da-ce609035931c container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:43:32.293: INFO: Waiting for pod pod-configmaps-2373de51-3060-4435-b3da-ce609035931c to disappear
Apr 27 16:43:32.297: INFO: Pod pod-configmaps-2373de51-3060-4435-b3da-ce609035931c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:32.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9576" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":277,"completed":140,"skipped":2717,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:32.309: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8363
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8363
STEP: creating replication controller externalsvc in namespace services-8363
I0427 16:43:32.481222    7398 runners.go:190] Created replication controller with name: externalsvc, namespace: services-8363, replica count: 2
I0427 16:43:35.531717    7398 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr 27 16:43:35.553: INFO: Creating new exec pod
Apr 27 16:43:37.570: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-8363 execpod72sbv -- /bin/sh -x -c nslookup nodeport-service'
Apr 27 16:43:38.154: INFO: stderr: "+ nslookup nodeport-service\n"
Apr 27 16:43:38.154: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-8363.svc.cluster.local\tcanonical name = externalsvc.services-8363.svc.cluster.local.\nName:\texternalsvc.services-8363.svc.cluster.local\nAddress: 100.111.132.119\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8363, will wait for the garbage collector to delete the pods
Apr 27 16:43:38.216: INFO: Deleting ReplicationController externalsvc took: 6.52431ms
Apr 27 16:43:44.416: INFO: Terminating ReplicationController externalsvc pods took: 6.200341472s
Apr 27 16:43:55.030: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:55.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8363" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":277,"completed":141,"skipped":2720,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:55.053: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-853
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 16:43:55.206: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 16:43:55.222: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 16:43:55.226: INFO: 
Logging pods the kubelet thinks is on node izgw82palggheybhhd1s46z before test
Apr 27 16:43:55.250: INFO: csi-disk-plugin-alicloud-hzxms from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 16:43:55.250: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 16:43:55.250: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 16:43:55.250: INFO: calico-node-xjxjf from kube-system started at 2020-04-27 16:33:40 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.250: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 16:43:55.250: INFO: node-exporter-k58cv from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.250: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:43:55.250: INFO: node-problem-detector-m6qcf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.250: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:43:55.250: INFO: kube-proxy-r447h from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.250: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:43:55.250: INFO: execpod72sbv from services-8363 started at 2020-04-27 16:43:35 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.250: INFO: 	Container agnhost-pause ready: true, restart count 0
Apr 27 16:43:55.250: INFO: 
Logging pods the kubelet thinks is on node izgw873bmqhhfhflh483llz before test
Apr 27 16:43:55.318: INFO: csi-disk-plugin-alicloud-9szgk from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 16:43:55.318: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 16:43:55.318: INFO: calico-typha-vertical-autoscaler-5b477c88cf-ltrk8 from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:43:55.318: INFO: coredns-5cb857d789-x7mvm from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:43:55.318: INFO: kubernetes-dashboard-6b586c4cb4-nqch8 from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 16:43:55.318: INFO: calico-node-vertical-autoscaler-74d4897db8-m2vrd from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:43:55.318: INFO: node-exporter-gjwg5 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 16:43:55.318: INFO: metrics-server-7ff88f9d88-zmzhg from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 16:43:55.318: INFO: blackbox-exporter-5dc75b79b7-xshtf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 16:43:55.318: INFO: node-problem-detector-9ntf8 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 16:43:55.318: INFO: calico-typha-deploy-784665cc66-b2n69 from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 16:43:55.318: INFO: addons-nginx-ingress-controller-6cf77756b5-rwfsq from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 16:43:55.318: INFO: dashboard-metrics-scraper-76c7b697bc-zfk9z from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 16:43:55.318: INFO: kube-proxy-v48zq from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 16:43:55.318: INFO: calico-kube-controllers-77dcb8f688-44xhb from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 16:43:55.318: INFO: coredns-5cb857d789-5cvkp from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container coredns ready: true, restart count 0
Apr 27 16:43:55.318: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-qp9pw from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 16:43:55.318: INFO: vpn-shoot-6f75686cfb-ntkwh from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 16:43:55.318: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-dtlrp from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 16:43:55.318: INFO: calico-node-p7gsw from kube-system started at 2020-04-27 16:33:54 +0000 UTC (1 container statuses recorded)
Apr 27 16:43:55.318: INFO: 	Container calico-node ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node izgw82palggheybhhd1s46z
STEP: verifying the node has the label node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod addons-nginx-ingress-controller-6cf77756b5-rwfsq requesting resource cpu=100m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-qp9pw requesting resource cpu=0m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod blackbox-exporter-5dc75b79b7-xshtf requesting resource cpu=5m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod calico-kube-controllers-77dcb8f688-44xhb requesting resource cpu=10m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod calico-node-p7gsw requesting resource cpu=250m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod calico-node-vertical-autoscaler-74d4897db8-m2vrd requesting resource cpu=10m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod calico-node-xjxjf requesting resource cpu=250m on Node izgw82palggheybhhd1s46z
Apr 27 16:43:55.631: INFO: Pod calico-typha-deploy-784665cc66-b2n69 requesting resource cpu=200m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod calico-typha-horizontal-autoscaler-6fdd5d8746-dtlrp requesting resource cpu=10m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod calico-typha-vertical-autoscaler-5b477c88cf-ltrk8 requesting resource cpu=10m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod coredns-5cb857d789-5cvkp requesting resource cpu=50m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod coredns-5cb857d789-x7mvm requesting resource cpu=50m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod csi-disk-plugin-alicloud-9szgk requesting resource cpu=0m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod csi-disk-plugin-alicloud-hzxms requesting resource cpu=0m on Node izgw82palggheybhhd1s46z
Apr 27 16:43:55.631: INFO: Pod kube-proxy-r447h requesting resource cpu=20m on Node izgw82palggheybhhd1s46z
Apr 27 16:43:55.631: INFO: Pod kube-proxy-v48zq requesting resource cpu=20m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod metrics-server-7ff88f9d88-zmzhg requesting resource cpu=20m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod node-exporter-gjwg5 requesting resource cpu=5m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod node-exporter-k58cv requesting resource cpu=5m on Node izgw82palggheybhhd1s46z
Apr 27 16:43:55.631: INFO: Pod node-problem-detector-9ntf8 requesting resource cpu=20m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod node-problem-detector-m6qcf requesting resource cpu=20m on Node izgw82palggheybhhd1s46z
Apr 27 16:43:55.631: INFO: Pod vpn-shoot-6f75686cfb-ntkwh requesting resource cpu=100m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod dashboard-metrics-scraper-76c7b697bc-zfk9z requesting resource cpu=0m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.631: INFO: Pod kubernetes-dashboard-6b586c4cb4-nqch8 requesting resource cpu=50m on Node izgw873bmqhhfhflh483llz
Apr 27 16:43:55.632: INFO: Pod execpod72sbv requesting resource cpu=0m on Node izgw82palggheybhhd1s46z
STEP: Starting Pods to consume most of the cluster CPU.
Apr 27 16:43:55.632: INFO: Creating a pod which consumes cpu=1137m on Node izgw82palggheybhhd1s46z
Apr 27 16:43:55.640: INFO: Creating a pod which consumes cpu=707m on Node izgw873bmqhhfhflh483llz
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90.1609bae4d6994b19], Reason = [Scheduled], Message = [Successfully assigned sched-pred-853/filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90 to izgw82palggheybhhd1s46z]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90.1609bae5141e58ea], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90.1609bae5164e9401], Reason = [Created], Message = [Created container filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90.1609bae51c7252c3], Reason = [Started], Message = [Started container filler-pod-c3b78808-19b7-44e4-bb05-803b08506b90]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66.1609bae4d6e8a6be], Reason = [Scheduled], Message = [Successfully assigned sched-pred-853/filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66 to izgw873bmqhhfhflh483llz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66.1609bae504d1b257], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66.1609bae507239f3f], Reason = [Created], Message = [Created container filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66.1609bae50f6fbab9], Reason = [Started], Message = [Started container filler-pod-d2361178-5617-457e-9a38-0d3f93e01c66]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609bae54fcc2e60], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1609bae5501bd0ff], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node izgw82palggheybhhd1s46z
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node izgw873bmqhhfhflh483llz
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:43:58.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-853" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":277,"completed":142,"skipped":2763,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:43:58.723: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:05.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9299" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":277,"completed":143,"skipped":2779,"failed":0}
SSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:05.899: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-6537
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:06.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-6537" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":277,"completed":144,"skipped":2783,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:06.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:44:06.276: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9" in namespace "projected-8335" to be "Succeeded or Failed"
Apr 27 16:44:06.280: INFO: Pod "downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101839ms
Apr 27 16:44:08.285: INFO: Pod "downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00914868s
STEP: Saw pod success
Apr 27 16:44:08.285: INFO: Pod "downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9" satisfied condition "Succeeded or Failed"
Apr 27 16:44:08.289: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9 container client-container: <nil>
STEP: delete the pod
Apr 27 16:44:08.310: INFO: Waiting for pod downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9 to disappear
Apr 27 16:44:08.314: INFO: Pod downwardapi-volume-d42af01e-5b01-4fd1-afae-4878b612a1a9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:08.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8335" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":145,"skipped":2810,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:08.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-9abaa774-062b-4d23-8c78-68900c6b0e77 in namespace container-probe-4206
Apr 27 16:44:10.498: INFO: Started pod liveness-9abaa774-062b-4d23-8c78-68900c6b0e77 in namespace container-probe-4206
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:44:10.503: INFO: Initial restart count of pod liveness-9abaa774-062b-4d23-8c78-68900c6b0e77 is 0
Apr 27 16:44:28.551: INFO: Restart count of pod container-probe-4206/liveness-9abaa774-062b-4d23-8c78-68900c6b0e77 is now 1 (18.04815632s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:28.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4206" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":277,"completed":146,"skipped":2813,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:28.572: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:44:28.725: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 27 16:44:28.734: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 27 16:44:33.739: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 16:44:33.739: INFO: Creating deployment "test-rolling-update-deployment"
Apr 27 16:44:33.744: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 27 16:44:33.752: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 27 16:44:35.761: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 27 16:44:35.765: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 16:44:35.776: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3246 /apis/apps/v1/namespaces/deployment-3246/deployments/test-rolling-update-deployment 09eb495f-e2a3-4a08-85c0-4edec361c6d5 20430 1 2020-04-27 16:44:33 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-04-27 16:44:33 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:44:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004689de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 16:44:33 +0000 UTC,LastTransitionTime:2020-04-27 16:44:33 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-04-27 16:44:35 +0000 UTC,LastTransitionTime:2020-04-27 16:44:33 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 16:44:35.781: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-3246 /apis/apps/v1/namespaces/deployment-3246/replicasets/test-rolling-update-deployment-59d5cb45c7 efb424b7-4704-49a2-9b0f-71fb3b38b99a 20423 1 2020-04-27 16:44:33 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 09eb495f-e2a3-4a08-85c0-4edec361c6d5 0xc005ed0857 0xc005ed0858}] []  [{kube-controller-manager Update apps/v1 2020-04-27 16:44:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 57 101 98 52 57 53 102 45 101 50 97 51 45 52 97 48 56 45 56 53 99 48 45 52 101 100 101 99 51 54 49 99 54 100 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005ed0938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:44:35.781: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 27 16:44:35.781: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3246 /apis/apps/v1/namespaces/deployment-3246/replicasets/test-rolling-update-controller 6f0b42c2-c895-4bfe-90dd-1f33d9a4090d 20429 2 2020-04-27 16:44:28 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 09eb495f-e2a3-4a08-85c0-4edec361c6d5 0xc005ed0667 0xc005ed0668}] []  [{e2e.test Update apps/v1 2020-04-27 16:44:28 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 16:44:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 57 101 98 52 57 53 102 45 101 50 97 51 45 52 97 48 56 45 56 53 99 48 45 52 101 100 101 99 51 54 49 99 54 100 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005ed0788 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 27 16:44:35.785: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-j9nnc" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-j9nnc test-rolling-update-deployment-59d5cb45c7- deployment-3246 /api/v1/namespaces/deployment-3246/pods/test-rolling-update-deployment-59d5cb45c7-j9nnc bccee039-38e3-4009-acac-45bc10b2158d 20422 0 2020-04-27 16:44:33 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:100.64.1.173/32 cni.projectcalico.org/podIPs:100.64.1.173/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 efb424b7-4704-49a2-9b0f-71fb3b38b99a 0xc005f162e7 0xc005f162e8}] []  [{kube-controller-manager Update v1 2020-04-27 16:44:33 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 102 98 52 50 52 98 55 45 52 55 48 52 45 52 57 97 50 45 57 98 48 102 45 55 49 102 98 51 98 51 56 98 57 57 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 16:44:34 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 16:44:35 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 49 55 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6svw7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6svw7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6svw7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:44:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 16:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.173,StartTime:2020-04-27 16:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 16:44:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://ddecbc45ff87ad86e536adbb8c9f10e61dc48457bdae00b8712dfd061f5c950a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.173,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:35.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3246" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":277,"completed":147,"skipped":2832,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:35.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-959
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:44:35.943: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:44:35.970: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:44:37.974: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:44:39.974: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:44:41.975: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:44:43.975: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:44:45.974: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:44:47.974: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:44:47.983: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:44:50.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.175:8080/dial?request=hostname&protocol=udp&host=100.64.1.174&port=8081&tries=1'] Namespace:pod-network-test-959 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:44:50.011: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:44:50.391: INFO: Waiting for responses: map[]
Apr 27 16:44:50.396: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.175:8080/dial?request=hostname&protocol=udp&host=100.64.0.56&port=8081&tries=1'] Namespace:pod-network-test-959 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:44:50.396: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:44:50.782: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:44:50.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-959" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":277,"completed":148,"skipped":2844,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:44:50.796: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4639
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-rr22
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 16:44:50.960: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rr22" in namespace "subpath-4639" to be "Succeeded or Failed"
Apr 27 16:44:50.964: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Pending", Reason="", readiness=false. Elapsed: 3.979022ms
Apr 27 16:44:52.969: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 2.008942945s
Apr 27 16:44:54.974: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 4.013885361s
Apr 27 16:44:56.978: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 6.018472254s
Apr 27 16:44:58.984: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 8.023814896s
Apr 27 16:45:00.988: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 10.02856694s
Apr 27 16:45:02.993: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 12.033556922s
Apr 27 16:45:04.998: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 14.038148024s
Apr 27 16:45:07.002: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 16.042668373s
Apr 27 16:45:09.007: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 18.047366894s
Apr 27 16:45:11.012: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Running", Reason="", readiness=true. Elapsed: 20.052145934s
Apr 27 16:45:13.017: INFO: Pod "pod-subpath-test-downwardapi-rr22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.057342989s
STEP: Saw pod success
Apr 27 16:45:13.017: INFO: Pod "pod-subpath-test-downwardapi-rr22" satisfied condition "Succeeded or Failed"
Apr 27 16:45:13.021: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-subpath-test-downwardapi-rr22 container test-container-subpath-downwardapi-rr22: <nil>
STEP: delete the pod
Apr 27 16:45:13.044: INFO: Waiting for pod pod-subpath-test-downwardapi-rr22 to disappear
Apr 27 16:45:13.048: INFO: Pod pod-subpath-test-downwardapi-rr22 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rr22
Apr 27 16:45:13.048: INFO: Deleting pod "pod-subpath-test-downwardapi-rr22" in namespace "subpath-4639"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:13.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4639" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":277,"completed":149,"skipped":2875,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:13.064: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5453
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-5453
Apr 27 16:45:13.227: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:45:23.233: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 16:45:23.255: INFO: Deleting all statefulset in ns statefulset-5453
Apr 27 16:45:23.260: INFO: Scaling statefulset ss to 0
Apr 27 16:45:53.280: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:45:53.283: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:45:53.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5453" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":277,"completed":150,"skipped":2882,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:45:53.310: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-1751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 27 16:45:59.499: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:45:59.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:45:59.877: INFO: Exec stderr: ""
Apr 27 16:45:59.877: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:45:59.877: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:00.284: INFO: Exec stderr: ""
Apr 27 16:46:00.284: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:00.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:00.724: INFO: Exec stderr: ""
Apr 27 16:46:00.724: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:00.724: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:01.136: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 27 16:46:01.137: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:01.137: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:01.501: INFO: Exec stderr: ""
Apr 27 16:46:01.501: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:01.501: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:01.872: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 27 16:46:01.872: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:01.872: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:02.246: INFO: Exec stderr: ""
Apr 27 16:46:02.246: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:02.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:02.653: INFO: Exec stderr: ""
Apr 27 16:46:02.653: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:02.653: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:03.039: INFO: Exec stderr: ""
Apr 27 16:46:03.039: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1751 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:03.039: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:03.422: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:03.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1751" for this suite.
•{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":151,"skipped":2924,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:03.436: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-129.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-129.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:46:08.188: INFO: DNS probes using dns-129/dns-test-0353d4e7-a0f1-4e13-870d-296cf7a22990 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:08.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-129" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":277,"completed":152,"skipped":2925,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:08.210: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Apr 27 16:46:08.365: INFO: Created pod &Pod{ObjectMeta:{dns-2305  dns-2305 /api/v1/namespaces/dns-2305/pods/dns-2305 372c91bb-8066-4f99-a63f-d4620343cf60 21027 0 2020-04-27 16:46:08 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2020-04-27 16:46:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-p9gb9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-p9gb9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-p9gb9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 27 16:46:08.369: INFO: The status of Pod dns-2305 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:46:10.374: INFO: The status of Pod dns-2305 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Apr 27 16:46:10.375: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-2305 PodName:dns-2305 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:10.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Verifying customized DNS server is configured on pod...
Apr 27 16:46:10.748: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-2305 PodName:dns-2305 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:46:10.748: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:46:11.130: INFO: Deleting pod dns-2305...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:11.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2305" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":277,"completed":153,"skipped":2938,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:11.152: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7311
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-a6fc829d-43e1-42b6-b9c2-c617df447e87
STEP: Creating configMap with name cm-test-opt-upd-5a621f71-c17d-4f79-8042-e09b484c0025
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a6fc829d-43e1-42b6-b9c2-c617df447e87
STEP: Updating configmap cm-test-opt-upd-5a621f71-c17d-4f79-8042-e09b484c0025
STEP: Creating configMap with name cm-test-opt-create-cdda7a2e-ed34-4675-9e08-4ec410e0eb2d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:15.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7311" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":154,"skipped":2942,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:15.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:46:15.896: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67" in namespace "projected-7564" to be "Succeeded or Failed"
Apr 27 16:46:15.901: INFO: Pod "downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67": Phase="Pending", Reason="", readiness=false. Elapsed: 4.216876ms
Apr 27 16:46:17.906: INFO: Pod "downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009551046s
STEP: Saw pod success
Apr 27 16:46:17.906: INFO: Pod "downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67" satisfied condition "Succeeded or Failed"
Apr 27 16:46:17.911: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67 container client-container: <nil>
STEP: delete the pod
Apr 27 16:46:17.970: INFO: Waiting for pod downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67 to disappear
Apr 27 16:46:17.974: INFO: Pod downwardapi-volume-c9f41223-832b-472f-a334-7a52b66e7a67 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:17.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7564" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":155,"skipped":2947,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:17.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:46:18.498: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:46:20.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602778, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602778, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602778, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602778, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:46:23.526: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:46:23.532: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-848-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:25.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4276" for this suite.
STEP: Destroying namespace "webhook-4276-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":277,"completed":156,"skipped":2958,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:25.397: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 27 16:46:25.559: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 27 16:46:30.563: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:31.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1700" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":277,"completed":157,"skipped":2977,"failed":0}
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:31.598: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:46:31.754: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3d83c722-b908-4c94-86bb-9f1ddcc77969" in namespace "security-context-test-8515" to be "Succeeded or Failed"
Apr 27 16:46:31.758: INFO: Pod "busybox-privileged-false-3d83c722-b908-4c94-86bb-9f1ddcc77969": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28051ms
Apr 27 16:46:33.764: INFO: Pod "busybox-privileged-false-3d83c722-b908-4c94-86bb-9f1ddcc77969": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009477079s
Apr 27 16:46:33.764: INFO: Pod "busybox-privileged-false-3d83c722-b908-4c94-86bb-9f1ddcc77969" satisfied condition "Succeeded or Failed"
Apr 27 16:46:33.778: INFO: Got logs for pod "busybox-privileged-false-3d83c722-b908-4c94-86bb-9f1ddcc77969": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:33.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8515" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":158,"skipped":2982,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:33.791: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:46:33.937: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Apr 27 16:46:34.015: INFO: stderr: ""
Apr 27 16:46:34.015: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:56:40Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.2\", GitCommit:\"52c56ce7a8272c798dbc29846288d7cd9fbae032\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:48:36Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:46:34.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7875" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":277,"completed":159,"skipped":2992,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:46:34.027: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 16:46:34.173: INFO: PodSpec: initContainers in spec.initContainers
Apr 27 16:47:15.788: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-21cff4d9-c1bb-4417-8846-d89f57d9ee39", GenerateName:"", Namespace:"init-container-5115", SelfLink:"/api/v1/namespaces/init-container-5115/pods/pod-init-21cff4d9-c1bb-4417-8846-d89f57d9ee39", UID:"db054388-285a-4461-bb7e-bb9c3b0dac29", ResourceVersion:"21554", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63723602794, loc:(*time.Location)(0x7b501e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"173218061"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.187/32", "cni.projectcalico.org/podIPs":"100.64.1.187/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00558a120), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00558a180)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00558a1e0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00558a240)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc00558a2a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00558a300)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-b78hd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0031ce000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b78hd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b78hd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-b78hd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0051ec0c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"izgw82palggheybhhd1s46z", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000826000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0051ec140)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0051ec160)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0051ec168), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0051ec16c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602794, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602794, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602794, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602794, loc:(*time.Location)(0x7b501e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.31.184", PodIP:"100.64.1.187", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.187"}}, StartTime:(*v1.Time)(0xc00558a360), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000826150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008261c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://e6dc5ebb57e92789c7eeb30a4a2c5662f5b3a4bdb58f7bfee9eb099e13eca0f1", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00558a420), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00558a3c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0051ec1ef)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:15.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5115" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":277,"completed":160,"skipped":3000,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:15.801: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6507
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:47:15.955: INFO: Waiting up to 5m0s for pod "busybox-user-65534-67d127c6-0239-4ca7-afc4-62ec8ecf039a" in namespace "security-context-test-6507" to be "Succeeded or Failed"
Apr 27 16:47:15.960: INFO: Pod "busybox-user-65534-67d127c6-0239-4ca7-afc4-62ec8ecf039a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0657ms
Apr 27 16:47:17.965: INFO: Pod "busybox-user-65534-67d127c6-0239-4ca7-afc4-62ec8ecf039a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009283333s
Apr 27 16:47:17.965: INFO: Pod "busybox-user-65534-67d127c6-0239-4ca7-afc4-62ec8ecf039a" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:17.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6507" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":161,"skipped":3010,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:17.979: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 16:47:18.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-56775d36-8622-4350-89e7-952a52183169" in namespace "projected-6462" to be "Succeeded or Failed"
Apr 27 16:47:18.142: INFO: Pod "downwardapi-volume-56775d36-8622-4350-89e7-952a52183169": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016774ms
Apr 27 16:47:20.147: INFO: Pod "downwardapi-volume-56775d36-8622-4350-89e7-952a52183169": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009091493s
STEP: Saw pod success
Apr 27 16:47:20.147: INFO: Pod "downwardapi-volume-56775d36-8622-4350-89e7-952a52183169" satisfied condition "Succeeded or Failed"
Apr 27 16:47:20.151: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-56775d36-8622-4350-89e7-952a52183169 container client-container: <nil>
STEP: delete the pod
Apr 27 16:47:20.174: INFO: Waiting for pod downwardapi-volume-56775d36-8622-4350-89e7-952a52183169 to disappear
Apr 27 16:47:20.178: INFO: Pod downwardapi-volume-56775d36-8622-4350-89e7-952a52183169 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:20.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6462" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":277,"completed":162,"skipped":3032,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:20.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-4839665b-e589-47db-931f-358ccccc69ef
STEP: Creating a pod to test consume configMaps
Apr 27 16:47:20.353: INFO: Waiting up to 5m0s for pod "pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c" in namespace "configmap-6636" to be "Succeeded or Failed"
Apr 27 16:47:20.357: INFO: Pod "pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51278ms
Apr 27 16:47:22.363: INFO: Pod "pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009964867s
STEP: Saw pod success
Apr 27 16:47:22.363: INFO: Pod "pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c" satisfied condition "Succeeded or Failed"
Apr 27 16:47:22.367: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:47:22.389: INFO: Waiting for pod pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c to disappear
Apr 27 16:47:22.392: INFO: Pod pod-configmaps-816dfa2b-b32d-4ce8-80bd-8ca990118e6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:22.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6636" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":163,"skipped":3034,"failed":0}
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:22.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6368
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-6368
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 16:47:22.554: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 16:47:22.583: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 16:47:24.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:26.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:28.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:30.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:32.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:34.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:36.588: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 16:47:38.588: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 16:47:38.597: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 16:47:42.625: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.192:8080/dial?request=hostname&protocol=http&host=100.64.1.191&port=8080&tries=1'] Namespace:pod-network-test-6368 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:47:42.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:47:43.105: INFO: Waiting for responses: map[]
Apr 27 16:47:43.110: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.192:8080/dial?request=hostname&protocol=http&host=100.64.0.57&port=8080&tries=1'] Namespace:pod-network-test-6368 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 16:47:43.110: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 16:47:43.486: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:47:43.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6368" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":277,"completed":164,"skipped":3036,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:47:43.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:47:43.728: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 27 16:47:43.738: INFO: Number of nodes with available pods: 0
Apr 27 16:47:43.738: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 27 16:47:43.759: INFO: Number of nodes with available pods: 0
Apr 27 16:47:43.760: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:44.765: INFO: Number of nodes with available pods: 0
Apr 27 16:47:44.765: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:45.765: INFO: Number of nodes with available pods: 1
Apr 27 16:47:45.765: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 27 16:47:45.788: INFO: Number of nodes with available pods: 1
Apr 27 16:47:45.788: INFO: Number of running nodes: 0, number of available pods: 1
Apr 27 16:47:46.793: INFO: Number of nodes with available pods: 0
Apr 27 16:47:46.793: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 27 16:47:46.808: INFO: Number of nodes with available pods: 0
Apr 27 16:47:46.808: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:47.812: INFO: Number of nodes with available pods: 0
Apr 27 16:47:47.812: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:48.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:48.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:49.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:49.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:50.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:50.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:51.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:51.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:52.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:52.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:53.812: INFO: Number of nodes with available pods: 0
Apr 27 16:47:53.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:54.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:54.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:55.813: INFO: Number of nodes with available pods: 0
Apr 27 16:47:55.813: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:47:56.813: INFO: Number of nodes with available pods: 1
Apr 27 16:47:56.813: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4145, will wait for the garbage collector to delete the pods
Apr 27 16:47:56.883: INFO: Deleting DaemonSet.extensions daemon-set took: 6.666471ms
Apr 27 16:47:57.483: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.375634ms
Apr 27 16:48:04.988: INFO: Number of nodes with available pods: 0
Apr 27 16:48:04.989: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:48:04.993: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4145/daemonsets","resourceVersion":"21931"},"items":null}

Apr 27 16:48:04.997: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4145/pods","resourceVersion":"21931"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:05.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4145" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":277,"completed":165,"skipped":3037,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:05.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2211
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-697140d1-878d-4eb1-955d-2eef92b88ad7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-697140d1-878d-4eb1-955d-2eef92b88ad7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:11.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2211" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":166,"skipped":3039,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:11.359: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:48:11.797: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:48:13.812: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602891, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602891, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602891, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723602891, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:48:16.825: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:17.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7107" for this suite.
STEP: Destroying namespace "webhook-7107-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":277,"completed":167,"skipped":3049,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:17.066: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3108
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8070
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:46.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6246" for this suite.
STEP: Destroying namespace "nsdeletetest-3108" for this suite.
Apr 27 16:48:46.559: INFO: Namespace nsdeletetest-3108 was already deleted
STEP: Destroying namespace "nsdeletetest-8070" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":277,"completed":168,"skipped":3065,"failed":0}
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:46.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9315
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-9315
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9315 to expose endpoints map[]
Apr 27 16:48:46.726: INFO: successfully validated that service endpoint-test2 in namespace services-9315 exposes endpoints map[] (4.198165ms elapsed)
STEP: Creating pod pod1 in namespace services-9315
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9315 to expose endpoints map[pod1:[80]]
Apr 27 16:48:48.761: INFO: successfully validated that service endpoint-test2 in namespace services-9315 exposes endpoints map[pod1:[80]] (2.027964044s elapsed)
STEP: Creating pod pod2 in namespace services-9315
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9315 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 27 16:48:49.794: INFO: successfully validated that service endpoint-test2 in namespace services-9315 exposes endpoints map[pod1:[80] pod2:[80]] (1.025434575s elapsed)
STEP: Deleting pod pod1 in namespace services-9315
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9315 to expose endpoints map[pod2:[80]]
Apr 27 16:48:50.820: INFO: successfully validated that service endpoint-test2 in namespace services-9315 exposes endpoints map[pod2:[80]] (1.018993875s elapsed)
STEP: Deleting pod pod2 in namespace services-9315
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9315 to expose endpoints map[]
Apr 27 16:48:50.829: INFO: successfully validated that service endpoint-test2 in namespace services-9315 exposes endpoints map[] (3.774572ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:48:50.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9315" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":277,"completed":169,"skipped":3067,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:48:50.856: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-ef3b1b71-3bfa-480c-9324-696bf5ecc24a in namespace container-probe-7809
Apr 27 16:48:53.020: INFO: Started pod busybox-ef3b1b71-3bfa-480c-9324-696bf5ecc24a in namespace container-probe-7809
STEP: checking the pod's current state and verifying that restartCount is present
Apr 27 16:48:53.024: INFO: Initial restart count of pod busybox-ef3b1b71-3bfa-480c-9324-696bf5ecc24a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:52:53.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7809" for this suite.
•{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":277,"completed":170,"skipped":3081,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:52:53.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:06.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-265" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":277,"completed":171,"skipped":3108,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:06.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 16:53:07.047: INFO: Waiting up to 5m0s for pod "pod-97897038-88f3-4e6e-bb13-8dad80b8f01a" in namespace "emptydir-9868" to be "Succeeded or Failed"
Apr 27 16:53:07.051: INFO: Pod "pod-97897038-88f3-4e6e-bb13-8dad80b8f01a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090424ms
Apr 27 16:53:09.056: INFO: Pod "pod-97897038-88f3-4e6e-bb13-8dad80b8f01a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009497767s
STEP: Saw pod success
Apr 27 16:53:09.057: INFO: Pod "pod-97897038-88f3-4e6e-bb13-8dad80b8f01a" satisfied condition "Succeeded or Failed"
Apr 27 16:53:09.061: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-97897038-88f3-4e6e-bb13-8dad80b8f01a container test-container: <nil>
STEP: delete the pod
Apr 27 16:53:09.177: INFO: Waiting for pod pod-97897038-88f3-4e6e-bb13-8dad80b8f01a to disappear
Apr 27 16:53:09.182: INFO: Pod pod-97897038-88f3-4e6e-bb13-8dad80b8f01a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:09.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9868" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":172,"skipped":3110,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:09.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:53:09.345: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:11.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4004" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":277,"completed":173,"skipped":3120,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:11.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3061
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:53:11.592: INFO: Create a RollingUpdate DaemonSet
Apr 27 16:53:11.598: INFO: Check that daemon pods launch on every node of the cluster
Apr 27 16:53:11.608: INFO: Number of nodes with available pods: 0
Apr 27 16:53:11.608: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:53:12.621: INFO: Number of nodes with available pods: 0
Apr 27 16:53:12.621: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 16:53:13.621: INFO: Number of nodes with available pods: 2
Apr 27 16:53:13.621: INFO: Number of running nodes: 2, number of available pods: 2
Apr 27 16:53:13.621: INFO: Update the DaemonSet to trigger a rollout
Apr 27 16:53:13.631: INFO: Updating DaemonSet daemon-set
Apr 27 16:53:25.653: INFO: Roll back the DaemonSet before rollout is complete
Apr 27 16:53:25.662: INFO: Updating DaemonSet daemon-set
Apr 27 16:53:25.662: INFO: Make sure DaemonSet rollback is complete
Apr 27 16:53:25.667: INFO: Wrong image for pod: daemon-set-5ff27. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:53:25.667: INFO: Pod daemon-set-5ff27 is not available
Apr 27 16:53:26.677: INFO: Wrong image for pod: daemon-set-5ff27. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:53:26.677: INFO: Pod daemon-set-5ff27 is not available
Apr 27 16:53:27.677: INFO: Wrong image for pod: daemon-set-5ff27. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 27 16:53:27.677: INFO: Pod daemon-set-5ff27 is not available
Apr 27 16:53:28.677: INFO: Pod daemon-set-pztkn is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3061, will wait for the garbage collector to delete the pods
Apr 27 16:53:28.753: INFO: Deleting DaemonSet.extensions daemon-set took: 7.114804ms
Apr 27 16:53:29.354: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.338964ms
Apr 27 16:53:34.959: INFO: Number of nodes with available pods: 0
Apr 27 16:53:34.959: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 16:53:34.963: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3061/daemonsets","resourceVersion":"23721"},"items":null}

Apr 27 16:53:34.967: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3061/pods","resourceVersion":"23721"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:34.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3061" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":277,"completed":174,"skipped":3148,"failed":0}

------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:34.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4358
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:53:35.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:37.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4358" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":277,"completed":175,"skipped":3148,"failed":0}
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:37.340: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-b5kgt in namespace proxy-6585
I0427 16:53:37.502477    7398 runners.go:190] Created replication controller with name: proxy-service-b5kgt, namespace: proxy-6585, replica count: 1
I0427 16:53:38.553057    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 16:53:39.553356    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:40.553575    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:41.553849    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:42.554130    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:43.554433    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:44.554702    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0427 16:53:45.554927    7398 runners.go:190] proxy-service-b5kgt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:53:45.559: INFO: setup took 8.071795541s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 54.39349ms)
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 54.397249ms)
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 54.653798ms)
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 54.704571ms)
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 54.943063ms)
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 54.762201ms)
Apr 27 16:53:45.614: INFO: (0) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 54.843701ms)
Apr 27 16:53:45.619: INFO: (0) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 59.268901ms)
Apr 27 16:53:45.621: INFO: (0) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 61.252952ms)
Apr 27 16:53:45.621: INFO: (0) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 61.281647ms)
Apr 27 16:53:45.622: INFO: (0) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 63.051953ms)
Apr 27 16:53:45.626: INFO: (0) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 67.006648ms)
Apr 27 16:53:45.626: INFO: (0) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 67.169623ms)
Apr 27 16:53:45.628: INFO: (0) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 68.644485ms)
Apr 27 16:53:45.628: INFO: (0) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 68.588851ms)
Apr 27 16:53:45.630: INFO: (0) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 70.972871ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.248633ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 9.178349ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 9.000764ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 9.151552ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 9.260496ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 9.127554ms)
Apr 27 16:53:45.640: INFO: (1) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 9.197869ms)
Apr 27 16:53:45.641: INFO: (1) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 10.823774ms)
Apr 27 16:53:45.641: INFO: (1) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 10.886851ms)
Apr 27 16:53:45.641: INFO: (1) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 10.91917ms)
Apr 27 16:53:45.641: INFO: (1) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 10.784876ms)
Apr 27 16:53:45.641: INFO: (1) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 10.841951ms)
Apr 27 16:53:45.643: INFO: (1) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 12.674463ms)
Apr 27 16:53:45.643: INFO: (1) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 12.595029ms)
Apr 27 16:53:45.645: INFO: (1) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 14.400193ms)
Apr 27 16:53:45.645: INFO: (1) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 14.377483ms)
Apr 27 16:53:45.654: INFO: (2) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 8.471898ms)
Apr 27 16:53:45.654: INFO: (2) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 8.777049ms)
Apr 27 16:53:45.654: INFO: (2) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.514252ms)
Apr 27 16:53:45.654: INFO: (2) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 8.592861ms)
Apr 27 16:53:45.654: INFO: (2) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.514386ms)
Apr 27 16:53:45.654: INFO: (2) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 8.52541ms)
Apr 27 16:53:45.656: INFO: (2) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 10.56089ms)
Apr 27 16:53:45.656: INFO: (2) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 10.526054ms)
Apr 27 16:53:45.656: INFO: (2) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 10.591982ms)
Apr 27 16:53:45.656: INFO: (2) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 10.606099ms)
Apr 27 16:53:45.656: INFO: (2) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 10.674762ms)
Apr 27 16:53:45.656: INFO: (2) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 10.674178ms)
Apr 27 16:53:45.657: INFO: (2) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 12.081588ms)
Apr 27 16:53:45.659: INFO: (2) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.853936ms)
Apr 27 16:53:45.659: INFO: (2) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 13.969213ms)
Apr 27 16:53:45.659: INFO: (2) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 13.899896ms)
Apr 27 16:53:45.667: INFO: (3) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.176504ms)
Apr 27 16:53:45.667: INFO: (3) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 8.065962ms)
Apr 27 16:53:45.667: INFO: (3) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 8.222412ms)
Apr 27 16:53:45.667: INFO: (3) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 8.045851ms)
Apr 27 16:53:45.667: INFO: (3) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.116109ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 9.923709ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 9.960663ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 9.920954ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 10.030769ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 9.95995ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 9.937104ms)
Apr 27 16:53:45.669: INFO: (3) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 9.925716ms)
Apr 27 16:53:45.672: INFO: (3) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 12.15869ms)
Apr 27 16:53:45.672: INFO: (3) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 12.255063ms)
Apr 27 16:53:45.714: INFO: (3) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 54.716592ms)
Apr 27 16:53:45.714: INFO: (3) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 54.766697ms)
Apr 27 16:53:45.723: INFO: (4) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.979816ms)
Apr 27 16:53:45.723: INFO: (4) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 8.953227ms)
Apr 27 16:53:45.723: INFO: (4) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 9.148049ms)
Apr 27 16:53:45.723: INFO: (4) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 8.977402ms)
Apr 27 16:53:45.723: INFO: (4) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 9.066191ms)
Apr 27 16:53:45.723: INFO: (4) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 9.092752ms)
Apr 27 16:53:45.724: INFO: (4) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 9.755385ms)
Apr 27 16:53:45.724: INFO: (4) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 9.718957ms)
Apr 27 16:53:45.724: INFO: (4) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 9.884401ms)
Apr 27 16:53:45.724: INFO: (4) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 9.924278ms)
Apr 27 16:53:45.724: INFO: (4) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 9.783099ms)
Apr 27 16:53:45.726: INFO: (4) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 11.665439ms)
Apr 27 16:53:45.726: INFO: (4) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.672468ms)
Apr 27 16:53:45.728: INFO: (4) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 13.5387ms)
Apr 27 16:53:45.728: INFO: (4) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 13.471455ms)
Apr 27 16:53:45.730: INFO: (4) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 15.418562ms)
Apr 27 16:53:45.737: INFO: (5) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 7.244576ms)
Apr 27 16:53:45.737: INFO: (5) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.336557ms)
Apr 27 16:53:45.739: INFO: (5) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 9.206834ms)
Apr 27 16:53:45.739: INFO: (5) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 9.075931ms)
Apr 27 16:53:45.739: INFO: (5) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 9.283358ms)
Apr 27 16:53:45.741: INFO: (5) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 11.01125ms)
Apr 27 16:53:45.741: INFO: (5) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 11.089667ms)
Apr 27 16:53:45.741: INFO: (5) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 11.008013ms)
Apr 27 16:53:45.741: INFO: (5) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 11.118616ms)
Apr 27 16:53:45.743: INFO: (5) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 12.893835ms)
Apr 27 16:53:45.743: INFO: (5) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 12.891336ms)
Apr 27 16:53:45.743: INFO: (5) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 13.019852ms)
Apr 27 16:53:45.743: INFO: (5) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 12.906967ms)
Apr 27 16:53:45.743: INFO: (5) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 12.937193ms)
Apr 27 16:53:45.745: INFO: (5) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 14.728636ms)
Apr 27 16:53:45.749: INFO: (5) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 18.849412ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.855748ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.256509ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 8.200461ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.220906ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 8.294127ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 8.299396ms)
Apr 27 16:53:45.757: INFO: (6) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.359938ms)
Apr 27 16:53:45.759: INFO: (6) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 10.265077ms)
Apr 27 16:53:45.759: INFO: (6) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 10.233352ms)
Apr 27 16:53:45.759: INFO: (6) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 10.08048ms)
Apr 27 16:53:45.759: INFO: (6) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 10.145184ms)
Apr 27 16:53:45.759: INFO: (6) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 10.185878ms)
Apr 27 16:53:45.761: INFO: (6) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.936864ms)
Apr 27 16:53:45.761: INFO: (6) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 11.945373ms)
Apr 27 16:53:45.763: INFO: (6) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.831498ms)
Apr 27 16:53:45.765: INFO: (6) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 15.793478ms)
Apr 27 16:53:45.773: INFO: (7) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 7.903133ms)
Apr 27 16:53:45.773: INFO: (7) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.932613ms)
Apr 27 16:53:45.775: INFO: (7) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 9.755442ms)
Apr 27 16:53:45.775: INFO: (7) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 9.939384ms)
Apr 27 16:53:45.775: INFO: (7) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 9.84123ms)
Apr 27 16:53:45.775: INFO: (7) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.829469ms)
Apr 27 16:53:45.775: INFO: (7) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 9.865681ms)
Apr 27 16:53:45.775: INFO: (7) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 9.969826ms)
Apr 27 16:53:45.777: INFO: (7) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 11.942186ms)
Apr 27 16:53:45.777: INFO: (7) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 11.870954ms)
Apr 27 16:53:45.777: INFO: (7) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 11.986088ms)
Apr 27 16:53:45.777: INFO: (7) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.883721ms)
Apr 27 16:53:45.779: INFO: (7) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 13.591022ms)
Apr 27 16:53:45.781: INFO: (7) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 15.575582ms)
Apr 27 16:53:45.781: INFO: (7) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 15.616129ms)
Apr 27 16:53:45.782: INFO: (7) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 17.243087ms)
Apr 27 16:53:45.790: INFO: (8) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 7.704292ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 8.166815ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.215358ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.311734ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 8.327476ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.399362ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 8.286176ms)
Apr 27 16:53:45.791: INFO: (8) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.449797ms)
Apr 27 16:53:45.793: INFO: (8) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 10.172137ms)
Apr 27 16:53:45.793: INFO: (8) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 10.027835ms)
Apr 27 16:53:45.793: INFO: (8) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 10.132399ms)
Apr 27 16:53:45.794: INFO: (8) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 11.83171ms)
Apr 27 16:53:45.794: INFO: (8) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 11.926432ms)
Apr 27 16:53:45.796: INFO: (8) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 13.883206ms)
Apr 27 16:53:45.798: INFO: (8) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 15.647919ms)
Apr 27 16:53:45.800: INFO: (8) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 17.742659ms)
Apr 27 16:53:45.808: INFO: (9) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 7.750268ms)
Apr 27 16:53:45.809: INFO: (9) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 8.31907ms)
Apr 27 16:53:45.809: INFO: (9) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 8.643206ms)
Apr 27 16:53:45.809: INFO: (9) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.668461ms)
Apr 27 16:53:45.809: INFO: (9) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 8.668943ms)
Apr 27 16:53:45.809: INFO: (9) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 8.612591ms)
Apr 27 16:53:45.809: INFO: (9) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 8.610005ms)
Apr 27 16:53:45.810: INFO: (9) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 9.292111ms)
Apr 27 16:53:45.812: INFO: (9) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 11.338161ms)
Apr 27 16:53:45.812: INFO: (9) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 11.395036ms)
Apr 27 16:53:45.812: INFO: (9) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 11.503ms)
Apr 27 16:53:45.812: INFO: (9) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 11.307994ms)
Apr 27 16:53:45.814: INFO: (9) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.572249ms)
Apr 27 16:53:45.814: INFO: (9) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 13.58144ms)
Apr 27 16:53:45.815: INFO: (9) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 15.133041ms)
Apr 27 16:53:45.817: INFO: (9) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 17.093893ms)
Apr 27 16:53:45.825: INFO: (10) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 7.510037ms)
Apr 27 16:53:45.825: INFO: (10) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.592204ms)
Apr 27 16:53:45.825: INFO: (10) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 7.745479ms)
Apr 27 16:53:45.825: INFO: (10) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.449703ms)
Apr 27 16:53:45.825: INFO: (10) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 7.458907ms)
Apr 27 16:53:45.827: INFO: (10) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 9.262967ms)
Apr 27 16:53:45.827: INFO: (10) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 9.282144ms)
Apr 27 16:53:45.827: INFO: (10) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.299455ms)
Apr 27 16:53:45.829: INFO: (10) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 11.623149ms)
Apr 27 16:53:45.829: INFO: (10) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 11.504969ms)
Apr 27 16:53:45.829: INFO: (10) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 11.504931ms)
Apr 27 16:53:45.829: INFO: (10) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 11.671805ms)
Apr 27 16:53:45.829: INFO: (10) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 11.515482ms)
Apr 27 16:53:45.829: INFO: (10) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.481251ms)
Apr 27 16:53:45.831: INFO: (10) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 13.225825ms)
Apr 27 16:53:45.831: INFO: (10) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 13.348797ms)
Apr 27 16:53:45.839: INFO: (11) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.288734ms)
Apr 27 16:53:45.839: INFO: (11) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.259871ms)
Apr 27 16:53:45.840: INFO: (11) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 8.360181ms)
Apr 27 16:53:45.839: INFO: (11) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.297029ms)
Apr 27 16:53:45.839: INFO: (11) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 8.258671ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 10.311554ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 10.184334ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 10.220073ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 10.295368ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 10.358958ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 10.325759ms)
Apr 27 16:53:45.841: INFO: (11) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 10.320189ms)
Apr 27 16:53:45.844: INFO: (11) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 12.487666ms)
Apr 27 16:53:45.844: INFO: (11) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 12.480905ms)
Apr 27 16:53:45.846: INFO: (11) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 14.430905ms)
Apr 27 16:53:45.847: INFO: (11) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 16.269447ms)
Apr 27 16:53:45.857: INFO: (12) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.982976ms)
Apr 27 16:53:45.857: INFO: (12) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.062683ms)
Apr 27 16:53:45.857: INFO: (12) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.841665ms)
Apr 27 16:53:45.857: INFO: (12) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 8.914319ms)
Apr 27 16:53:45.857: INFO: (12) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.928197ms)
Apr 27 16:53:45.859: INFO: (12) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 11.025345ms)
Apr 27 16:53:45.859: INFO: (12) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 11.173169ms)
Apr 27 16:53:45.859: INFO: (12) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 11.005405ms)
Apr 27 16:53:45.859: INFO: (12) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 11.17573ms)
Apr 27 16:53:45.859: INFO: (12) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 11.054379ms)
Apr 27 16:53:45.859: INFO: (12) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 11.187738ms)
Apr 27 16:53:45.861: INFO: (12) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 13.152032ms)
Apr 27 16:53:45.863: INFO: (12) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 14.84763ms)
Apr 27 16:53:45.863: INFO: (12) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 14.885327ms)
Apr 27 16:53:45.863: INFO: (12) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 15.069516ms)
Apr 27 16:53:45.865: INFO: (12) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 16.842657ms)
Apr 27 16:53:45.873: INFO: (13) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.927982ms)
Apr 27 16:53:45.873: INFO: (13) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 8.130037ms)
Apr 27 16:53:45.873: INFO: (13) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.052852ms)
Apr 27 16:53:45.873: INFO: (13) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.057985ms)
Apr 27 16:53:45.873: INFO: (13) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 8.134526ms)
Apr 27 16:53:45.875: INFO: (13) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.876997ms)
Apr 27 16:53:45.875: INFO: (13) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 9.888162ms)
Apr 27 16:53:45.875: INFO: (13) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 9.840883ms)
Apr 27 16:53:45.875: INFO: (13) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 9.847298ms)
Apr 27 16:53:45.875: INFO: (13) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 9.836679ms)
Apr 27 16:53:45.876: INFO: (13) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 11.594227ms)
Apr 27 16:53:45.876: INFO: (13) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 11.605964ms)
Apr 27 16:53:45.876: INFO: (13) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 11.627197ms)
Apr 27 16:53:45.876: INFO: (13) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 11.677051ms)
Apr 27 16:53:45.878: INFO: (13) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 13.480158ms)
Apr 27 16:53:45.878: INFO: (13) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 13.586676ms)
Apr 27 16:53:45.886: INFO: (14) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.763725ms)
Apr 27 16:53:45.886: INFO: (14) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 7.976416ms)
Apr 27 16:53:45.888: INFO: (14) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 9.665878ms)
Apr 27 16:53:45.888: INFO: (14) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 9.846878ms)
Apr 27 16:53:45.888: INFO: (14) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 9.716878ms)
Apr 27 16:53:45.888: INFO: (14) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 9.713606ms)
Apr 27 16:53:45.888: INFO: (14) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.637593ms)
Apr 27 16:53:45.888: INFO: (14) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 9.69368ms)
Apr 27 16:53:45.890: INFO: (14) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 11.729463ms)
Apr 27 16:53:45.890: INFO: (14) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 11.787089ms)
Apr 27 16:53:45.890: INFO: (14) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 11.830035ms)
Apr 27 16:53:45.890: INFO: (14) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 11.788789ms)
Apr 27 16:53:45.892: INFO: (14) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 13.507682ms)
Apr 27 16:53:45.892: INFO: (14) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 13.462713ms)
Apr 27 16:53:45.894: INFO: (14) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 15.560999ms)
Apr 27 16:53:45.894: INFO: (14) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 15.470844ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.557912ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 7.623643ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 7.775649ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 7.61248ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.414065ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 8.273869ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 8.296045ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.299765ms)
Apr 27 16:53:45.902: INFO: (15) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.246122ms)
Apr 27 16:53:45.903: INFO: (15) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 9.413134ms)
Apr 27 16:53:45.903: INFO: (15) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 9.294308ms)
Apr 27 16:53:45.905: INFO: (15) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 11.328813ms)
Apr 27 16:53:45.905: INFO: (15) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 11.318312ms)
Apr 27 16:53:45.907: INFO: (15) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.360328ms)
Apr 27 16:53:45.907: INFO: (15) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 13.512747ms)
Apr 27 16:53:45.908: INFO: (15) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 13.448971ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 8.0022ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 8.02959ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 8.134719ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 8.021895ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.730051ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 8.659573ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 8.786206ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.724578ms)
Apr 27 16:53:45.916: INFO: (16) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.796023ms)
Apr 27 16:53:45.917: INFO: (16) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.450554ms)
Apr 27 16:53:45.917: INFO: (16) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 9.600274ms)
Apr 27 16:53:45.917: INFO: (16) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 9.562575ms)
Apr 27 16:53:45.919: INFO: (16) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 11.630436ms)
Apr 27 16:53:45.921: INFO: (16) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 13.840174ms)
Apr 27 16:53:45.921: INFO: (16) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.848257ms)
Apr 27 16:53:45.921: INFO: (16) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 13.749538ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 8.186444ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 7.965807ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.046349ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 8.152588ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 8.12169ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 8.016037ms)
Apr 27 16:53:45.930: INFO: (17) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 8.120929ms)
Apr 27 16:53:45.931: INFO: (17) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 9.844643ms)
Apr 27 16:53:45.931: INFO: (17) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 9.735094ms)
Apr 27 16:53:45.931: INFO: (17) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 9.684878ms)
Apr 27 16:53:45.933: INFO: (17) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 11.599283ms)
Apr 27 16:53:45.933: INFO: (17) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 11.613845ms)
Apr 27 16:53:45.935: INFO: (17) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 13.566558ms)
Apr 27 16:53:45.935: INFO: (17) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 13.546741ms)
Apr 27 16:53:45.937: INFO: (17) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 15.386492ms)
Apr 27 16:53:45.937: INFO: (17) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 15.339883ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 8.294976ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 8.576899ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 8.674364ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 8.689258ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 8.656743ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 8.636975ms)
Apr 27 16:53:45.946: INFO: (18) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 8.641742ms)
Apr 27 16:53:45.947: INFO: (18) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 10.005208ms)
Apr 27 16:53:45.947: INFO: (18) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 10.012305ms)
Apr 27 16:53:45.947: INFO: (18) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 10.049875ms)
Apr 27 16:53:45.947: INFO: (18) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 10.139815ms)
Apr 27 16:53:45.949: INFO: (18) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 11.919006ms)
Apr 27 16:53:45.949: INFO: (18) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.893426ms)
Apr 27 16:53:45.949: INFO: (18) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.934167ms)
Apr 27 16:53:45.951: INFO: (18) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.889536ms)
Apr 27 16:53:45.951: INFO: (18) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 13.916747ms)
Apr 27 16:53:45.960: INFO: (19) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q/proxy/rewriteme">test</a> (200; 8.69132ms)
Apr 27 16:53:45.960: INFO: (19) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname1/proxy/: foo (200; 8.63847ms)
Apr 27 16:53:45.960: INFO: (19) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname2/proxy/: bar (200; 8.709385ms)
Apr 27 16:53:45.960: INFO: (19) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">test<... (200; 8.731788ms)
Apr 27 16:53:45.961: INFO: (19) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:443/proxy/tlsrewritem... (200; 9.658345ms)
Apr 27 16:53:45.961: INFO: (19) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 9.65622ms)
Apr 27 16:53:45.961: INFO: (19) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:462/proxy/: tls qux (200; 9.621805ms)
Apr 27 16:53:45.961: INFO: (19) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname1/proxy/: tls baz (200; 9.619097ms)
Apr 27 16:53:45.961: INFO: (19) /api/v1/namespaces/proxy-6585/services/https:proxy-service-b5kgt:tlsportname2/proxy/: tls qux (200; 9.645175ms)
Apr 27 16:53:45.961: INFO: (19) /api/v1/namespaces/proxy-6585/services/http:proxy-service-b5kgt:portname2/proxy/: bar (200; 9.807213ms)
Apr 27 16:53:45.963: INFO: (19) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/: <a href="/api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:1080/proxy/rewriteme">... (200; 11.695002ms)
Apr 27 16:53:45.963: INFO: (19) /api/v1/namespaces/proxy-6585/pods/https:proxy-service-b5kgt-2qv9q:460/proxy/: tls baz (200; 11.616323ms)
Apr 27 16:53:45.963: INFO: (19) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 11.73547ms)
Apr 27 16:53:45.963: INFO: (19) /api/v1/namespaces/proxy-6585/pods/proxy-service-b5kgt-2qv9q:160/proxy/: foo (200; 11.549691ms)
Apr 27 16:53:45.965: INFO: (19) /api/v1/namespaces/proxy-6585/services/proxy-service-b5kgt:portname1/proxy/: foo (200; 13.46856ms)
Apr 27 16:53:45.967: INFO: (19) /api/v1/namespaces/proxy-6585/pods/http:proxy-service-b5kgt-2qv9q:162/proxy/: bar (200; 15.370252ms)
STEP: deleting ReplicationController proxy-service-b5kgt in namespace proxy-6585, will wait for the garbage collector to delete the pods
Apr 27 16:53:46.027: INFO: Deleting ReplicationController proxy-service-b5kgt took: 6.329612ms
Apr 27 16:53:46.628: INFO: Terminating ReplicationController proxy-service-b5kgt pods took: 600.37679ms
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:54.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6585" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":277,"completed":176,"skipped":3153,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:54.941: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:53:57.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8888" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":277,"completed":177,"skipped":3186,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:53:57.145: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5261
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5261
STEP: creating replication controller externalsvc in namespace services-5261
I0427 16:53:57.315442    7398 runners.go:190] Created replication controller with name: externalsvc, namespace: services-5261, replica count: 2
I0427 16:54:00.366058    7398 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr 27 16:54:00.384: INFO: Creating new exec pod
Apr 27 16:54:02.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5261 execpodml7vp -- /bin/sh -x -c nslookup clusterip-service'
Apr 27 16:54:03.154: INFO: stderr: "+ nslookup clusterip-service\n"
Apr 27 16:54:03.154: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-5261.svc.cluster.local\tcanonical name = externalsvc.services-5261.svc.cluster.local.\nName:\texternalsvc.services-5261.svc.cluster.local\nAddress: 100.110.117.94\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5261, will wait for the garbage collector to delete the pods
Apr 27 16:54:03.215: INFO: Deleting ReplicationController externalsvc took: 6.821233ms
Apr 27 16:54:03.316: INFO: Terminating ReplicationController externalsvc pods took: 100.304264ms
Apr 27 16:54:07.728: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:07.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5261" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":277,"completed":178,"skipped":3194,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:07.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:54:08.247: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:54:11.269: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:11.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-879" for this suite.
STEP: Destroying namespace "webhook-879-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":277,"completed":179,"skipped":3198,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:11.922: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:54:12.452: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 16:54:14.466: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603252, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603252, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603252, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603252, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:54:17.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:17.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9835" for this suite.
STEP: Destroying namespace "webhook-9835-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":277,"completed":180,"skipped":3208,"failed":0}
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:17.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7317
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7317.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7317.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7317.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7317.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7317.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7317.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:54:20.299: INFO: DNS probes using dns-7317/dns-test-bb2be579-01ff-46b3-91c6-f1f4cb0dde8c succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:20.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7317" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":277,"completed":181,"skipped":3214,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:20.329: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7072
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 27 16:54:20.527: INFO: Waiting up to 5m0s for pod "pod-508e7122-d218-416d-8e9e-cd27db557683" in namespace "emptydir-7072" to be "Succeeded or Failed"
Apr 27 16:54:20.531: INFO: Pod "pod-508e7122-d218-416d-8e9e-cd27db557683": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397022ms
Apr 27 16:54:22.536: INFO: Pod "pod-508e7122-d218-416d-8e9e-cd27db557683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009327244s
STEP: Saw pod success
Apr 27 16:54:22.536: INFO: Pod "pod-508e7122-d218-416d-8e9e-cd27db557683" satisfied condition "Succeeded or Failed"
Apr 27 16:54:22.540: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-508e7122-d218-416d-8e9e-cd27db557683 container test-container: <nil>
STEP: delete the pod
Apr 27 16:54:22.564: INFO: Waiting for pod pod-508e7122-d218-416d-8e9e-cd27db557683 to disappear
Apr 27 16:54:22.568: INFO: Pod pod-508e7122-d218-416d-8e9e-cd27db557683 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:22.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7072" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":182,"skipped":3222,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:22.580: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:33.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8906" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":277,"completed":183,"skipped":3232,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:33.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 16:54:34.231: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 16:54:37.254: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:54:37.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7734" for this suite.
STEP: Destroying namespace "webhook-7734-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":277,"completed":184,"skipped":3237,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:54:37.482: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6339
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6339.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6339.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6339.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 16:54:41.755: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.800: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.808: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.815: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.963: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.970: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.977: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:41.984: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:42.079: INFO: Lookups using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local]

Apr 27 16:54:47.087: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.094: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.101: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.108: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.248: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.262: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.269: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:47.364: INFO: Lookups using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local]

Apr 27 16:54:52.087: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.094: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.101: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.108: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.247: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.262: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.268: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:52.363: INFO: Lookups using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local]

Apr 27 16:54:57.087: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.093: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.100: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.107: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.247: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.262: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.269: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:54:57.363: INFO: Lookups using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local]

Apr 27 16:55:02.087: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.094: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.101: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.108: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.247: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.255: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.261: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.270: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:02.364: INFO: Lookups using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local]

Apr 27 16:55:07.087: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.093: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.100: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.107: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.246: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.253: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.260: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.267: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local from pod dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0: the server could not find the requested resource (get pods dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0)
Apr 27 16:55:07.361: INFO: Lookups using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6339.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6339.svc.cluster.local jessie_udp@dns-test-service-2.dns-6339.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6339.svc.cluster.local]

Apr 27 16:55:12.839: INFO: DNS probes using dns-6339/dns-test-2eb08960-9a99-4155-9b96-ac3c116fe4e0 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:12.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6339" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":277,"completed":185,"skipped":3240,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:12.868: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6579
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 16:55:13.022: INFO: Waiting up to 5m0s for pod "downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b" in namespace "downward-api-6579" to be "Succeeded or Failed"
Apr 27 16:55:13.027: INFO: Pod "downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.457269ms
Apr 27 16:55:15.032: INFO: Pod "downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009546848s
STEP: Saw pod success
Apr 27 16:55:15.032: INFO: Pod "downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b" satisfied condition "Succeeded or Failed"
Apr 27 16:55:15.036: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b container dapi-container: <nil>
STEP: delete the pod
Apr 27 16:55:15.061: INFO: Waiting for pod downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b to disappear
Apr 27 16:55:15.065: INFO: Pod downward-api-2f5b414b-9f87-410c-8e48-4fc0828cf06b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:15.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6579" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":277,"completed":186,"skipped":3242,"failed":0}
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:15.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1531
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:15.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1531" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":277,"completed":187,"skipped":3247,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:15.251: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-e5fce652-0413-4ea5-83c1-d2bd5d3c3ba7
STEP: Creating a pod to test consume configMaps
Apr 27 16:55:15.414: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7" in namespace "projected-9901" to be "Succeeded or Failed"
Apr 27 16:55:15.418: INFO: Pod "pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.953877ms
Apr 27 16:55:17.423: INFO: Pod "pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00883472s
STEP: Saw pod success
Apr 27 16:55:17.423: INFO: Pod "pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7" satisfied condition "Succeeded or Failed"
Apr 27 16:55:17.427: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 16:55:17.448: INFO: Waiting for pod pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7 to disappear
Apr 27 16:55:17.452: INFO: Pod pod-projected-configmaps-7e2818dd-69b0-4925-886f-f6696fc883f7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:17.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9901" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":188,"skipped":3253,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:17.464: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3877
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Apr 27 16:55:17.609: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3877'
Apr 27 16:55:17.840: INFO: stderr: ""
Apr 27 16:55:17.840: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 27 16:55:17.840: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3877'
Apr 27 16:55:17.918: INFO: stderr: ""
Apr 27 16:55:17.918: INFO: stdout: "update-demo-nautilus-bmjfd update-demo-nautilus-h9gpd "
Apr 27 16:55:17.918: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-bmjfd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Apr 27 16:55:23.001: INFO: stderr: ""
Apr 27 16:55:23.001: INFO: stdout: "true"
Apr 27 16:55:23.001: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-bmjfd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Apr 27 16:55:23.084: INFO: stderr: ""
Apr 27 16:55:23.084: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:55:23.084: INFO: validating pod update-demo-nautilus-bmjfd
Apr 27 16:55:23.178: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:55:23.179: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:55:23.179: INFO: update-demo-nautilus-bmjfd is verified up and running
Apr 27 16:55:23.179: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h9gpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Apr 27 16:55:23.260: INFO: stderr: ""
Apr 27 16:55:23.260: INFO: stdout: "true"
Apr 27 16:55:23.260: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h9gpd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Apr 27 16:55:23.346: INFO: stderr: ""
Apr 27 16:55:23.346: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 27 16:55:23.347: INFO: validating pod update-demo-nautilus-h9gpd
Apr 27 16:55:23.441: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 27 16:55:23.441: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 27 16:55:23.441: INFO: update-demo-nautilus-h9gpd is verified up and running
STEP: using delete to clean up resources
Apr 27 16:55:23.441: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3877'
Apr 27 16:55:23.539: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 16:55:23.539: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 27 16:55:23.539: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3877'
Apr 27 16:55:23.634: INFO: stderr: "No resources found in kubectl-3877 namespace.\n"
Apr 27 16:55:23.634: INFO: stdout: ""
Apr 27 16:55:23.634: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-3877 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:55:23.720: INFO: stderr: ""
Apr 27 16:55:23.720: INFO: stdout: "update-demo-nautilus-bmjfd\nupdate-demo-nautilus-h9gpd\n"
Apr 27 16:55:24.220: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3877'
Apr 27 16:55:24.303: INFO: stderr: "No resources found in kubectl-3877 namespace.\n"
Apr 27 16:55:24.303: INFO: stdout: ""
Apr 27 16:55:24.303: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-3877 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 16:55:24.384: INFO: stderr: ""
Apr 27 16:55:24.384: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:24.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3877" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":277,"completed":189,"skipped":3262,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:24.397: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 16:55:28.685: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:55:28.689: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:55:30.689: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:55:30.694: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:55:32.689: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:55:32.696: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:55:34.689: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:55:34.694: INFO: Pod pod-with-poststart-http-hook still exists
Apr 27 16:55:36.689: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 27 16:55:36.694: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:36.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6365" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":277,"completed":190,"skipped":3276,"failed":0}

------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:36.707: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9156
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-297
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:43.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3899" for this suite.
STEP: Destroying namespace "nsdeletetest-9156" for this suite.
Apr 27 16:55:43.183: INFO: Namespace nsdeletetest-9156 was already deleted
STEP: Destroying namespace "nsdeletetest-297" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":277,"completed":191,"skipped":3276,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:43.189: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 27 16:55:43.341: INFO: Waiting up to 5m0s for pod "pod-fa41a406-82a2-456c-b4d4-d283a37f3903" in namespace "emptydir-844" to be "Succeeded or Failed"
Apr 27 16:55:43.345: INFO: Pod "pod-fa41a406-82a2-456c-b4d4-d283a37f3903": Phase="Pending", Reason="", readiness=false. Elapsed: 3.735898ms
Apr 27 16:55:45.351: INFO: Pod "pod-fa41a406-82a2-456c-b4d4-d283a37f3903": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009245519s
STEP: Saw pod success
Apr 27 16:55:45.351: INFO: Pod "pod-fa41a406-82a2-456c-b4d4-d283a37f3903" satisfied condition "Succeeded or Failed"
Apr 27 16:55:45.355: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-fa41a406-82a2-456c-b4d4-d283a37f3903 container test-container: <nil>
STEP: delete the pod
Apr 27 16:55:45.382: INFO: Waiting for pod pod-fa41a406-82a2-456c-b4d4-d283a37f3903 to disappear
Apr 27 16:55:45.386: INFO: Pod pod-fa41a406-82a2-456c-b4d4-d283a37f3903 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:45.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-844" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":192,"skipped":3345,"failed":0}

------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:45.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8132
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 16:55:45.567: INFO: (0) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.459112ms)
Apr 27 16:55:45.613: INFO: (1) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 45.183034ms)
Apr 27 16:55:45.620: INFO: (2) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.516406ms)
Apr 27 16:55:45.627: INFO: (3) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.677284ms)
Apr 27 16:55:45.634: INFO: (4) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.690503ms)
Apr 27 16:55:45.641: INFO: (5) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.892111ms)
Apr 27 16:55:45.649: INFO: (6) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.938427ms)
Apr 27 16:55:45.655: INFO: (7) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.315156ms)
Apr 27 16:55:45.662: INFO: (8) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.372719ms)
Apr 27 16:55:45.668: INFO: (9) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.415209ms)
Apr 27 16:55:45.675: INFO: (10) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.457065ms)
Apr 27 16:55:45.681: INFO: (11) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.457523ms)
Apr 27 16:55:45.688: INFO: (12) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.506306ms)
Apr 27 16:55:45.694: INFO: (13) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.690764ms)
Apr 27 16:55:45.701: INFO: (14) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.74097ms)
Apr 27 16:55:45.708: INFO: (15) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.576098ms)
Apr 27 16:55:45.714: INFO: (16) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.423427ms)
Apr 27 16:55:45.722: INFO: (17) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.179358ms)
Apr 27 16:55:45.729: INFO: (18) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.987981ms)
Apr 27 16:55:45.736: INFO: (19) /api/v1/nodes/izgw82palggheybhhd1s46z:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.750981ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:45.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8132" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":277,"completed":193,"skipped":3345,"failed":0}
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:45.745: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 27 16:55:48.422: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7894 pod-service-account-a052c372-4c97-405c-90a2-e203f8b2bf95 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 27 16:55:48.939: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7894 pod-service-account-a052c372-4c97-405c-90a2-e203f8b2bf95 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 27 16:55:49.382: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-7894 pod-service-account-a052c372-4c97-405c-90a2-e203f8b2bf95 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:49.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7894" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":277,"completed":194,"skipped":3353,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:49.899: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2561
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2561
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2561
I0427 16:55:50.067368    7398 runners.go:190] Created replication controller with name: externalname-service, namespace: services-2561, replica count: 2
Apr 27 16:55:53.117: INFO: Creating new exec pod
I0427 16:55:53.117911    7398 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 16:55:56.134: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2561 execpodpbgqc -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 27 16:55:56.607: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 27 16:55:56.607: INFO: stdout: ""
Apr 27 16:55:56.607: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2561 execpodpbgqc -- /bin/sh -x -c nc -zv -t -w 2 100.105.150.74 80'
Apr 27 16:55:57.157: INFO: stderr: "+ nc -zv -t -w 2 100.105.150.74 80\nConnection to 100.105.150.74 80 port [tcp/http] succeeded!\n"
Apr 27 16:55:57.157: INFO: stdout: ""
Apr 27 16:55:57.157: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 16:55:57.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2561" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":277,"completed":195,"skipped":3358,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 16:55:57.182: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-7717
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-7717
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7717
Apr 27 16:55:57.343: INFO: Found 0 stateful pods, waiting for 1
Apr 27 16:56:07.350: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 27 16:56:07.354: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:56:07.862: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:56:07.862: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:56:07.862: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:56:07.867: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 27 16:56:17.873: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:17.873: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:56:17.892: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999575s
Apr 27 16:56:18.898: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994858649s
Apr 27 16:56:19.903: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989546747s
Apr 27 16:56:20.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984123309s
Apr 27 16:56:21.915: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978502881s
Apr 27 16:56:22.920: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.972845749s
Apr 27 16:56:23.925: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967417784s
Apr 27 16:56:24.930: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.962006276s
Apr 27 16:56:25.936: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.956955774s
Apr 27 16:56:26.941: INFO: Verifying statefulset ss doesn't scale past 1 for another 951.390191ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7717
Apr 27 16:56:27.947: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:56:28.462: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:56:28.462: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:56:28.462: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:56:28.467: INFO: Found 1 stateful pods, waiting for 3
Apr 27 16:56:38.473: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:56:38.473: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 16:56:38.473: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 27 16:56:38.483: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:56:39.010: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:56:39.010: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:56:39.010: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:56:39.010: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:56:39.573: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:56:39.573: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:56:39.573: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:56:39.573: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 16:56:40.084: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 16:56:40.084: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 16:56:40.084: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 16:56:40.084: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 16:56:40.089: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 27 16:56:50.101: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:50.101: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:50.101: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 27 16:56:50.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999597s
Apr 27 16:56:51.121: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994940814s
Apr 27 16:56:52.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989110954s
Apr 27 16:56:53.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983411912s
Apr 27 16:56:54.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977601524s
Apr 27 16:56:55.144: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972239104s
Apr 27 16:56:56.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966455916s
Apr 27 16:56:57.156: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960252009s
Apr 27 16:56:58.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.954413665s
Apr 27 16:56:59.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.557764ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7717
Apr 27 16:57:00.174: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:00.783: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:57:00.783: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:57:00.783: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:57:00.783: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:01.272: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 16:57:01.272: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 16:57:01.272: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 16:57:01.272: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:01.783: INFO: rc: 1
Apr 27 16:57:01.783: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (001853c565f3dff0be37b1506e688d11e0249235a010f0dafb69b0a8c7f928b5)

error:
exit status 1
Apr 27 16:57:11.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:11.867: INFO: rc: 1
Apr 27 16:57:11.867: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:57:21.867: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:21.996: INFO: rc: 1
Apr 27 16:57:21.996: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:57:31.996: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:32.127: INFO: rc: 1
Apr 27 16:57:32.127: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:57:42.127: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:42.216: INFO: rc: 1
Apr 27 16:57:42.216: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:57:52.217: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:57:52.305: INFO: rc: 1
Apr 27 16:57:52.305: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:58:02.305: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:02.440: INFO: rc: 1
Apr 27 16:58:02.440: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:58:12.441: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:12.579: INFO: rc: 1
Apr 27 16:58:12.579: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:58:22.579: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:22.747: INFO: rc: 1
Apr 27 16:58:22.747: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:58:32.748: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:32.830: INFO: rc: 1
Apr 27 16:58:32.830: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:58:42.830: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:42.915: INFO: rc: 1
Apr 27 16:58:42.915: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:58:52.916: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:58:53.006: INFO: rc: 1
Apr 27 16:58:53.006: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:59:03.006: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:03.090: INFO: rc: 1
Apr 27 16:59:03.091: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:59:13.091: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:13.181: INFO: rc: 1
Apr 27 16:59:13.182: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:59:23.182: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:23.314: INFO: rc: 1
Apr 27 16:59:23.314: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:59:33.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:33.453: INFO: rc: 1
Apr 27 16:59:33.453: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:59:43.454: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:43.540: INFO: rc: 1
Apr 27 16:59:43.540: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 16:59:53.541: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 16:59:53.698: INFO: rc: 1
Apr 27 16:59:53.698: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:00:03.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:03.829: INFO: rc: 1
Apr 27 17:00:03.829: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:00:13.829: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:13.918: INFO: rc: 1
Apr 27 17:00:13.918: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:00:23.918: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:24.048: INFO: rc: 1
Apr 27 17:00:24.048: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:00:34.049: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:34.133: INFO: rc: 1
Apr 27 17:00:34.133: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:00:44.133: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:44.214: INFO: rc: 1
Apr 27 17:00:44.214: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:00:54.215: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:00:54.356: INFO: rc: 1
Apr 27 17:00:54.357: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:01:04.357: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:04.442: INFO: rc: 1
Apr 27 17:01:04.442: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:01:14.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:14.566: INFO: rc: 1
Apr 27 17:01:14.566: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:01:24.567: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:24.663: INFO: rc: 1
Apr 27 17:01:24.663: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:01:34.663: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:34.763: INFO: rc: 1
Apr 27 17:01:34.763: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:01:44.763: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:49.847: INFO: rc: 1
Apr 27 17:01:49.847: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:01:59.847: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:01:59.938: INFO: rc: 1
Apr 27 17:01:59.938: INFO: Waiting 10s to retry failed RunHostCmd: error running /go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 27 17:02:09.939: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:02:10.036: INFO: rc: 1
Apr 27 17:02:10.036: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Apr 27 17:02:10.036: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:02:10.053: INFO: Deleting all statefulset in ns statefulset-7717
Apr 27 17:02:10.058: INFO: Scaling statefulset ss to 0
Apr 27 17:02:10.072: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:02:10.076: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:02:10.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7717" for this suite.

• [SLOW TEST:372.922 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":277,"completed":196,"skipped":3359,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:02:10.104: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4196
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 17:02:10.269: INFO: Found 0 stateful pods, waiting for 3
Apr 27 17:02:20.276: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:02:20.276: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:02:20.276: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 17:02:20.310: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 27 17:02:30.352: INFO: Updating stateful set ss2
Apr 27 17:02:30.361: INFO: Waiting for Pod statefulset-4196/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Apr 27 17:02:40.396: INFO: Found 1 stateful pods, waiting for 3
Apr 27 17:02:50.403: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:02:50.403: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:02:50.403: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 27 17:02:50.432: INFO: Updating stateful set ss2
Apr 27 17:02:50.441: INFO: Waiting for Pod statefulset-4196/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 27 17:03:00.472: INFO: Updating stateful set ss2
Apr 27 17:03:00.481: INFO: Waiting for StatefulSet statefulset-4196/ss2 to complete update
Apr 27 17:03:00.481: INFO: Waiting for Pod statefulset-4196/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:03:10.492: INFO: Deleting all statefulset in ns statefulset-4196
Apr 27 17:03:10.496: INFO: Scaling statefulset ss2 to 0
Apr 27 17:03:40.516: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:03:40.521: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:40.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4196" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":277,"completed":197,"skipped":3361,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:40.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 27 17:03:40.705: INFO: Waiting up to 5m0s for pod "pod-a288740f-3407-4f0b-adb9-cd0674b49f64" in namespace "emptydir-8182" to be "Succeeded or Failed"
Apr 27 17:03:40.709: INFO: Pod "pod-a288740f-3407-4f0b-adb9-cd0674b49f64": Phase="Pending", Reason="", readiness=false. Elapsed: 3.976203ms
Apr 27 17:03:42.714: INFO: Pod "pod-a288740f-3407-4f0b-adb9-cd0674b49f64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008928378s
STEP: Saw pod success
Apr 27 17:03:42.714: INFO: Pod "pod-a288740f-3407-4f0b-adb9-cd0674b49f64" satisfied condition "Succeeded or Failed"
Apr 27 17:03:42.718: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-a288740f-3407-4f0b-adb9-cd0674b49f64 container test-container: <nil>
STEP: delete the pod
Apr 27 17:03:42.837: INFO: Waiting for pod pod-a288740f-3407-4f0b-adb9-cd0674b49f64 to disappear
Apr 27 17:03:42.841: INFO: Pod pod-a288740f-3407-4f0b-adb9-cd0674b49f64 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:42.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8182" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":198,"skipped":3385,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:42.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:03:43.428: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:03:45.442: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603823, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603823, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603823, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723603823, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:03:48.457: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:03:48.462: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7848-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:03:49.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8756" for this suite.
STEP: Destroying namespace "webhook-8756-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":277,"completed":199,"skipped":3406,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:03:50.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:07.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8160" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":277,"completed":200,"skipped":3411,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:07.333: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3358.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3358.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3358.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3358.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:04:09.692: INFO: DNS probes using dns-test-134fe150-0924-4bd4-9bfa-e9224261ca64 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3358.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3358.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3358.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3358.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:04:11.912: INFO: DNS probes using dns-test-79711565-1bd9-4190-9825-ed6bfb3b108b succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3358.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3358.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3358.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3358.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:04:14.140: INFO: DNS probes using dns-test-b18c5f48-d726-4260-862e-d958bd87790d succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:14.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3358" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":277,"completed":201,"skipped":3432,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:14.170: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 27 17:04:14.317: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-7752'
Apr 27 17:04:14.676: INFO: stderr: ""
Apr 27 17:04:14.676: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr 27 17:04:19.726: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-7752 -o json'
Apr 27 17:04:19.808: INFO: stderr: ""
Apr 27 17:04:19.808: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.246/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.64.1.246/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-04-27T17:04:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:04:14Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:04:15Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"100.64.1.246\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-04-27T17:04:15Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7752\",\n        \"resourceVersion\": \"27807\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7752/pods/e2e-test-httpd-pod\",\n        \"uid\": \"c72b07b9-abd6-4a47-8d35-f2dab1372ce9\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4qvvh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"izgw82palggheybhhd1s46z\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4qvvh\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4qvvh\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:04:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:04:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:04:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-27T17:04:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f9059ece4f276e2cbf2839933b0e7689007d1374159728329ea621577b5dd1db\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-04-27T17:04:15Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.31.184\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.246\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.246\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-04-27T17:04:14Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 27 17:04:19.809: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-7752'
Apr 27 17:04:20.075: INFO: stderr: ""
Apr 27 17:04:20.075: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Apr 27 17:04:20.079: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-7752'
Apr 27 17:04:24.903: INFO: stderr: ""
Apr 27 17:04:24.903: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:24.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7752" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":277,"completed":202,"skipped":3448,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:24.916: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Apr 27 17:04:25.075: INFO: Waiting up to 5m0s for pod "downward-api-5872328f-de15-4709-850f-5ecf466b0af7" in namespace "downward-api-2257" to be "Succeeded or Failed"
Apr 27 17:04:25.079: INFO: Pod "downward-api-5872328f-de15-4709-850f-5ecf466b0af7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076979ms
Apr 27 17:04:27.084: INFO: Pod "downward-api-5872328f-de15-4709-850f-5ecf466b0af7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009113679s
STEP: Saw pod success
Apr 27 17:04:27.084: INFO: Pod "downward-api-5872328f-de15-4709-850f-5ecf466b0af7" satisfied condition "Succeeded or Failed"
Apr 27 17:04:27.088: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downward-api-5872328f-de15-4709-850f-5ecf466b0af7 container dapi-container: <nil>
STEP: delete the pod
Apr 27 17:04:27.113: INFO: Waiting for pod downward-api-5872328f-de15-4709-850f-5ecf466b0af7 to disappear
Apr 27 17:04:27.117: INFO: Pod downward-api-5872328f-de15-4709-850f-5ecf466b0af7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:27.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2257" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":277,"completed":203,"skipped":3494,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:27.130: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-04c6c676-4f6d-416a-8997-2f7310f6aecc
STEP: Creating a pod to test consume secrets
Apr 27 17:04:27.289: INFO: Waiting up to 5m0s for pod "pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef" in namespace "secrets-8042" to be "Succeeded or Failed"
Apr 27 17:04:27.294: INFO: Pod "pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.680419ms
Apr 27 17:04:29.299: INFO: Pod "pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010019727s
STEP: Saw pod success
Apr 27 17:04:29.299: INFO: Pod "pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef" satisfied condition "Succeeded or Failed"
Apr 27 17:04:29.304: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:04:29.331: INFO: Waiting for pod pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef to disappear
Apr 27 17:04:29.335: INFO: Pod pod-secrets-4b03c75d-9e65-43b3-b1f1-0ed1c4c674ef no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:04:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8042" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":204,"skipped":3506,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:04:29.348: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:04:29.519: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 27 17:04:29.535: INFO: Number of nodes with available pods: 0
Apr 27 17:04:29.535: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 17:04:30.548: INFO: Number of nodes with available pods: 0
Apr 27 17:04:30.548: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 17:04:31.549: INFO: Number of nodes with available pods: 2
Apr 27 17:04:31.549: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 27 17:04:31.584: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:31.584: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:32.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:32.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:33.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:33.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:34.595: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:34.595: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:34.595: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:35.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:35.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:35.594: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:36.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:36.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:36.594: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:37.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:37.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:37.594: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:38.595: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:38.595: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:38.595: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:39.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:39.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:39.594: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:40.595: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:40.595: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:40.595: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:41.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:41.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:41.594: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:42.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:42.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:42.594: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:43.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:43.594: INFO: Wrong image for pod: daemon-set-xvqgr. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:43.595: INFO: Pod daemon-set-xvqgr is not available
Apr 27 17:04:44.594: INFO: Pod daemon-set-49cpf is not available
Apr 27 17:04:44.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:45.594: INFO: Pod daemon-set-49cpf is not available
Apr 27 17:04:45.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:46.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:46.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:47.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:47.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:48.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:48.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:49.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:49.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:50.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:50.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:51.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:51.595: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:52.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:52.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:53.595: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:53.595: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:54.594: INFO: Wrong image for pod: daemon-set-6qhmd. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Apr 27 17:04:54.594: INFO: Pod daemon-set-6qhmd is not available
Apr 27 17:04:55.594: INFO: Pod daemon-set-zmltw is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 27 17:04:55.613: INFO: Number of nodes with available pods: 1
Apr 27 17:04:55.613: INFO: Node izgw82palggheybhhd1s46z is running more than one daemon pod
Apr 27 17:04:56.625: INFO: Number of nodes with available pods: 2
Apr 27 17:04:56.625: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2604, will wait for the garbage collector to delete the pods
Apr 27 17:04:56.708: INFO: Deleting DaemonSet.extensions daemon-set took: 6.522346ms
Apr 27 17:04:57.308: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.324231ms
Apr 27 17:05:04.912: INFO: Number of nodes with available pods: 0
Apr 27 17:05:04.912: INFO: Number of running nodes: 0, number of available pods: 0
Apr 27 17:05:04.916: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2604/daemonsets","resourceVersion":"28149"},"items":null}

Apr 27 17:05:04.920: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2604/pods","resourceVersion":"28149"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:04.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2604" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":277,"completed":205,"skipped":3515,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:04.946: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8946
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:05.095: INFO: Creating ReplicaSet my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba
Apr 27 17:05:05.105: INFO: Pod name my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba: Found 0 pods out of 1
Apr 27 17:05:10.110: INFO: Pod name my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba: Found 1 pods out of 1
Apr 27 17:05:10.110: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba" is running
Apr 27 17:05:10.115: INFO: Pod "my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba-zptnn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:05:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:05:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:05:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-27 17:05:05 +0000 UTC Reason: Message:}])
Apr 27 17:05:10.115: INFO: Trying to dial the pod
Apr 27 17:05:15.221: INFO: Controller my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba: Got expected result from replica 1 [my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba-zptnn]: "my-hostname-basic-9c6caf06-91e7-45d9-bc38-bbd6ce4678ba-zptnn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:15.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8946" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":277,"completed":206,"skipped":3540,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:15.238: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 27 17:05:15.398: INFO: Waiting up to 5m0s for pod "pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0" in namespace "emptydir-6091" to be "Succeeded or Failed"
Apr 27 17:05:15.402: INFO: Pod "pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.569684ms
Apr 27 17:05:17.407: INFO: Pod "pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009530342s
STEP: Saw pod success
Apr 27 17:05:17.407: INFO: Pod "pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0" satisfied condition "Succeeded or Failed"
Apr 27 17:05:17.412: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0 container test-container: <nil>
STEP: delete the pod
Apr 27 17:05:17.432: INFO: Waiting for pod pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0 to disappear
Apr 27 17:05:17.438: INFO: Pod pod-063e0c19-74ee-472d-9a03-19cd38e8f4a0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:17.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6091" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":207,"skipped":3591,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:17.452: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1483
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:17.598: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:18.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1483" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":277,"completed":208,"skipped":3597,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:18.638: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-5485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-5485
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5485
STEP: Deleting pre-stop pod
Apr 27 17:05:28.045: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:28.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5485" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":277,"completed":209,"skipped":3606,"failed":0}
SSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:28.065: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-5231
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Apr 27 17:05:28.220: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Apr 27 17:05:28.228: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 17:05:28.228: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Apr 27 17:05:28.238: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 27 17:05:28.238: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Apr 27 17:05:28.248: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 27 17:05:28.248: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Apr 27 17:05:35.290: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:35.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-5231" for this suite.
•{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":277,"completed":210,"skipped":3615,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:35.310: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:05:35.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0" in namespace "downward-api-3143" to be "Succeeded or Failed"
Apr 27 17:05:35.470: INFO: Pod "downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.977391ms
Apr 27 17:05:37.475: INFO: Pod "downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010561359s
STEP: Saw pod success
Apr 27 17:05:37.475: INFO: Pod "downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0" satisfied condition "Succeeded or Failed"
Apr 27 17:05:37.479: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0 container client-container: <nil>
STEP: delete the pod
Apr 27 17:05:37.500: INFO: Waiting for pod downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0 to disappear
Apr 27 17:05:37.503: INFO: Pod downwardapi-volume-a369153f-98ec-4d82-a6e3-8a32fd5679a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:37.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3143" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":277,"completed":211,"skipped":3628,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:37.516: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:05:39.690: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:39.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1558" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":212,"skipped":3640,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:39.715: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:39.861: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3931
I0427 17:05:39.872504    7398 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3931, replica count: 1
I0427 17:05:40.923162    7398 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0427 17:05:41.923447    7398 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 17:05:42.032: INFO: Created: latency-svc-btlnq
Apr 27 17:05:42.037: INFO: Got endpoints: latency-svc-btlnq [13.95133ms]
Apr 27 17:05:42.047: INFO: Created: latency-svc-z4gd5
Apr 27 17:05:42.050: INFO: Created: latency-svc-t7qn9
Apr 27 17:05:42.050: INFO: Got endpoints: latency-svc-z4gd5 [12.893269ms]
Apr 27 17:05:42.054: INFO: Got endpoints: latency-svc-t7qn9 [16.273892ms]
Apr 27 17:05:42.054: INFO: Created: latency-svc-jnv7c
Apr 27 17:05:42.057: INFO: Got endpoints: latency-svc-jnv7c [19.917281ms]
Apr 27 17:05:42.057: INFO: Created: latency-svc-w87nk
Apr 27 17:05:42.061: INFO: Created: latency-svc-vnjl6
Apr 27 17:05:42.061: INFO: Got endpoints: latency-svc-w87nk [23.679921ms]
Apr 27 17:05:42.063: INFO: Got endpoints: latency-svc-vnjl6 [25.741756ms]
Apr 27 17:05:42.064: INFO: Created: latency-svc-xjbsg
Apr 27 17:05:42.068: INFO: Got endpoints: latency-svc-xjbsg [30.597109ms]
Apr 27 17:05:42.069: INFO: Created: latency-svc-khrl9
Apr 27 17:05:42.071: INFO: Got endpoints: latency-svc-khrl9 [33.198909ms]
Apr 27 17:05:42.073: INFO: Created: latency-svc-rpfqg
Apr 27 17:05:42.076: INFO: Got endpoints: latency-svc-rpfqg [38.380605ms]
Apr 27 17:05:42.076: INFO: Created: latency-svc-mjf5t
Apr 27 17:05:42.078: INFO: Got endpoints: latency-svc-mjf5t [40.633093ms]
Apr 27 17:05:42.080: INFO: Created: latency-svc-h4tpz
Apr 27 17:05:42.083: INFO: Got endpoints: latency-svc-h4tpz [45.565001ms]
Apr 27 17:05:42.085: INFO: Created: latency-svc-r7xm6
Apr 27 17:05:42.088: INFO: Got endpoints: latency-svc-r7xm6 [50.361612ms]
Apr 27 17:05:42.088: INFO: Created: latency-svc-d5f26
Apr 27 17:05:42.092: INFO: Created: latency-svc-7d92p
Apr 27 17:05:42.092: INFO: Got endpoints: latency-svc-d5f26 [54.502031ms]
Apr 27 17:05:42.100: INFO: Got endpoints: latency-svc-7d92p [62.770537ms]
Apr 27 17:05:42.101: INFO: Created: latency-svc-445ht
Apr 27 17:05:42.151: INFO: Got endpoints: latency-svc-445ht [113.490163ms]
Apr 27 17:05:42.151: INFO: Created: latency-svc-nf897
Apr 27 17:05:42.156: INFO: Got endpoints: latency-svc-nf897 [117.983546ms]
Apr 27 17:05:42.156: INFO: Created: latency-svc-wdlkp
Apr 27 17:05:42.159: INFO: Got endpoints: latency-svc-wdlkp [108.91152ms]
Apr 27 17:05:42.160: INFO: Created: latency-svc-jnltz
Apr 27 17:05:42.163: INFO: Got endpoints: latency-svc-jnltz [109.54745ms]
Apr 27 17:05:42.164: INFO: Created: latency-svc-2d5jz
Apr 27 17:05:42.165: INFO: Got endpoints: latency-svc-2d5jz [108.128693ms]
Apr 27 17:05:42.168: INFO: Created: latency-svc-422md
Apr 27 17:05:42.172: INFO: Got endpoints: latency-svc-422md [111.098758ms]
Apr 27 17:05:42.174: INFO: Created: latency-svc-nz674
Apr 27 17:05:42.177: INFO: Got endpoints: latency-svc-nz674 [113.307972ms]
Apr 27 17:05:42.177: INFO: Created: latency-svc-5pcgh
Apr 27 17:05:42.181: INFO: Got endpoints: latency-svc-5pcgh [112.296884ms]
Apr 27 17:05:42.181: INFO: Created: latency-svc-42dp6
Apr 27 17:05:42.185: INFO: Got endpoints: latency-svc-42dp6 [113.880737ms]
Apr 27 17:05:42.185: INFO: Created: latency-svc-zj92t
Apr 27 17:05:42.189: INFO: Got endpoints: latency-svc-zj92t [112.865771ms]
Apr 27 17:05:42.190: INFO: Created: latency-svc-xqxf8
Apr 27 17:05:42.194: INFO: Created: latency-svc-jz72p
Apr 27 17:05:42.194: INFO: Got endpoints: latency-svc-xqxf8 [115.627318ms]
Apr 27 17:05:42.198: INFO: Got endpoints: latency-svc-jz72p [114.298892ms]
Apr 27 17:05:42.198: INFO: Created: latency-svc-qxmb2
Apr 27 17:05:42.207: INFO: Got endpoints: latency-svc-qxmb2 [118.750265ms]
Apr 27 17:05:42.207: INFO: Created: latency-svc-b6zfv
Apr 27 17:05:42.249: INFO: Created: latency-svc-gqf4f
Apr 27 17:05:42.251: INFO: Got endpoints: latency-svc-b6zfv [158.393283ms]
Apr 27 17:05:42.252: INFO: Got endpoints: latency-svc-gqf4f [151.075313ms]
Apr 27 17:05:42.255: INFO: Created: latency-svc-n4cjz
Apr 27 17:05:42.257: INFO: Got endpoints: latency-svc-n4cjz [106.067435ms]
Apr 27 17:05:42.260: INFO: Created: latency-svc-h2wmw
Apr 27 17:05:42.264: INFO: Created: latency-svc-7cc7b
Apr 27 17:05:42.264: INFO: Got endpoints: latency-svc-h2wmw [107.976172ms]
Apr 27 17:05:42.266: INFO: Got endpoints: latency-svc-7cc7b [106.494024ms]
Apr 27 17:05:42.269: INFO: Created: latency-svc-9pjmm
Apr 27 17:05:42.272: INFO: Got endpoints: latency-svc-9pjmm [108.806634ms]
Apr 27 17:05:42.273: INFO: Created: latency-svc-s297j
Apr 27 17:05:42.277: INFO: Got endpoints: latency-svc-s297j [111.312882ms]
Apr 27 17:05:42.277: INFO: Created: latency-svc-nsnts
Apr 27 17:05:42.282: INFO: Created: latency-svc-8fbtf
Apr 27 17:05:42.286: INFO: Got endpoints: latency-svc-nsnts [113.236915ms]
Apr 27 17:05:42.286: INFO: Created: latency-svc-trfph
Apr 27 17:05:42.290: INFO: Created: latency-svc-26vll
Apr 27 17:05:42.293: INFO: Created: latency-svc-tkhwl
Apr 27 17:05:42.297: INFO: Created: latency-svc-77mr2
Apr 27 17:05:42.301: INFO: Created: latency-svc-hbllw
Apr 27 17:05:42.305: INFO: Created: latency-svc-kn72r
Apr 27 17:05:42.315: INFO: Created: latency-svc-v4xbq
Apr 27 17:05:42.350: INFO: Created: latency-svc-r6xwc
Apr 27 17:05:42.350: INFO: Got endpoints: latency-svc-8fbtf [77.718165ms]
Apr 27 17:05:42.356: INFO: Created: latency-svc-jpzg9
Apr 27 17:05:42.359: INFO: Created: latency-svc-vtgr8
Apr 27 17:05:42.363: INFO: Created: latency-svc-4rzm4
Apr 27 17:05:42.367: INFO: Created: latency-svc-wl8n8
Apr 27 17:05:42.371: INFO: Created: latency-svc-glvqr
Apr 27 17:05:42.374: INFO: Created: latency-svc-r8wqr
Apr 27 17:05:42.378: INFO: Created: latency-svc-sgc4x
Apr 27 17:05:42.386: INFO: Got endpoints: latency-svc-trfph [208.906199ms]
Apr 27 17:05:42.395: INFO: Created: latency-svc-92hb6
Apr 27 17:05:42.436: INFO: Got endpoints: latency-svc-26vll [255.27808ms]
Apr 27 17:05:42.445: INFO: Created: latency-svc-rb6hc
Apr 27 17:05:42.487: INFO: Got endpoints: latency-svc-tkhwl [302.054775ms]
Apr 27 17:05:42.496: INFO: Created: latency-svc-ctdpf
Apr 27 17:05:42.536: INFO: Got endpoints: latency-svc-77mr2 [347.176088ms]
Apr 27 17:05:42.545: INFO: Created: latency-svc-9c5zx
Apr 27 17:05:42.586: INFO: Got endpoints: latency-svc-hbllw [391.72519ms]
Apr 27 17:05:42.594: INFO: Created: latency-svc-r8zsd
Apr 27 17:05:42.635: INFO: Got endpoints: latency-svc-kn72r [437.758264ms]
Apr 27 17:05:42.643: INFO: Created: latency-svc-452lf
Apr 27 17:05:42.686: INFO: Got endpoints: latency-svc-v4xbq [478.899135ms]
Apr 27 17:05:42.694: INFO: Created: latency-svc-5p7vh
Apr 27 17:05:42.737: INFO: Got endpoints: latency-svc-r6xwc [485.928752ms]
Apr 27 17:05:42.746: INFO: Created: latency-svc-hn82w
Apr 27 17:05:42.786: INFO: Got endpoints: latency-svc-jpzg9 [533.977327ms]
Apr 27 17:05:42.794: INFO: Created: latency-svc-gr2p4
Apr 27 17:05:42.836: INFO: Got endpoints: latency-svc-vtgr8 [578.650589ms]
Apr 27 17:05:42.852: INFO: Created: latency-svc-7p4lm
Apr 27 17:05:42.886: INFO: Got endpoints: latency-svc-4rzm4 [622.220059ms]
Apr 27 17:05:42.894: INFO: Created: latency-svc-65hk5
Apr 27 17:05:42.936: INFO: Got endpoints: latency-svc-wl8n8 [670.404216ms]
Apr 27 17:05:42.945: INFO: Created: latency-svc-44jvr
Apr 27 17:05:42.986: INFO: Got endpoints: latency-svc-glvqr [709.229458ms]
Apr 27 17:05:42.999: INFO: Created: latency-svc-cz66s
Apr 27 17:05:43.036: INFO: Got endpoints: latency-svc-r8wqr [750.482593ms]
Apr 27 17:05:43.045: INFO: Created: latency-svc-xc77g
Apr 27 17:05:43.086: INFO: Got endpoints: latency-svc-sgc4x [736.218301ms]
Apr 27 17:05:43.095: INFO: Created: latency-svc-nhmb9
Apr 27 17:05:43.136: INFO: Got endpoints: latency-svc-92hb6 [750.357641ms]
Apr 27 17:05:43.145: INFO: Created: latency-svc-9dzkt
Apr 27 17:05:43.186: INFO: Got endpoints: latency-svc-rb6hc [749.910243ms]
Apr 27 17:05:43.196: INFO: Created: latency-svc-7tsqf
Apr 27 17:05:43.236: INFO: Got endpoints: latency-svc-ctdpf [749.295245ms]
Apr 27 17:05:43.245: INFO: Created: latency-svc-8c8rs
Apr 27 17:05:43.286: INFO: Got endpoints: latency-svc-9c5zx [750.338495ms]
Apr 27 17:05:43.294: INFO: Created: latency-svc-wcf49
Apr 27 17:05:43.337: INFO: Got endpoints: latency-svc-r8zsd [751.152088ms]
Apr 27 17:05:43.345: INFO: Created: latency-svc-997sc
Apr 27 17:05:43.387: INFO: Got endpoints: latency-svc-452lf [752.021305ms]
Apr 27 17:05:43.396: INFO: Created: latency-svc-n46lg
Apr 27 17:05:43.436: INFO: Got endpoints: latency-svc-5p7vh [749.795316ms]
Apr 27 17:05:43.445: INFO: Created: latency-svc-qwxnq
Apr 27 17:05:43.486: INFO: Got endpoints: latency-svc-hn82w [749.338552ms]
Apr 27 17:05:43.495: INFO: Created: latency-svc-x6tc7
Apr 27 17:05:43.536: INFO: Got endpoints: latency-svc-gr2p4 [750.130098ms]
Apr 27 17:05:43.545: INFO: Created: latency-svc-ndr2p
Apr 27 17:05:43.586: INFO: Got endpoints: latency-svc-7p4lm [750.396282ms]
Apr 27 17:05:43.595: INFO: Created: latency-svc-zbx44
Apr 27 17:05:43.638: INFO: Got endpoints: latency-svc-65hk5 [752.202471ms]
Apr 27 17:05:43.647: INFO: Created: latency-svc-s4hzz
Apr 27 17:05:43.686: INFO: Got endpoints: latency-svc-44jvr [749.636577ms]
Apr 27 17:05:43.695: INFO: Created: latency-svc-f6gqk
Apr 27 17:05:43.736: INFO: Got endpoints: latency-svc-cz66s [750.067423ms]
Apr 27 17:05:43.746: INFO: Created: latency-svc-hh9r6
Apr 27 17:05:43.786: INFO: Got endpoints: latency-svc-xc77g [749.913571ms]
Apr 27 17:05:43.795: INFO: Created: latency-svc-cmsjn
Apr 27 17:05:43.836: INFO: Got endpoints: latency-svc-nhmb9 [750.186743ms]
Apr 27 17:05:43.845: INFO: Created: latency-svc-vtp7w
Apr 27 17:05:43.886: INFO: Got endpoints: latency-svc-9dzkt [749.749728ms]
Apr 27 17:05:43.894: INFO: Created: latency-svc-zqrkj
Apr 27 17:05:43.936: INFO: Got endpoints: latency-svc-7tsqf [750.26025ms]
Apr 27 17:05:43.951: INFO: Created: latency-svc-gdvzw
Apr 27 17:05:43.986: INFO: Got endpoints: latency-svc-8c8rs [749.941908ms]
Apr 27 17:05:43.995: INFO: Created: latency-svc-rr8jg
Apr 27 17:05:44.036: INFO: Got endpoints: latency-svc-wcf49 [749.366646ms]
Apr 27 17:05:44.044: INFO: Created: latency-svc-4vssh
Apr 27 17:05:44.086: INFO: Got endpoints: latency-svc-997sc [749.232377ms]
Apr 27 17:05:44.095: INFO: Created: latency-svc-vmrf4
Apr 27 17:05:44.136: INFO: Got endpoints: latency-svc-n46lg [748.298306ms]
Apr 27 17:05:44.145: INFO: Created: latency-svc-6tppq
Apr 27 17:05:44.186: INFO: Got endpoints: latency-svc-qwxnq [750.404675ms]
Apr 27 17:05:44.194: INFO: Created: latency-svc-4r97w
Apr 27 17:05:44.237: INFO: Got endpoints: latency-svc-x6tc7 [750.536016ms]
Apr 27 17:05:44.245: INFO: Created: latency-svc-zrv4w
Apr 27 17:05:44.287: INFO: Got endpoints: latency-svc-ndr2p [750.72974ms]
Apr 27 17:05:44.295: INFO: Created: latency-svc-gwm2j
Apr 27 17:05:44.337: INFO: Got endpoints: latency-svc-zbx44 [750.906638ms]
Apr 27 17:05:44.347: INFO: Created: latency-svc-ct9wg
Apr 27 17:05:44.387: INFO: Got endpoints: latency-svc-s4hzz [748.545639ms]
Apr 27 17:05:44.395: INFO: Created: latency-svc-76mwr
Apr 27 17:05:44.436: INFO: Got endpoints: latency-svc-f6gqk [750.172066ms]
Apr 27 17:05:44.446: INFO: Created: latency-svc-978nf
Apr 27 17:05:44.486: INFO: Got endpoints: latency-svc-hh9r6 [749.926069ms]
Apr 27 17:05:44.495: INFO: Created: latency-svc-4kg2n
Apr 27 17:05:44.536: INFO: Got endpoints: latency-svc-cmsjn [750.020946ms]
Apr 27 17:05:44.545: INFO: Created: latency-svc-8npbw
Apr 27 17:05:44.586: INFO: Got endpoints: latency-svc-vtp7w [749.612645ms]
Apr 27 17:05:44.595: INFO: Created: latency-svc-r75b5
Apr 27 17:05:44.636: INFO: Got endpoints: latency-svc-zqrkj [749.828907ms]
Apr 27 17:05:44.644: INFO: Created: latency-svc-gkxhr
Apr 27 17:05:44.687: INFO: Got endpoints: latency-svc-gdvzw [750.477238ms]
Apr 27 17:05:44.696: INFO: Created: latency-svc-5nsg7
Apr 27 17:05:44.736: INFO: Got endpoints: latency-svc-rr8jg [750.105629ms]
Apr 27 17:05:44.745: INFO: Created: latency-svc-cwf5b
Apr 27 17:05:44.787: INFO: Got endpoints: latency-svc-4vssh [751.163257ms]
Apr 27 17:05:44.795: INFO: Created: latency-svc-gclp6
Apr 27 17:05:44.836: INFO: Got endpoints: latency-svc-vmrf4 [749.504703ms]
Apr 27 17:05:44.844: INFO: Created: latency-svc-cjht2
Apr 27 17:05:44.885: INFO: Got endpoints: latency-svc-6tppq [749.544384ms]
Apr 27 17:05:44.894: INFO: Created: latency-svc-rtppr
Apr 27 17:05:44.936: INFO: Got endpoints: latency-svc-4r97w [749.622301ms]
Apr 27 17:05:44.944: INFO: Created: latency-svc-z8h79
Apr 27 17:05:44.986: INFO: Got endpoints: latency-svc-zrv4w [749.322977ms]
Apr 27 17:05:44.996: INFO: Created: latency-svc-pfj5n
Apr 27 17:05:45.037: INFO: Got endpoints: latency-svc-gwm2j [750.213932ms]
Apr 27 17:05:45.045: INFO: Created: latency-svc-rmj56
Apr 27 17:05:45.086: INFO: Got endpoints: latency-svc-ct9wg [748.801863ms]
Apr 27 17:05:45.095: INFO: Created: latency-svc-pbrv4
Apr 27 17:05:45.136: INFO: Got endpoints: latency-svc-76mwr [749.341935ms]
Apr 27 17:05:45.145: INFO: Created: latency-svc-ddcqg
Apr 27 17:05:45.186: INFO: Got endpoints: latency-svc-978nf [750.120457ms]
Apr 27 17:05:45.196: INFO: Created: latency-svc-j2xqk
Apr 27 17:05:45.237: INFO: Got endpoints: latency-svc-4kg2n [750.511697ms]
Apr 27 17:05:45.247: INFO: Created: latency-svc-4b78v
Apr 27 17:05:45.286: INFO: Got endpoints: latency-svc-8npbw [750.156794ms]
Apr 27 17:05:45.295: INFO: Created: latency-svc-6jl2h
Apr 27 17:05:45.337: INFO: Got endpoints: latency-svc-r75b5 [750.72546ms]
Apr 27 17:05:45.346: INFO: Created: latency-svc-s74j9
Apr 27 17:05:45.387: INFO: Got endpoints: latency-svc-gkxhr [750.780532ms]
Apr 27 17:05:45.395: INFO: Created: latency-svc-ff2fl
Apr 27 17:05:45.436: INFO: Got endpoints: latency-svc-5nsg7 [749.312377ms]
Apr 27 17:05:45.447: INFO: Created: latency-svc-qwgbg
Apr 27 17:05:45.505: INFO: Got endpoints: latency-svc-cwf5b [768.314373ms]
Apr 27 17:05:45.514: INFO: Created: latency-svc-m9qjp
Apr 27 17:05:45.537: INFO: Got endpoints: latency-svc-gclp6 [749.662572ms]
Apr 27 17:05:45.546: INFO: Created: latency-svc-dp4vg
Apr 27 17:05:45.588: INFO: Got endpoints: latency-svc-cjht2 [751.848833ms]
Apr 27 17:05:45.597: INFO: Created: latency-svc-jk9pc
Apr 27 17:05:45.637: INFO: Got endpoints: latency-svc-rtppr [751.493229ms]
Apr 27 17:05:45.646: INFO: Created: latency-svc-tvsn9
Apr 27 17:05:45.686: INFO: Got endpoints: latency-svc-z8h79 [750.214819ms]
Apr 27 17:05:45.695: INFO: Created: latency-svc-zggnb
Apr 27 17:05:45.736: INFO: Got endpoints: latency-svc-pfj5n [750.22666ms]
Apr 27 17:05:45.749: INFO: Created: latency-svc-rrsd4
Apr 27 17:05:45.786: INFO: Got endpoints: latency-svc-rmj56 [749.383536ms]
Apr 27 17:05:45.796: INFO: Created: latency-svc-kbccf
Apr 27 17:05:45.836: INFO: Got endpoints: latency-svc-pbrv4 [749.831115ms]
Apr 27 17:05:45.845: INFO: Created: latency-svc-gkrnb
Apr 27 17:05:45.886: INFO: Got endpoints: latency-svc-ddcqg [749.914363ms]
Apr 27 17:05:45.896: INFO: Created: latency-svc-fhr5p
Apr 27 17:05:45.937: INFO: Got endpoints: latency-svc-j2xqk [750.36474ms]
Apr 27 17:05:45.947: INFO: Created: latency-svc-4j7z5
Apr 27 17:05:45.988: INFO: Got endpoints: latency-svc-4b78v [750.688319ms]
Apr 27 17:05:45.996: INFO: Created: latency-svc-cc5q6
Apr 27 17:05:46.036: INFO: Got endpoints: latency-svc-6jl2h [749.706934ms]
Apr 27 17:05:46.045: INFO: Created: latency-svc-84bk5
Apr 27 17:05:46.086: INFO: Got endpoints: latency-svc-s74j9 [748.753715ms]
Apr 27 17:05:46.095: INFO: Created: latency-svc-dfd7h
Apr 27 17:05:46.136: INFO: Got endpoints: latency-svc-ff2fl [749.639351ms]
Apr 27 17:05:46.146: INFO: Created: latency-svc-plmkf
Apr 27 17:05:46.186: INFO: Got endpoints: latency-svc-qwgbg [750.159705ms]
Apr 27 17:05:46.196: INFO: Created: latency-svc-g67d8
Apr 27 17:05:46.236: INFO: Got endpoints: latency-svc-m9qjp [731.197874ms]
Apr 27 17:05:46.249: INFO: Created: latency-svc-sm5q5
Apr 27 17:05:46.287: INFO: Got endpoints: latency-svc-dp4vg [750.386222ms]
Apr 27 17:05:46.296: INFO: Created: latency-svc-x8wxk
Apr 27 17:05:46.345: INFO: Got endpoints: latency-svc-jk9pc [756.89177ms]
Apr 27 17:05:46.354: INFO: Created: latency-svc-qvdzn
Apr 27 17:05:46.386: INFO: Got endpoints: latency-svc-tvsn9 [748.665156ms]
Apr 27 17:05:46.395: INFO: Created: latency-svc-dbcrk
Apr 27 17:05:46.436: INFO: Got endpoints: latency-svc-zggnb [749.991106ms]
Apr 27 17:05:46.445: INFO: Created: latency-svc-f78kq
Apr 27 17:05:46.486: INFO: Got endpoints: latency-svc-rrsd4 [749.776715ms]
Apr 27 17:05:46.496: INFO: Created: latency-svc-tc6lb
Apr 27 17:05:46.537: INFO: Got endpoints: latency-svc-kbccf [750.260262ms]
Apr 27 17:05:46.557: INFO: Created: latency-svc-8rb4r
Apr 27 17:05:46.586: INFO: Got endpoints: latency-svc-gkrnb [750.05382ms]
Apr 27 17:05:46.596: INFO: Created: latency-svc-fplgn
Apr 27 17:05:46.637: INFO: Got endpoints: latency-svc-fhr5p [750.714555ms]
Apr 27 17:05:46.646: INFO: Created: latency-svc-bcwx4
Apr 27 17:05:46.689: INFO: Got endpoints: latency-svc-4j7z5 [752.122028ms]
Apr 27 17:05:46.699: INFO: Created: latency-svc-4gbct
Apr 27 17:05:46.815: INFO: Got endpoints: latency-svc-84bk5 [779.176487ms]
Apr 27 17:05:46.815: INFO: Got endpoints: latency-svc-cc5q6 [827.790285ms]
Apr 27 17:05:46.825: INFO: Created: latency-svc-nzrrs
Apr 27 17:05:46.828: INFO: Created: latency-svc-q8n4k
Apr 27 17:05:46.915: INFO: Got endpoints: latency-svc-plmkf [778.667797ms]
Apr 27 17:05:46.915: INFO: Got endpoints: latency-svc-dfd7h [829.251882ms]
Apr 27 17:05:46.924: INFO: Created: latency-svc-zddv9
Apr 27 17:05:46.929: INFO: Created: latency-svc-qxdrp
Apr 27 17:05:46.936: INFO: Got endpoints: latency-svc-g67d8 [749.777181ms]
Apr 27 17:05:46.946: INFO: Created: latency-svc-4gx47
Apr 27 17:05:47.014: INFO: Got endpoints: latency-svc-sm5q5 [777.974212ms]
Apr 27 17:05:47.023: INFO: Created: latency-svc-hhxlx
Apr 27 17:05:47.036: INFO: Got endpoints: latency-svc-x8wxk [748.560724ms]
Apr 27 17:05:47.048: INFO: Created: latency-svc-zrhvj
Apr 27 17:05:47.112: INFO: Got endpoints: latency-svc-dbcrk [726.187362ms]
Apr 27 17:05:47.122: INFO: Created: latency-svc-kglkb
Apr 27 17:05:47.136: INFO: Got endpoints: latency-svc-qvdzn [791.608487ms]
Apr 27 17:05:47.146: INFO: Created: latency-svc-vx57g
Apr 27 17:05:47.186: INFO: Got endpoints: latency-svc-f78kq [750.10116ms]
Apr 27 17:05:47.196: INFO: Created: latency-svc-ntz2r
Apr 27 17:05:47.237: INFO: Got endpoints: latency-svc-tc6lb [750.463741ms]
Apr 27 17:05:47.246: INFO: Created: latency-svc-n7rs2
Apr 27 17:05:47.286: INFO: Got endpoints: latency-svc-8rb4r [749.584491ms]
Apr 27 17:05:47.296: INFO: Created: latency-svc-h96j6
Apr 27 17:05:47.336: INFO: Got endpoints: latency-svc-fplgn [750.185242ms]
Apr 27 17:05:47.346: INFO: Created: latency-svc-ght92
Apr 27 17:05:47.386: INFO: Got endpoints: latency-svc-bcwx4 [748.931185ms]
Apr 27 17:05:47.396: INFO: Created: latency-svc-jrj4p
Apr 27 17:05:47.436: INFO: Got endpoints: latency-svc-4gbct [746.696802ms]
Apr 27 17:05:47.445: INFO: Created: latency-svc-8swwq
Apr 27 17:05:47.487: INFO: Got endpoints: latency-svc-nzrrs [671.382518ms]
Apr 27 17:05:47.497: INFO: Created: latency-svc-lmx7m
Apr 27 17:05:47.536: INFO: Got endpoints: latency-svc-q8n4k [720.508277ms]
Apr 27 17:05:47.545: INFO: Created: latency-svc-t8dnx
Apr 27 17:05:47.586: INFO: Got endpoints: latency-svc-zddv9 [670.962235ms]
Apr 27 17:05:47.596: INFO: Created: latency-svc-nllb8
Apr 27 17:05:47.638: INFO: Got endpoints: latency-svc-qxdrp [722.770154ms]
Apr 27 17:05:47.650: INFO: Created: latency-svc-6pxr4
Apr 27 17:05:47.711: INFO: Got endpoints: latency-svc-4gx47 [774.865608ms]
Apr 27 17:05:47.724: INFO: Created: latency-svc-vzc92
Apr 27 17:05:47.811: INFO: Got endpoints: latency-svc-zrhvj [775.160493ms]
Apr 27 17:05:47.811: INFO: Got endpoints: latency-svc-hhxlx [797.131333ms]
Apr 27 17:05:47.824: INFO: Created: latency-svc-jr6w9
Apr 27 17:05:47.911: INFO: Got endpoints: latency-svc-vx57g [774.689963ms]
Apr 27 17:05:47.911: INFO: Got endpoints: latency-svc-kglkb [799.108405ms]
Apr 27 17:05:47.916: INFO: Created: latency-svc-2jzxt
Apr 27 17:05:47.925: INFO: Created: latency-svc-qhmdm
Apr 27 17:05:47.927: INFO: Created: latency-svc-w2h29
Apr 27 17:05:47.936: INFO: Got endpoints: latency-svc-ntz2r [750.056337ms]
Apr 27 17:05:47.945: INFO: Created: latency-svc-7r6xd
Apr 27 17:05:47.986: INFO: Got endpoints: latency-svc-n7rs2 [749.68625ms]
Apr 27 17:05:48.016: INFO: Created: latency-svc-4brgd
Apr 27 17:05:48.036: INFO: Got endpoints: latency-svc-h96j6 [749.610094ms]
Apr 27 17:05:48.045: INFO: Created: latency-svc-mdlnk
Apr 27 17:05:48.086: INFO: Got endpoints: latency-svc-ght92 [749.488021ms]
Apr 27 17:05:48.095: INFO: Created: latency-svc-x5rkh
Apr 27 17:05:48.136: INFO: Got endpoints: latency-svc-jrj4p [749.811818ms]
Apr 27 17:05:48.144: INFO: Created: latency-svc-4289q
Apr 27 17:05:48.186: INFO: Got endpoints: latency-svc-8swwq [750.31141ms]
Apr 27 17:05:48.195: INFO: Created: latency-svc-wmd6n
Apr 27 17:05:48.236: INFO: Got endpoints: latency-svc-lmx7m [749.094709ms]
Apr 27 17:05:48.245: INFO: Created: latency-svc-k6xr2
Apr 27 17:05:48.286: INFO: Got endpoints: latency-svc-t8dnx [749.997881ms]
Apr 27 17:05:48.295: INFO: Created: latency-svc-57w2w
Apr 27 17:05:48.337: INFO: Got endpoints: latency-svc-nllb8 [750.601535ms]
Apr 27 17:05:48.346: INFO: Created: latency-svc-q2pww
Apr 27 17:05:48.386: INFO: Got endpoints: latency-svc-6pxr4 [748.279749ms]
Apr 27 17:05:48.395: INFO: Created: latency-svc-j2cnd
Apr 27 17:05:48.436: INFO: Got endpoints: latency-svc-vzc92 [724.789154ms]
Apr 27 17:05:48.445: INFO: Created: latency-svc-4gpfq
Apr 27 17:05:48.489: INFO: Got endpoints: latency-svc-jr6w9 [677.391974ms]
Apr 27 17:05:48.497: INFO: Created: latency-svc-qf78k
Apr 27 17:05:48.538: INFO: Got endpoints: latency-svc-2jzxt [726.195469ms]
Apr 27 17:05:48.547: INFO: Created: latency-svc-tcls7
Apr 27 17:05:48.587: INFO: Got endpoints: latency-svc-qhmdm [675.422438ms]
Apr 27 17:05:48.597: INFO: Created: latency-svc-b9s25
Apr 27 17:05:48.637: INFO: Got endpoints: latency-svc-w2h29 [726.017408ms]
Apr 27 17:05:48.647: INFO: Created: latency-svc-4jndn
Apr 27 17:05:48.687: INFO: Got endpoints: latency-svc-7r6xd [750.12318ms]
Apr 27 17:05:48.698: INFO: Created: latency-svc-2k7db
Apr 27 17:05:48.737: INFO: Got endpoints: latency-svc-4brgd [750.883444ms]
Apr 27 17:05:48.746: INFO: Created: latency-svc-8w5kp
Apr 27 17:05:48.786: INFO: Got endpoints: latency-svc-mdlnk [750.031599ms]
Apr 27 17:05:48.795: INFO: Created: latency-svc-s4glt
Apr 27 17:05:48.836: INFO: Got endpoints: latency-svc-x5rkh [750.288059ms]
Apr 27 17:05:48.845: INFO: Created: latency-svc-lh7zz
Apr 27 17:05:48.886: INFO: Got endpoints: latency-svc-4289q [750.142637ms]
Apr 27 17:05:48.895: INFO: Created: latency-svc-9m5xp
Apr 27 17:05:48.937: INFO: Got endpoints: latency-svc-wmd6n [750.285138ms]
Apr 27 17:05:48.946: INFO: Created: latency-svc-qbds6
Apr 27 17:05:48.986: INFO: Got endpoints: latency-svc-k6xr2 [750.093224ms]
Apr 27 17:05:48.995: INFO: Created: latency-svc-c4cfl
Apr 27 17:05:49.036: INFO: Got endpoints: latency-svc-57w2w [750.002658ms]
Apr 27 17:05:49.045: INFO: Created: latency-svc-v9l22
Apr 27 17:05:49.086: INFO: Got endpoints: latency-svc-q2pww [749.370841ms]
Apr 27 17:05:49.095: INFO: Created: latency-svc-rdkmq
Apr 27 17:05:49.136: INFO: Got endpoints: latency-svc-j2cnd [749.960059ms]
Apr 27 17:05:49.145: INFO: Created: latency-svc-t48jc
Apr 27 17:05:49.187: INFO: Got endpoints: latency-svc-4gpfq [750.604052ms]
Apr 27 17:05:49.197: INFO: Created: latency-svc-c7g2c
Apr 27 17:05:49.236: INFO: Got endpoints: latency-svc-qf78k [747.057184ms]
Apr 27 17:05:49.244: INFO: Created: latency-svc-qvm6z
Apr 27 17:05:49.286: INFO: Got endpoints: latency-svc-tcls7 [748.294887ms]
Apr 27 17:05:49.296: INFO: Created: latency-svc-8hfzj
Apr 27 17:05:49.336: INFO: Got endpoints: latency-svc-b9s25 [749.6667ms]
Apr 27 17:05:49.345: INFO: Created: latency-svc-lhvns
Apr 27 17:05:49.386: INFO: Got endpoints: latency-svc-4jndn [748.824104ms]
Apr 27 17:05:49.395: INFO: Created: latency-svc-2wgcz
Apr 27 17:05:49.437: INFO: Got endpoints: latency-svc-2k7db [749.81953ms]
Apr 27 17:05:49.446: INFO: Created: latency-svc-vt9jj
Apr 27 17:05:49.486: INFO: Got endpoints: latency-svc-8w5kp [748.963686ms]
Apr 27 17:05:49.496: INFO: Created: latency-svc-tm2wc
Apr 27 17:05:49.536: INFO: Got endpoints: latency-svc-s4glt [749.740192ms]
Apr 27 17:05:49.546: INFO: Created: latency-svc-5c5m9
Apr 27 17:05:49.587: INFO: Got endpoints: latency-svc-lh7zz [750.23655ms]
Apr 27 17:05:49.595: INFO: Created: latency-svc-8jg56
Apr 27 17:05:49.637: INFO: Got endpoints: latency-svc-9m5xp [750.299229ms]
Apr 27 17:05:49.645: INFO: Created: latency-svc-pgbt2
Apr 27 17:05:49.687: INFO: Got endpoints: latency-svc-qbds6 [750.070534ms]
Apr 27 17:05:49.697: INFO: Created: latency-svc-jmp7d
Apr 27 17:05:49.738: INFO: Got endpoints: latency-svc-c4cfl [751.498379ms]
Apr 27 17:05:49.747: INFO: Created: latency-svc-vk8zc
Apr 27 17:05:49.786: INFO: Got endpoints: latency-svc-v9l22 [749.588244ms]
Apr 27 17:05:49.794: INFO: Created: latency-svc-wgg64
Apr 27 17:05:49.836: INFO: Got endpoints: latency-svc-rdkmq [750.039968ms]
Apr 27 17:05:49.852: INFO: Created: latency-svc-pz7fr
Apr 27 17:05:49.886: INFO: Got endpoints: latency-svc-t48jc [749.489193ms]
Apr 27 17:05:49.936: INFO: Got endpoints: latency-svc-c7g2c [749.338513ms]
Apr 27 17:05:49.987: INFO: Got endpoints: latency-svc-qvm6z [751.016936ms]
Apr 27 17:05:50.036: INFO: Got endpoints: latency-svc-8hfzj [750.113118ms]
Apr 27 17:05:50.087: INFO: Got endpoints: latency-svc-lhvns [750.399881ms]
Apr 27 17:05:50.136: INFO: Got endpoints: latency-svc-2wgcz [749.732518ms]
Apr 27 17:05:50.188: INFO: Got endpoints: latency-svc-vt9jj [750.89572ms]
Apr 27 17:05:50.237: INFO: Got endpoints: latency-svc-tm2wc [750.309866ms]
Apr 27 17:05:50.287: INFO: Got endpoints: latency-svc-5c5m9 [750.721598ms]
Apr 27 17:05:50.337: INFO: Got endpoints: latency-svc-8jg56 [750.017427ms]
Apr 27 17:05:50.387: INFO: Got endpoints: latency-svc-pgbt2 [750.262701ms]
Apr 27 17:05:50.437: INFO: Got endpoints: latency-svc-jmp7d [749.911291ms]
Apr 27 17:05:50.486: INFO: Got endpoints: latency-svc-vk8zc [748.28318ms]
Apr 27 17:05:50.536: INFO: Got endpoints: latency-svc-wgg64 [750.185608ms]
Apr 27 17:05:50.586: INFO: Got endpoints: latency-svc-pz7fr [749.882786ms]
Apr 27 17:05:50.586: INFO: Latencies: [12.893269ms 16.273892ms 19.917281ms 23.679921ms 25.741756ms 30.597109ms 33.198909ms 38.380605ms 40.633093ms 45.565001ms 50.361612ms 54.502031ms 62.770537ms 77.718165ms 106.067435ms 106.494024ms 107.976172ms 108.128693ms 108.806634ms 108.91152ms 109.54745ms 111.098758ms 111.312882ms 112.296884ms 112.865771ms 113.236915ms 113.307972ms 113.490163ms 113.880737ms 114.298892ms 115.627318ms 117.983546ms 118.750265ms 151.075313ms 158.393283ms 208.906199ms 255.27808ms 302.054775ms 347.176088ms 391.72519ms 437.758264ms 478.899135ms 485.928752ms 533.977327ms 578.650589ms 622.220059ms 670.404216ms 670.962235ms 671.382518ms 675.422438ms 677.391974ms 709.229458ms 720.508277ms 722.770154ms 724.789154ms 726.017408ms 726.187362ms 726.195469ms 731.197874ms 736.218301ms 746.696802ms 747.057184ms 748.279749ms 748.28318ms 748.294887ms 748.298306ms 748.545639ms 748.560724ms 748.665156ms 748.753715ms 748.801863ms 748.824104ms 748.931185ms 748.963686ms 749.094709ms 749.232377ms 749.295245ms 749.312377ms 749.322977ms 749.338513ms 749.338552ms 749.341935ms 749.366646ms 749.370841ms 749.383536ms 749.488021ms 749.489193ms 749.504703ms 749.544384ms 749.584491ms 749.588244ms 749.610094ms 749.612645ms 749.622301ms 749.636577ms 749.639351ms 749.662572ms 749.6667ms 749.68625ms 749.706934ms 749.732518ms 749.740192ms 749.749728ms 749.776715ms 749.777181ms 749.795316ms 749.811818ms 749.81953ms 749.828907ms 749.831115ms 749.882786ms 749.910243ms 749.911291ms 749.913571ms 749.914363ms 749.926069ms 749.941908ms 749.960059ms 749.991106ms 749.997881ms 750.002658ms 750.017427ms 750.020946ms 750.031599ms 750.039968ms 750.05382ms 750.056337ms 750.067423ms 750.070534ms 750.093224ms 750.10116ms 750.105629ms 750.113118ms 750.120457ms 750.12318ms 750.130098ms 750.142637ms 750.156794ms 750.159705ms 750.172066ms 750.185242ms 750.185608ms 750.186743ms 750.213932ms 750.214819ms 750.22666ms 750.23655ms 750.26025ms 750.260262ms 750.262701ms 750.285138ms 750.288059ms 750.299229ms 750.309866ms 750.31141ms 750.338495ms 750.357641ms 750.36474ms 750.386222ms 750.396282ms 750.399881ms 750.404675ms 750.463741ms 750.477238ms 750.482593ms 750.511697ms 750.536016ms 750.601535ms 750.604052ms 750.688319ms 750.714555ms 750.721598ms 750.72546ms 750.72974ms 750.780532ms 750.883444ms 750.89572ms 750.906638ms 751.016936ms 751.152088ms 751.163257ms 751.493229ms 751.498379ms 751.848833ms 752.021305ms 752.122028ms 752.202471ms 756.89177ms 768.314373ms 774.689963ms 774.865608ms 775.160493ms 777.974212ms 778.667797ms 779.176487ms 791.608487ms 797.131333ms 799.108405ms 827.790285ms 829.251882ms]
Apr 27 17:05:50.587: INFO: 50 %ile: 749.732518ms
Apr 27 17:05:50.587: INFO: 90 %ile: 751.163257ms
Apr 27 17:05:50.587: INFO: 99 %ile: 827.790285ms
Apr 27 17:05:50.587: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:50.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3931" for this suite.
•{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":277,"completed":213,"skipped":3648,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:50.601: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:05:50.849: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 27 17:05:55.854: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 27 17:05:55.854: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Apr 27 17:05:57.890: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3365 /apis/apps/v1/namespaces/deployment-3365/deployments/test-cleanup-deployment 1c554764-4ba3-4c1d-854f-1ad82fabcc99 29866 1 2020-04-27 17:05:55 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2020-04-27 17:05:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-04-27 17:05:57 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0020a36f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-27 17:05:55 +0000 UTC,LastTransitionTime:2020-04-27 17:05:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2020-04-27 17:05:57 +0000 UTC,LastTransitionTime:2020-04-27 17:05:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 27 17:05:57.894: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-3365 /apis/apps/v1/namespaces/deployment-3365/replicasets/test-cleanup-deployment-b4867b47f f2bbd53a-49e8-4613-af98-10ac050eb74f 29852 1 2020-04-27 17:05:55 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 1c554764-4ba3-4c1d-854f-1ad82fabcc99 0xc0020a3b70 0xc0020a3b71}] []  [{kube-controller-manager Update apps/v1 2020-04-27 17:05:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 99 53 53 52 55 54 52 45 52 98 97 51 45 52 99 49 100 45 56 53 52 102 45 49 97 100 56 50 102 97 98 99 99 57 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0020a3be8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 27 17:05:57.899: INFO: Pod "test-cleanup-deployment-b4867b47f-sdzrv" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-sdzrv test-cleanup-deployment-b4867b47f- deployment-3365 /api/v1/namespaces/deployment-3365/pods/test-cleanup-deployment-b4867b47f-sdzrv b4af41bb-61dd-463e-9622-7f374ec793dc 29849 0 2020-04-27 17:05:55 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[cni.projectcalico.org/podIP:100.64.1.8/32 cni.projectcalico.org/podIPs:100.64.1.8/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f f2bbd53a-49e8-4613-af98-10ac050eb74f 0xc001f6e010 0xc001f6e011}] []  [{kube-controller-manager Update v1 2020-04-27 17:05:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 50 98 98 100 53 51 97 45 52 57 101 56 45 52 54 49 51 45 97 102 57 56 45 49 48 97 99 48 53 48 101 98 55 52 102 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-04-27 17:05:56 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-04-27 17:05:57 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-dhq65,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-dhq65,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-dhq65,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:05:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:05:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:05:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:05:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.8,StartTime:2020-04-27 17:05:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:05:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://641e5bdf62fbfb09010b85cfda8490c8dde4172ea4b528ef8e6a931e3eba745c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:05:57.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3365" for this suite.
•{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":277,"completed":214,"skipped":3655,"failed":0}
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:05:57.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 27 17:06:02.624: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0e64338a-3784-4a81-9492-0e3bb6975a27"
Apr 27 17:06:02.624: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0e64338a-3784-4a81-9492-0e3bb6975a27" in namespace "pods-9041" to be "terminated due to deadline exceeded"
Apr 27 17:06:02.629: INFO: Pod "pod-update-activedeadlineseconds-0e64338a-3784-4a81-9492-0e3bb6975a27": Phase="Running", Reason="", readiness=true. Elapsed: 4.397236ms
Apr 27 17:06:04.634: INFO: Pod "pod-update-activedeadlineseconds-0e64338a-3784-4a81-9492-0e3bb6975a27": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.009716279s
Apr 27 17:06:04.634: INFO: Pod "pod-update-activedeadlineseconds-0e64338a-3784-4a81-9492-0e3bb6975a27" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:04.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9041" for this suite.
•{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":277,"completed":215,"skipped":3658,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:04.647: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-249
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Apr 27 17:06:04.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-249'
Apr 27 17:06:05.024: INFO: stderr: ""
Apr 27 17:06:05.025: INFO: stdout: "pod/pause created\n"
Apr 27 17:06:05.025: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 27 17:06:05.025: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-249" to be "running and ready"
Apr 27 17:06:05.029: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127192ms
Apr 27 17:06:07.034: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.00933909s
Apr 27 17:06:07.034: INFO: Pod "pause" satisfied condition "running and ready"
Apr 27 17:06:07.034: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 27 17:06:07.034: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-249'
Apr 27 17:06:07.170: INFO: stderr: ""
Apr 27 17:06:07.170: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 27 17:06:07.170: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-249'
Apr 27 17:06:07.304: INFO: stderr: ""
Apr 27 17:06:07.304: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 27 17:06:07.304: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-249'
Apr 27 17:06:07.395: INFO: stderr: ""
Apr 27 17:06:07.395: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 27 17:06:07.395: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-249'
Apr 27 17:06:07.481: INFO: stderr: ""
Apr 27 17:06:07.481: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Apr 27 17:06:07.481: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-249'
Apr 27 17:06:07.614: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 27 17:06:07.614: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 27 17:06:07.614: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-249'
Apr 27 17:06:07.699: INFO: stderr: "No resources found in kubectl-249 namespace.\n"
Apr 27 17:06:07.699: INFO: stdout: ""
Apr 27 17:06:07.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-249 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 27 17:06:07.817: INFO: stderr: ""
Apr 27 17:06:07.817: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:07.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-249" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":277,"completed":216,"skipped":3667,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:07.830: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Apr 27 17:06:18.015: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 17:06:18.015530    7398 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:18.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-371" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":277,"completed":217,"skipped":3671,"failed":0}
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:18.029: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2902
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-2902
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 17:06:18.178: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 17:06:18.206: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:06:20.214: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:22.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:24.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:26.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:28.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:30.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:32.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:34.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:36.212: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:06:38.212: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 17:06:38.220: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 17:06:40.263: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.13 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2902 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:06:40.263: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:06:46.560: INFO: Found all expected endpoints: [netserver-0]
Apr 27 17:06:46.565: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.61 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2902 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:06:46.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:06:47.995: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:47.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2902" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":218,"skipped":3675,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:48.010: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4402
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:06:50.712: INFO: Successfully updated pod "annotationupdate0568132b-0d7d-46cc-90dc-684e26f227a2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:54.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4402" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":277,"completed":219,"skipped":3677,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:54.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Apr 27 17:06:54.915: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Apr 27 17:06:55.047: INFO: stderr: ""
Apr 27 17:06:55.047: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:06:55.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6715" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":277,"completed":220,"skipped":3727,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:06:55.061: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-906
STEP: creating replication controller nodeport-test in namespace services-906
I0427 17:06:55.229360    7398 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-906, replica count: 2
I0427 17:06:58.279957    7398 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 27 17:06:58.280: INFO: Creating new exec pod
Apr 27 17:07:01.306: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-906 execpodgpv7k -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Apr 27 17:07:06.938: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 27 17:07:06.938: INFO: stdout: ""
Apr 27 17:07:06.938: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-906 execpodgpv7k -- /bin/sh -x -c nc -zv -t -w 2 100.110.226.97 80'
Apr 27 17:07:07.432: INFO: stderr: "+ nc -zv -t -w 2 100.110.226.97 80\nConnection to 100.110.226.97 80 port [tcp/http] succeeded!\n"
Apr 27 17:07:07.432: INFO: stdout: ""
Apr 27 17:07:07.432: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-906 execpodgpv7k -- /bin/sh -x -c nc -zv -t -w 2 10.250.31.184 30672'
Apr 27 17:07:07.984: INFO: stderr: "+ nc -zv -t -w 2 10.250.31.184 30672\nConnection to 10.250.31.184 30672 port [tcp/30672] succeeded!\n"
Apr 27 17:07:07.984: INFO: stdout: ""
Apr 27 17:07:07.984: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-906 execpodgpv7k -- /bin/sh -x -c nc -zv -t -w 2 10.250.31.185 30672'
Apr 27 17:07:08.442: INFO: stderr: "+ nc -zv -t -w 2 10.250.31.185 30672\nConnection to 10.250.31.185 30672 port [tcp/30672] succeeded!\n"
Apr 27 17:07:08.442: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:08.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-906" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":277,"completed":221,"skipped":3744,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:08.456: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7376
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:16.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7376" for this suite.
•{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":277,"completed":222,"skipped":3773,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:16.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:07:17.019: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:07:19.033: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604037, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604037, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604037, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604037, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:07:22.046: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:22.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5823" for this suite.
STEP: Destroying namespace "webhook-5823-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":277,"completed":223,"skipped":3787,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:22.270: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5109
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:07:22.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52" in namespace "projected-5109" to be "Succeeded or Failed"
Apr 27 17:07:22.431: INFO: Pod "downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.249389ms
Apr 27 17:07:24.436: INFO: Pod "downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009362258s
Apr 27 17:07:26.442: INFO: Pod "downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014704799s
STEP: Saw pod success
Apr 27 17:07:26.442: INFO: Pod "downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52" satisfied condition "Succeeded or Failed"
Apr 27 17:07:26.446: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52 container client-container: <nil>
STEP: delete the pod
Apr 27 17:07:26.467: INFO: Waiting for pod downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52 to disappear
Apr 27 17:07:26.471: INFO: Pod downwardapi-volume-6845603b-3ed9-47a0-be86-c9dea5a09a52 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:26.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5109" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":224,"skipped":3810,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:26.484: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-e5f5941b-5358-4458-93f5-6a7582363c71
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:26.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3635" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":277,"completed":225,"skipped":3845,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:26.649: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:07:29.348: INFO: Successfully updated pod "labelsupdate95b45245-dfb3-42a5-b32e-37eecf331f30"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:31.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7669" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":226,"skipped":3848,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:31.389: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Apr 27 17:07:31.545: INFO: Waiting up to 5m0s for pod "client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668" in namespace "containers-1967" to be "Succeeded or Failed"
Apr 27 17:07:31.549: INFO: Pod "client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668": Phase="Pending", Reason="", readiness=false. Elapsed: 4.098904ms
Apr 27 17:07:33.554: INFO: Pod "client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009308804s
STEP: Saw pod success
Apr 27 17:07:33.554: INFO: Pod "client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668" satisfied condition "Succeeded or Failed"
Apr 27 17:07:33.559: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668 container test-container: <nil>
STEP: delete the pod
Apr 27 17:07:33.583: INFO: Waiting for pod client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668 to disappear
Apr 27 17:07:33.587: INFO: Pod client-containers-53e6e1d9-eee0-447c-9b2a-b2cdb710a668 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:33.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1967" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":277,"completed":227,"skipped":3863,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:33.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 27 17:07:35.777: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:35.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3236" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":277,"completed":228,"skipped":3882,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:35.802: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:07:35.950: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:07:35.967: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:07:35.971: INFO: 
Logging pods the kubelet thinks is on node izgw82palggheybhhd1s46z before test
Apr 27 17:07:35.992: INFO: labelsupdate95b45245-dfb3-42a5-b32e-37eecf331f30 from projected-7669 started at 2020-04-27 17:07:26 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:35.992: INFO: 	Container client-container ready: true, restart count 0
Apr 27 17:07:35.992: INFO: kube-proxy-r447h from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:35.992: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:07:35.992: INFO: node-problem-detector-m6qcf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:35.992: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:07:35.992: INFO: csi-disk-plugin-alicloud-hzxms from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 17:07:35.992: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 17:07:35.992: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 17:07:35.992: INFO: node-exporter-k58cv from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:35.992: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:07:35.992: INFO: calico-node-xjxjf from kube-system started at 2020-04-27 16:33:40 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:35.992: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:07:35.992: INFO: 
Logging pods the kubelet thinks is on node izgw873bmqhhfhflh483llz before test
Apr 27 17:07:36.034: INFO: blackbox-exporter-5dc75b79b7-xshtf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:07:36.034: INFO: node-problem-detector-9ntf8 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:07:36.034: INFO: calico-typha-deploy-784665cc66-b2n69 from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:07:36.034: INFO: addons-nginx-ingress-controller-6cf77756b5-rwfsq from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:07:36.034: INFO: dashboard-metrics-scraper-76c7b697bc-zfk9z from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:07:36.034: INFO: kube-proxy-v48zq from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:07:36.034: INFO: calico-kube-controllers-77dcb8f688-44xhb from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 17:07:36.034: INFO: coredns-5cb857d789-5cvkp from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:07:36.034: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-qp9pw from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:07:36.034: INFO: vpn-shoot-6f75686cfb-ntkwh from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:07:36.034: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-dtlrp from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:07:36.034: INFO: calico-node-p7gsw from kube-system started at 2020-04-27 16:33:54 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:07:36.034: INFO: csi-disk-plugin-alicloud-9szgk from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 17:07:36.034: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 17:07:36.034: INFO: calico-typha-vertical-autoscaler-5b477c88cf-ltrk8 from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:07:36.034: INFO: coredns-5cb857d789-x7mvm from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:07:36.034: INFO: kubernetes-dashboard-6b586c4cb4-nqch8 from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 17:07:36.034: INFO: calico-node-vertical-autoscaler-74d4897db8-m2vrd from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:07:36.034: INFO: node-exporter-gjwg5 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:07:36.034: INFO: metrics-server-7ff88f9d88-zmzhg from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:07:36.034: INFO: 	Container metrics-server ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-db24c95f-2a44-4828-9e7e-4b6494d08759 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-db24c95f-2a44-4828-9e7e-4b6494d08759 off the node izgw82palggheybhhd1s46z
STEP: verifying the node doesn't have the label kubernetes.io/e2e-db24c95f-2a44-4828-9e7e-4b6494d08759
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:40.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6094" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":277,"completed":229,"skipped":3919,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:40.131: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Apr 27 17:07:40.278: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:44.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2274" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":277,"completed":230,"skipped":3936,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:44.123: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 27 17:07:54.365: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0427 17:07:54.365379    7398 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 17:07:54.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8207" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":277,"completed":231,"skipped":3959,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:54.376: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Apr 27 17:07:57.071: INFO: Successfully updated pod "labelsupdatef124572b-13e0-4813-9b8b-a4cd9f9dda05"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:07:59.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7003" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":277,"completed":232,"skipped":4008,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:07:59.112: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9191
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:07:59.811: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:08:01.826: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604079, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:08:04.841: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr 27 17:08:04.957: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:05.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9191" for this suite.
STEP: Destroying namespace "webhook-9191-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":277,"completed":233,"skipped":4015,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:05.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3201
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-8f500053-f7ab-4013-aee1-2f1579bd10ed
STEP: Creating a pod to test consume secrets
Apr 27 17:08:05.232: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681" in namespace "projected-3201" to be "Succeeded or Failed"
Apr 27 17:08:05.236: INFO: Pod "pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681": Phase="Pending", Reason="", readiness=false. Elapsed: 4.633726ms
Apr 27 17:08:07.242: INFO: Pod "pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010183042s
STEP: Saw pod success
Apr 27 17:08:07.242: INFO: Pod "pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681" satisfied condition "Succeeded or Failed"
Apr 27 17:08:07.246: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:08:07.267: INFO: Waiting for pod pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681 to disappear
Apr 27 17:08:07.271: INFO: Pod pod-projected-secrets-107546a3-9adb-4d6b-a563-fe3b1f2be681 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:07.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3201" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":234,"skipped":4028,"failed":0}

------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:07.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:08:07.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d" in namespace "downward-api-6271" to be "Succeeded or Failed"
Apr 27 17:08:07.446: INFO: Pod "downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.376245ms
Apr 27 17:08:09.454: INFO: Pod "downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012107915s
STEP: Saw pod success
Apr 27 17:08:09.454: INFO: Pod "downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d" satisfied condition "Succeeded or Failed"
Apr 27 17:08:09.458: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d container client-container: <nil>
STEP: delete the pod
Apr 27 17:08:09.479: INFO: Waiting for pod downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d to disappear
Apr 27 17:08:09.483: INFO: Pod downwardapi-volume-5033eb64-937f-401f-be0e-c0fbea967c9d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:09.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6271" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":277,"completed":235,"skipped":4028,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:09.496: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:08:10.524: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Apr 27 17:08:12.539: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604090, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604090, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604090, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604090, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:08:15.553: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:08:15.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:08:16.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2151" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":277,"completed":236,"skipped":4039,"failed":0}
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:08:16.975: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:17.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3595" for this suite.
•{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":277,"completed":237,"skipped":4043,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:17.179: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1258
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-791a13f4-6066-4960-ac27-0d87f5efa712
STEP: Creating a pod to test consume secrets
Apr 27 17:09:17.340: INFO: Waiting up to 5m0s for pod "pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa" in namespace "secrets-1258" to be "Succeeded or Failed"
Apr 27 17:09:17.344: INFO: Pod "pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022758ms
Apr 27 17:09:19.350: INFO: Pod "pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00941581s
STEP: Saw pod success
Apr 27 17:09:19.350: INFO: Pod "pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa" satisfied condition "Succeeded or Failed"
Apr 27 17:09:19.354: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:09:19.379: INFO: Waiting for pod pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa to disappear
Apr 27 17:09:19.383: INFO: Pod pod-secrets-c334a323-f81e-47cc-a5c9-f38b46c6d6fa no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:19.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1258" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":238,"skipped":4051,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:19.396: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-33371acb-609d-4313-a2aa-5ab0e115fdca
STEP: Creating a pod to test consume secrets
Apr 27 17:09:19.555: INFO: Waiting up to 5m0s for pod "pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44" in namespace "secrets-834" to be "Succeeded or Failed"
Apr 27 17:09:19.559: INFO: Pod "pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44": Phase="Pending", Reason="", readiness=false. Elapsed: 3.895659ms
Apr 27 17:09:21.564: INFO: Pod "pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008974904s
STEP: Saw pod success
Apr 27 17:09:21.564: INFO: Pod "pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44" satisfied condition "Succeeded or Failed"
Apr 27 17:09:21.569: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:09:21.589: INFO: Waiting for pod pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44 to disappear
Apr 27 17:09:21.593: INFO: Pod pod-secrets-e4fe80ef-97d7-4cd0-9ba7-21d1a2c02f44 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:21.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-834" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":239,"skipped":4060,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:21.606: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6520
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 27 17:09:21.760: INFO: Waiting up to 5m0s for pod "pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c" in namespace "emptydir-6520" to be "Succeeded or Failed"
Apr 27 17:09:21.764: INFO: Pod "pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04224ms
Apr 27 17:09:23.769: INFO: Pod "pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009100719s
STEP: Saw pod success
Apr 27 17:09:23.769: INFO: Pod "pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c" satisfied condition "Succeeded or Failed"
Apr 27 17:09:23.773: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c container test-container: <nil>
STEP: delete the pod
Apr 27 17:09:23.794: INFO: Waiting for pod pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c to disappear
Apr 27 17:09:23.798: INFO: Pod pod-5d4ff3be-1403-4707-8e01-c5d2ca71f15c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:23.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6520" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":240,"skipped":4083,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:23.811: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:09:24.498: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:09:27.528: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:27.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4425" for this suite.
STEP: Destroying namespace "webhook-4425-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":277,"completed":241,"skipped":4101,"failed":0}
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:27.828: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 27 17:09:27.984: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr 27 17:09:35.034: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:35.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1453" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":277,"completed":242,"skipped":4104,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:35.051: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6273
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:09:35.812: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:09:38.836: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:39.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6273" for this suite.
STEP: Destroying namespace "webhook-6273-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":277,"completed":243,"skipped":4139,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:39.053: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2049
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 27 17:09:41.233: INFO: &Pod{ObjectMeta:{send-events-c8f18e76-558e-4a06-a795-efc138d219e9  events-2049 /api/v1/namespaces/events-2049/pods/send-events-c8f18e76-558e-4a06-a795-efc138d219e9 1d206153-d255-40f0-a19b-b3b048e4cdeb 32309 0 2020-04-27 17:09:39 +0000 UTC <nil> <nil> map[name:foo time:204916454] map[cni.projectcalico.org/podIP:100.64.1.54/32 cni.projectcalico.org/podIPs:100.64.1.54/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{calico Update v1 2020-04-27 17:09:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {e2e.test Update v1 2020-04-27 17:09:39 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-04-27 17:09:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 48 46 54 52 46 49 46 53 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fl55w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fl55w,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fl55w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw82palggheybhhd1s46z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:09:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:09:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-27 17:09:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.31.184,PodIP:100.64.1.54,StartTime:2020-04-27 17:09:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-27 17:09:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://f065363cfd0a5a4ed51b4e2e81713069882abacd4a60c0f1827685b14ec136c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr 27 17:09:43.239: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 27 17:09:45.244: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:45.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2049" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":277,"completed":244,"skipped":4168,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:45.264: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3051
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-e53ffb9b-83e8-4992-afe9-2c2fc418bd6c
STEP: Creating a pod to test consume configMaps
Apr 27 17:09:45.425: INFO: Waiting up to 5m0s for pod "pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845" in namespace "configmap-3051" to be "Succeeded or Failed"
Apr 27 17:09:45.430: INFO: Pod "pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232427ms
Apr 27 17:09:47.435: INFO: Pod "pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009971508s
STEP: Saw pod success
Apr 27 17:09:47.435: INFO: Pod "pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845" satisfied condition "Succeeded or Failed"
Apr 27 17:09:47.440: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:09:47.463: INFO: Waiting for pod pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845 to disappear
Apr 27 17:09:47.467: INFO: Pod pod-configmaps-fa3fe755-dde1-4c17-bbb3-745c4c75a845 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:09:47.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3051" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":245,"skipped":4181,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:09:47.481: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1878
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1878
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Apr 27 17:09:47.648: INFO: Found 0 stateful pods, waiting for 3
Apr 27 17:09:57.655: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:09:57.655: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:09:57.655: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 27 17:09:57.668: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1878 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:09:58.171: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:09:58.171: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:09:58.171: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 27 17:10:08.211: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 27 17:10:18.237: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1878 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:10:18.738: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 17:10:18.738: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:10:18.738: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:10:38.767: INFO: Waiting for StatefulSet statefulset-1878/ss2 to complete update
Apr 27 17:10:38.767: INFO: Waiting for Pod statefulset-1878/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Apr 27 17:10:48.778: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1878 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 27 17:10:54.321: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 27 17:10:54.322: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 27 17:10:54.322: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 27 17:11:04.362: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 27 17:11:14.386: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-1878 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 27 17:11:14.987: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 27 17:11:14.987: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 27 17:11:14.987: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 27 17:11:35.015: INFO: Waiting for StatefulSet statefulset-1878/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:11:45.029: INFO: Deleting all statefulset in ns statefulset-1878
Apr 27 17:11:45.033: INFO: Scaling statefulset ss2 to 0
Apr 27 17:12:15.054: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:12:15.058: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:15.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1878" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":277,"completed":246,"skipped":4188,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:15.089: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-x4p5
STEP: Creating a pod to test atomic-volume-subpath
Apr 27 17:12:15.257: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-x4p5" in namespace "subpath-707" to be "Succeeded or Failed"
Apr 27 17:12:15.261: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.955391ms
Apr 27 17:12:17.266: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008896271s
Apr 27 17:12:19.271: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 4.014141052s
Apr 27 17:12:21.277: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 6.019663188s
Apr 27 17:12:23.282: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 8.02490223s
Apr 27 17:12:25.288: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 10.030549912s
Apr 27 17:12:27.293: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 12.036330883s
Apr 27 17:12:29.298: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 14.041355465s
Apr 27 17:12:31.304: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 16.046933738s
Apr 27 17:12:33.309: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 18.05216514s
Apr 27 17:12:35.314: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Running", Reason="", readiness=true. Elapsed: 20.057032316s
Apr 27 17:12:37.319: INFO: Pod "pod-subpath-test-secret-x4p5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.061810717s
STEP: Saw pod success
Apr 27 17:12:37.319: INFO: Pod "pod-subpath-test-secret-x4p5" satisfied condition "Succeeded or Failed"
Apr 27 17:12:37.323: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-subpath-test-secret-x4p5 container test-container-subpath-secret-x4p5: <nil>
STEP: delete the pod
Apr 27 17:12:37.413: INFO: Waiting for pod pod-subpath-test-secret-x4p5 to disappear
Apr 27 17:12:37.417: INFO: Pod pod-subpath-test-secret-x4p5 no longer exists
STEP: Deleting pod pod-subpath-test-secret-x4p5
Apr 27 17:12:37.417: INFO: Deleting pod "pod-subpath-test-secret-x4p5" in namespace "subpath-707"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:37.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-707" for this suite.
•{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":277,"completed":247,"skipped":4191,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:37.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Apr 27 17:12:39.612: INFO: Pod pod-hostip-184ae88a-c22f-4a68-8395-e0ad139773fb has hostIP: 10.250.31.184
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:39.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4502" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":277,"completed":248,"skipped":4203,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:39.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 27 17:12:43.834: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:43.838: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:12:45.839: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:45.844: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:12:47.839: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:47.844: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:12:49.839: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:49.844: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:12:51.839: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:51.844: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:12:53.839: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:53.844: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 27 17:12:55.839: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 27 17:12:55.844: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:55.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2463" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":277,"completed":249,"skipped":4217,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:55.859: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Apr 27 17:12:56.006: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix158739872/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:12:56.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9625" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":277,"completed":250,"skipped":4230,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:12:56.072: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4240.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4240.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4240.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4240.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4240.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 209.99.105.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.105.99.209_udp@PTR;check="$$(dig +tcp +noall +answer +search 209.99.105.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.105.99.209_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4240.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4240.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4240.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4240.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4240.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4240.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 209.99.105.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.105.99.209_udp@PTR;check="$$(dig +tcp +noall +answer +search 209.99.105.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.105.99.209_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 27 17:12:58.349: INFO: Unable to read wheezy_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.396: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.403: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.411: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.791: INFO: Unable to read jessie_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.799: INFO: Unable to read jessie_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.806: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:58.813: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:12:59.173: INFO: Lookups using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 failed for: [wheezy_udp@dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_udp@dns-test-service.dns-4240.svc.cluster.local jessie_tcp@dns-test-service.dns-4240.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local]

Apr 27 17:13:04.181: INFO: Unable to read wheezy_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.189: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.197: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.203: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.610: INFO: Unable to read jessie_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.617: INFO: Unable to read jessie_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.625: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.632: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:04.992: INFO: Lookups using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 failed for: [wheezy_udp@dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_udp@dns-test-service.dns-4240.svc.cluster.local jessie_tcp@dns-test-service.dns-4240.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local]

Apr 27 17:13:09.181: INFO: Unable to read wheezy_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.188: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.195: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.202: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.607: INFO: Unable to read jessie_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.614: INFO: Unable to read jessie_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.622: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.629: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:09.997: INFO: Lookups using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 failed for: [wheezy_udp@dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_udp@dns-test-service.dns-4240.svc.cluster.local jessie_tcp@dns-test-service.dns-4240.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local]

Apr 27 17:13:14.181: INFO: Unable to read wheezy_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.188: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.196: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.203: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.601: INFO: Unable to read jessie_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.609: INFO: Unable to read jessie_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.616: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:14.623: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:15.028: INFO: Lookups using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 failed for: [wheezy_udp@dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_udp@dns-test-service.dns-4240.svc.cluster.local jessie_tcp@dns-test-service.dns-4240.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local]

Apr 27 17:13:19.181: INFO: Unable to read wheezy_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.226: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.233: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.240: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.644: INFO: Unable to read jessie_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.651: INFO: Unable to read jessie_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.658: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.665: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:19.988: INFO: Lookups using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 failed for: [wheezy_udp@dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_udp@dns-test-service.dns-4240.svc.cluster.local jessie_tcp@dns-test-service.dns-4240.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local]

Apr 27 17:13:24.181: INFO: Unable to read wheezy_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.188: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.195: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.201: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.609: INFO: Unable to read jessie_udp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.616: INFO: Unable to read jessie_tcp@dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.623: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:24.631: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local from pod dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3: the server could not find the requested resource (get pods dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3)
Apr 27 17:13:25.033: INFO: Lookups using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 failed for: [wheezy_udp@dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@dns-test-service.dns-4240.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_udp@dns-test-service.dns-4240.svc.cluster.local jessie_tcp@dns-test-service.dns-4240.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4240.svc.cluster.local]

Apr 27 17:13:30.459: INFO: DNS probes using dns-4240/dns-test-fb51ac5b-3d02-4bf5-b217-9b35aaa32cf3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:13:30.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4240" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":277,"completed":251,"skipped":4232,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:13:30.501: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7747
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr 27 17:14:10.690: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
W0427 17:14:10.690884    7398 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 27 17:14:10.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7747" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":277,"completed":252,"skipped":4244,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:10.702: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6031
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 27 17:14:16.893: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 17:14:16.893292    7398 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:16.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6031" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":277,"completed":253,"skipped":4280,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:16.906: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:14:17.064: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6c9007c0-28e7-4f2c-983d-f4281acfe9ad" in namespace "security-context-test-2784" to be "Succeeded or Failed"
Apr 27 17:14:17.068: INFO: Pod "busybox-readonly-false-6c9007c0-28e7-4f2c-983d-f4281acfe9ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.228003ms
Apr 27 17:14:19.073: INFO: Pod "busybox-readonly-false-6c9007c0-28e7-4f2c-983d-f4281acfe9ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008837464s
Apr 27 17:14:21.078: INFO: Pod "busybox-readonly-false-6c9007c0-28e7-4f2c-983d-f4281acfe9ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014157196s
Apr 27 17:14:21.078: INFO: Pod "busybox-readonly-false-6c9007c0-28e7-4f2c-983d-f4281acfe9ad" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:21.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2784" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":277,"completed":254,"skipped":4291,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:21.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-529
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-0b691419-9863-47d2-b55b-16ce348c470d
STEP: Creating a pod to test consume secrets
Apr 27 17:14:21.257: INFO: Waiting up to 5m0s for pod "pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5" in namespace "secrets-529" to be "Succeeded or Failed"
Apr 27 17:14:21.261: INFO: Pod "pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.134112ms
Apr 27 17:14:23.266: INFO: Pod "pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009552789s
STEP: Saw pod success
Apr 27 17:14:23.267: INFO: Pod "pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5" satisfied condition "Succeeded or Failed"
Apr 27 17:14:23.271: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:14:23.387: INFO: Waiting for pod pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5 to disappear
Apr 27 17:14:23.391: INFO: Pod pod-secrets-9bbb4c5a-6dfb-49f3-af81-830897dc6be5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:23.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-529" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":255,"skipped":4320,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:23.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 27 17:14:23.562: INFO: Waiting up to 5m0s for pod "pod-a11185c5-169d-47c8-944f-d01feef39636" in namespace "emptydir-7933" to be "Succeeded or Failed"
Apr 27 17:14:23.566: INFO: Pod "pod-a11185c5-169d-47c8-944f-d01feef39636": Phase="Pending", Reason="", readiness=false. Elapsed: 4.353817ms
Apr 27 17:14:25.572: INFO: Pod "pod-a11185c5-169d-47c8-944f-d01feef39636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010380395s
STEP: Saw pod success
Apr 27 17:14:25.572: INFO: Pod "pod-a11185c5-169d-47c8-944f-d01feef39636" satisfied condition "Succeeded or Failed"
Apr 27 17:14:25.577: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-a11185c5-169d-47c8-944f-d01feef39636 container test-container: <nil>
STEP: delete the pod
Apr 27 17:14:25.599: INFO: Waiting for pod pod-a11185c5-169d-47c8-944f-d01feef39636 to disappear
Apr 27 17:14:25.603: INFO: Pod pod-a11185c5-169d-47c8-944f-d01feef39636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:25.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7933" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":256,"skipped":4333,"failed":0}
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:25.617: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8860
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 27 17:14:29.818: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:14:29.822: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:14:31.822: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:14:31.828: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 27 17:14:33.822: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 27 17:14:33.828: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:33.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8860" for this suite.
•{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":277,"completed":257,"skipped":4335,"failed":0}
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:33.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3825
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-3825
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 27 17:14:34.000: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 27 17:14:34.033: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:14:36.038: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 27 17:14:38.038: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:40.039: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:42.039: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:44.040: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:46.039: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:48.038: INFO: The status of Pod netserver-0 is Running (Ready = false)
Apr 27 17:14:50.038: INFO: The status of Pod netserver-0 is Running (Ready = true)
Apr 27 17:14:50.047: INFO: The status of Pod netserver-1 is Running (Ready = false)
Apr 27 17:14:52.053: INFO: The status of Pod netserver-1 is Running (Ready = true)
STEP: Creating test pods
Apr 27 17:14:54.096: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.89:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3825 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:14:54.096: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:14:54.557: INFO: Found all expected endpoints: [netserver-0]
Apr 27 17:14:54.562: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.70:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3825 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:14:54.562: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:14:55.005: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:14:55.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3825" for this suite.
•{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":258,"skipped":4341,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:14:55.020: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Apr 27 17:14:55.171: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 27 17:14:55.190: INFO: Waiting for terminating namespaces to be deleted...
Apr 27 17:14:55.194: INFO: 
Logging pods the kubelet thinks is on node izgw82palggheybhhd1s46z before test
Apr 27 17:14:55.221: INFO: node-exporter-k58cv from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container node-exporter ready: true, restart count 0
Apr 27 17:14:55.221: INFO: calico-node-xjxjf from kube-system started at 2020-04-27 16:33:40 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:14:55.221: INFO: kube-proxy-r447h from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:14:55.221: INFO: node-problem-detector-m6qcf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:14:55.221: INFO: host-test-container-pod from pod-network-test-3825 started at 2020-04-27 17:14:52 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container agnhost ready: true, restart count 0
Apr 27 17:14:55.221: INFO: test-container-pod from pod-network-test-3825 started at 2020-04-27 17:14:52 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container webserver ready: true, restart count 0
Apr 27 17:14:55.221: INFO: netserver-0 from pod-network-test-3825 started at 2020-04-27 17:14:34 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container webserver ready: true, restart count 0
Apr 27 17:14:55.221: INFO: csi-disk-plugin-alicloud-hzxms from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 17:14:55.221: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 17:14:55.221: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 17:14:55.221: INFO: 
Logging pods the kubelet thinks is on node izgw873bmqhhfhflh483llz before test
Apr 27 17:14:55.325: INFO: calico-typha-deploy-784665cc66-b2n69 from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container calico-typha ready: true, restart count 0
Apr 27 17:14:55.325: INFO: blackbox-exporter-5dc75b79b7-xshtf from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 27 17:14:55.325: INFO: node-problem-detector-9ntf8 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 27 17:14:55.325: INFO: addons-nginx-ingress-controller-6cf77756b5-rwfsq from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr 27 17:14:55.325: INFO: dashboard-metrics-scraper-76c7b697bc-zfk9z from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 27 17:14:55.325: INFO: kube-proxy-v48zq from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 27 17:14:55.325: INFO: calico-kube-controllers-77dcb8f688-44xhb from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 27 17:14:55.325: INFO: vpn-shoot-6f75686cfb-ntkwh from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 27 17:14:55.325: INFO: calico-typha-horizontal-autoscaler-6fdd5d8746-dtlrp from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:14:55.325: INFO: calico-node-p7gsw from kube-system started at 2020-04-27 16:33:54 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container calico-node ready: true, restart count 0
Apr 27 17:14:55.325: INFO: coredns-5cb857d789-5cvkp from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:14:55.325: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6455cb4dc8-qp9pw from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr 27 17:14:55.325: INFO: coredns-5cb857d789-x7mvm from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container coredns ready: true, restart count 0
Apr 27 17:14:55.325: INFO: kubernetes-dashboard-6b586c4cb4-nqch8 from kubernetes-dashboard started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 27 17:14:55.325: INFO: csi-disk-plugin-alicloud-9szgk from kube-system started at 2020-04-27 15:53:23 +0000 UTC (2 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container csi-diskplugin ready: true, restart count 0
Apr 27 17:14:55.325: INFO: 	Container driver-registrar ready: true, restart count 0
Apr 27 17:14:55.325: INFO: calico-typha-vertical-autoscaler-5b477c88cf-ltrk8 from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:14:55.325: INFO: netserver-1 from pod-network-test-3825 started at 2020-04-27 17:14:34 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container webserver ready: true, restart count 0
Apr 27 17:14:55.325: INFO: metrics-server-7ff88f9d88-zmzhg from kube-system started at 2020-04-27 15:53:53 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container metrics-server ready: true, restart count 0
Apr 27 17:14:55.325: INFO: calico-node-vertical-autoscaler-74d4897db8-m2vrd from kube-system started at 2020-04-27 16:33:01 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container autoscaler ready: true, restart count 0
Apr 27 17:14:55.325: INFO: node-exporter-gjwg5 from kube-system started at 2020-04-27 15:53:23 +0000 UTC (1 container statuses recorded)
Apr 27 17:14:55.325: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3be70426-d609-48c6-a7dd-8b69c5aecaa8 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-3be70426-d609-48c6-a7dd-8b69c5aecaa8 off the node izgw82palggheybhhd1s46z
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3be70426-d609-48c6-a7dd-8b69c5aecaa8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:19:59.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4177" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:304.422 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":277,"completed":259,"skipped":4343,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:19:59.443: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:19:59.601: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3" in namespace "projected-708" to be "Succeeded or Failed"
Apr 27 17:19:59.605: INFO: Pod "downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.878108ms
Apr 27 17:20:01.610: INFO: Pod "downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009078557s
STEP: Saw pod success
Apr 27 17:20:01.610: INFO: Pod "downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3" satisfied condition "Succeeded or Failed"
Apr 27 17:20:01.615: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3 container client-container: <nil>
STEP: delete the pod
Apr 27 17:20:01.734: INFO: Waiting for pod downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3 to disappear
Apr 27 17:20:01.738: INFO: Pod downwardapi-volume-e8d176e6-f1cc-438b-bb14-5eaff4c9c5b3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:01.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-708" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":260,"skipped":4393,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:01.751: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1070
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:17.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1070" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":277,"completed":261,"skipped":4396,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:17.998: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5663
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-244c37fe-43df-4357-b6e8-0a2413a4b7bb
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-244c37fe-43df-4357-b6e8-0a2413a4b7bb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:22.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5663" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":277,"completed":262,"skipped":4405,"failed":0}
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:22.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9380
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:24.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9380" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":263,"skipped":4409,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:24.508: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2568
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:20:24.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191" in namespace "downward-api-2568" to be "Succeeded or Failed"
Apr 27 17:20:24.666: INFO: Pod "downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106967ms
Apr 27 17:20:26.671: INFO: Pod "downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009401036s
STEP: Saw pod success
Apr 27 17:20:26.671: INFO: Pod "downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191" satisfied condition "Succeeded or Failed"
Apr 27 17:20:26.676: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191 container client-container: <nil>
STEP: delete the pod
Apr 27 17:20:26.696: INFO: Waiting for pod downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191 to disappear
Apr 27 17:20:26.700: INFO: Pod downwardapi-volume-a3cb1820-0a35-453b-8216-111bde7ff191 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:20:26.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2568" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":277,"completed":264,"skipped":4415,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:20:26.714: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-2186
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:20:26.868: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Apr 27 17:20:27.459: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:20:27Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:20:27Z]] name:name1 resourceVersion:36112 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:d905a2ae-e3e4-4f15-b262-fbc3b11eadd2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr 27 17:20:37.466: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:20:37Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:20:37Z]] name:name2 resourceVersion:36173 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:42310f54-6ff0-493b-9cc8-42a469f3102b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr 27 17:20:47.473: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:20:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:20:47Z]] name:name1 resourceVersion:36214 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:d905a2ae-e3e4-4f15-b262-fbc3b11eadd2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr 27 17:20:57.481: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:20:37Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:20:57Z]] name:name2 resourceVersion:36281 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:42310f54-6ff0-493b-9cc8-42a469f3102b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr 27 17:21:07.489: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:20:27Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:20:47Z]] name:name1 resourceVersion:36327 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:d905a2ae-e3e4-4f15-b262-fbc3b11eadd2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr 27 17:21:17.497: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-27T17:20:37Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-04-27T17:20:57Z]] name:name2 resourceVersion:36368 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:42310f54-6ff0-493b-9cc8-42a469f3102b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:28.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2186" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":277,"completed":265,"skipped":4426,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:28.031: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:21:28.190: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467" in namespace "downward-api-3909" to be "Succeeded or Failed"
Apr 27 17:21:28.195: INFO: Pod "downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467": Phase="Pending", Reason="", readiness=false. Elapsed: 4.836367ms
Apr 27 17:21:30.200: INFO: Pod "downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010404827s
STEP: Saw pod success
Apr 27 17:21:30.200: INFO: Pod "downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467" satisfied condition "Succeeded or Failed"
Apr 27 17:21:30.205: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467 container client-container: <nil>
STEP: delete the pod
Apr 27 17:21:30.232: INFO: Waiting for pod downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467 to disappear
Apr 27 17:21:30.236: INFO: Pod downwardapi-volume-3a911dcd-1e07-4134-9d81-b658e05ac467 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:30.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3909" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":277,"completed":266,"skipped":4428,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:30.250: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Apr 27 17:21:30.401: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm1nh-obu.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:30.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4467" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":277,"completed":267,"skipped":4454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:30.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-574
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Apr 27 17:21:32.709: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-574 PodName:pod-sharedvolume-a3428e1e-ee07-4574-a8ad-1eeb4f9d010c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 27 17:21:32.709: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Apr 27 17:21:33.089: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:33.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-574" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":277,"completed":268,"skipped":4503,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:33.102: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:21:33.249: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr 27 17:21:34.283: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:34.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5653" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":277,"completed":269,"skipped":4534,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:34.303: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-4fa38e90-87fb-4e40-911a-b16441ad6af5
STEP: Creating a pod to test consume secrets
Apr 27 17:21:34.463: INFO: Waiting up to 5m0s for pod "pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9" in namespace "secrets-4337" to be "Succeeded or Failed"
Apr 27 17:21:34.468: INFO: Pod "pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.556131ms
Apr 27 17:21:36.473: INFO: Pod "pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009241437s
STEP: Saw pod success
Apr 27 17:21:36.473: INFO: Pod "pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9" satisfied condition "Succeeded or Failed"
Apr 27 17:21:36.477: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9 container secret-volume-test: <nil>
STEP: delete the pod
Apr 27 17:21:36.497: INFO: Waiting for pod pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9 to disappear
Apr 27 17:21:36.501: INFO: Pod pod-secrets-fe4e403c-fba9-4f2c-b308-57a046c7f8a9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:36.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4337" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":277,"completed":270,"skipped":4575,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:36.514: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5122
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Apr 27 17:21:36.673: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba" in namespace "downward-api-5122" to be "Succeeded or Failed"
Apr 27 17:21:36.677: INFO: Pod "downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.081943ms
Apr 27 17:21:38.682: INFO: Pod "downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009354962s
STEP: Saw pod success
Apr 27 17:21:38.682: INFO: Pod "downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba" satisfied condition "Succeeded or Failed"
Apr 27 17:21:38.686: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba container client-container: <nil>
STEP: delete the pod
Apr 27 17:21:38.707: INFO: Waiting for pod downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba to disappear
Apr 27 17:21:38.711: INFO: Pod downwardapi-volume-40e421bd-688b-4994-9455-569ebe4112ba no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:38.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5122" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":277,"completed":271,"skipped":4590,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:38.723: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-82acc7b6-5b71-4a4c-ade7-77995e490b49
STEP: Creating a pod to test consume configMaps
Apr 27 17:21:38.884: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7" in namespace "projected-5044" to be "Succeeded or Failed"
Apr 27 17:21:38.888: INFO: Pod "pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.873598ms
Apr 27 17:21:40.893: INFO: Pod "pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009217361s
STEP: Saw pod success
Apr 27 17:21:40.893: INFO: Pod "pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7" satisfied condition "Succeeded or Failed"
Apr 27 17:21:40.897: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:21:40.923: INFO: Waiting for pod pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7 to disappear
Apr 27 17:21:40.927: INFO: Pod pod-projected-configmaps-ed0b25ca-4dba-441b-8ae7-97c708e0dde7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:40.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5044" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":277,"completed":272,"skipped":4594,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:40.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 27 17:21:41.409: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 27 17:21:43.423: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604901, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604901, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604901, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723604901, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 27 17:21:46.440: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:21:46.445: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:47.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-750" for this suite.
STEP: Destroying namespace "webhook-750-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":277,"completed":273,"skipped":4596,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:48.064: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8629
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Apr 27 17:21:48.622: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"2822851d-da5d-4b24-bb1e-bdc97711a216", Controller:(*bool)(0xc0040598ee), BlockOwnerDeletion:(*bool)(0xc0040598ef)}}
Apr 27 17:21:48.632: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4b834ec2-c2ff-421b-9aa5-abdec318c32a", Controller:(*bool)(0xc0046b38da), BlockOwnerDeletion:(*bool)(0xc0046b38db)}}
Apr 27 17:21:48.638: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"714adf9a-c836-480f-92db-26ab48a331da", Controller:(*bool)(0xc004059b2a), BlockOwnerDeletion:(*bool)(0xc004059b2b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:53.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8629" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":277,"completed":274,"skipped":4600,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:53.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8164
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 27 17:21:54.372: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0427 17:21:54.372420    7398 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:54.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8164" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":277,"completed":275,"skipped":4608,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:54.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-3aa89924-6bac-47f7-91a8-fc089bbdc64c
STEP: Creating a pod to test consume configMaps
Apr 27 17:21:54.579: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936" in namespace "projected-7401" to be "Succeeded or Failed"
Apr 27 17:21:54.584: INFO: Pod "pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936": Phase="Pending", Reason="", readiness=false. Elapsed: 5.0784ms
Apr 27 17:21:56.590: INFO: Pod "pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010452161s
STEP: Saw pod success
Apr 27 17:21:56.590: INFO: Pod "pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936" satisfied condition "Succeeded or Failed"
Apr 27 17:21:56.594: INFO: Trying to get logs from node izgw82palggheybhhd1s46z pod pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 27 17:21:56.614: INFO: Waiting for pod pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936 to disappear
Apr 27 17:21:56.618: INFO: Pod pod-projected-configmaps-f6651871-8423-4a8f-8d87-7e6b7f159936 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:21:56.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7401" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":277,"completed":276,"skipped":4644,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Apr 27 17:21:56.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6097
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6097
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6097
STEP: Creating statefulset with conflicting port in namespace statefulset-6097
STEP: Waiting until pod test-pod will start running in namespace statefulset-6097
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6097
Apr 27 17:21:58.815: INFO: Observed stateful pod in namespace: statefulset-6097, name: ss-0, uid: a0cd0af9-d864-4df4-94f1-637470b2178b, status phase: Pending. Waiting for statefulset controller to delete.
Apr 27 17:21:58.833: INFO: Observed stateful pod in namespace: statefulset-6097, name: ss-0, uid: a0cd0af9-d864-4df4-94f1-637470b2178b, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 17:21:58.905: INFO: Observed stateful pod in namespace: statefulset-6097, name: ss-0, uid: a0cd0af9-d864-4df4-94f1-637470b2178b, status phase: Failed. Waiting for statefulset controller to delete.
Apr 27 17:21:58.907: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6097
STEP: Removing pod with conflicting port in namespace statefulset-6097
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6097 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Apr 27 17:22:00.925: INFO: Deleting all statefulset in ns statefulset-6097
Apr 27 17:22:00.930: INFO: Scaling statefulset ss to 0
Apr 27 17:22:20.950: INFO: Waiting for statefulset status.replicas updated to 0
Apr 27 17:22:20.955: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Apr 27 17:22:20.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6097" for this suite.
•{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":277,"completed":277,"skipped":4682,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSApr 27 17:22:20.981: INFO: Running AfterSuite actions on all nodes
Apr 27 17:22:20.981: INFO: Running AfterSuite actions on node 1
Apr 27 17:22:20.982: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/e2e/artifacts/1588003781/junit_01.xml
{"msg":"Test Suite completed","total":277,"completed":277,"skipped":4715,"failed":0}

Ran 277 of 4992 Specs in 4356.673 seconds
SUCCESS! -- 277 Passed | 0 Failed | 0 Flaked | 0 Pending | 4715 Skipped
PASS

Ginkgo ran 1 suite in 1h12m38.464548925s
Test Suite Passed
