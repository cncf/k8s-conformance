I0313 09:15:47.020780      26 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-141385212
I0313 09:15:47.020802      26 test_context.go:419] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0313 09:15:47.020974      26 e2e.go:109] Starting e2e run "3f51d3fa-c3d4-45cd-922f-9b1f292eb026" on Ginkgo node 1
{"msg":"Test Suite starting","total":280,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1584090945 - Will randomize all specs
Will run 280 of 4843 specs

Mar 13 09:15:47.031: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
E0313 09:15:47.032454      26 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post http://localhost:8099/progress: dial tcp 127.0.0.1:8099: connect: connection refused
Mar 13 09:15:47.034: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 13 09:15:47.047: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 13 09:15:47.081: INFO: The status of Pod rke-coredns-addon-deploy-job-frlv2 is Succeeded, skipping waiting
Mar 13 09:15:47.082: INFO: The status of Pod rke-ingress-controller-deploy-job-mmxvc is Succeeded, skipping waiting
Mar 13 09:15:47.082: INFO: The status of Pod rke-metrics-addon-deploy-job-w79dp is Succeeded, skipping waiting
Mar 13 09:15:47.082: INFO: The status of Pod rke-network-plugin-deploy-job-chk5v is Succeeded, skipping waiting
Mar 13 09:15:47.082: INFO: 6 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 13 09:15:47.082: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Mar 13 09:15:47.082: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 13 09:15:47.090: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Mar 13 09:15:47.090: INFO: e2e test version: v1.17.2
Mar 13 09:15:47.091: INFO: kube-apiserver version: v1.17.2
Mar 13 09:15:47.091: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:15:47.095: INFO: Cluster IP family: ipv4
S
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:15:47.095: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
Mar 13 09:15:47.110: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl label
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1382
STEP: creating the pod
Mar 13 09:15:47.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-2301'
Mar 13 09:15:47.353: INFO: stderr: ""
Mar 13 09:15:47.353: INFO: stdout: "pod/pause created\n"
Mar 13 09:15:47.353: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 13 09:15:47.353: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2301" to be "running and ready"
Mar 13 09:15:47.354: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.536146ms
Mar 13 09:15:49.357: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.003952458s
Mar 13 09:15:49.357: INFO: Pod "pause" satisfied condition "running and ready"
Mar 13 09:15:49.357: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 13 09:15:49.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 label pods pause testing-label=testing-label-value --namespace=kubectl-2301'
Mar 13 09:15:49.441: INFO: stderr: ""
Mar 13 09:15:49.441: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 13 09:15:49.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pod pause -L testing-label --namespace=kubectl-2301'
Mar 13 09:15:49.516: INFO: stderr: ""
Mar 13 09:15:49.516: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 13 09:15:49.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 label pods pause testing-label- --namespace=kubectl-2301'
Mar 13 09:15:49.599: INFO: stderr: ""
Mar 13 09:15:49.599: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 13 09:15:49.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pod pause -L testing-label --namespace=kubectl-2301'
Mar 13 09:15:49.673: INFO: stderr: ""
Mar 13 09:15:49.673: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1389
STEP: using delete to clean up resources
Mar 13 09:15:49.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-2301'
Mar 13 09:15:49.747: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:15:49.747: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 13 09:15:49.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get rc,svc -l name=pause --no-headers --namespace=kubectl-2301'
Mar 13 09:15:49.831: INFO: stderr: "No resources found in kubectl-2301 namespace.\n"
Mar 13 09:15:49.831: INFO: stdout: ""
Mar 13 09:15:49.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -l name=pause --namespace=kubectl-2301 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 13 09:15:49.907: INFO: stderr: ""
Mar 13 09:15:49.907: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:15:49.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2301" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":280,"completed":1,"skipped":1,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:15:49.912: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
E0313 09:15:49.913247      26 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post http://localhost:8099/progress: dial tcp 127.0.0.1:8099: connect: connection refused
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl logs
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1464
STEP: creating an pod
Mar 13 09:15:49.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.8 --namespace=kubectl-6661 -- logs-generator --log-lines-total 100 --run-duration 20s'
Mar 13 09:15:50.012: INFO: stderr: ""
Mar 13 09:15:50.012: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Waiting for log generator to start.
Mar 13 09:15:50.012: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Mar 13 09:15:50.012: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6661" to be "running and ready, or succeeded"
Mar 13 09:15:50.014: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.676746ms
Mar 13 09:15:52.017: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.004150864s
Mar 13 09:15:52.017: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Mar 13 09:15:52.017: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Mar 13 09:15:52.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs logs-generator logs-generator --namespace=kubectl-6661'
Mar 13 09:15:52.116: INFO: stderr: ""
Mar 13 09:15:52.116: INFO: stdout: "I0313 09:15:50.723364       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/7j87 452\nI0313 09:15:50.923512       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/vh25 280\nI0313 09:15:51.123518       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/8kw 307\nI0313 09:15:51.323538       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/5bmw 343\nI0313 09:15:51.523511       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/xxqc 217\nI0313 09:15:51.723534       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/xc2p 254\nI0313 09:15:51.923492       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/88mx 505\n"
STEP: limiting log lines
Mar 13 09:15:52.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs logs-generator logs-generator --namespace=kubectl-6661 --tail=1'
Mar 13 09:15:52.220: INFO: stderr: ""
Mar 13 09:15:52.220: INFO: stdout: "I0313 09:15:52.123486       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/nwcm 214\n"
Mar 13 09:15:52.220: INFO: got output "I0313 09:15:52.123486       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/nwcm 214\n"
STEP: limiting log bytes
Mar 13 09:15:52.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs logs-generator logs-generator --namespace=kubectl-6661 --limit-bytes=1'
Mar 13 09:15:52.315: INFO: stderr: ""
Mar 13 09:15:52.315: INFO: stdout: "I"
Mar 13 09:15:52.315: INFO: got output "I"
STEP: exposing timestamps
Mar 13 09:15:52.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs logs-generator logs-generator --namespace=kubectl-6661 --tail=1 --timestamps'
Mar 13 09:15:52.412: INFO: stderr: ""
Mar 13 09:15:52.412: INFO: stdout: "2020-03-13T09:15:52.323591264Z I0313 09:15:52.323502       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/6ds 406\n"
Mar 13 09:15:52.412: INFO: got output "2020-03-13T09:15:52.323591264Z I0313 09:15:52.323502       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/6ds 406\n"
STEP: restricting to a time range
Mar 13 09:15:54.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs logs-generator logs-generator --namespace=kubectl-6661 --since=1s'
Mar 13 09:15:55.003: INFO: stderr: ""
Mar 13 09:15:55.003: INFO: stdout: "I0313 09:15:54.123551       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/q6p5 569\nI0313 09:15:54.323516       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/dxwn 557\nI0313 09:15:54.523494       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kf88 325\nI0313 09:15:54.723512       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/pjlr 301\nI0313 09:15:54.923504       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/98vg 423\n"
Mar 13 09:15:55.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs logs-generator logs-generator --namespace=kubectl-6661 --since=24h'
Mar 13 09:15:55.088: INFO: stderr: ""
Mar 13 09:15:55.088: INFO: stdout: "I0313 09:15:50.723364       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/7j87 452\nI0313 09:15:50.923512       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/vh25 280\nI0313 09:15:51.123518       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/8kw 307\nI0313 09:15:51.323538       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/5bmw 343\nI0313 09:15:51.523511       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/xxqc 217\nI0313 09:15:51.723534       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/xc2p 254\nI0313 09:15:51.923492       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/88mx 505\nI0313 09:15:52.123486       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/nwcm 214\nI0313 09:15:52.323502       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/6ds 406\nI0313 09:15:52.523544       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/jwqg 282\nI0313 09:15:52.723546       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/cplw 479\nI0313 09:15:52.923548       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/6dxf 595\nI0313 09:15:53.123539       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/z29t 569\nI0313 09:15:53.323518       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/2sx 261\nI0313 09:15:53.523522       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/vfc5 558\nI0313 09:15:53.723565       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/k5h 554\nI0313 09:15:53.923524       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/89wv 415\nI0313 09:15:54.123551       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/q6p5 569\nI0313 09:15:54.323516       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/dxwn 557\nI0313 09:15:54.523494       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/kf88 325\nI0313 09:15:54.723512       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/pjlr 301\nI0313 09:15:54.923504       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/98vg 423\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1470
Mar 13 09:15:55.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete pod logs-generator --namespace=kubectl-6661'
Mar 13 09:15:57.356: INFO: stderr: ""
Mar 13 09:15:57.356: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:15:57.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6661" for this suite.

• [SLOW TEST:7.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":280,"completed":2,"skipped":5,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:15:57.362: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:15:57.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2392" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":280,"completed":3,"skipped":54,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:15:57.393: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 13 09:15:57.411: INFO: Waiting up to 5m0s for pod "pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379" in namespace "emptydir-9792" to be "success or failure"
Mar 13 09:15:57.412: INFO: Pod "pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379": Phase="Pending", Reason="", readiness=false. Elapsed: 1.244599ms
Mar 13 09:15:59.415: INFO: Pod "pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003494782s
STEP: Saw pod success
Mar 13 09:15:59.415: INFO: Pod "pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379" satisfied condition "success or failure"
Mar 13 09:15:59.416: INFO: Trying to get logs from node 172.24.5.7 pod pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379 container test-container: <nil>
STEP: delete the pod
Mar 13 09:15:59.425: INFO: Waiting for pod pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379 to disappear
Mar 13 09:15:59.426: INFO: Pod pod-0773ff1b-1195-4a3f-a7e5-1eceb130b379 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:15:59.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9792" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":4,"skipped":58,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:15:59.431: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:15:59.447: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 13 09:15:59.450: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 13 09:16:04.452: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 13 09:16:04.453: INFO: Creating deployment "test-rolling-update-deployment"
Mar 13 09:16:04.454: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 13 09:16:04.457: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 13 09:16:06.462: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 13 09:16:06.464: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 13 09:16:06.469: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3902 /apis/apps/v1/namespaces/deployment-3902/deployments/test-rolling-update-deployment 1bd26a08-521e-4c6a-909a-cef3899dd6c3 41004 1 2020-03-13 09:16:04 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00329dc28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-13 09:16:04 +0000 UTC,LastTransitionTime:2020-03-13 09:16:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67cf4f6444" has successfully progressed.,LastUpdateTime:2020-03-13 09:16:05 +0000 UTC,LastTransitionTime:2020-03-13 09:16:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar 13 09:16:06.471: INFO: New ReplicaSet "test-rolling-update-deployment-67cf4f6444" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67cf4f6444  deployment-3902 /apis/apps/v1/namespaces/deployment-3902/replicasets/test-rolling-update-deployment-67cf4f6444 31777095-fd13-4842-8c7f-f64071f3e067 40993 1 2020-03-13 09:16:04 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 1bd26a08-521e-4c6a-909a-cef3899dd6c3 0xc001070117 0xc001070118}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67cf4f6444,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001070188 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:16:06.471: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 13 09:16:06.471: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3902 /apis/apps/v1/namespaces/deployment-3902/replicasets/test-rolling-update-controller 0221a386-a300-4d45-aa04-20bcb8d9b13e 41003 2 2020-03-13 09:15:59 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 1bd26a08-521e-4c6a-909a-cef3899dd6c3 0xc001070017 0xc001070018}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0010700a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:16:06.473: INFO: Pod "test-rolling-update-deployment-67cf4f6444-8vgvn" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67cf4f6444-8vgvn test-rolling-update-deployment-67cf4f6444- deployment-3902 /api/v1/namespaces/deployment-3902/pods/test-rolling-update-deployment-67cf4f6444-8vgvn 86e335a6-2a50-40c6-a702-0f8ccf8f13e5 40992 0 2020-03-13 09:16:04 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[cni.projectcalico.org/podIP:10.42.0.172/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-67cf4f6444 31777095-fd13-4842-8c7f-f64071f3e067 0xc001070617 0xc001070618}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w2l6w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w2l6w,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w2l6w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:16:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:16:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:16:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:10.42.0.172,StartTime:2020-03-13 09:16:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:16:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://a668e2dc73e08a566b32eb94951d29b5c67dc9f528aa8412a8c3ad4e23bbec05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:06.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3902" for this suite.

• [SLOW TEST:7.047 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":5,"skipped":91,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:06.478: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 13 09:16:06.508: INFO: Number of nodes with available pods: 0
Mar 13 09:16:06.508: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:07.513: INFO: Number of nodes with available pods: 0
Mar 13 09:16:07.513: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:08.512: INFO: Number of nodes with available pods: 1
Mar 13 09:16:08.512: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:09.512: INFO: Number of nodes with available pods: 1
Mar 13 09:16:09.512: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:10.512: INFO: Number of nodes with available pods: 1
Mar 13 09:16:10.512: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:11.512: INFO: Number of nodes with available pods: 1
Mar 13 09:16:11.512: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:12.513: INFO: Number of nodes with available pods: 1
Mar 13 09:16:12.513: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:13.512: INFO: Number of nodes with available pods: 1
Mar 13 09:16:13.512: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:14.515: INFO: Number of nodes with available pods: 1
Mar 13 09:16:14.515: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:15.513: INFO: Number of nodes with available pods: 1
Mar 13 09:16:15.513: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:16.512: INFO: Number of nodes with available pods: 1
Mar 13 09:16:16.512: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:17.512: INFO: Number of nodes with available pods: 2
Mar 13 09:16:17.512: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 13 09:16:17.521: INFO: Number of nodes with available pods: 1
Mar 13 09:16:17.521: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:18.526: INFO: Number of nodes with available pods: 1
Mar 13 09:16:18.526: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:16:19.526: INFO: Number of nodes with available pods: 2
Mar 13 09:16:19.526: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4412, will wait for the garbage collector to delete the pods
Mar 13 09:16:19.584: INFO: Deleting DaemonSet.extensions daemon-set took: 3.089088ms
Mar 13 09:16:19.684: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.189946ms
Mar 13 09:16:31.985: INFO: Number of nodes with available pods: 0
Mar 13 09:16:31.985: INFO: Number of running nodes: 0, number of available pods: 0
Mar 13 09:16:31.990: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4412/daemonsets","resourceVersion":"41160"},"items":null}

Mar 13 09:16:31.992: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4412/pods","resourceVersion":"41160"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:31.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4412" for this suite.

• [SLOW TEST:25.524 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":280,"completed":6,"skipped":120,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:32.002: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:16:32.022: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778" in namespace "projected-155" to be "success or failure"
Mar 13 09:16:32.023: INFO: Pod "downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778": Phase="Pending", Reason="", readiness=false. Elapsed: 1.229498ms
Mar 13 09:16:34.025: INFO: Pod "downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003288292s
Mar 13 09:16:36.027: INFO: Pod "downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005387155s
Mar 13 09:16:38.030: INFO: Pod "downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007685591s
STEP: Saw pod success
Mar 13 09:16:38.030: INFO: Pod "downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778" satisfied condition "success or failure"
Mar 13 09:16:38.031: INFO: Trying to get logs from node 172.24.5.5 pod downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778 container client-container: <nil>
STEP: delete the pod
Mar 13 09:16:38.041: INFO: Waiting for pod downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778 to disappear
Mar 13 09:16:38.042: INFO: Pod downwardapi-volume-6d04442d-26ad-4e3a-af6f-3489b08a2778 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:38.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-155" for this suite.

• [SLOW TEST:6.044 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":7,"skipped":129,"failed":0}
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:38.047: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:16:38.068: INFO: (0) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.385577ms)
Mar 13 09:16:38.070: INFO: (1) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.931764ms)
Mar 13 09:16:38.073: INFO: (2) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.551418ms)
Mar 13 09:16:38.076: INFO: (3) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.918732ms)
Mar 13 09:16:38.079: INFO: (4) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.424062ms)
Mar 13 09:16:38.081: INFO: (5) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.169944ms)
Mar 13 09:16:38.084: INFO: (6) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.380835ms)
Mar 13 09:16:38.086: INFO: (7) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.032324ms)
Mar 13 09:16:38.088: INFO: (8) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.102608ms)
Mar 13 09:16:38.090: INFO: (9) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.38347ms)
Mar 13 09:16:38.092: INFO: (10) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.020391ms)
Mar 13 09:16:38.095: INFO: (11) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.194914ms)
Mar 13 09:16:38.097: INFO: (12) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.034824ms)
Mar 13 09:16:38.099: INFO: (13) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.363402ms)
Mar 13 09:16:38.101: INFO: (14) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.257538ms)
Mar 13 09:16:38.103: INFO: (15) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.978138ms)
Mar 13 09:16:38.105: INFO: (16) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.085301ms)
Mar 13 09:16:38.108: INFO: (17) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.263052ms)
Mar 13 09:16:38.110: INFO: (18) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.956173ms)
Mar 13 09:16:38.112: INFO: (19) /api/v1/nodes/172.24.5.7:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.977323ms)
[AfterEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:38.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7627" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":280,"completed":8,"skipped":136,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:38.117: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:41.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-741" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":280,"completed":9,"skipped":145,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:41.152: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:16:41.712: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 13 09:16:43.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:16:46.724: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:46.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2809" for this suite.
STEP: Destroying namespace "webhook-2809-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.625 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":280,"completed":10,"skipped":154,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:46.777: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-7a841fe3-facc-439b-9cb3-e983cbf799a0
STEP: Creating a pod to test consume secrets
Mar 13 09:16:46.798: INFO: Waiting up to 5m0s for pod "pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741" in namespace "secrets-8684" to be "success or failure"
Mar 13 09:16:46.799: INFO: Pod "pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741": Phase="Pending", Reason="", readiness=false. Elapsed: 1.421217ms
Mar 13 09:16:48.801: INFO: Pod "pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003559827s
STEP: Saw pod success
Mar 13 09:16:48.801: INFO: Pod "pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741" satisfied condition "success or failure"
Mar 13 09:16:48.803: INFO: Trying to get logs from node 172.24.5.7 pod pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741 container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:16:48.811: INFO: Waiting for pod pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741 to disappear
Mar 13 09:16:48.813: INFO: Pod pod-secrets-02f08d4e-d5a5-4d78-9f54-aa19fa16f741 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:48.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8684" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":11,"skipped":160,"failed":0}
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:48.817: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-1a9c2d7f-913a-44a2-8863-c8a587e67a0c
STEP: Creating a pod to test consume secrets
Mar 13 09:16:48.838: INFO: Waiting up to 5m0s for pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4" in namespace "secrets-2511" to be "success or failure"
Mar 13 09:16:48.841: INFO: Pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.759679ms
Mar 13 09:16:50.843: INFO: Pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005165864s
Mar 13 09:16:52.845: INFO: Pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007437774s
Mar 13 09:16:54.848: INFO: Pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009789984s
Mar 13 09:16:56.850: INFO: Pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.01204228s
STEP: Saw pod success
Mar 13 09:16:56.850: INFO: Pod "pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4" satisfied condition "success or failure"
Mar 13 09:16:56.852: INFO: Trying to get logs from node 172.24.5.5 pod pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4 container secret-env-test: <nil>
STEP: delete the pod
Mar 13 09:16:56.862: INFO: Waiting for pod pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4 to disappear
Mar 13 09:16:56.863: INFO: Pod pod-secrets-18d3a7a7-df68-4a8e-8535-f2c67c1ea2d4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:56.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2511" for this suite.

• [SLOW TEST:8.050 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":280,"completed":12,"skipped":162,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:56.868: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 13 09:16:57.893: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:16:57.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2865" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":280,"completed":13,"skipped":176,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:16:57.903: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:16:58.255: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 13 09:17:00.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:17:02.263: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:17:04.263: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719687818, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:17:07.266: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Mar 13 09:17:07.282: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:17:07.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9318" for this suite.
STEP: Destroying namespace "webhook-9318-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.613 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":280,"completed":14,"skipped":185,"failed":0}
SSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:17:07.517: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:17:07.536: INFO: Waiting up to 5m0s for pod "busybox-user-65534-7df0a279-7e45-47ad-a770-df5ef2af0502" in namespace "security-context-test-6032" to be "success or failure"
Mar 13 09:17:07.537: INFO: Pod "busybox-user-65534-7df0a279-7e45-47ad-a770-df5ef2af0502": Phase="Pending", Reason="", readiness=false. Elapsed: 1.286807ms
Mar 13 09:17:09.539: INFO: Pod "busybox-user-65534-7df0a279-7e45-47ad-a770-df5ef2af0502": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003555489s
Mar 13 09:17:09.539: INFO: Pod "busybox-user-65534-7df0a279-7e45-47ad-a770-df5ef2af0502" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:17:09.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6032" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":15,"skipped":188,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:17:09.545: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-1a1fb9a2-a930-40b8-920a-6d7ff79a9a50
STEP: Creating configMap with name cm-test-opt-upd-e1a228c9-8a75-4205-8ebe-8a6b01ec8459
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1a1fb9a2-a930-40b8-920a-6d7ff79a9a50
STEP: Updating configmap cm-test-opt-upd-e1a228c9-8a75-4205-8ebe-8a6b01ec8459
STEP: Creating configMap with name cm-test-opt-create-550beb1a-328c-4709-b99c-8399e3699147
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:17:15.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8945" for this suite.

• [SLOW TEST:6.075 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":16,"skipped":220,"failed":0}
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:17:15.619: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 13 09:17:19.652: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:19.652: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:19.815: INFO: Exec stderr: ""
Mar 13 09:17:19.815: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:19.815: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:19.965: INFO: Exec stderr: ""
Mar 13 09:17:19.966: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:19.966: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.104: INFO: Exec stderr: ""
Mar 13 09:17:20.105: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.105: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.258: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 13 09:17:20.259: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.259: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.396: INFO: Exec stderr: ""
Mar 13 09:17:20.397: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.397: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.551: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 13 09:17:20.551: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.551: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.665: INFO: Exec stderr: ""
Mar 13 09:17:20.665: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.665: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.771: INFO: Exec stderr: ""
Mar 13 09:17:20.771: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.771: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.868: INFO: Exec stderr: ""
Mar 13 09:17:20.868: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5755 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:17:20.868: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:17:20.959: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:17:20.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5755" for this suite.

• [SLOW TEST:5.345 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":17,"skipped":220,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:17:20.964: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1692
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 09:17:20.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5720'
Mar 13 09:17:21.066: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 13 09:17:21.066: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Mar 13 09:17:21.070: INFO: scanned /root for discovery docs: <nil>
Mar 13 09:17:21.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5720'
Mar 13 09:17:36.796: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 13 09:17:36.796: INFO: stdout: "Created e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f\nScaling up e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Mar 13 09:17:36.796: INFO: stdout: "Created e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f\nScaling up e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Mar 13 09:17:36.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-5720'
Mar 13 09:17:36.876: INFO: stderr: ""
Mar 13 09:17:36.876: INFO: stdout: "e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f-dtwp5 "
Mar 13 09:17:36.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f-dtwp5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Mar 13 09:17:36.958: INFO: stderr: ""
Mar 13 09:17:36.958: INFO: stdout: "true"
Mar 13 09:17:36.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f-dtwp5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Mar 13 09:17:37.039: INFO: stderr: ""
Mar 13 09:17:37.039: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Mar 13 09:17:37.039: INFO: e2e-test-httpd-rc-22da35eb52a4e8d8b7c739d09ca7b92f-dtwp5 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
Mar 13 09:17:37.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete rc e2e-test-httpd-rc --namespace=kubectl-5720'
Mar 13 09:17:37.122: INFO: stderr: ""
Mar 13 09:17:37.122: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:17:37.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5720" for this suite.

• [SLOW TEST:16.162 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl rolling-update should support rolling-update to same image  [Conformance]","total":280,"completed":18,"skipped":225,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:17:37.126: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-07f79b25-1540-4ae9-823a-3d3832d415b4
STEP: Creating secret with name s-test-opt-upd-099c5299-6096-4401-bb21-e73f9b509d08
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-07f79b25-1540-4ae9-823a-3d3832d415b4
STEP: Updating secret s-test-opt-upd-099c5299-6096-4401-bb21-e73f9b509d08
STEP: Creating secret with name s-test-opt-create-a8c918e8-173e-489f-8435-11e94860ce58
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:17:43.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7342" for this suite.

• [SLOW TEST:6.076 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":19,"skipped":238,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:17:43.203: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:17:43.228: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 13 09:17:43.231: INFO: Number of nodes with available pods: 0
Mar 13 09:17:43.231: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 13 09:17:43.239: INFO: Number of nodes with available pods: 0
Mar 13 09:17:43.239: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:44.241: INFO: Number of nodes with available pods: 0
Mar 13 09:17:44.241: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:45.241: INFO: Number of nodes with available pods: 1
Mar 13 09:17:45.241: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 13 09:17:45.249: INFO: Number of nodes with available pods: 1
Mar 13 09:17:45.249: INFO: Number of running nodes: 0, number of available pods: 1
Mar 13 09:17:46.251: INFO: Number of nodes with available pods: 0
Mar 13 09:17:46.251: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 13 09:17:46.255: INFO: Number of nodes with available pods: 0
Mar 13 09:17:46.255: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:47.257: INFO: Number of nodes with available pods: 0
Mar 13 09:17:47.257: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:48.257: INFO: Number of nodes with available pods: 0
Mar 13 09:17:48.257: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:49.257: INFO: Number of nodes with available pods: 0
Mar 13 09:17:49.257: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:50.257: INFO: Number of nodes with available pods: 0
Mar 13 09:17:50.257: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:51.257: INFO: Number of nodes with available pods: 0
Mar 13 09:17:51.257: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:52.257: INFO: Number of nodes with available pods: 0
Mar 13 09:17:52.257: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:17:53.257: INFO: Number of nodes with available pods: 1
Mar 13 09:17:53.257: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1887, will wait for the garbage collector to delete the pods
Mar 13 09:17:53.315: INFO: Deleting DaemonSet.extensions daemon-set took: 2.502533ms
Mar 13 09:17:53.715: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.220976ms
Mar 13 09:18:02.017: INFO: Number of nodes with available pods: 0
Mar 13 09:18:02.017: INFO: Number of running nodes: 0, number of available pods: 0
Mar 13 09:18:02.018: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1887/daemonsets","resourceVersion":"42020"},"items":null}

Mar 13 09:18:02.020: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1887/pods","resourceVersion":"42020"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:18:02.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1887" for this suite.

• [SLOW TEST:18.830 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":280,"completed":20,"skipped":250,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:18:02.033: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar 13 09:18:02.052: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:18:21.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7796" for this suite.

• [SLOW TEST:19.955 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":280,"completed":21,"skipped":283,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:18:21.988: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-850f1e2b-f591-4c9f-a6bf-ddde2a62381a
STEP: Creating a pod to test consume configMaps
Mar 13 09:18:22.011: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823" in namespace "projected-4667" to be "success or failure"
Mar 13 09:18:22.012: INFO: Pod "pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823": Phase="Pending", Reason="", readiness=false. Elapsed: 1.43945ms
Mar 13 09:18:24.014: INFO: Pod "pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003401527s
STEP: Saw pod success
Mar 13 09:18:24.014: INFO: Pod "pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823" satisfied condition "success or failure"
Mar 13 09:18:24.016: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:18:24.024: INFO: Waiting for pod pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823 to disappear
Mar 13 09:18:24.026: INFO: Pod pod-projected-configmaps-22f1bac0-8a25-4dae-ad6d-b1e295daf823 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:18:24.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4667" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":22,"skipped":331,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:18:24.030: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-28
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-28
I0313 09:18:24.055585      26 runners.go:189] Created replication controller with name: externalname-service, namespace: services-28, replica count: 2
Mar 13 09:18:27.106: INFO: Creating new exec pod
I0313 09:18:27.106216      26 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 13 09:18:30.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-28 execpodv56fx -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar 13 09:18:30.386: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar 13 09:18:30.386: INFO: stdout: ""
Mar 13 09:18:30.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-28 execpodv56fx -- /bin/sh -x -c nc -zv -t -w 2 10.43.157.226 80'
Mar 13 09:18:30.654: INFO: stderr: "+ nc -zv -t -w 2 10.43.157.226 80\nConnection to 10.43.157.226 80 port [tcp/http] succeeded!\n"
Mar 13 09:18:30.654: INFO: stdout: ""
Mar 13 09:18:30.654: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:18:30.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-28" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:6.635 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":280,"completed":23,"skipped":359,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:18:30.666: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-secret-2tfz
STEP: Creating a pod to test atomic-volume-subpath
Mar 13 09:18:30.689: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2tfz" in namespace "subpath-7387" to be "success or failure"
Mar 13 09:18:30.691: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Pending", Reason="", readiness=false. Elapsed: 1.493818ms
Mar 13 09:18:32.692: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 2.0033413s
Mar 13 09:18:34.694: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 4.005343792s
Mar 13 09:18:36.696: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 6.007284918s
Mar 13 09:18:38.698: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 8.00938409s
Mar 13 09:18:40.701: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 10.01192088s
Mar 13 09:18:42.703: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 12.013997438s
Mar 13 09:18:44.705: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 14.01597241s
Mar 13 09:18:46.707: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 16.01775227s
Mar 13 09:18:48.709: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 18.019738235s
Mar 13 09:18:50.711: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Running", Reason="", readiness=true. Elapsed: 20.022049644s
Mar 13 09:18:52.713: INFO: Pod "pod-subpath-test-secret-2tfz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.024413376s
STEP: Saw pod success
Mar 13 09:18:52.713: INFO: Pod "pod-subpath-test-secret-2tfz" satisfied condition "success or failure"
Mar 13 09:18:52.715: INFO: Trying to get logs from node 172.24.5.7 pod pod-subpath-test-secret-2tfz container test-container-subpath-secret-2tfz: <nil>
STEP: delete the pod
Mar 13 09:18:52.724: INFO: Waiting for pod pod-subpath-test-secret-2tfz to disappear
Mar 13 09:18:52.726: INFO: Pod pod-subpath-test-secret-2tfz no longer exists
STEP: Deleting pod pod-subpath-test-secret-2tfz
Mar 13 09:18:52.726: INFO: Deleting pod "pod-subpath-test-secret-2tfz" in namespace "subpath-7387"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:18:52.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7387" for this suite.

• [SLOW TEST:22.066 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":280,"completed":24,"skipped":388,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:18:52.731: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 13 09:18:52.751: INFO: Waiting up to 5m0s for pod "pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6" in namespace "emptydir-5166" to be "success or failure"
Mar 13 09:18:52.753: INFO: Pod "pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.439304ms
Mar 13 09:18:54.755: INFO: Pod "pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003694494s
STEP: Saw pod success
Mar 13 09:18:54.755: INFO: Pod "pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6" satisfied condition "success or failure"
Mar 13 09:18:54.757: INFO: Trying to get logs from node 172.24.5.7 pod pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6 container test-container: <nil>
STEP: delete the pod
Mar 13 09:18:54.764: INFO: Waiting for pod pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6 to disappear
Mar 13 09:18:54.766: INFO: Pod pod-3a0ac0a1-3bf2-42e4-9b5f-c095c06061f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:18:54.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5166" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":25,"skipped":388,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:18:54.770: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 13 09:18:57.306: INFO: Successfully updated pod "labelsupdate2b2ab897-7f66-4e37-b681-819d4ee30c74"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:19:01.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4226" for this suite.

• [SLOW TEST:6.559 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":26,"skipped":390,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:19:01.330: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-86583491-0eef-4d38-98cf-e2a0687cd922
STEP: Creating a pod to test consume configMaps
Mar 13 09:19:01.352: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b" in namespace "configmap-8639" to be "success or failure"
Mar 13 09:19:01.353: INFO: Pod "pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.358757ms
Mar 13 09:19:03.355: INFO: Pod "pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003551937s
STEP: Saw pod success
Mar 13 09:19:03.355: INFO: Pod "pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b" satisfied condition "success or failure"
Mar 13 09:19:03.357: INFO: Trying to get logs from node 172.24.5.5 pod pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:19:03.367: INFO: Waiting for pod pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b to disappear
Mar 13 09:19:03.369: INFO: Pod pod-configmaps-4fa1d105-99ae-4980-b6fd-cde334fc8c2b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:19:03.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8639" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":27,"skipped":435,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:19:03.374: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:19:03.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8" in namespace "projected-6690" to be "success or failure"
Mar 13 09:19:03.396: INFO: Pod "downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.38057ms
Mar 13 09:19:05.398: INFO: Pod "downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003391582s
STEP: Saw pod success
Mar 13 09:19:05.398: INFO: Pod "downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8" satisfied condition "success or failure"
Mar 13 09:19:05.399: INFO: Trying to get logs from node 172.24.5.5 pod downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8 container client-container: <nil>
STEP: delete the pod
Mar 13 09:19:05.409: INFO: Waiting for pod downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8 to disappear
Mar 13 09:19:05.411: INFO: Pod downwardapi-volume-206aafad-2e44-497a-8d17-50d1cc72c3c8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:19:05.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6690" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":28,"skipped":452,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:19:05.415: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test env composition
Mar 13 09:19:05.435: INFO: Waiting up to 5m0s for pod "var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe" in namespace "var-expansion-7552" to be "success or failure"
Mar 13 09:19:05.436: INFO: Pod "var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.323682ms
Mar 13 09:19:07.439: INFO: Pod "var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003579501s
STEP: Saw pod success
Mar 13 09:19:07.439: INFO: Pod "var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe" satisfied condition "success or failure"
Mar 13 09:19:07.440: INFO: Trying to get logs from node 172.24.5.5 pod var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe container dapi-container: <nil>
STEP: delete the pod
Mar 13 09:19:07.451: INFO: Waiting for pod var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe to disappear
Mar 13 09:19:07.452: INFO: Pod var-expansion-c5f8bee7-7217-4dcd-8a50-a1ea892ee3fe no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:19:07.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7552" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":280,"completed":29,"skipped":469,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:19:07.456: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:344
Mar 13 09:19:07.472: INFO: Waiting up to 1m0s for all nodes to be ready
Mar 13 09:20:07.483: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:20:07.485: INFO: Starting informer...
STEP: Starting pods...
Mar 13 09:20:07.693: INFO: Pod1 is running on 172.24.5.5. Tainting Node
Mar 13 09:20:09.903: INFO: Pod2 is running on 172.24.5.5. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Mar 13 09:20:16.883: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Mar 13 09:20:41.983: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:20:41.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-118" for this suite.

• [SLOW TEST:94.539 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":280,"completed":30,"skipped":486,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:20:41.995: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name projected-secret-test-2391fb27-8f2d-45e9-ae53-a0bd86a97279
STEP: Creating a pod to test consume secrets
Mar 13 09:20:42.017: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da" in namespace "projected-954" to be "success or failure"
Mar 13 09:20:42.018: INFO: Pod "pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da": Phase="Pending", Reason="", readiness=false. Elapsed: 1.321231ms
Mar 13 09:20:44.020: INFO: Pod "pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003180416s
STEP: Saw pod success
Mar 13 09:20:44.020: INFO: Pod "pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da" satisfied condition "success or failure"
Mar 13 09:20:44.022: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:20:44.037: INFO: Waiting for pod pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da to disappear
Mar 13 09:20:44.038: INFO: Pod pod-projected-secrets-f805b4c6-d555-4b32-9b45-796acaa312da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:20:44.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-954" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":31,"skipped":496,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:20:44.043: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 13 09:20:44.062: INFO: Waiting up to 5m0s for pod "pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c" in namespace "emptydir-3072" to be "success or failure"
Mar 13 09:20:44.064: INFO: Pod "pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.487714ms
Mar 13 09:20:46.066: INFO: Pod "pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003522021s
STEP: Saw pod success
Mar 13 09:20:46.066: INFO: Pod "pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c" satisfied condition "success or failure"
Mar 13 09:20:46.068: INFO: Trying to get logs from node 172.24.5.5 pod pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c container test-container: <nil>
STEP: delete the pod
Mar 13 09:20:46.088: INFO: Waiting for pod pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c to disappear
Mar 13 09:20:46.090: INFO: Pod pod-8b441f53-86d9-4133-8588-5b9d42ff2b3c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:20:46.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3072" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":32,"skipped":539,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:20:46.094: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Mar 13 09:21:26.129: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0313 09:21:26.129239      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:21:26.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-690" for this suite.

• [SLOW TEST:40.039 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":280,"completed":33,"skipped":547,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:21:26.133: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:21:26.161: INFO: Create a RollingUpdate DaemonSet
Mar 13 09:21:26.163: INFO: Check that daemon pods launch on every node of the cluster
Mar 13 09:21:26.166: INFO: Number of nodes with available pods: 0
Mar 13 09:21:26.166: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:21:27.171: INFO: Number of nodes with available pods: 0
Mar 13 09:21:27.171: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:21:28.171: INFO: Number of nodes with available pods: 2
Mar 13 09:21:28.171: INFO: Number of running nodes: 2, number of available pods: 2
Mar 13 09:21:28.171: INFO: Update the DaemonSet to trigger a rollout
Mar 13 09:21:28.174: INFO: Updating DaemonSet daemon-set
Mar 13 09:21:34.183: INFO: Roll back the DaemonSet before rollout is complete
Mar 13 09:21:34.186: INFO: Updating DaemonSet daemon-set
Mar 13 09:21:34.186: INFO: Make sure DaemonSet rollback is complete
Mar 13 09:21:34.188: INFO: Wrong image for pod: daemon-set-g7xmm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar 13 09:21:34.188: INFO: Pod daemon-set-g7xmm is not available
Mar 13 09:21:35.192: INFO: Wrong image for pod: daemon-set-g7xmm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar 13 09:21:35.192: INFO: Pod daemon-set-g7xmm is not available
Mar 13 09:21:36.192: INFO: Wrong image for pod: daemon-set-g7xmm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar 13 09:21:36.192: INFO: Pod daemon-set-g7xmm is not available
Mar 13 09:21:37.192: INFO: Wrong image for pod: daemon-set-g7xmm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar 13 09:21:37.192: INFO: Pod daemon-set-g7xmm is not available
Mar 13 09:21:38.193: INFO: Pod daemon-set-kw77s is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8340, will wait for the garbage collector to delete the pods
Mar 13 09:21:38.254: INFO: Deleting DaemonSet.extensions daemon-set took: 3.131283ms
Mar 13 09:21:38.654: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.21631ms
Mar 13 09:23:06.556: INFO: Number of nodes with available pods: 0
Mar 13 09:23:06.556: INFO: Number of running nodes: 0, number of available pods: 0
Mar 13 09:23:06.558: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8340/daemonsets","resourceVersion":"43480"},"items":null}

Mar 13 09:23:06.559: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8340/pods","resourceVersion":"43480"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:23:06.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8340" for this suite.

• [SLOW TEST:100.436 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":280,"completed":34,"skipped":574,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:23:06.570: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-fa7bbb3a-f6ad-47f4-91bc-7c14c972de72
STEP: Creating configMap with name cm-test-opt-upd-65fbb67c-6bf4-4684-be30-2af24ac08a1e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fa7bbb3a-f6ad-47f4-91bc-7c14c972de72
STEP: Updating configmap cm-test-opt-upd-65fbb67c-6bf4-4684-be30-2af24ac08a1e
STEP: Creating configMap with name cm-test-opt-create-6892f79d-5281-4d84-b521-3c6b1d504e11
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:23:10.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3484" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":35,"skipped":590,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:23:10.647: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 13 09:23:10.664: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 13 09:23:10.670: INFO: Waiting for terminating namespaces to be deleted...
Mar 13 09:23:10.672: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.5 before test
Mar 13 09:23:10.690: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:23:10.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:23:10.690: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:23:10.690: INFO: canal-m4mzr from kube-system started at 2020-03-13 09:11:02 +0000 UTC (2 container statuses recorded)
Mar 13 09:23:10.690: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:23:10.690: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 09:23:10.690: INFO: nginx-ingress-controller-6b2t4 from ingress-nginx started at 2020-03-13 09:11:08 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.690: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:23:10.690: INFO: coredns-7c5566588d-9gx44 from kube-system started at 2020-03-13 09:11:16 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.690: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:23:10.690: INFO: sonobuoy-e2e-job-53adb94536da47d3 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:23:10.690: INFO: 	Container e2e ready: true, restart count 0
Mar 13 09:23:10.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:23:10.690: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.7 before test
Mar 13 09:23:10.696: INFO: rke-metrics-addon-deploy-job-w79dp from kube-system started at 2020-03-13 06:25:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 13 09:23:10.696: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-6mljq from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:23:10.696: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:23:10.696: INFO: metrics-server-6b55c64f86-gp7kb from kube-system started at 2020-03-13 06:25:09 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container metrics-server ready: true, restart count 0
Mar 13 09:23:10.696: INFO: sonobuoy from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 13 09:23:10.696: INFO: rke-ingress-controller-deploy-job-mmxvc from kube-system started at 2020-03-13 06:25:12 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 13 09:23:10.696: INFO: coredns-7c5566588d-dx5r6 from kube-system started at 2020-03-13 06:40:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:23:10.696: INFO: canal-fd4wb from kube-system started at 2020-03-13 06:22:33 +0000 UTC (2 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:23:10.696: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 09:23:10.696: INFO: rke-coredns-addon-deploy-job-frlv2 from kube-system started at 2020-03-13 06:25:02 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Mar 13 09:23:10.696: INFO: coredns-autoscaler-65bfc8d47d-d5vsc from kube-system started at 2020-03-13 06:25:04 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container autoscaler ready: true, restart count 0
Mar 13 09:23:10.696: INFO: default-http-backend-67cf578fc4-rwkbq from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 13 09:23:10.696: INFO: rke-network-plugin-deploy-job-chk5v from kube-system started at 2020-03-13 06:22:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 13 09:23:10.696: INFO: nginx-ingress-controller-mhtcd from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:23:10.696: INFO: pod-projected-configmaps-48dd78ce-61e5-4f27-a5b2-974ec5547292 from projected-3484 started at 2020-03-13 09:23:06 +0000 UTC (3 container statuses recorded)
Mar 13 09:23:10.696: INFO: 	Container createcm-volume-test ready: true, restart count 0
Mar 13 09:23:10.696: INFO: 	Container delcm-volume-test ready: true, restart count 0
Mar 13 09:23:10.696: INFO: 	Container updcm-volume-test ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e2ad97e9-aaf9-4ade-ad15-3a951fdbbcff 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-e2ad97e9-aaf9-4ade-ad15-3a951fdbbcff off the node 172.24.5.5
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e2ad97e9-aaf9-4ade-ad15-3a951fdbbcff
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:28:14.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2029" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:304.091 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":280,"completed":36,"skipped":619,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:28:14.738: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 13 09:28:14.755: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 13 09:28:14.762: INFO: Waiting for terminating namespaces to be deleted...
Mar 13 09:28:14.763: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.5 before test
Mar 13 09:28:14.781: INFO: canal-m4mzr from kube-system started at 2020-03-13 09:11:02 +0000 UTC (2 container statuses recorded)
Mar 13 09:28:14.781: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:28:14.781: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 09:28:14.781: INFO: nginx-ingress-controller-6b2t4 from ingress-nginx started at 2020-03-13 09:11:08 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.781: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:28:14.781: INFO: coredns-7c5566588d-9gx44 from kube-system started at 2020-03-13 09:11:16 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.781: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:28:14.781: INFO: sonobuoy-e2e-job-53adb94536da47d3 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:28:14.781: INFO: 	Container e2e ready: true, restart count 0
Mar 13 09:28:14.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:28:14.781: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:28:14.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:28:14.781: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:28:14.781: INFO: pod4 from sched-pred-2029 started at 2020-03-13 09:23:12 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.781: INFO: 	Container pod4 ready: true, restart count 0
Mar 13 09:28:14.781: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.7 before test
Mar 13 09:28:14.795: INFO: rke-coredns-addon-deploy-job-frlv2 from kube-system started at 2020-03-13 06:25:02 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Mar 13 09:28:14.795: INFO: coredns-autoscaler-65bfc8d47d-d5vsc from kube-system started at 2020-03-13 06:25:04 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container autoscaler ready: true, restart count 0
Mar 13 09:28:14.795: INFO: default-http-backend-67cf578fc4-rwkbq from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 13 09:28:14.795: INFO: rke-network-plugin-deploy-job-chk5v from kube-system started at 2020-03-13 06:22:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 13 09:28:14.795: INFO: nginx-ingress-controller-mhtcd from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:28:14.795: INFO: rke-metrics-addon-deploy-job-w79dp from kube-system started at 2020-03-13 06:25:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 13 09:28:14.795: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-6mljq from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:28:14.795: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:28:14.795: INFO: metrics-server-6b55c64f86-gp7kb from kube-system started at 2020-03-13 06:25:09 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container metrics-server ready: true, restart count 0
Mar 13 09:28:14.795: INFO: sonobuoy from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 13 09:28:14.795: INFO: rke-ingress-controller-deploy-job-mmxvc from kube-system started at 2020-03-13 06:25:12 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 13 09:28:14.795: INFO: coredns-7c5566588d-dx5r6 from kube-system started at 2020-03-13 06:40:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:28:14.795: INFO: canal-fd4wb from kube-system started at 2020-03-13 06:22:33 +0000 UTC (2 container statuses recorded)
Mar 13 09:28:14.795: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:28:14.795: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6abb3de2-47d2-4b7d-bf2e-5b707ba4cfff 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-6abb3de2-47d2-4b7d-bf2e-5b707ba4cfff off the node 172.24.5.7
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6abb3de2-47d2-4b7d-bf2e-5b707ba4cfff
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:28:22.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6898" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:8.102 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":280,"completed":37,"skipped":633,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:28:22.841: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-1706
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating stateful set ss in namespace statefulset-1706
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1706
Mar 13 09:28:22.863: INFO: Found 0 stateful pods, waiting for 1
Mar 13 09:28:32.865: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 13 09:28:32.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 09:28:33.170: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 09:28:33.170: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 09:28:33.170: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 09:28:33.172: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 13 09:28:43.174: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 09:28:43.174: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 09:28:43.181: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:28:43.181: INFO: ss-0  172.24.5.5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:22 +0000 UTC  }]
Mar 13 09:28:43.181: INFO: 
Mar 13 09:28:43.181: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 13 09:28:44.184: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998125334s
Mar 13 09:28:45.186: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995411903s
Mar 13 09:28:46.189: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.993151529s
Mar 13 09:28:47.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.99070343s
Mar 13 09:28:48.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98828426s
Mar 13 09:28:49.196: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.985951877s
Mar 13 09:28:50.198: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983317227s
Mar 13 09:28:51.201: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.981025132s
Mar 13 09:28:52.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 978.46141ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1706
Mar 13 09:28:53.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:28:53.455: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 09:28:53.455: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 09:28:53.455: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 09:28:53.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:28:53.664: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 13 09:28:53.664: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 09:28:53.664: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 09:28:53.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:28:53.899: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 13 09:28:53.899: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 09:28:53.899: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 09:28:53.901: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 09:28:53.901: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 09:28:53.901: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 13 09:28:53.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 09:28:54.129: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 09:28:54.129: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 09:28:54.129: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 09:28:54.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 09:28:54.323: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 09:28:54.323: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 09:28:54.323: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 09:28:54.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 09:28:54.569: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 09:28:54.569: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 09:28:54.569: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 09:28:54.569: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 09:28:54.571: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 13 09:29:04.575: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 09:29:04.575: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 09:29:04.575: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 09:29:04.580: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:04.581: INFO: ss-0  172.24.5.5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:22 +0000 UTC  }]
Mar 13 09:29:04.581: INFO: ss-1  172.24.5.7  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:04.581: INFO: ss-2  172.24.5.5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:04.581: INFO: 
Mar 13 09:29:04.581: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 13 09:29:05.583: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:05.583: INFO: ss-0  172.24.5.5  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:22 +0000 UTC  }]
Mar 13 09:29:05.583: INFO: ss-1  172.24.5.7  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:05.583: INFO: ss-2  172.24.5.5  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:05.583: INFO: 
Mar 13 09:29:05.583: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 13 09:29:06.585: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:06.585: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:06.586: INFO: 
Mar 13 09:29:06.586: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:07.588: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:07.588: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:07.588: INFO: 
Mar 13 09:29:07.588: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:08.590: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:08.590: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:08.590: INFO: 
Mar 13 09:29:08.590: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:09.592: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:09.592: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:09.592: INFO: 
Mar 13 09:29:09.592: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:10.594: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:10.594: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:10.594: INFO: 
Mar 13 09:29:10.594: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:11.596: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:11.597: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:11.597: INFO: 
Mar 13 09:29:11.597: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:12.599: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:12.599: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:12.599: INFO: 
Mar 13 09:29:12.599: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 13 09:29:13.601: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
Mar 13 09:29:13.602: INFO: ss-1  172.24.5.7  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-13 09:28:43 +0000 UTC  }]
Mar 13 09:29:13.602: INFO: 
Mar 13 09:29:13.602: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1706
Mar 13 09:29:14.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:29:14.717: INFO: rc: 1
Mar 13 09:29:14.717: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Mar 13 09:29:24.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:29:24.797: INFO: rc: 1
Mar 13 09:29:24.797: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:29:34.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:29:34.876: INFO: rc: 1
Mar 13 09:29:34.876: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:29:44.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:29:44.966: INFO: rc: 1
Mar 13 09:29:44.966: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:29:54.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:29:55.046: INFO: rc: 1
Mar 13 09:29:55.046: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:30:05.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:30:05.133: INFO: rc: 1
Mar 13 09:30:05.133: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:30:15.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:30:15.229: INFO: rc: 1
Mar 13 09:30:15.229: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:30:25.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:30:25.308: INFO: rc: 1
Mar 13 09:30:25.308: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:30:35.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:30:35.399: INFO: rc: 1
Mar 13 09:30:35.399: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:30:45.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:30:45.476: INFO: rc: 1
Mar 13 09:30:45.476: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:30:55.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:30:55.555: INFO: rc: 1
Mar 13 09:30:55.555: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:31:05.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:31:05.644: INFO: rc: 1
Mar 13 09:31:05.644: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:31:15.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:31:15.725: INFO: rc: 1
Mar 13 09:31:15.725: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:31:25.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:31:25.808: INFO: rc: 1
Mar 13 09:31:25.808: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:31:35.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:31:35.889: INFO: rc: 1
Mar 13 09:31:35.889: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:31:45.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:31:45.972: INFO: rc: 1
Mar 13 09:31:45.972: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:31:55.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:31:56.057: INFO: rc: 1
Mar 13 09:31:56.057: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:32:06.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:32:06.142: INFO: rc: 1
Mar 13 09:32:06.142: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:32:16.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:32:16.220: INFO: rc: 1
Mar 13 09:32:16.220: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:32:26.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:32:26.300: INFO: rc: 1
Mar 13 09:32:26.300: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:32:36.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:32:36.383: INFO: rc: 1
Mar 13 09:32:36.383: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:32:46.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:32:46.465: INFO: rc: 1
Mar 13 09:32:46.465: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:32:56.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:32:56.546: INFO: rc: 1
Mar 13 09:32:56.546: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:33:06.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:33:06.641: INFO: rc: 1
Mar 13 09:33:06.641: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:33:16.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:33:16.721: INFO: rc: 1
Mar 13 09:33:16.721: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:33:26.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:33:26.801: INFO: rc: 1
Mar 13 09:33:26.801: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:33:36.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:33:36.887: INFO: rc: 1
Mar 13 09:33:36.887: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:33:46.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:33:46.975: INFO: rc: 1
Mar 13 09:33:46.975: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:33:56.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:33:57.067: INFO: rc: 1
Mar 13 09:33:57.067: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:34:07.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:34:07.147: INFO: rc: 1
Mar 13 09:34:07.147: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Mar 13 09:34:17.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1706 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 09:34:17.231: INFO: rc: 1
Mar 13 09:34:17.231: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Mar 13 09:34:17.231: INFO: Scaling statefulset ss to 0
Mar 13 09:34:17.237: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 13 09:34:17.238: INFO: Deleting all statefulset in ns statefulset-1706
Mar 13 09:34:17.240: INFO: Scaling statefulset ss to 0
Mar 13 09:34:17.244: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 09:34:17.246: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:17.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1706" for this suite.

• [SLOW TEST:354.414 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":280,"completed":38,"skipped":659,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:17.256: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:34:17.659: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:34:20.668: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:34:20.670: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:21.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2483" for this suite.
STEP: Destroying namespace "webhook-2483-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":280,"completed":39,"skipped":694,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:21.456: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Mar 13 09:34:21.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-745'
Mar 13 09:34:21.622: INFO: stderr: ""
Mar 13 09:34:21.622: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Mar 13 09:34:22.624: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:34:22.625: INFO: Found 0 / 1
Mar 13 09:34:23.625: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:34:23.625: INFO: Found 1 / 1
Mar 13 09:34:23.625: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 13 09:34:23.627: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:34:23.627: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 13 09:34:23.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 patch pod agnhost-master-qwlbw --namespace=kubectl-745 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 13 09:34:23.707: INFO: stderr: ""
Mar 13 09:34:23.707: INFO: stdout: "pod/agnhost-master-qwlbw patched\n"
STEP: checking annotations
Mar 13 09:34:23.708: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:34:23.708: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:23.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-745" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":280,"completed":40,"skipped":727,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:23.714: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:23.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-338" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":280,"completed":41,"skipped":777,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:23.754: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 13 09:34:23.773: INFO: Waiting up to 5m0s for pod "downward-api-a73d0d85-750b-446c-9187-d87411bdf196" in namespace "downward-api-5564" to be "success or failure"
Mar 13 09:34:23.774: INFO: Pod "downward-api-a73d0d85-750b-446c-9187-d87411bdf196": Phase="Pending", Reason="", readiness=false. Elapsed: 1.33291ms
Mar 13 09:34:25.776: INFO: Pod "downward-api-a73d0d85-750b-446c-9187-d87411bdf196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003519388s
STEP: Saw pod success
Mar 13 09:34:25.776: INFO: Pod "downward-api-a73d0d85-750b-446c-9187-d87411bdf196" satisfied condition "success or failure"
Mar 13 09:34:25.778: INFO: Trying to get logs from node 172.24.5.7 pod downward-api-a73d0d85-750b-446c-9187-d87411bdf196 container dapi-container: <nil>
STEP: delete the pod
Mar 13 09:34:25.795: INFO: Waiting for pod downward-api-a73d0d85-750b-446c-9187-d87411bdf196 to disappear
Mar 13 09:34:25.796: INFO: Pod downward-api-a73d0d85-750b-446c-9187-d87411bdf196 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:25.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5564" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":280,"completed":42,"skipped":817,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:25.801: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-q656x in namespace proxy-4869
I0313 09:34:25.822347      26 runners.go:189] Created replication controller with name: proxy-service-q656x, namespace: proxy-4869, replica count: 1
I0313 09:34:26.872813      26 runners.go:189] proxy-service-q656x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0313 09:34:27.873019      26 runners.go:189] proxy-service-q656x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0313 09:34:28.873218      26 runners.go:189] proxy-service-q656x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0313 09:34:29.873468      26 runners.go:189] proxy-service-q656x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 13 09:34:29.875: INFO: setup took 4.057575323s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 13 09:34:29.878: INFO: (0) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.823268ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 3.963757ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 3.837097ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 3.808417ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 4.182482ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 4.182639ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 4.250279ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 4.290762ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 4.35947ms)
Mar 13 09:34:29.879: INFO: (0) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 4.330682ms)
Mar 13 09:34:29.880: INFO: (0) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 5.418889ms)
Mar 13 09:34:29.884: INFO: (0) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 8.997483ms)
Mar 13 09:34:29.884: INFO: (0) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 9.136475ms)
Mar 13 09:34:29.885: INFO: (0) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 10.456638ms)
Mar 13 09:34:29.885: INFO: (0) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 10.547878ms)
Mar 13 09:34:29.886: INFO: (0) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 11.046118ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.891236ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.897853ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.037897ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.079183ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.015204ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.929937ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.020287ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.935754ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.279186ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.54916ms)
Mar 13 09:34:29.888: INFO: (1) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.528949ms)
Mar 13 09:34:29.889: INFO: (1) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.56118ms)
Mar 13 09:34:29.889: INFO: (1) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.54948ms)
Mar 13 09:34:29.889: INFO: (1) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.713439ms)
Mar 13 09:34:29.889: INFO: (1) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.564275ms)
Mar 13 09:34:29.889: INFO: (1) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.56372ms)
Mar 13 09:34:29.890: INFO: (2) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.747379ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.367923ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.295755ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.498706ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.62764ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.721497ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.617621ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.814058ms)
Mar 13 09:34:29.891: INFO: (2) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.796265ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.935338ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 3.118663ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 3.172404ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 3.262574ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 3.30889ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 3.369814ms)
Mar 13 09:34:29.892: INFO: (2) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 3.390174ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 1.570754ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.559338ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.687402ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.655845ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.721626ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.837493ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.038854ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.273675ms)
Mar 13 09:34:29.894: INFO: (3) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.302992ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.257571ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.320402ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.286025ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.273286ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.348093ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.427013ms)
Mar 13 09:34:29.895: INFO: (3) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.371949ms)
Mar 13 09:34:29.896: INFO: (4) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.747209ms)
Mar 13 09:34:29.896: INFO: (4) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.751729ms)
Mar 13 09:34:29.896: INFO: (4) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.655018ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.723359ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 1.785977ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 1.759976ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.951975ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.95072ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.120778ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.31304ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.488211ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.431569ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.545459ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.533277ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.46729ms)
Mar 13 09:34:29.897: INFO: (4) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.526193ms)
Mar 13 09:34:29.899: INFO: (5) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 1.347814ms)
Mar 13 09:34:29.899: INFO: (5) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.377203ms)
Mar 13 09:34:29.899: INFO: (5) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.632016ms)
Mar 13 09:34:29.899: INFO: (5) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.011324ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.091781ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.039793ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.054317ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.143804ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.215135ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.287874ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.309899ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.442843ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.492341ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.5237ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.578479ms)
Mar 13 09:34:29.900: INFO: (5) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.572913ms)
Mar 13 09:34:29.901: INFO: (6) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.240974ms)
Mar 13 09:34:29.902: INFO: (6) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.683442ms)
Mar 13 09:34:29.902: INFO: (6) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.186114ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.237004ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.242612ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.466239ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.413176ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.442043ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.433813ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.613937ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.61732ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.509823ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.599986ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.630803ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.746277ms)
Mar 13 09:34:29.903: INFO: (6) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.61189ms)
Mar 13 09:34:29.905: INFO: (7) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.598392ms)
Mar 13 09:34:29.905: INFO: (7) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 1.629009ms)
Mar 13 09:34:29.905: INFO: (7) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.778225ms)
Mar 13 09:34:29.905: INFO: (7) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.954491ms)
Mar 13 09:34:29.905: INFO: (7) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.100651ms)
Mar 13 09:34:29.905: INFO: (7) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.351724ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.559155ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.640178ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.660137ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.643387ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.737507ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.725257ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.71911ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.718975ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.834082ms)
Mar 13 09:34:29.906: INFO: (7) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.727492ms)
Mar 13 09:34:29.907: INFO: (8) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.469285ms)
Mar 13 09:34:29.907: INFO: (8) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.505501ms)
Mar 13 09:34:29.908: INFO: (8) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.776416ms)
Mar 13 09:34:29.908: INFO: (8) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.137274ms)
Mar 13 09:34:29.908: INFO: (8) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.399633ms)
Mar 13 09:34:29.908: INFO: (8) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.366315ms)
Mar 13 09:34:29.908: INFO: (8) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.505377ms)
Mar 13 09:34:29.908: INFO: (8) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.460636ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.617596ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.651093ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.776521ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.794231ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.726105ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.751658ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.705024ms)
Mar 13 09:34:29.909: INFO: (8) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.756302ms)
Mar 13 09:34:29.910: INFO: (9) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.589128ms)
Mar 13 09:34:29.910: INFO: (9) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.456568ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.149578ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.302142ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.413696ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.357002ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.398449ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.562761ms)
Mar 13 09:34:29.911: INFO: (9) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.598763ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.719943ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.651254ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.632354ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.716271ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.784134ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.780044ms)
Mar 13 09:34:29.912: INFO: (9) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.791604ms)
Mar 13 09:34:29.913: INFO: (10) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.367957ms)
Mar 13 09:34:29.913: INFO: (10) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.650873ms)
Mar 13 09:34:29.913: INFO: (10) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.673346ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.927834ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.925233ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.106937ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.089008ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.101701ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.230862ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.39538ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.417589ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.417344ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.443109ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.531329ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.532117ms)
Mar 13 09:34:29.914: INFO: (10) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.435996ms)
Mar 13 09:34:29.916: INFO: (11) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.882206ms)
Mar 13 09:34:29.916: INFO: (11) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.950241ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.300781ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.414905ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.357749ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.432103ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.328012ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.400723ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.356179ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.407772ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.443496ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.465049ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.404009ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.451405ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.440478ms)
Mar 13 09:34:29.917: INFO: (11) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.594796ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.576888ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.68046ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.781481ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.876093ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 1.8861ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.94404ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.95649ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.006908ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.047118ms)
Mar 13 09:34:29.919: INFO: (12) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.039068ms)
Mar 13 09:34:29.920: INFO: (12) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.692838ms)
Mar 13 09:34:29.920: INFO: (12) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.681454ms)
Mar 13 09:34:29.920: INFO: (12) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.740345ms)
Mar 13 09:34:29.920: INFO: (12) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.745159ms)
Mar 13 09:34:29.920: INFO: (12) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.787692ms)
Mar 13 09:34:29.920: INFO: (12) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.754189ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.674265ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.888417ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 1.811862ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.845322ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.903779ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.179501ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.05026ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.169071ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.094969ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.222986ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.374942ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.476681ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.454209ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.511547ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.507744ms)
Mar 13 09:34:29.922: INFO: (13) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.49263ms)
Mar 13 09:34:29.924: INFO: (14) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.311674ms)
Mar 13 09:34:29.928: INFO: (14) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 5.658505ms)
Mar 13 09:34:29.929: INFO: (14) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 6.1518ms)
Mar 13 09:34:29.929: INFO: (14) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 6.229429ms)
Mar 13 09:34:29.929: INFO: (14) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 6.23752ms)
Mar 13 09:34:29.929: INFO: (14) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 6.588298ms)
Mar 13 09:34:29.929: INFO: (14) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 6.669245ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 8.989904ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 9.117438ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 9.139424ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 9.068987ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 9.04238ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 9.056511ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 9.190019ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 9.12716ms)
Mar 13 09:34:29.932: INFO: (14) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 9.099901ms)
Mar 13 09:34:29.935: INFO: (15) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 3.484625ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 3.696963ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 3.835279ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 3.839002ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 4.040186ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 4.138629ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 4.189088ms)
Mar 13 09:34:29.936: INFO: (15) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 4.088921ms)
Mar 13 09:34:29.937: INFO: (15) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 5.312857ms)
Mar 13 09:34:29.937: INFO: (15) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 5.406006ms)
Mar 13 09:34:29.937: INFO: (15) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 5.407269ms)
Mar 13 09:34:29.937: INFO: (15) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 5.423402ms)
Mar 13 09:34:29.938: INFO: (15) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 5.763104ms)
Mar 13 09:34:29.938: INFO: (15) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 6.401179ms)
Mar 13 09:34:29.942: INFO: (15) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 10.235838ms)
Mar 13 09:34:29.942: INFO: (15) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 10.137963ms)
Mar 13 09:34:29.943: INFO: (16) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.420135ms)
Mar 13 09:34:29.944: INFO: (16) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.703728ms)
Mar 13 09:34:29.944: INFO: (16) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.774149ms)
Mar 13 09:34:29.944: INFO: (16) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.914123ms)
Mar 13 09:34:29.944: INFO: (16) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.00498ms)
Mar 13 09:34:29.944: INFO: (16) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.048634ms)
Mar 13 09:34:29.944: INFO: (16) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.142204ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.544319ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.491639ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.494906ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.69353ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.798697ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.724158ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.89779ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.858838ms)
Mar 13 09:34:29.945: INFO: (16) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.718998ms)
Mar 13 09:34:29.947: INFO: (17) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 1.597694ms)
Mar 13 09:34:29.947: INFO: (17) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.761058ms)
Mar 13 09:34:29.947: INFO: (17) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 1.948658ms)
Mar 13 09:34:29.947: INFO: (17) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.044178ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.366715ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.419362ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.482425ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.760381ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 2.69981ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.822539ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.727452ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.779704ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.735051ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.793097ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 2.801468ms)
Mar 13 09:34:29.948: INFO: (17) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.931558ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.331283ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.460448ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.655636ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.784278ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.8688ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.124631ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.144125ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 2.137601ms)
Mar 13 09:34:29.950: INFO: (18) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.202888ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 2.316923ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.460649ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.502513ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.560488ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.560787ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.61432ms)
Mar 13 09:34:29.951: INFO: (18) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.724319ms)
Mar 13 09:34:29.952: INFO: (19) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:160/proxy/: foo (200; 1.41876ms)
Mar 13 09:34:29.952: INFO: (19) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:462/proxy/: tls qux (200; 1.513491ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:460/proxy/: tls baz (200; 1.762786ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/https:proxy-service-q656x-wvz7r:443/proxy/tlsrewritem... (200; 1.786581ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r/proxy/rewriteme">test</a> (200; 1.91388ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:162/proxy/: bar (200; 1.846317ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:1080/proxy/rewriteme">test<... (200; 2.165737ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:162/proxy/: bar (200; 2.066918ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/proxy-service-q656x-wvz7r:160/proxy/: foo (200; 2.105134ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/: <a href="/api/v1/namespaces/proxy-4869/pods/http:proxy-service-q656x-wvz7r:1080/proxy/rewriteme">... (200; 2.137015ms)
Mar 13 09:34:29.953: INFO: (19) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname2/proxy/: bar (200; 2.45534ms)
Mar 13 09:34:29.954: INFO: (19) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname1/proxy/: foo (200; 2.595978ms)
Mar 13 09:34:29.954: INFO: (19) /api/v1/namespaces/proxy-4869/services/http:proxy-service-q656x:portname1/proxy/: foo (200; 2.598264ms)
Mar 13 09:34:29.954: INFO: (19) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname1/proxy/: tls baz (200; 2.573395ms)
Mar 13 09:34:29.954: INFO: (19) /api/v1/namespaces/proxy-4869/services/https:proxy-service-q656x:tlsportname2/proxy/: tls qux (200; 2.603974ms)
Mar 13 09:34:29.954: INFO: (19) /api/v1/namespaces/proxy-4869/services/proxy-service-q656x:portname2/proxy/: bar (200; 2.642208ms)
STEP: deleting ReplicationController proxy-service-q656x in namespace proxy-4869, will wait for the garbage collector to delete the pods
Mar 13 09:34:30.008: INFO: Deleting ReplicationController proxy-service-q656x took: 2.876492ms
Mar 13 09:34:30.108: INFO: Terminating ReplicationController proxy-service-q656x pods took: 100.223915ms
[AfterEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:36.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4869" for this suite.

• [SLOW TEST:10.813 seconds]
[sig-network] Proxy
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":280,"completed":43,"skipped":826,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:36.614: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:34:36.634: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e" in namespace "downward-api-196" to be "success or failure"
Mar 13 09:34:36.636: INFO: Pod "downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.431967ms
Mar 13 09:34:38.638: INFO: Pod "downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003506764s
STEP: Saw pod success
Mar 13 09:34:38.638: INFO: Pod "downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e" satisfied condition "success or failure"
Mar 13 09:34:38.639: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e container client-container: <nil>
STEP: delete the pod
Mar 13 09:34:38.648: INFO: Waiting for pod downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e to disappear
Mar 13 09:34:38.649: INFO: Pod downwardapi-volume-b9868a37-d9ca-4b5e-b52e-10715250268e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:38.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-196" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":44,"skipped":841,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:38.654: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:34:39.036: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:34:42.045: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:34:52.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-357" for this suite.
STEP: Destroying namespace "webhook-357-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:13.695 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":280,"completed":45,"skipped":869,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:34:52.349: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Mar 13 09:34:52.366: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:35:07.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2980" for this suite.

• [SLOW TEST:15.217 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":280,"completed":46,"skipped":875,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:35:07.566: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:35:07.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3442" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":280,"completed":47,"skipped":888,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:35:07.595: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:35:07.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989" in namespace "downward-api-1739" to be "success or failure"
Mar 13 09:35:07.616: INFO: Pod "downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989": Phase="Pending", Reason="", readiness=false. Elapsed: 1.441742ms
Mar 13 09:35:09.618: INFO: Pod "downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003562718s
STEP: Saw pod success
Mar 13 09:35:09.618: INFO: Pod "downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989" satisfied condition "success or failure"
Mar 13 09:35:09.619: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989 container client-container: <nil>
STEP: delete the pod
Mar 13 09:35:09.628: INFO: Waiting for pod downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989 to disappear
Mar 13 09:35:09.629: INFO: Pod downwardapi-volume-a8affc82-f639-4875-aa3e-9a82a86c4989 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:35:09.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1739" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":48,"skipped":901,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:35:09.634: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-982846af-08df-433c-b32f-696aad2fdee2
STEP: Creating a pod to test consume secrets
Mar 13 09:35:09.655: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74" in namespace "projected-9264" to be "success or failure"
Mar 13 09:35:09.657: INFO: Pod "pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74": Phase="Pending", Reason="", readiness=false. Elapsed: 1.511942ms
Mar 13 09:35:11.659: INFO: Pod "pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003485625s
STEP: Saw pod success
Mar 13 09:35:11.659: INFO: Pod "pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74" satisfied condition "success or failure"
Mar 13 09:35:11.660: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:35:11.669: INFO: Waiting for pod pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74 to disappear
Mar 13 09:35:11.670: INFO: Pod pod-projected-secrets-712eade6-35d9-4a67-a76a-258428068d74 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:35:11.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9264" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":49,"skipped":920,"failed":0}

------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:35:11.674: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 13 09:35:11.694: INFO: Waiting up to 5m0s for pod "downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81" in namespace "downward-api-1522" to be "success or failure"
Mar 13 09:35:11.695: INFO: Pod "downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81": Phase="Pending", Reason="", readiness=false. Elapsed: 1.402457ms
Mar 13 09:35:13.697: INFO: Pod "downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003502603s
STEP: Saw pod success
Mar 13 09:35:13.697: INFO: Pod "downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81" satisfied condition "success or failure"
Mar 13 09:35:13.699: INFO: Trying to get logs from node 172.24.5.7 pod downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81 container dapi-container: <nil>
STEP: delete the pod
Mar 13 09:35:13.707: INFO: Waiting for pod downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81 to disappear
Mar 13 09:35:13.708: INFO: Pod downward-api-b3c4d200-0a76-42c9-94f6-d10bb8effa81 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:35:13.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1522" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":280,"completed":50,"skipped":920,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:35:13.713: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-downwardapi-2wdh
STEP: Creating a pod to test atomic-volume-subpath
Mar 13 09:35:13.735: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-2wdh" in namespace "subpath-6707" to be "success or failure"
Mar 13 09:35:13.736: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Pending", Reason="", readiness=false. Elapsed: 1.419424ms
Mar 13 09:35:15.738: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 2.00353938s
Mar 13 09:35:17.740: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 4.005286758s
Mar 13 09:35:19.742: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 6.007726016s
Mar 13 09:35:21.744: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 8.009429584s
Mar 13 09:35:23.746: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 10.011386145s
Mar 13 09:35:25.748: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 12.013596489s
Mar 13 09:35:27.750: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 14.015329426s
Mar 13 09:35:29.752: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 16.017172705s
Mar 13 09:35:31.754: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 18.018990372s
Mar 13 09:35:33.755: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Running", Reason="", readiness=true. Elapsed: 20.020883637s
Mar 13 09:35:35.758: INFO: Pod "pod-subpath-test-downwardapi-2wdh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.023025057s
STEP: Saw pod success
Mar 13 09:35:35.758: INFO: Pod "pod-subpath-test-downwardapi-2wdh" satisfied condition "success or failure"
Mar 13 09:35:35.759: INFO: Trying to get logs from node 172.24.5.7 pod pod-subpath-test-downwardapi-2wdh container test-container-subpath-downwardapi-2wdh: <nil>
STEP: delete the pod
Mar 13 09:35:35.768: INFO: Waiting for pod pod-subpath-test-downwardapi-2wdh to disappear
Mar 13 09:35:35.770: INFO: Pod pod-subpath-test-downwardapi-2wdh no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-2wdh
Mar 13 09:35:35.770: INFO: Deleting pod "pod-subpath-test-downwardapi-2wdh" in namespace "subpath-6707"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:35:35.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6707" for this suite.

• [SLOW TEST:22.062 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":280,"completed":51,"skipped":934,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:35:35.776: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-89fe8bf5-799c-4518-ae1d-40dce5ae3206 in namespace container-probe-8795
Mar 13 09:35:37.799: INFO: Started pod busybox-89fe8bf5-799c-4518-ae1d-40dce5ae3206 in namespace container-probe-8795
STEP: checking the pod's current state and verifying that restartCount is present
Mar 13 09:35:37.800: INFO: Initial restart count of pod busybox-89fe8bf5-799c-4518-ae1d-40dce5ae3206 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:38.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8795" for this suite.

• [SLOW TEST:242.278 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":52,"skipped":940,"failed":0}
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:38.053: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:39:38.079: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3a06e718-8be6-4c21-8f08-cfe748475e2b", Controller:(*bool)(0xc002fdeae6), BlockOwnerDeletion:(*bool)(0xc002fdeae7)}}
Mar 13 09:39:38.081: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"00fc193a-5da5-41ea-a24f-d8ece4323242", Controller:(*bool)(0xc002fdecb6), BlockOwnerDeletion:(*bool)(0xc002fdecb7)}}
Mar 13 09:39:38.083: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"5f65884c-1885-4795-922b-28141d859ef8", Controller:(*bool)(0xc002e1b63a), BlockOwnerDeletion:(*bool)(0xc002e1b63b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:43.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9441" for this suite.

• [SLOW TEST:5.038 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":280,"completed":53,"skipped":940,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:43.092: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:39:43.107: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:45.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1800" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":280,"completed":54,"skipped":949,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:45.307: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 13 09:39:45.326: INFO: Waiting up to 5m0s for pod "pod-422719a7-c17b-464e-8e35-048fe1fec82c" in namespace "emptydir-497" to be "success or failure"
Mar 13 09:39:45.328: INFO: Pod "pod-422719a7-c17b-464e-8e35-048fe1fec82c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.324002ms
Mar 13 09:39:47.330: INFO: Pod "pod-422719a7-c17b-464e-8e35-048fe1fec82c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003190811s
STEP: Saw pod success
Mar 13 09:39:47.330: INFO: Pod "pod-422719a7-c17b-464e-8e35-048fe1fec82c" satisfied condition "success or failure"
Mar 13 09:39:47.331: INFO: Trying to get logs from node 172.24.5.7 pod pod-422719a7-c17b-464e-8e35-048fe1fec82c container test-container: <nil>
STEP: delete the pod
Mar 13 09:39:47.347: INFO: Waiting for pod pod-422719a7-c17b-464e-8e35-048fe1fec82c to disappear
Mar 13 09:39:47.348: INFO: Pod pod-422719a7-c17b-464e-8e35-048fe1fec82c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:47.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-497" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":55,"skipped":954,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:47.352: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:39:47.368: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar 13 09:39:49.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-4314 create -f -'
Mar 13 09:39:49.460: INFO: stderr: ""
Mar 13 09:39:49.460: INFO: stdout: "e2e-test-crd-publish-openapi-9552-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar 13 09:39:49.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-4314 delete e2e-test-crd-publish-openapi-9552-crds test-cr'
Mar 13 09:39:49.547: INFO: stderr: ""
Mar 13 09:39:49.548: INFO: stdout: "e2e-test-crd-publish-openapi-9552-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Mar 13 09:39:49.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-4314 apply -f -'
Mar 13 09:39:49.701: INFO: stderr: ""
Mar 13 09:39:49.701: INFO: stdout: "e2e-test-crd-publish-openapi-9552-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar 13 09:39:49.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-4314 delete e2e-test-crd-publish-openapi-9552-crds test-cr'
Mar 13 09:39:49.783: INFO: stderr: ""
Mar 13 09:39:49.783: INFO: stdout: "e2e-test-crd-publish-openapi-9552-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Mar 13 09:39:49.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-9552-crds'
Mar 13 09:39:49.914: INFO: stderr: ""
Mar 13 09:39:49.914: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9552-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:51.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4314" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":280,"completed":56,"skipped":955,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:51.753: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:178
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:51.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2617" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":280,"completed":57,"skipped":968,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:51.781: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:39:51.799: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586" in namespace "downward-api-7806" to be "success or failure"
Mar 13 09:39:51.800: INFO: Pod "downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586": Phase="Pending", Reason="", readiness=false. Elapsed: 1.388185ms
Mar 13 09:39:53.803: INFO: Pod "downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003677085s
STEP: Saw pod success
Mar 13 09:39:53.803: INFO: Pod "downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586" satisfied condition "success or failure"
Mar 13 09:39:53.804: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586 container client-container: <nil>
STEP: delete the pod
Mar 13 09:39:53.813: INFO: Waiting for pod downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586 to disappear
Mar 13 09:39:53.815: INFO: Pod downwardapi-volume-b661bdd6-9046-41aa-8836-222fb2acc586 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:53.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7806" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":58,"skipped":991,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:53.820: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: executing a command with run --rm and attach with stdin
Mar 13 09:39:53.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=kubectl-1944 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 13 09:39:55.235: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 13 09:39:55.235: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:57.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1944" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run --rm job should create a job from an image, then delete the job  [Conformance]","total":280,"completed":59,"skipped":1021,"failed":0}
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:57.243: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override all
Mar 13 09:39:57.263: INFO: Waiting up to 5m0s for pod "client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a" in namespace "containers-573" to be "success or failure"
Mar 13 09:39:57.265: INFO: Pod "client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.357637ms
Mar 13 09:39:59.267: INFO: Pod "client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00380317s
STEP: Saw pod success
Mar 13 09:39:59.267: INFO: Pod "client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a" satisfied condition "success or failure"
Mar 13 09:39:59.269: INFO: Trying to get logs from node 172.24.5.7 pod client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a container test-container: <nil>
STEP: delete the pod
Mar 13 09:39:59.277: INFO: Waiting for pod client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a to disappear
Mar 13 09:39:59.279: INFO: Pod client-containers-8da70f0d-1a8d-41e9-8f69-66bb9f97248a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:39:59.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-573" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":280,"completed":60,"skipped":1027,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:39:59.284: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-d10fdd49-2ca8-4e81-8e59-1fcf5339ca82
STEP: Creating a pod to test consume configMaps
Mar 13 09:39:59.306: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d" in namespace "projected-1658" to be "success or failure"
Mar 13 09:39:59.308: INFO: Pod "pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.368887ms
Mar 13 09:40:01.310: INFO: Pod "pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003237788s
STEP: Saw pod success
Mar 13 09:40:01.310: INFO: Pod "pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d" satisfied condition "success or failure"
Mar 13 09:40:01.311: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:40:01.319: INFO: Waiting for pod pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d to disappear
Mar 13 09:40:01.321: INFO: Pod pod-projected-configmaps-64164915-dcca-42c8-bc08-333c32491b9d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:40:01.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1658" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":280,"completed":61,"skipped":1046,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:40:01.325: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 13 09:40:03.353: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:40:03.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-929" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":62,"skipped":1048,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:40:03.362: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test hostPath mode
Mar 13 09:40:03.381: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7988" to be "success or failure"
Mar 13 09:40:03.383: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.501661ms
Mar 13 09:40:05.385: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0035301s
STEP: Saw pod success
Mar 13 09:40:05.385: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 13 09:40:05.387: INFO: Trying to get logs from node 172.24.5.7 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 13 09:40:05.395: INFO: Waiting for pod pod-host-path-test to disappear
Mar 13 09:40:05.396: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:40:05.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7988" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":63,"skipped":1082,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:40:05.400: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 13 09:40:07.935: INFO: Successfully updated pod "labelsupdate76bbb1fe-f90c-4b95-b9e3-a890acfebee5"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:40:11.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4095" for this suite.

• [SLOW TEST:6.558 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":64,"skipped":1095,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:40:11.959: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:41:11.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3377" for this suite.

• [SLOW TEST:60.026 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":280,"completed":65,"skipped":1125,"failed":0}
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:41:11.985: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:41:29.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2178" for this suite.

• [SLOW TEST:17.041 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":280,"completed":66,"skipped":1125,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:41:29.026: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl replace
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1897
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 09:41:29.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-9822'
Mar 13 09:41:29.144: INFO: stderr: ""
Mar 13 09:41:29.144: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Mar 13 09:41:34.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pod e2e-test-httpd-pod --namespace=kubectl-9822 -o json'
Mar 13 09:41:34.287: INFO: stderr: ""
Mar 13 09:41:34.287: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.42.1.43/32\"\n        },\n        \"creationTimestamp\": \"2020-03-13T09:41:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9822\",\n        \"resourceVersion\": \"47444\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9822/pods/e2e-test-httpd-pod\",\n        \"uid\": \"900000c4-912e-42af-b4af-295e32f382ab\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4jv6s\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"172.24.5.5\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4jv6s\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4jv6s\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-13T09:41:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-13T09:41:30Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-13T09:41:30Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-13T09:41:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://54cdd22bdd39cafb25e14e99c65c58a0babd7f66f820665bed6ae090a4c86c02\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-13T09:41:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.24.5.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.1.43\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.42.1.43\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-13T09:41:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 13 09:41:34.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 replace -f - --namespace=kubectl-9822'
Mar 13 09:41:34.494: INFO: stderr: ""
Mar 13 09:41:34.494: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1902
Mar 13 09:41:34.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete pods e2e-test-httpd-pod --namespace=kubectl-9822'
Mar 13 09:41:41.986: INFO: stderr: ""
Mar 13 09:41:41.986: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:41:41.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9822" for this suite.

• [SLOW TEST:12.964 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1893
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":280,"completed":67,"skipped":1131,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:41:41.991: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0313 09:42:12.525059      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 13 09:42:12.525: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:12.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8869" for this suite.

• [SLOW TEST:30.538 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":280,"completed":68,"skipped":1142,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:12.530: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service nodeport-test with type=NodePort in namespace services-6160
STEP: creating replication controller nodeport-test in namespace services-6160
I0313 09:42:12.552954      26 runners.go:189] Created replication controller with name: nodeport-test, namespace: services-6160, replica count: 2
I0313 09:42:15.603490      26 runners.go:189] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 13 09:42:15.603: INFO: Creating new exec pod
Mar 13 09:42:18.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-6160 execpodj2zvx -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Mar 13 09:42:18.816: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Mar 13 09:42:18.816: INFO: stdout: ""
Mar 13 09:42:18.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-6160 execpodj2zvx -- /bin/sh -x -c nc -zv -t -w 2 10.43.162.214 80'
Mar 13 09:42:18.992: INFO: stderr: "+ nc -zv -t -w 2 10.43.162.214 80\nConnection to 10.43.162.214 80 port [tcp/http] succeeded!\n"
Mar 13 09:42:18.992: INFO: stdout: ""
Mar 13 09:42:18.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-6160 execpodj2zvx -- /bin/sh -x -c nc -zv -t -w 2 172.24.5.5 31374'
Mar 13 09:42:19.191: INFO: stderr: "+ nc -zv -t -w 2 172.24.5.5 31374\nConnection to 172.24.5.5 31374 port [tcp/31374] succeeded!\n"
Mar 13 09:42:19.191: INFO: stdout: ""
Mar 13 09:42:19.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-6160 execpodj2zvx -- /bin/sh -x -c nc -zv -t -w 2 172.24.5.7 31374'
Mar 13 09:42:19.382: INFO: stderr: "+ nc -zv -t -w 2 172.24.5.7 31374\nConnection to 172.24.5.7 31374 port [tcp/31374] succeeded!\n"
Mar 13 09:42:19.382: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:19.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6160" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:6.858 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":280,"completed":69,"skipped":1160,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:19.388: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:42:20.046: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:42:23.056: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:23.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3014" for this suite.
STEP: Destroying namespace "webhook-3014-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":280,"completed":70,"skipped":1172,"failed":0}
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:23.123: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's args
Mar 13 09:42:23.142: INFO: Waiting up to 5m0s for pod "var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab" in namespace "var-expansion-2135" to be "success or failure"
Mar 13 09:42:23.144: INFO: Pod "var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab": Phase="Pending", Reason="", readiness=false. Elapsed: 1.495008ms
Mar 13 09:42:25.146: INFO: Pod "var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004071971s
STEP: Saw pod success
Mar 13 09:42:25.146: INFO: Pod "var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab" satisfied condition "success or failure"
Mar 13 09:42:25.148: INFO: Trying to get logs from node 172.24.5.7 pod var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab container dapi-container: <nil>
STEP: delete the pod
Mar 13 09:42:25.163: INFO: Waiting for pod var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab to disappear
Mar 13 09:42:25.164: INFO: Pod var-expansion-27a3695f-83c5-43fd-88cc-2378772053ab no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:25.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2135" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":280,"completed":71,"skipped":1178,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:25.171: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9659
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9659
STEP: creating replication controller externalsvc in namespace services-9659
I0313 09:42:25.197653      26 runners.go:189] Created replication controller with name: externalsvc, namespace: services-9659, replica count: 2
I0313 09:42:28.248154      26 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Mar 13 09:42:28.255: INFO: Creating new exec pod
Mar 13 09:42:30.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-9659 execpodtjc2r -- /bin/sh -x -c nslookup clusterip-service'
Mar 13 09:42:30.529: INFO: stderr: "+ nslookup clusterip-service\n"
Mar 13 09:42:30.529: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nclusterip-service.services-9659.svc.cluster.local\tcanonical name = externalsvc.services-9659.svc.cluster.local.\nName:\texternalsvc.services-9659.svc.cluster.local\nAddress: 10.43.160.191\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9659, will wait for the garbage collector to delete the pods
Mar 13 09:42:30.584: INFO: Deleting ReplicationController externalsvc took: 2.704331ms
Mar 13 09:42:30.684: INFO: Terminating ReplicationController externalsvc pods took: 100.207793ms
Mar 13 09:42:41.990: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:41.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9659" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:16.828 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":280,"completed":72,"skipped":1235,"failed":0}
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:41.998: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-ef627526-4090-47ba-b285-7e8ddb09ceae
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ef627526-4090-47ba-b285-7e8ddb09ceae
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:46.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5417" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":73,"skipped":1235,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:46.066: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-3de1d467-56bc-4d9c-9c46-57ff5be0f09e
STEP: Creating a pod to test consume secrets
Mar 13 09:42:46.086: INFO: Waiting up to 5m0s for pod "pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c" in namespace "secrets-3608" to be "success or failure"
Mar 13 09:42:46.088: INFO: Pod "pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.370587ms
Mar 13 09:42:48.090: INFO: Pod "pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003589183s
STEP: Saw pod success
Mar 13 09:42:48.090: INFO: Pod "pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c" satisfied condition "success or failure"
Mar 13 09:42:48.092: INFO: Trying to get logs from node 172.24.5.7 pod pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:42:48.100: INFO: Waiting for pod pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c to disappear
Mar 13 09:42:48.102: INFO: Pod pod-secrets-86ecba68-b23e-4225-90a3-5681b0c6358c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:48.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3608" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":74,"skipped":1262,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:48.106: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 13 09:42:48.123: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:52.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4874" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":280,"completed":75,"skipped":1271,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:52.879: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:42:52.900: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9d50203e-9c8f-414f-bd3b-556b1dd8be08" in namespace "security-context-test-1157" to be "success or failure"
Mar 13 09:42:52.902: INFO: Pod "busybox-privileged-false-9d50203e-9c8f-414f-bd3b-556b1dd8be08": Phase="Pending", Reason="", readiness=false. Elapsed: 1.527179ms
Mar 13 09:42:54.904: INFO: Pod "busybox-privileged-false-9d50203e-9c8f-414f-bd3b-556b1dd8be08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003945485s
Mar 13 09:42:54.904: INFO: Pod "busybox-privileged-false-9d50203e-9c8f-414f-bd3b-556b1dd8be08" satisfied condition "success or failure"
Mar 13 09:42:54.909: INFO: Got logs for pod "busybox-privileged-false-9d50203e-9c8f-414f-bd3b-556b1dd8be08": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:54.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1157" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":76,"skipped":1314,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:54.914: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-abf13741-2a8e-4d07-92d4-467c9f4ea672
STEP: Creating a pod to test consume secrets
Mar 13 09:42:54.936: INFO: Waiting up to 5m0s for pod "pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0" in namespace "secrets-8492" to be "success or failure"
Mar 13 09:42:54.938: INFO: Pod "pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.505074ms
Mar 13 09:42:56.940: INFO: Pod "pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003711519s
STEP: Saw pod success
Mar 13 09:42:56.940: INFO: Pod "pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0" satisfied condition "success or failure"
Mar 13 09:42:56.942: INFO: Trying to get logs from node 172.24.5.7 pod pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0 container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:42:56.950: INFO: Waiting for pod pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0 to disappear
Mar 13 09:42:56.952: INFO: Pod pod-secrets-6537e2c6-b2fc-495c-bc7a-af0a926c7ce0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:42:56.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8492" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":77,"skipped":1327,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:42:56.957: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:42:57.275: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:43:00.284: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:43:00.286: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:01.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9822" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":280,"completed":78,"skipped":1340,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:01.452: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 13 09:43:05.486: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 13 09:43:05.488: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 13 09:43:07.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 13 09:43:07.491: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 13 09:43:09.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 13 09:43:09.491: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 13 09:43:11.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 13 09:43:11.491: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 13 09:43:13.489: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 13 09:43:13.491: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:13.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6335" for this suite.

• [SLOW TEST:12.049 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":280,"completed":79,"skipped":1403,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:13.501: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override command
Mar 13 09:43:13.520: INFO: Waiting up to 5m0s for pod "client-containers-14f21599-05db-418d-bf7f-1883733201c0" in namespace "containers-3807" to be "success or failure"
Mar 13 09:43:13.522: INFO: Pod "client-containers-14f21599-05db-418d-bf7f-1883733201c0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.333958ms
Mar 13 09:43:15.524: INFO: Pod "client-containers-14f21599-05db-418d-bf7f-1883733201c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003568106s
STEP: Saw pod success
Mar 13 09:43:15.524: INFO: Pod "client-containers-14f21599-05db-418d-bf7f-1883733201c0" satisfied condition "success or failure"
Mar 13 09:43:15.526: INFO: Trying to get logs from node 172.24.5.5 pod client-containers-14f21599-05db-418d-bf7f-1883733201c0 container test-container: <nil>
STEP: delete the pod
Mar 13 09:43:15.536: INFO: Waiting for pod client-containers-14f21599-05db-418d-bf7f-1883733201c0 to disappear
Mar 13 09:43:15.537: INFO: Pod client-containers-14f21599-05db-418d-bf7f-1883733201c0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:15.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3807" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":280,"completed":80,"skipped":1426,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:15.542: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7715.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7715.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7715.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7715.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7715.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7715.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7715.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 09:43:17.573: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.575: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.576: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.578: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.584: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.586: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.588: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.589: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7715.svc.cluster.local from pod dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa: the server could not find the requested resource (get pods dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa)
Mar 13 09:43:17.593: INFO: Lookups using dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7715.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7715.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7715.svc.cluster.local jessie_udp@dns-test-service-2.dns-7715.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7715.svc.cluster.local]

Mar 13 09:43:22.616: INFO: DNS probes using dns-7715/dns-test-bb98b780-fc2d-4b04-a939-cefffc90b4fa succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:22.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7715" for this suite.

• [SLOW TEST:7.088 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":280,"completed":81,"skipped":1450,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:22.630: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 13 09:43:25.168: INFO: Successfully updated pod "annotationupdate21409829-b0cf-4818-afe8-af9b85494ae2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:29.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7636" for this suite.

• [SLOW TEST:6.558 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":82,"skipped":1456,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:29.188: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Mar 13 09:43:29.206: INFO: namespace kubectl-81
Mar 13 09:43:29.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-81'
Mar 13 09:43:29.420: INFO: stderr: ""
Mar 13 09:43:29.420: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Mar 13 09:43:30.423: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:43:30.423: INFO: Found 0 / 1
Mar 13 09:43:31.422: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:43:31.422: INFO: Found 1 / 1
Mar 13 09:43:31.422: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 13 09:43:31.424: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 09:43:31.424: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 13 09:43:31.424: INFO: wait on agnhost-master startup in kubectl-81 
Mar 13 09:43:31.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs agnhost-master-24vst agnhost-master --namespace=kubectl-81'
Mar 13 09:43:31.517: INFO: stderr: ""
Mar 13 09:43:31.517: INFO: stdout: "Paused\n"
STEP: exposing RC
Mar 13 09:43:31.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-81'
Mar 13 09:43:31.616: INFO: stderr: ""
Mar 13 09:43:31.616: INFO: stdout: "service/rm2 exposed\n"
Mar 13 09:43:31.617: INFO: Service rm2 in namespace kubectl-81 found.
STEP: exposing service
Mar 13 09:43:33.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-81'
Mar 13 09:43:33.714: INFO: stderr: ""
Mar 13 09:43:33.714: INFO: stdout: "service/rm3 exposed\n"
Mar 13 09:43:33.715: INFO: Service rm3 in namespace kubectl-81 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:35.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-81" for this suite.

• [SLOW TEST:6.536 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1295
    should create services for rc  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":280,"completed":83,"skipped":1459,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:35.725: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-f690b68f-ef51-45a1-9d16-b617e9b3be5f
STEP: Creating a pod to test consume secrets
Mar 13 09:43:35.762: INFO: Waiting up to 5m0s for pod "pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab" in namespace "secrets-6798" to be "success or failure"
Mar 13 09:43:35.764: INFO: Pod "pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.136022ms
Mar 13 09:43:37.767: INFO: Pod "pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004568884s
STEP: Saw pod success
Mar 13 09:43:37.767: INFO: Pod "pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab" satisfied condition "success or failure"
Mar 13 09:43:37.768: INFO: Trying to get logs from node 172.24.5.7 pod pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:43:37.778: INFO: Waiting for pod pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab to disappear
Mar 13 09:43:37.779: INFO: Pod pod-secrets-4db77423-e36c-4c15-86d5-a87f5ba0c8ab no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:37.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6798" for this suite.
STEP: Destroying namespace "secret-namespace-451" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":280,"completed":84,"skipped":1488,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:37.785: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service multi-endpoint-test in namespace services-2313
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2313 to expose endpoints map[]
Mar 13 09:43:37.806: INFO: successfully validated that service multi-endpoint-test in namespace services-2313 exposes endpoints map[] (1.450837ms elapsed)
STEP: Creating pod pod1 in namespace services-2313
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2313 to expose endpoints map[pod1:[100]]
Mar 13 09:43:39.818: INFO: successfully validated that service multi-endpoint-test in namespace services-2313 exposes endpoints map[pod1:[100]] (2.008913017s elapsed)
STEP: Creating pod pod2 in namespace services-2313
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2313 to expose endpoints map[pod1:[100] pod2:[101]]
Mar 13 09:43:41.835: INFO: successfully validated that service multi-endpoint-test in namespace services-2313 exposes endpoints map[pod1:[100] pod2:[101]] (2.014287784s elapsed)
STEP: Deleting pod pod1 in namespace services-2313
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2313 to expose endpoints map[pod2:[101]]
Mar 13 09:43:42.844: INFO: successfully validated that service multi-endpoint-test in namespace services-2313 exposes endpoints map[pod2:[101]] (1.005880591s elapsed)
STEP: Deleting pod pod2 in namespace services-2313
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2313 to expose endpoints map[]
Mar 13 09:43:43.849: INFO: successfully validated that service multi-endpoint-test in namespace services-2313 exposes endpoints map[] (1.003452834s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:43.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2313" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:6.074 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":280,"completed":85,"skipped":1492,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:43.860: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 13 09:43:43.881: INFO: Waiting up to 5m0s for pod "downward-api-f08ab731-5a79-45df-b72c-cb280940008c" in namespace "downward-api-3977" to be "success or failure"
Mar 13 09:43:43.883: INFO: Pod "downward-api-f08ab731-5a79-45df-b72c-cb280940008c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.464455ms
Mar 13 09:43:45.885: INFO: Pod "downward-api-f08ab731-5a79-45df-b72c-cb280940008c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003731982s
STEP: Saw pod success
Mar 13 09:43:45.885: INFO: Pod "downward-api-f08ab731-5a79-45df-b72c-cb280940008c" satisfied condition "success or failure"
Mar 13 09:43:45.886: INFO: Trying to get logs from node 172.24.5.7 pod downward-api-f08ab731-5a79-45df-b72c-cb280940008c container dapi-container: <nil>
STEP: delete the pod
Mar 13 09:43:45.895: INFO: Waiting for pod downward-api-f08ab731-5a79-45df-b72c-cb280940008c to disappear
Mar 13 09:43:45.896: INFO: Pod downward-api-f08ab731-5a79-45df-b72c-cb280940008c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:43:45.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3977" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":280,"completed":86,"skipped":1514,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:43:45.900: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Mar 13 09:43:45.917: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:43:48.776: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:44:00.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-388" for this suite.

• [SLOW TEST:14.126 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":280,"completed":87,"skipped":1520,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:44:00.027: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:44:00.044: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:44:00.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5503" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":280,"completed":88,"skipped":1528,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:44:00.569: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-cf9fbaaa-2e52-4129-92de-b14e8a34366c
STEP: Creating a pod to test consume configMaps
Mar 13 09:44:00.589: INFO: Waiting up to 5m0s for pod "pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f" in namespace "configmap-9695" to be "success or failure"
Mar 13 09:44:00.591: INFO: Pod "pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.507148ms
Mar 13 09:44:02.593: INFO: Pod "pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004078867s
STEP: Saw pod success
Mar 13 09:44:02.593: INFO: Pod "pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f" satisfied condition "success or failure"
Mar 13 09:44:02.595: INFO: Trying to get logs from node 172.24.5.7 pod pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:44:02.604: INFO: Waiting for pod pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f to disappear
Mar 13 09:44:02.605: INFO: Pod pod-configmaps-854fd35b-7519-496b-8213-43cb223ad92f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:44:02.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9695" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":89,"skipped":1536,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:44:02.610: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:44:13.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6247" for this suite.

• [SLOW TEST:11.039 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":280,"completed":90,"skipped":1543,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:44:13.649: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1733
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 09:44:13.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-7702'
Mar 13 09:44:13.755: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 13 09:44:13.755: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1738
Mar 13 09:44:15.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7702'
Mar 13 09:44:15.841: INFO: stderr: ""
Mar 13 09:44:15.841: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:44:15.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7702" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run deployment should create a deployment from an image  [Conformance]","total":280,"completed":91,"skipped":1552,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:44:15.846: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 13 09:44:15.861: INFO: PodSpec: initContainers in spec.initContainers
Mar 13 09:44:55.988: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-26dd08a8-7c77-4cd9-ad93-50f390012fc0", GenerateName:"", Namespace:"init-container-4254", SelfLink:"/api/v1/namespaces/init-container-4254/pods/pod-init-26dd08a8-7c77-4cd9-ad93-50f390012fc0", UID:"1f59051a-642a-40f4-b66d-56d0139909f4", ResourceVersion:"49009", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63719689455, loc:(*time.Location)(0x7db4bc0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"861284215"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.42.0.231/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-msj6t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc006988b40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-msj6t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-msj6t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-msj6t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0057dcb98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"172.24.5.7", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003d72c60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0057dcc20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0057dcc40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0057dcc48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0057dcc4c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689455, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689455, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689455, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689455, loc:(*time.Location)(0x7db4bc0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.24.5.7", PodIP:"10.42.0.231", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.42.0.231"}}, StartTime:(*v1.Time)(0xc0030e8500), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002f32af0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002f32b60)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://7ea55dbebde94be67f26beb82b83cdfefd5b8b922f2bc1a346b19eaa2c32e8ff", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030e8540), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030e8520), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0057dccff)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:44:55.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4254" for this suite.

• [SLOW TEST:40.148 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":280,"completed":92,"skipped":1557,"failed":0}
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:44:55.993: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:44:56.010: INFO: Creating ReplicaSet my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36
Mar 13 09:44:56.013: INFO: Pod name my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36: Found 0 pods out of 1
Mar 13 09:45:01.015: INFO: Pod name my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36: Found 1 pods out of 1
Mar 13 09:45:01.015: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36" is running
Mar 13 09:45:01.017: INFO: Pod "my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36-7zftw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:44:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:44:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:44:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:44:56 +0000 UTC Reason: Message:}])
Mar 13 09:45:01.017: INFO: Trying to dial the pod
Mar 13 09:45:06.023: INFO: Controller my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36: Got expected result from replica 1 [my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36-7zftw]: "my-hostname-basic-d63cea80-a40c-4901-994d-58b2d6437e36-7zftw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:45:06.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9496" for this suite.

• [SLOW TEST:10.035 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":93,"skipped":1557,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:45:06.029: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-cad86444-148e-4cb1-bd82-8cdad906ff78
STEP: Creating a pod to test consume secrets
Mar 13 09:45:06.052: INFO: Waiting up to 5m0s for pod "pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821" in namespace "secrets-751" to be "success or failure"
Mar 13 09:45:06.053: INFO: Pod "pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821": Phase="Pending", Reason="", readiness=false. Elapsed: 1.329707ms
Mar 13 09:45:08.055: INFO: Pod "pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003295868s
STEP: Saw pod success
Mar 13 09:45:08.055: INFO: Pod "pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821" satisfied condition "success or failure"
Mar 13 09:45:08.057: INFO: Trying to get logs from node 172.24.5.7 pod pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821 container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:45:08.066: INFO: Waiting for pod pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821 to disappear
Mar 13 09:45:08.067: INFO: Pod pod-secrets-6a0bd50c-f42b-449d-abdd-67ffba781821 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:45:08.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-751" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":94,"skipped":1603,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:45:08.072: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1232, will wait for the garbage collector to delete the pods
Mar 13 09:45:10.147: INFO: Deleting Job.batch foo took: 2.851242ms
Mar 13 09:45:10.547: INFO: Terminating Job.batch foo pods took: 400.214475ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:45:44.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1232" for this suite.

• [SLOW TEST:36.682 seconds]
[sig-apps] Job
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":280,"completed":95,"skipped":1630,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:45:44.754: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:45:44.771: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:45:45.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4459" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":280,"completed":96,"skipped":1650,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:45:45.788: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:01.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1004" for this suite.

• [SLOW TEST:16.062 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":280,"completed":97,"skipped":1668,"failed":0}
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:01.850: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Mar 13 09:46:11.879: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0313 09:46:11.879174      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 13 09:46:11.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2040" for this suite.

• [SLOW TEST:10.033 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":280,"completed":98,"skipped":1668,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:11.883: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-905d4ce9-9190-44b5-860f-2960e404493e
STEP: Creating a pod to test consume configMaps
Mar 13 09:46:11.904: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b" in namespace "configmap-3406" to be "success or failure"
Mar 13 09:46:11.906: INFO: Pod "pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.415905ms
Mar 13 09:46:13.908: INFO: Pod "pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003814381s
STEP: Saw pod success
Mar 13 09:46:13.908: INFO: Pod "pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b" satisfied condition "success or failure"
Mar 13 09:46:13.910: INFO: Trying to get logs from node 172.24.5.7 pod pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:46:13.919: INFO: Waiting for pod pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b to disappear
Mar 13 09:46:13.920: INFO: Pod pod-configmaps-0c7cf2b8-ac39-4ba9-95fc-53545438b60b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:13.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3406" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":99,"skipped":1688,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:13.925: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar 13 09:46:19.955: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0313 09:46:19.955076      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 13 09:46:19.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1726" for this suite.

• [SLOW TEST:6.034 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":280,"completed":100,"skipped":1698,"failed":0}
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:19.959: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:172
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating server pod server in namespace prestop-2031
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2031
STEP: Deleting pre-stop pod
Mar 13 09:46:30.995: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:30.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2031" for this suite.

• [SLOW TEST:11.044 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":280,"completed":101,"skipped":1702,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:31.004: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:46:31.410: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 13 09:46:33.416: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689591, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689591, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689591, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689591, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:46:36.422: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:36.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6600" for this suite.
STEP: Destroying namespace "webhook-6600-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.524 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":280,"completed":102,"skipped":1705,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:36.528: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override arguments
Mar 13 09:46:36.547: INFO: Waiting up to 5m0s for pod "client-containers-4d395536-1293-429f-908e-287b872ad540" in namespace "containers-6838" to be "success or failure"
Mar 13 09:46:36.548: INFO: Pod "client-containers-4d395536-1293-429f-908e-287b872ad540": Phase="Pending", Reason="", readiness=false. Elapsed: 1.388241ms
Mar 13 09:46:38.550: INFO: Pod "client-containers-4d395536-1293-429f-908e-287b872ad540": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003500139s
STEP: Saw pod success
Mar 13 09:46:38.550: INFO: Pod "client-containers-4d395536-1293-429f-908e-287b872ad540" satisfied condition "success or failure"
Mar 13 09:46:38.552: INFO: Trying to get logs from node 172.24.5.7 pod client-containers-4d395536-1293-429f-908e-287b872ad540 container test-container: <nil>
STEP: delete the pod
Mar 13 09:46:38.560: INFO: Waiting for pod client-containers-4d395536-1293-429f-908e-287b872ad540 to disappear
Mar 13 09:46:38.561: INFO: Pod client-containers-4d395536-1293-429f-908e-287b872ad540 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:38.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6838" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":280,"completed":103,"skipped":1717,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:38.566: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating pod
Mar 13 09:46:40.591: INFO: Pod pod-hostip-34f6f79a-993a-4b4e-9035-dd0b1f35bc3b has hostIP: 172.24.5.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:40.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9069" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":280,"completed":104,"skipped":1724,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:40.596: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:46:40.613: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4705
I0313 09:46:40.625776      26 runners.go:189] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4705, replica count: 1
I0313 09:46:41.676201      26 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0313 09:46:42.676420      26 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 13 09:46:42.780: INFO: Created: latency-svc-5wx84
Mar 13 09:46:42.783: INFO: Got endpoints: latency-svc-5wx84 [7.13458ms]
Mar 13 09:46:42.787: INFO: Created: latency-svc-8jwvf
Mar 13 09:46:42.788: INFO: Created: latency-svc-jjwl4
Mar 13 09:46:42.788: INFO: Got endpoints: latency-svc-8jwvf [4.851955ms]
Mar 13 09:46:42.789: INFO: Created: latency-svc-bhqkh
Mar 13 09:46:42.789: INFO: Got endpoints: latency-svc-jjwl4 [5.848553ms]
Mar 13 09:46:42.790: INFO: Created: latency-svc-xdrg9
Mar 13 09:46:42.791: INFO: Got endpoints: latency-svc-bhqkh [7.241771ms]
Mar 13 09:46:42.792: INFO: Created: latency-svc-5gz8c
Mar 13 09:46:42.792: INFO: Got endpoints: latency-svc-xdrg9 [8.382486ms]
Mar 13 09:46:42.793: INFO: Created: latency-svc-4hfns
Mar 13 09:46:42.793: INFO: Got endpoints: latency-svc-5gz8c [9.477342ms]
Mar 13 09:46:42.794: INFO: Created: latency-svc-42f8d
Mar 13 09:46:42.794: INFO: Got endpoints: latency-svc-4hfns [10.729828ms]
Mar 13 09:46:42.796: INFO: Created: latency-svc-9jwsc
Mar 13 09:46:42.796: INFO: Got endpoints: latency-svc-42f8d [12.178387ms]
Mar 13 09:46:42.797: INFO: Created: latency-svc-kp7fx
Mar 13 09:46:42.797: INFO: Got endpoints: latency-svc-9jwsc [13.508567ms]
Mar 13 09:46:42.798: INFO: Created: latency-svc-7wrsc
Mar 13 09:46:42.798: INFO: Got endpoints: latency-svc-kp7fx [14.815461ms]
Mar 13 09:46:42.799: INFO: Got endpoints: latency-svc-7wrsc [15.774698ms]
Mar 13 09:46:42.800: INFO: Created: latency-svc-sbs94
Mar 13 09:46:42.801: INFO: Created: latency-svc-qkxfm
Mar 13 09:46:42.801: INFO: Got endpoints: latency-svc-sbs94 [17.229579ms]
Mar 13 09:46:42.802: INFO: Created: latency-svc-4hth6
Mar 13 09:46:42.802: INFO: Got endpoints: latency-svc-qkxfm [18.649279ms]
Mar 13 09:46:42.803: INFO: Created: latency-svc-jgp4n
Mar 13 09:46:42.804: INFO: Got endpoints: latency-svc-4hth6 [19.908513ms]
Mar 13 09:46:42.804: INFO: Got endpoints: latency-svc-jgp4n [21.073519ms]
Mar 13 09:46:42.805: INFO: Created: latency-svc-sbr7v
Mar 13 09:46:42.806: INFO: Created: latency-svc-nmlsk
Mar 13 09:46:42.806: INFO: Got endpoints: latency-svc-sbr7v [22.312136ms]
Mar 13 09:46:42.807: INFO: Got endpoints: latency-svc-nmlsk [18.912081ms]
Mar 13 09:46:42.807: INFO: Created: latency-svc-p9p2w
Mar 13 09:46:42.809: INFO: Created: latency-svc-dwv5z
Mar 13 09:46:42.809: INFO: Got endpoints: latency-svc-p9p2w [19.496375ms]
Mar 13 09:46:42.810: INFO: Created: latency-svc-fmzll
Mar 13 09:46:42.810: INFO: Got endpoints: latency-svc-dwv5z [19.30326ms]
Mar 13 09:46:42.811: INFO: Got endpoints: latency-svc-fmzll [18.984572ms]
Mar 13 09:46:42.811: INFO: Created: latency-svc-zktgf
Mar 13 09:46:42.813: INFO: Created: latency-svc-l45h4
Mar 13 09:46:42.813: INFO: Got endpoints: latency-svc-zktgf [19.527922ms]
Mar 13 09:46:42.814: INFO: Got endpoints: latency-svc-l45h4 [19.498885ms]
Mar 13 09:46:42.814: INFO: Created: latency-svc-5sv2w
Mar 13 09:46:42.815: INFO: Got endpoints: latency-svc-5sv2w [19.37653ms]
Mar 13 09:46:42.815: INFO: Created: latency-svc-bx9pf
Mar 13 09:46:42.817: INFO: Got endpoints: latency-svc-bx9pf [19.510017ms]
Mar 13 09:46:42.817: INFO: Created: latency-svc-rk57d
Mar 13 09:46:42.818: INFO: Got endpoints: latency-svc-rk57d [19.357794ms]
Mar 13 09:46:42.818: INFO: Created: latency-svc-jj97f
Mar 13 09:46:42.819: INFO: Got endpoints: latency-svc-jj97f [19.956183ms]
Mar 13 09:46:42.819: INFO: Created: latency-svc-6sbck
Mar 13 09:46:42.821: INFO: Got endpoints: latency-svc-6sbck [19.904296ms]
Mar 13 09:46:42.821: INFO: Created: latency-svc-j4zbh
Mar 13 09:46:42.822: INFO: Created: latency-svc-gvc5x
Mar 13 09:46:42.822: INFO: Got endpoints: latency-svc-j4zbh [20.071571ms]
Mar 13 09:46:42.824: INFO: Got endpoints: latency-svc-gvc5x [20.182387ms]
Mar 13 09:46:42.824: INFO: Created: latency-svc-pq4zk
Mar 13 09:46:42.825: INFO: Created: latency-svc-7hhhg
Mar 13 09:46:42.825: INFO: Got endpoints: latency-svc-pq4zk [20.75583ms]
Mar 13 09:46:42.826: INFO: Created: latency-svc-db8lx
Mar 13 09:46:42.828: INFO: Created: latency-svc-z7bfb
Mar 13 09:46:42.829: INFO: Created: latency-svc-mp9ns
Mar 13 09:46:42.830: INFO: Created: latency-svc-pwz56
Mar 13 09:46:42.831: INFO: Created: latency-svc-rj6sr
Mar 13 09:46:42.832: INFO: Got endpoints: latency-svc-7hhhg [25.801301ms]
Mar 13 09:46:42.832: INFO: Created: latency-svc-j46pl
Mar 13 09:46:42.834: INFO: Created: latency-svc-cxlxv
Mar 13 09:46:42.835: INFO: Created: latency-svc-pbp6g
Mar 13 09:46:42.836: INFO: Created: latency-svc-x822g
Mar 13 09:46:42.837: INFO: Created: latency-svc-7gcbd
Mar 13 09:46:42.838: INFO: Created: latency-svc-m7bwz
Mar 13 09:46:42.840: INFO: Created: latency-svc-b628n
Mar 13 09:46:42.841: INFO: Created: latency-svc-tgsb6
Mar 13 09:46:42.842: INFO: Created: latency-svc-f7lvd
Mar 13 09:46:42.844: INFO: Created: latency-svc-x2kbw
Mar 13 09:46:42.882: INFO: Got endpoints: latency-svc-db8lx [75.09051ms]
Mar 13 09:46:42.885: INFO: Created: latency-svc-b4c4x
Mar 13 09:46:42.932: INFO: Got endpoints: latency-svc-z7bfb [123.299573ms]
Mar 13 09:46:42.935: INFO: Created: latency-svc-gv6d7
Mar 13 09:46:42.982: INFO: Got endpoints: latency-svc-mp9ns [172.211008ms]
Mar 13 09:46:42.985: INFO: Created: latency-svc-2wn9b
Mar 13 09:46:43.032: INFO: Got endpoints: latency-svc-pwz56 [221.3511ms]
Mar 13 09:46:43.036: INFO: Created: latency-svc-zcwk8
Mar 13 09:46:43.082: INFO: Got endpoints: latency-svc-rj6sr [269.547472ms]
Mar 13 09:46:43.086: INFO: Created: latency-svc-vqj78
Mar 13 09:46:43.132: INFO: Got endpoints: latency-svc-j46pl [318.559075ms]
Mar 13 09:46:43.136: INFO: Created: latency-svc-dqqjk
Mar 13 09:46:43.182: INFO: Got endpoints: latency-svc-cxlxv [367.003579ms]
Mar 13 09:46:43.186: INFO: Created: latency-svc-w26gk
Mar 13 09:46:43.232: INFO: Got endpoints: latency-svc-pbp6g [415.422821ms]
Mar 13 09:46:43.235: INFO: Created: latency-svc-565sv
Mar 13 09:46:43.282: INFO: Got endpoints: latency-svc-x822g [464.497191ms]
Mar 13 09:46:43.286: INFO: Created: latency-svc-jhxtd
Mar 13 09:46:43.332: INFO: Got endpoints: latency-svc-7gcbd [512.807787ms]
Mar 13 09:46:43.336: INFO: Created: latency-svc-hkq2t
Mar 13 09:46:43.382: INFO: Got endpoints: latency-svc-m7bwz [561.301325ms]
Mar 13 09:46:43.386: INFO: Created: latency-svc-629hf
Mar 13 09:46:43.432: INFO: Got endpoints: latency-svc-b628n [609.723483ms]
Mar 13 09:46:43.436: INFO: Created: latency-svc-l4x9j
Mar 13 09:46:43.482: INFO: Got endpoints: latency-svc-tgsb6 [658.561171ms]
Mar 13 09:46:43.486: INFO: Created: latency-svc-dm624
Mar 13 09:46:43.532: INFO: Got endpoints: latency-svc-f7lvd [706.999502ms]
Mar 13 09:46:43.536: INFO: Created: latency-svc-bvdzb
Mar 13 09:46:43.582: INFO: Got endpoints: latency-svc-x2kbw [750.134458ms]
Mar 13 09:46:43.585: INFO: Created: latency-svc-l9njv
Mar 13 09:46:43.632: INFO: Got endpoints: latency-svc-b4c4x [749.862144ms]
Mar 13 09:46:43.635: INFO: Created: latency-svc-vjn5f
Mar 13 09:46:43.683: INFO: Got endpoints: latency-svc-gv6d7 [750.35992ms]
Mar 13 09:46:43.686: INFO: Created: latency-svc-kgdcl
Mar 13 09:46:43.732: INFO: Got endpoints: latency-svc-2wn9b [750.085822ms]
Mar 13 09:46:43.736: INFO: Created: latency-svc-mq6mk
Mar 13 09:46:43.782: INFO: Got endpoints: latency-svc-zcwk8 [749.866078ms]
Mar 13 09:46:43.785: INFO: Created: latency-svc-vkhns
Mar 13 09:46:43.832: INFO: Got endpoints: latency-svc-vqj78 [750.052266ms]
Mar 13 09:46:43.836: INFO: Created: latency-svc-6zb5v
Mar 13 09:46:43.882: INFO: Got endpoints: latency-svc-dqqjk [749.774337ms]
Mar 13 09:46:43.885: INFO: Created: latency-svc-zg47d
Mar 13 09:46:43.932: INFO: Got endpoints: latency-svc-w26gk [749.843367ms]
Mar 13 09:46:43.936: INFO: Created: latency-svc-tjrcv
Mar 13 09:46:43.982: INFO: Got endpoints: latency-svc-565sv [750.033543ms]
Mar 13 09:46:43.986: INFO: Created: latency-svc-whd7q
Mar 13 09:46:44.032: INFO: Got endpoints: latency-svc-jhxtd [750.095923ms]
Mar 13 09:46:44.036: INFO: Created: latency-svc-cp79n
Mar 13 09:46:44.083: INFO: Got endpoints: latency-svc-hkq2t [750.341987ms]
Mar 13 09:46:44.086: INFO: Created: latency-svc-5rdh7
Mar 13 09:46:44.132: INFO: Got endpoints: latency-svc-629hf [750.077496ms]
Mar 13 09:46:44.135: INFO: Created: latency-svc-2hr55
Mar 13 09:46:44.182: INFO: Got endpoints: latency-svc-l4x9j [749.838626ms]
Mar 13 09:46:44.186: INFO: Created: latency-svc-j7m94
Mar 13 09:46:44.232: INFO: Got endpoints: latency-svc-dm624 [749.883812ms]
Mar 13 09:46:44.236: INFO: Created: latency-svc-hvw74
Mar 13 09:46:44.283: INFO: Got endpoints: latency-svc-bvdzb [750.213129ms]
Mar 13 09:46:44.286: INFO: Created: latency-svc-kqzvl
Mar 13 09:46:44.332: INFO: Got endpoints: latency-svc-l9njv [750.360135ms]
Mar 13 09:46:44.336: INFO: Created: latency-svc-b8wxp
Mar 13 09:46:44.382: INFO: Got endpoints: latency-svc-vjn5f [749.883424ms]
Mar 13 09:46:44.385: INFO: Created: latency-svc-x2kbl
Mar 13 09:46:44.432: INFO: Got endpoints: latency-svc-kgdcl [749.700686ms]
Mar 13 09:46:44.435: INFO: Created: latency-svc-jmt8p
Mar 13 09:46:44.482: INFO: Got endpoints: latency-svc-mq6mk [749.988155ms]
Mar 13 09:46:44.486: INFO: Created: latency-svc-ppjjk
Mar 13 09:46:44.532: INFO: Got endpoints: latency-svc-vkhns [749.999515ms]
Mar 13 09:46:44.535: INFO: Created: latency-svc-lps26
Mar 13 09:46:44.582: INFO: Got endpoints: latency-svc-6zb5v [749.813748ms]
Mar 13 09:46:44.585: INFO: Created: latency-svc-dhzjk
Mar 13 09:46:44.632: INFO: Got endpoints: latency-svc-zg47d [749.961405ms]
Mar 13 09:46:44.636: INFO: Created: latency-svc-rzwqc
Mar 13 09:46:44.682: INFO: Got endpoints: latency-svc-tjrcv [750.193714ms]
Mar 13 09:46:44.686: INFO: Created: latency-svc-2spcw
Mar 13 09:46:44.732: INFO: Got endpoints: latency-svc-whd7q [749.918618ms]
Mar 13 09:46:44.736: INFO: Created: latency-svc-l5rjs
Mar 13 09:46:44.782: INFO: Got endpoints: latency-svc-cp79n [749.717858ms]
Mar 13 09:46:44.786: INFO: Created: latency-svc-bvbr8
Mar 13 09:46:44.832: INFO: Got endpoints: latency-svc-5rdh7 [749.412899ms]
Mar 13 09:46:44.835: INFO: Created: latency-svc-6srb6
Mar 13 09:46:44.882: INFO: Got endpoints: latency-svc-2hr55 [750.025876ms]
Mar 13 09:46:44.886: INFO: Created: latency-svc-2xqph
Mar 13 09:46:44.932: INFO: Got endpoints: latency-svc-j7m94 [750.012009ms]
Mar 13 09:46:44.936: INFO: Created: latency-svc-ngt4n
Mar 13 09:46:44.982: INFO: Got endpoints: latency-svc-hvw74 [750.102433ms]
Mar 13 09:46:44.986: INFO: Created: latency-svc-49v5h
Mar 13 09:46:45.032: INFO: Got endpoints: latency-svc-kqzvl [749.842941ms]
Mar 13 09:46:45.036: INFO: Created: latency-svc-f99pl
Mar 13 09:46:45.082: INFO: Got endpoints: latency-svc-b8wxp [749.956645ms]
Mar 13 09:46:45.086: INFO: Created: latency-svc-pm7lk
Mar 13 09:46:45.132: INFO: Got endpoints: latency-svc-x2kbl [749.974308ms]
Mar 13 09:46:45.135: INFO: Created: latency-svc-nnjxl
Mar 13 09:46:45.182: INFO: Got endpoints: latency-svc-jmt8p [749.910861ms]
Mar 13 09:46:45.186: INFO: Created: latency-svc-wc9lq
Mar 13 09:46:45.232: INFO: Got endpoints: latency-svc-ppjjk [749.750794ms]
Mar 13 09:46:45.236: INFO: Created: latency-svc-hhsg9
Mar 13 09:46:45.282: INFO: Got endpoints: latency-svc-lps26 [749.849858ms]
Mar 13 09:46:45.285: INFO: Created: latency-svc-kqlsp
Mar 13 09:46:45.332: INFO: Got endpoints: latency-svc-dhzjk [750.121723ms]
Mar 13 09:46:45.336: INFO: Created: latency-svc-mmqds
Mar 13 09:46:45.382: INFO: Got endpoints: latency-svc-rzwqc [749.864061ms]
Mar 13 09:46:45.386: INFO: Created: latency-svc-g4ll5
Mar 13 09:46:45.432: INFO: Got endpoints: latency-svc-2spcw [749.990308ms]
Mar 13 09:46:45.436: INFO: Created: latency-svc-x7lz5
Mar 13 09:46:45.482: INFO: Got endpoints: latency-svc-l5rjs [750.096582ms]
Mar 13 09:46:45.486: INFO: Created: latency-svc-9jn6q
Mar 13 09:46:45.532: INFO: Got endpoints: latency-svc-bvbr8 [750.23082ms]
Mar 13 09:46:45.537: INFO: Created: latency-svc-qdrzn
Mar 13 09:46:45.582: INFO: Got endpoints: latency-svc-6srb6 [750.387621ms]
Mar 13 09:46:45.586: INFO: Created: latency-svc-hwg29
Mar 13 09:46:45.632: INFO: Got endpoints: latency-svc-2xqph [749.704981ms]
Mar 13 09:46:45.635: INFO: Created: latency-svc-44w2q
Mar 13 09:46:45.682: INFO: Got endpoints: latency-svc-ngt4n [750.25535ms]
Mar 13 09:46:45.686: INFO: Created: latency-svc-9fxdv
Mar 13 09:46:45.732: INFO: Got endpoints: latency-svc-49v5h [749.868854ms]
Mar 13 09:46:45.736: INFO: Created: latency-svc-cl8x5
Mar 13 09:46:45.782: INFO: Got endpoints: latency-svc-f99pl [750.014301ms]
Mar 13 09:46:45.786: INFO: Created: latency-svc-p92lt
Mar 13 09:46:45.832: INFO: Got endpoints: latency-svc-pm7lk [749.849293ms]
Mar 13 09:46:45.836: INFO: Created: latency-svc-q7d62
Mar 13 09:46:45.882: INFO: Got endpoints: latency-svc-nnjxl [750.005821ms]
Mar 13 09:46:45.885: INFO: Created: latency-svc-c27zl
Mar 13 09:46:45.933: INFO: Got endpoints: latency-svc-wc9lq [750.287234ms]
Mar 13 09:46:45.936: INFO: Created: latency-svc-jlgss
Mar 13 09:46:45.982: INFO: Got endpoints: latency-svc-hhsg9 [750.013449ms]
Mar 13 09:46:45.985: INFO: Created: latency-svc-xkvvp
Mar 13 09:46:46.032: INFO: Got endpoints: latency-svc-kqlsp [749.952809ms]
Mar 13 09:46:46.035: INFO: Created: latency-svc-sl98h
Mar 13 09:46:46.082: INFO: Got endpoints: latency-svc-mmqds [749.923605ms]
Mar 13 09:46:46.086: INFO: Created: latency-svc-9wjv7
Mar 13 09:46:46.132: INFO: Got endpoints: latency-svc-g4ll5 [750.116192ms]
Mar 13 09:46:46.136: INFO: Created: latency-svc-p8rkv
Mar 13 09:46:46.182: INFO: Got endpoints: latency-svc-x7lz5 [749.842515ms]
Mar 13 09:46:46.186: INFO: Created: latency-svc-c2tf9
Mar 13 09:46:46.232: INFO: Got endpoints: latency-svc-9jn6q [749.929451ms]
Mar 13 09:46:46.236: INFO: Created: latency-svc-t29ws
Mar 13 09:46:46.282: INFO: Got endpoints: latency-svc-qdrzn [749.810681ms]
Mar 13 09:46:46.285: INFO: Created: latency-svc-xpqzh
Mar 13 09:46:46.332: INFO: Got endpoints: latency-svc-hwg29 [749.61377ms]
Mar 13 09:46:46.335: INFO: Created: latency-svc-cbvqz
Mar 13 09:46:46.382: INFO: Got endpoints: latency-svc-44w2q [749.874185ms]
Mar 13 09:46:46.385: INFO: Created: latency-svc-8jrkj
Mar 13 09:46:46.432: INFO: Got endpoints: latency-svc-9fxdv [749.699204ms]
Mar 13 09:46:46.435: INFO: Created: latency-svc-rkjv4
Mar 13 09:46:46.482: INFO: Got endpoints: latency-svc-cl8x5 [750.035968ms]
Mar 13 09:46:46.486: INFO: Created: latency-svc-xgllt
Mar 13 09:46:46.532: INFO: Got endpoints: latency-svc-p92lt [749.826641ms]
Mar 13 09:46:46.535: INFO: Created: latency-svc-gvgdm
Mar 13 09:46:46.582: INFO: Got endpoints: latency-svc-q7d62 [749.561613ms]
Mar 13 09:46:46.585: INFO: Created: latency-svc-rzcrf
Mar 13 09:46:46.632: INFO: Got endpoints: latency-svc-c27zl [749.917156ms]
Mar 13 09:46:46.635: INFO: Created: latency-svc-z2pwg
Mar 13 09:46:46.682: INFO: Got endpoints: latency-svc-jlgss [749.721247ms]
Mar 13 09:46:46.686: INFO: Created: latency-svc-ts4dr
Mar 13 09:46:46.732: INFO: Got endpoints: latency-svc-xkvvp [749.890694ms]
Mar 13 09:46:46.735: INFO: Created: latency-svc-sg268
Mar 13 09:46:46.782: INFO: Got endpoints: latency-svc-sl98h [750.176563ms]
Mar 13 09:46:46.786: INFO: Created: latency-svc-qgrqh
Mar 13 09:46:46.832: INFO: Got endpoints: latency-svc-9wjv7 [749.730496ms]
Mar 13 09:46:46.835: INFO: Created: latency-svc-4jlc8
Mar 13 09:46:46.882: INFO: Got endpoints: latency-svc-p8rkv [750.128729ms]
Mar 13 09:46:46.886: INFO: Created: latency-svc-6lhg7
Mar 13 09:46:46.932: INFO: Got endpoints: latency-svc-c2tf9 [749.921235ms]
Mar 13 09:46:46.936: INFO: Created: latency-svc-dgpcg
Mar 13 09:46:46.982: INFO: Got endpoints: latency-svc-t29ws [749.918895ms]
Mar 13 09:46:46.986: INFO: Created: latency-svc-54d44
Mar 13 09:46:47.032: INFO: Got endpoints: latency-svc-xpqzh [750.161603ms]
Mar 13 09:46:47.036: INFO: Created: latency-svc-qn8xg
Mar 13 09:46:47.082: INFO: Got endpoints: latency-svc-cbvqz [750.081453ms]
Mar 13 09:46:47.086: INFO: Created: latency-svc-8fqr2
Mar 13 09:46:47.132: INFO: Got endpoints: latency-svc-8jrkj [750.167287ms]
Mar 13 09:46:47.136: INFO: Created: latency-svc-gtj6d
Mar 13 09:46:47.182: INFO: Got endpoints: latency-svc-rkjv4 [749.897398ms]
Mar 13 09:46:47.185: INFO: Created: latency-svc-6vrbc
Mar 13 09:46:47.232: INFO: Got endpoints: latency-svc-xgllt [749.784804ms]
Mar 13 09:46:47.235: INFO: Created: latency-svc-vntkp
Mar 13 09:46:47.282: INFO: Got endpoints: latency-svc-gvgdm [750.014415ms]
Mar 13 09:46:47.286: INFO: Created: latency-svc-7gj5h
Mar 13 09:46:47.332: INFO: Got endpoints: latency-svc-rzcrf [750.371ms]
Mar 13 09:46:47.336: INFO: Created: latency-svc-xjw2h
Mar 13 09:46:47.382: INFO: Got endpoints: latency-svc-z2pwg [750.220232ms]
Mar 13 09:46:47.386: INFO: Created: latency-svc-bfjxb
Mar 13 09:46:47.432: INFO: Got endpoints: latency-svc-ts4dr [749.760085ms]
Mar 13 09:46:47.435: INFO: Created: latency-svc-gwqcp
Mar 13 09:46:47.482: INFO: Got endpoints: latency-svc-sg268 [750.014019ms]
Mar 13 09:46:47.486: INFO: Created: latency-svc-ccq4t
Mar 13 09:46:47.533: INFO: Got endpoints: latency-svc-qgrqh [750.140366ms]
Mar 13 09:46:47.536: INFO: Created: latency-svc-g4hnn
Mar 13 09:46:47.583: INFO: Got endpoints: latency-svc-4jlc8 [750.444343ms]
Mar 13 09:46:47.586: INFO: Created: latency-svc-ls67p
Mar 13 09:46:47.632: INFO: Got endpoints: latency-svc-6lhg7 [749.754251ms]
Mar 13 09:46:47.636: INFO: Created: latency-svc-zrt2j
Mar 13 09:46:47.683: INFO: Got endpoints: latency-svc-dgpcg [750.270984ms]
Mar 13 09:46:47.686: INFO: Created: latency-svc-ck6hd
Mar 13 09:46:47.732: INFO: Got endpoints: latency-svc-54d44 [749.985778ms]
Mar 13 09:46:47.736: INFO: Created: latency-svc-74llq
Mar 13 09:46:47.782: INFO: Got endpoints: latency-svc-qn8xg [749.758634ms]
Mar 13 09:46:47.786: INFO: Created: latency-svc-bzdrq
Mar 13 09:46:47.832: INFO: Got endpoints: latency-svc-8fqr2 [749.897065ms]
Mar 13 09:46:47.836: INFO: Created: latency-svc-dwkgc
Mar 13 09:46:47.882: INFO: Got endpoints: latency-svc-gtj6d [749.994017ms]
Mar 13 09:46:47.885: INFO: Created: latency-svc-j5k92
Mar 13 09:46:47.932: INFO: Got endpoints: latency-svc-6vrbc [749.886071ms]
Mar 13 09:46:47.935: INFO: Created: latency-svc-klvlq
Mar 13 09:46:47.985: INFO: Got endpoints: latency-svc-vntkp [752.349317ms]
Mar 13 09:46:47.992: INFO: Created: latency-svc-zgpj7
Mar 13 09:46:48.032: INFO: Got endpoints: latency-svc-7gj5h [749.783248ms]
Mar 13 09:46:48.036: INFO: Created: latency-svc-c4qb8
Mar 13 09:46:48.082: INFO: Got endpoints: latency-svc-xjw2h [749.983797ms]
Mar 13 09:46:48.086: INFO: Created: latency-svc-tbfwz
Mar 13 09:46:48.132: INFO: Got endpoints: latency-svc-bfjxb [749.702229ms]
Mar 13 09:46:48.136: INFO: Created: latency-svc-49fkc
Mar 13 09:46:48.182: INFO: Got endpoints: latency-svc-gwqcp [749.998227ms]
Mar 13 09:46:48.185: INFO: Created: latency-svc-7l5rs
Mar 13 09:46:48.232: INFO: Got endpoints: latency-svc-ccq4t [750.235329ms]
Mar 13 09:46:48.236: INFO: Created: latency-svc-4p8rp
Mar 13 09:46:48.283: INFO: Got endpoints: latency-svc-g4hnn [750.111115ms]
Mar 13 09:46:48.286: INFO: Created: latency-svc-lcb2w
Mar 13 09:46:48.332: INFO: Got endpoints: latency-svc-ls67p [749.671236ms]
Mar 13 09:46:48.336: INFO: Created: latency-svc-d52tf
Mar 13 09:46:48.382: INFO: Got endpoints: latency-svc-zrt2j [750.137136ms]
Mar 13 09:46:48.386: INFO: Created: latency-svc-96qgf
Mar 13 09:46:48.433: INFO: Got endpoints: latency-svc-ck6hd [750.156702ms]
Mar 13 09:46:48.436: INFO: Created: latency-svc-ld7bb
Mar 13 09:46:48.482: INFO: Got endpoints: latency-svc-74llq [750.124992ms]
Mar 13 09:46:48.486: INFO: Created: latency-svc-cplkd
Mar 13 09:46:48.532: INFO: Got endpoints: latency-svc-bzdrq [750.052727ms]
Mar 13 09:46:48.536: INFO: Created: latency-svc-wbcpk
Mar 13 09:46:48.582: INFO: Got endpoints: latency-svc-dwkgc [750.138772ms]
Mar 13 09:46:48.586: INFO: Created: latency-svc-jzs4b
Mar 13 09:46:48.632: INFO: Got endpoints: latency-svc-j5k92 [749.785186ms]
Mar 13 09:46:48.636: INFO: Created: latency-svc-jrnvs
Mar 13 09:46:48.683: INFO: Got endpoints: latency-svc-klvlq [750.637614ms]
Mar 13 09:46:48.686: INFO: Created: latency-svc-qdtvc
Mar 13 09:46:48.732: INFO: Got endpoints: latency-svc-zgpj7 [747.624442ms]
Mar 13 09:46:48.736: INFO: Created: latency-svc-pt84j
Mar 13 09:46:48.782: INFO: Got endpoints: latency-svc-c4qb8 [749.853341ms]
Mar 13 09:46:48.786: INFO: Created: latency-svc-n8cnk
Mar 13 09:46:48.832: INFO: Got endpoints: latency-svc-tbfwz [749.819287ms]
Mar 13 09:46:48.836: INFO: Created: latency-svc-827mx
Mar 13 09:46:48.882: INFO: Got endpoints: latency-svc-49fkc [750.028929ms]
Mar 13 09:46:48.885: INFO: Created: latency-svc-nm4xl
Mar 13 09:46:48.932: INFO: Got endpoints: latency-svc-7l5rs [750.005918ms]
Mar 13 09:46:48.935: INFO: Created: latency-svc-sp7vt
Mar 13 09:46:48.982: INFO: Got endpoints: latency-svc-4p8rp [749.673957ms]
Mar 13 09:46:48.985: INFO: Created: latency-svc-wrfcz
Mar 13 09:46:49.032: INFO: Got endpoints: latency-svc-lcb2w [749.424411ms]
Mar 13 09:46:49.036: INFO: Created: latency-svc-bbr8n
Mar 13 09:46:49.082: INFO: Got endpoints: latency-svc-d52tf [749.92458ms]
Mar 13 09:46:49.086: INFO: Created: latency-svc-kjkw2
Mar 13 09:46:49.132: INFO: Got endpoints: latency-svc-96qgf [749.90093ms]
Mar 13 09:46:49.136: INFO: Created: latency-svc-pgn7b
Mar 13 09:46:49.182: INFO: Got endpoints: latency-svc-ld7bb [749.611813ms]
Mar 13 09:46:49.186: INFO: Created: latency-svc-7vv4x
Mar 13 09:46:49.232: INFO: Got endpoints: latency-svc-cplkd [749.837977ms]
Mar 13 09:46:49.236: INFO: Created: latency-svc-7ctpd
Mar 13 09:46:49.282: INFO: Got endpoints: latency-svc-wbcpk [749.997412ms]
Mar 13 09:46:49.286: INFO: Created: latency-svc-q7pqf
Mar 13 09:46:49.332: INFO: Got endpoints: latency-svc-jzs4b [750.109276ms]
Mar 13 09:46:49.336: INFO: Created: latency-svc-25dm9
Mar 13 09:46:49.382: INFO: Got endpoints: latency-svc-jrnvs [750.326584ms]
Mar 13 09:46:49.386: INFO: Created: latency-svc-b8p45
Mar 13 09:46:49.432: INFO: Got endpoints: latency-svc-qdtvc [749.76285ms]
Mar 13 09:46:49.436: INFO: Created: latency-svc-k6wtt
Mar 13 09:46:49.483: INFO: Got endpoints: latency-svc-pt84j [750.190397ms]
Mar 13 09:46:49.486: INFO: Created: latency-svc-82g88
Mar 13 09:46:49.532: INFO: Got endpoints: latency-svc-n8cnk [750.35438ms]
Mar 13 09:46:49.536: INFO: Created: latency-svc-t5drf
Mar 13 09:46:49.582: INFO: Got endpoints: latency-svc-827mx [750.231566ms]
Mar 13 09:46:49.586: INFO: Created: latency-svc-hncqg
Mar 13 09:46:49.632: INFO: Got endpoints: latency-svc-nm4xl [749.930327ms]
Mar 13 09:46:49.636: INFO: Created: latency-svc-xbrth
Mar 13 09:46:49.682: INFO: Got endpoints: latency-svc-sp7vt [750.138706ms]
Mar 13 09:46:49.686: INFO: Created: latency-svc-4tqqf
Mar 13 09:46:49.732: INFO: Got endpoints: latency-svc-wrfcz [750.287957ms]
Mar 13 09:46:49.736: INFO: Created: latency-svc-5vwcc
Mar 13 09:46:49.782: INFO: Got endpoints: latency-svc-bbr8n [750.248369ms]
Mar 13 09:46:49.786: INFO: Created: latency-svc-hvg4p
Mar 13 09:46:49.832: INFO: Got endpoints: latency-svc-kjkw2 [749.956815ms]
Mar 13 09:46:49.836: INFO: Created: latency-svc-rdj6x
Mar 13 09:46:49.882: INFO: Got endpoints: latency-svc-pgn7b [749.785808ms]
Mar 13 09:46:49.886: INFO: Created: latency-svc-cnwz7
Mar 13 09:46:49.932: INFO: Got endpoints: latency-svc-7vv4x [749.787599ms]
Mar 13 09:46:49.935: INFO: Created: latency-svc-xvlrj
Mar 13 09:46:49.982: INFO: Got endpoints: latency-svc-7ctpd [750.14068ms]
Mar 13 09:46:49.986: INFO: Created: latency-svc-j95qx
Mar 13 09:46:50.032: INFO: Got endpoints: latency-svc-q7pqf [749.705623ms]
Mar 13 09:46:50.036: INFO: Created: latency-svc-sv2h7
Mar 13 09:46:50.082: INFO: Got endpoints: latency-svc-25dm9 [749.725731ms]
Mar 13 09:46:50.086: INFO: Created: latency-svc-p4jc6
Mar 13 09:46:50.132: INFO: Got endpoints: latency-svc-b8p45 [749.771448ms]
Mar 13 09:46:50.136: INFO: Created: latency-svc-26lfm
Mar 13 09:46:50.182: INFO: Got endpoints: latency-svc-k6wtt [749.746264ms]
Mar 13 09:46:50.186: INFO: Created: latency-svc-w8zs4
Mar 13 09:46:50.233: INFO: Got endpoints: latency-svc-82g88 [750.30871ms]
Mar 13 09:46:50.236: INFO: Created: latency-svc-p7hlj
Mar 13 09:46:50.282: INFO: Got endpoints: latency-svc-t5drf [749.940006ms]
Mar 13 09:46:50.286: INFO: Created: latency-svc-vsvcp
Mar 13 09:46:50.332: INFO: Got endpoints: latency-svc-hncqg [749.87163ms]
Mar 13 09:46:50.336: INFO: Created: latency-svc-vkq76
Mar 13 09:46:50.382: INFO: Got endpoints: latency-svc-xbrth [750.123729ms]
Mar 13 09:46:50.386: INFO: Created: latency-svc-blpjz
Mar 13 09:46:50.432: INFO: Got endpoints: latency-svc-4tqqf [749.760214ms]
Mar 13 09:46:50.435: INFO: Created: latency-svc-z4kt7
Mar 13 09:46:50.482: INFO: Got endpoints: latency-svc-5vwcc [749.660644ms]
Mar 13 09:46:50.485: INFO: Created: latency-svc-82lzf
Mar 13 09:46:50.532: INFO: Got endpoints: latency-svc-hvg4p [749.716646ms]
Mar 13 09:46:50.536: INFO: Created: latency-svc-xr9bt
Mar 13 09:46:50.582: INFO: Got endpoints: latency-svc-rdj6x [750.024148ms]
Mar 13 09:46:50.586: INFO: Created: latency-svc-rnx8c
Mar 13 09:46:50.632: INFO: Got endpoints: latency-svc-cnwz7 [750.235109ms]
Mar 13 09:46:50.682: INFO: Got endpoints: latency-svc-xvlrj [749.934277ms]
Mar 13 09:46:50.732: INFO: Got endpoints: latency-svc-j95qx [749.521403ms]
Mar 13 09:46:50.782: INFO: Got endpoints: latency-svc-sv2h7 [750.039789ms]
Mar 13 09:46:50.832: INFO: Got endpoints: latency-svc-p4jc6 [749.822581ms]
Mar 13 09:46:50.882: INFO: Got endpoints: latency-svc-26lfm [749.954315ms]
Mar 13 09:46:50.932: INFO: Got endpoints: latency-svc-w8zs4 [749.983298ms]
Mar 13 09:46:50.982: INFO: Got endpoints: latency-svc-p7hlj [749.221118ms]
Mar 13 09:46:51.032: INFO: Got endpoints: latency-svc-vsvcp [749.788988ms]
Mar 13 09:46:51.082: INFO: Got endpoints: latency-svc-vkq76 [749.888088ms]
Mar 13 09:46:51.132: INFO: Got endpoints: latency-svc-blpjz [749.728434ms]
Mar 13 09:46:51.182: INFO: Got endpoints: latency-svc-z4kt7 [750.200756ms]
Mar 13 09:46:51.232: INFO: Got endpoints: latency-svc-82lzf [750.065639ms]
Mar 13 09:46:51.282: INFO: Got endpoints: latency-svc-xr9bt [750.055226ms]
Mar 13 09:46:51.333: INFO: Got endpoints: latency-svc-rnx8c [750.218963ms]
Mar 13 09:46:51.333: INFO: Latencies: [4.851955ms 5.848553ms 7.241771ms 8.382486ms 9.477342ms 10.729828ms 12.178387ms 13.508567ms 14.815461ms 15.774698ms 17.229579ms 18.649279ms 18.912081ms 18.984572ms 19.30326ms 19.357794ms 19.37653ms 19.496375ms 19.498885ms 19.510017ms 19.527922ms 19.904296ms 19.908513ms 19.956183ms 20.071571ms 20.182387ms 20.75583ms 21.073519ms 22.312136ms 25.801301ms 75.09051ms 123.299573ms 172.211008ms 221.3511ms 269.547472ms 318.559075ms 367.003579ms 415.422821ms 464.497191ms 512.807787ms 561.301325ms 609.723483ms 658.561171ms 706.999502ms 747.624442ms 749.221118ms 749.412899ms 749.424411ms 749.521403ms 749.561613ms 749.611813ms 749.61377ms 749.660644ms 749.671236ms 749.673957ms 749.699204ms 749.700686ms 749.702229ms 749.704981ms 749.705623ms 749.716646ms 749.717858ms 749.721247ms 749.725731ms 749.728434ms 749.730496ms 749.746264ms 749.750794ms 749.754251ms 749.758634ms 749.760085ms 749.760214ms 749.76285ms 749.771448ms 749.774337ms 749.783248ms 749.784804ms 749.785186ms 749.785808ms 749.787599ms 749.788988ms 749.810681ms 749.813748ms 749.819287ms 749.822581ms 749.826641ms 749.837977ms 749.838626ms 749.842515ms 749.842941ms 749.843367ms 749.849293ms 749.849858ms 749.853341ms 749.862144ms 749.864061ms 749.866078ms 749.868854ms 749.87163ms 749.874185ms 749.883424ms 749.883812ms 749.886071ms 749.888088ms 749.890694ms 749.897065ms 749.897398ms 749.90093ms 749.910861ms 749.917156ms 749.918618ms 749.918895ms 749.921235ms 749.923605ms 749.92458ms 749.929451ms 749.930327ms 749.934277ms 749.940006ms 749.952809ms 749.954315ms 749.956645ms 749.956815ms 749.961405ms 749.974308ms 749.983298ms 749.983797ms 749.985778ms 749.988155ms 749.990308ms 749.994017ms 749.997412ms 749.998227ms 749.999515ms 750.005821ms 750.005918ms 750.012009ms 750.013449ms 750.014019ms 750.014301ms 750.014415ms 750.024148ms 750.025876ms 750.028929ms 750.033543ms 750.035968ms 750.039789ms 750.052266ms 750.052727ms 750.055226ms 750.065639ms 750.077496ms 750.081453ms 750.085822ms 750.095923ms 750.096582ms 750.102433ms 750.109276ms 750.111115ms 750.116192ms 750.121723ms 750.123729ms 750.124992ms 750.128729ms 750.134458ms 750.137136ms 750.138706ms 750.138772ms 750.140366ms 750.14068ms 750.156702ms 750.161603ms 750.167287ms 750.176563ms 750.190397ms 750.193714ms 750.200756ms 750.213129ms 750.218963ms 750.220232ms 750.23082ms 750.231566ms 750.235109ms 750.235329ms 750.248369ms 750.25535ms 750.270984ms 750.287234ms 750.287957ms 750.30871ms 750.326584ms 750.341987ms 750.35438ms 750.35992ms 750.360135ms 750.371ms 750.387621ms 750.444343ms 750.637614ms 752.349317ms]
Mar 13 09:46:51.333: INFO: 50 %ile: 749.883424ms
Mar 13 09:46:51.333: INFO: 90 %ile: 750.23082ms
Mar 13 09:46:51.333: INFO: 99 %ile: 750.637614ms
Mar 13 09:46:51.333: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:46:51.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4705" for this suite.

• [SLOW TEST:10.743 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":280,"completed":105,"skipped":1756,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:46:51.339: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 13 09:46:51.360: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 50620 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 13 09:46:51.360: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 50620 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 13 09:47:01.364: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 51304 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 13 09:47:01.364: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 51304 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 13 09:47:11.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 51335 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 13 09:47:11.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 51335 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 13 09:47:21.372: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 51362 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 13 09:47:21.372: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-a 985c255b-8bbf-436b-a294-c6205c1b5b9e 51362 0 2020-03-13 09:46:51 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 13 09:47:31.375: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-b d8b2399f-b5db-4503-8a0d-3c611e3d2a62 51388 0 2020-03-13 09:47:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 13 09:47:31.375: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-b d8b2399f-b5db-4503-8a0d-3c611e3d2a62 51388 0 2020-03-13 09:47:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 13 09:47:41.379: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-b d8b2399f-b5db-4503-8a0d-3c611e3d2a62 51413 0 2020-03-13 09:47:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 13 09:47:41.379: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4822 /api/v1/namespaces/watch-4822/configmaps/e2e-watch-test-configmap-b d8b2399f-b5db-4503-8a0d-3c611e3d2a62 51413 0 2020-03-13 09:47:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:47:51.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4822" for this suite.

• [SLOW TEST:60.045 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":280,"completed":106,"skipped":1762,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:47:51.384: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating secret secrets-5964/secret-test-c5012e40-2e15-45dd-b267-783fa03427b3
STEP: Creating a pod to test consume secrets
Mar 13 09:47:51.406: INFO: Waiting up to 5m0s for pod "pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d" in namespace "secrets-5964" to be "success or failure"
Mar 13 09:47:51.407: INFO: Pod "pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.649469ms
Mar 13 09:47:53.409: INFO: Pod "pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003728597s
STEP: Saw pod success
Mar 13 09:47:53.409: INFO: Pod "pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d" satisfied condition "success or failure"
Mar 13 09:47:53.411: INFO: Trying to get logs from node 172.24.5.5 pod pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d container env-test: <nil>
STEP: delete the pod
Mar 13 09:47:53.434: INFO: Waiting for pod pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d to disappear
Mar 13 09:47:53.435: INFO: Pod pod-configmaps-333d7497-2f1e-451d-a8a7-ac5e5b4f5e5d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:47:53.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5964" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":107,"skipped":1769,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:47:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 13 09:47:53.458: INFO: Waiting up to 5m0s for pod "pod-1fec4e27-b246-44c6-a365-ddb828ffd385" in namespace "emptydir-7159" to be "success or failure"
Mar 13 09:47:53.460: INFO: Pod "pod-1fec4e27-b246-44c6-a365-ddb828ffd385": Phase="Pending", Reason="", readiness=false. Elapsed: 1.557288ms
Mar 13 09:47:55.462: INFO: Pod "pod-1fec4e27-b246-44c6-a365-ddb828ffd385": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003739953s
STEP: Saw pod success
Mar 13 09:47:55.462: INFO: Pod "pod-1fec4e27-b246-44c6-a365-ddb828ffd385" satisfied condition "success or failure"
Mar 13 09:47:55.463: INFO: Trying to get logs from node 172.24.5.5 pod pod-1fec4e27-b246-44c6-a365-ddb828ffd385 container test-container: <nil>
STEP: delete the pod
Mar 13 09:47:55.473: INFO: Waiting for pod pod-1fec4e27-b246-44c6-a365-ddb828ffd385 to disappear
Mar 13 09:47:55.474: INFO: Pod pod-1fec4e27-b246-44c6-a365-ddb828ffd385 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:47:55.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7159" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":108,"skipped":1770,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:47:55.479: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-7806
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7806
STEP: Creating statefulset with conflicting port in namespace statefulset-7806
STEP: Waiting until pod test-pod will start running in namespace statefulset-7806
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7806
Mar 13 09:47:57.510: INFO: Observed stateful pod in namespace: statefulset-7806, name: ss-0, uid: 5464022f-b845-4bb5-8481-c6b19b8a550c, status phase: Pending. Waiting for statefulset controller to delete.
Mar 13 09:47:58.076: INFO: Observed stateful pod in namespace: statefulset-7806, name: ss-0, uid: 5464022f-b845-4bb5-8481-c6b19b8a550c, status phase: Failed. Waiting for statefulset controller to delete.
Mar 13 09:47:58.079: INFO: Observed stateful pod in namespace: statefulset-7806, name: ss-0, uid: 5464022f-b845-4bb5-8481-c6b19b8a550c, status phase: Failed. Waiting for statefulset controller to delete.
Mar 13 09:47:58.081: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7806
STEP: Removing pod with conflicting port in namespace statefulset-7806
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7806 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 13 09:48:02.092: INFO: Deleting all statefulset in ns statefulset-7806
Mar 13 09:48:02.094: INFO: Scaling statefulset ss to 0
Mar 13 09:48:12.101: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 09:48:12.103: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:48:12.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7806" for this suite.

• [SLOW TEST:16.633 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":280,"completed":109,"skipped":1817,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:48:12.113: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:48:12.536: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 13 09:48:14.541: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689692, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689692, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689692, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719689692, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:48:17.547: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:48:17.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6725" for this suite.
STEP: Destroying namespace "webhook-6725-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.477 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":280,"completed":110,"skipped":1823,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:48:17.590: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-fa8fdd52-f287-414b-bffc-7716c3715293
STEP: Creating a pod to test consume secrets
Mar 13 09:48:17.614: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87" in namespace "projected-5588" to be "success or failure"
Mar 13 09:48:17.615: INFO: Pod "pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87": Phase="Pending", Reason="", readiness=false. Elapsed: 1.520224ms
Mar 13 09:48:19.618: INFO: Pod "pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003798149s
STEP: Saw pod success
Mar 13 09:48:19.618: INFO: Pod "pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87" satisfied condition "success or failure"
Mar 13 09:48:19.619: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:48:19.635: INFO: Waiting for pod pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87 to disappear
Mar 13 09:48:19.636: INFO: Pod pod-projected-secrets-b47a3373-5660-44f5-b1e0-de619eda0e87 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:48:19.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5588" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":111,"skipped":1841,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:48:19.641: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:48:19.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a" in namespace "projected-1518" to be "success or failure"
Mar 13 09:48:19.662: INFO: Pod "downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.564148ms
Mar 13 09:48:21.664: INFO: Pod "downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003526938s
STEP: Saw pod success
Mar 13 09:48:21.664: INFO: Pod "downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a" satisfied condition "success or failure"
Mar 13 09:48:21.666: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a container client-container: <nil>
STEP: delete the pod
Mar 13 09:48:21.674: INFO: Waiting for pod downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a to disappear
Mar 13 09:48:21.675: INFO: Pod downwardapi-volume-80342ac2-11fa-4143-852d-f98b7d7bd62a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:48:21.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1518" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":112,"skipped":1890,"failed":0}
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:48:21.680: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:48:23.709: INFO: Waiting up to 5m0s for pod "client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf" in namespace "pods-9067" to be "success or failure"
Mar 13 09:48:23.711: INFO: Pod "client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.426522ms
Mar 13 09:48:25.713: INFO: Pod "client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003437604s
STEP: Saw pod success
Mar 13 09:48:25.713: INFO: Pod "client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf" satisfied condition "success or failure"
Mar 13 09:48:25.714: INFO: Trying to get logs from node 172.24.5.7 pod client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf container env3cont: <nil>
STEP: delete the pod
Mar 13 09:48:25.723: INFO: Waiting for pod client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf to disappear
Mar 13 09:48:25.725: INFO: Pod client-envvars-b14e8572-8f44-4577-98b4-097782dd21cf no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:48:25.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9067" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":280,"completed":113,"skipped":1895,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:48:25.729: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 13 09:48:25.751: INFO: Waiting up to 5m0s for pod "pod-91d7e94d-9959-4554-a3b0-f52896a2ab29" in namespace "emptydir-8061" to be "success or failure"
Mar 13 09:48:25.752: INFO: Pod "pod-91d7e94d-9959-4554-a3b0-f52896a2ab29": Phase="Pending", Reason="", readiness=false. Elapsed: 1.35942ms
Mar 13 09:48:27.754: INFO: Pod "pod-91d7e94d-9959-4554-a3b0-f52896a2ab29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003281229s
STEP: Saw pod success
Mar 13 09:48:27.754: INFO: Pod "pod-91d7e94d-9959-4554-a3b0-f52896a2ab29" satisfied condition "success or failure"
Mar 13 09:48:27.756: INFO: Trying to get logs from node 172.24.5.7 pod pod-91d7e94d-9959-4554-a3b0-f52896a2ab29 container test-container: <nil>
STEP: delete the pod
Mar 13 09:48:27.764: INFO: Waiting for pod pod-91d7e94d-9959-4554-a3b0-f52896a2ab29 to disappear
Mar 13 09:48:27.765: INFO: Pod pod-91d7e94d-9959-4554-a3b0-f52896a2ab29 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:48:27.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8061" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":114,"skipped":1898,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:48:27.770: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-7bf3f42d-4aca-43f9-9813-0c7c5623b5c1 in namespace container-probe-5647
Mar 13 09:48:29.793: INFO: Started pod busybox-7bf3f42d-4aca-43f9-9813-0c7c5623b5c1 in namespace container-probe-5647
STEP: checking the pod's current state and verifying that restartCount is present
Mar 13 09:48:29.795: INFO: Initial restart count of pod busybox-7bf3f42d-4aca-43f9-9813-0c7c5623b5c1 is 0
Mar 13 09:49:23.852: INFO: Restart count of pod container-probe-5647/busybox-7bf3f42d-4aca-43f9-9813-0c7c5623b5c1 is now 1 (54.057535766s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:49:23.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5647" for this suite.

• [SLOW TEST:56.091 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":115,"skipped":1942,"failed":0}
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:49:23.861: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 13 09:49:23.878: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 13 09:49:23.884: INFO: Waiting for terminating namespaces to be deleted...
Mar 13 09:49:23.886: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.5 before test
Mar 13 09:49:23.891: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:49:23.891: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:49:23.891: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:49:23.891: INFO: canal-m4mzr from kube-system started at 2020-03-13 09:11:02 +0000 UTC (2 container statuses recorded)
Mar 13 09:49:23.891: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:49:23.891: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 09:49:23.891: INFO: nginx-ingress-controller-6b2t4 from ingress-nginx started at 2020-03-13 09:11:08 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.891: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:49:23.891: INFO: coredns-7c5566588d-9gx44 from kube-system started at 2020-03-13 09:11:16 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.891: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:49:23.891: INFO: sonobuoy-e2e-job-53adb94536da47d3 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:49:23.891: INFO: 	Container e2e ready: true, restart count 0
Mar 13 09:49:23.891: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:49:23.891: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.7 before test
Mar 13 09:49:23.898: INFO: rke-coredns-addon-deploy-job-frlv2 from kube-system started at 2020-03-13 06:25:02 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Mar 13 09:49:23.898: INFO: coredns-autoscaler-65bfc8d47d-d5vsc from kube-system started at 2020-03-13 06:25:04 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container autoscaler ready: true, restart count 0
Mar 13 09:49:23.898: INFO: default-http-backend-67cf578fc4-rwkbq from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 13 09:49:23.898: INFO: rke-network-plugin-deploy-job-chk5v from kube-system started at 2020-03-13 06:22:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 13 09:49:23.898: INFO: nginx-ingress-controller-mhtcd from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:49:23.898: INFO: rke-metrics-addon-deploy-job-w79dp from kube-system started at 2020-03-13 06:25:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 13 09:49:23.898: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-6mljq from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:49:23.898: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:49:23.898: INFO: metrics-server-6b55c64f86-gp7kb from kube-system started at 2020-03-13 06:25:09 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container metrics-server ready: true, restart count 0
Mar 13 09:49:23.898: INFO: sonobuoy from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 13 09:49:23.898: INFO: rke-ingress-controller-deploy-job-mmxvc from kube-system started at 2020-03-13 06:25:12 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 13 09:49:23.898: INFO: coredns-7c5566588d-dx5r6 from kube-system started at 2020-03-13 06:40:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:49:23.898: INFO: canal-fd4wb from kube-system started at 2020-03-13 06:22:33 +0000 UTC (2 container statuses recorded)
Mar 13 09:49:23.898: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:49:23.898: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15fbd42864bfdc53], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:49:24.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6941" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":280,"completed":116,"skipped":1942,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:49:24.915: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 13 09:49:25.170: INFO: Pod name wrapped-volume-race-33dd67e7-99cb-4f76-b3ed-1c0f89470207: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-33dd67e7-99cb-4f76-b3ed-1c0f89470207 in namespace emptydir-wrapper-9289, will wait for the garbage collector to delete the pods
Mar 13 09:49:39.285: INFO: Deleting ReplicationController wrapped-volume-race-33dd67e7-99cb-4f76-b3ed-1c0f89470207 took: 3.708315ms
Mar 13 09:49:39.685: INFO: Terminating ReplicationController wrapped-volume-race-33dd67e7-99cb-4f76-b3ed-1c0f89470207 pods took: 400.215459ms
STEP: Creating RC which spawns configmap-volume pods
Mar 13 09:49:52.393: INFO: Pod name wrapped-volume-race-ef828c92-4bda-43df-b002-8835308cda25: Found 0 pods out of 5
Mar 13 09:49:57.397: INFO: Pod name wrapped-volume-race-ef828c92-4bda-43df-b002-8835308cda25: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ef828c92-4bda-43df-b002-8835308cda25 in namespace emptydir-wrapper-9289, will wait for the garbage collector to delete the pods
Mar 13 09:50:07.467: INFO: Deleting ReplicationController wrapped-volume-race-ef828c92-4bda-43df-b002-8835308cda25 took: 3.797447ms
Mar 13 09:50:07.868: INFO: Terminating ReplicationController wrapped-volume-race-ef828c92-4bda-43df-b002-8835308cda25 pods took: 400.258361ms
STEP: Creating RC which spawns configmap-volume pods
Mar 13 09:50:16.576: INFO: Pod name wrapped-volume-race-4c94f266-df5c-41bf-9417-5592d118a90c: Found 0 pods out of 5
Mar 13 09:50:21.580: INFO: Pod name wrapped-volume-race-4c94f266-df5c-41bf-9417-5592d118a90c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4c94f266-df5c-41bf-9417-5592d118a90c in namespace emptydir-wrapper-9289, will wait for the garbage collector to delete the pods
Mar 13 09:50:31.648: INFO: Deleting ReplicationController wrapped-volume-race-4c94f266-df5c-41bf-9417-5592d118a90c took: 3.380211ms
Mar 13 09:50:32.048: INFO: Terminating ReplicationController wrapped-volume-race-4c94f266-df5c-41bf-9417-5592d118a90c pods took: 400.246729ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:50:42.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9289" for this suite.

• [SLOW TEST:77.660 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":280,"completed":117,"skipped":1951,"failed":0}
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:50:42.575: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-8f1e3512-eb3f-4a5a-a9d3-03576db7d84c
STEP: Creating a pod to test consume configMaps
Mar 13 09:50:42.597: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8" in namespace "projected-5597" to be "success or failure"
Mar 13 09:50:42.598: INFO: Pod "pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.388974ms
Mar 13 09:50:44.600: INFO: Pod "pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003220718s
STEP: Saw pod success
Mar 13 09:50:44.600: INFO: Pod "pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8" satisfied condition "success or failure"
Mar 13 09:50:44.602: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:50:44.611: INFO: Waiting for pod pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8 to disappear
Mar 13 09:50:44.612: INFO: Pod pod-projected-configmaps-3196f22b-d77c-4f05-99ee-683d46e161e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:50:44.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5597" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":118,"skipped":1951,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:50:44.617: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:50:44.634: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar 13 09:50:46.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6095 create -f -'
Mar 13 09:50:46.747: INFO: stderr: ""
Mar 13 09:50:46.747: INFO: stdout: "e2e-test-crd-publish-openapi-76-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar 13 09:50:46.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6095 delete e2e-test-crd-publish-openapi-76-crds test-cr'
Mar 13 09:50:46.829: INFO: stderr: ""
Mar 13 09:50:46.829: INFO: stdout: "e2e-test-crd-publish-openapi-76-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Mar 13 09:50:46.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6095 apply -f -'
Mar 13 09:50:46.974: INFO: stderr: ""
Mar 13 09:50:46.974: INFO: stdout: "e2e-test-crd-publish-openapi-76-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar 13 09:50:46.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6095 delete e2e-test-crd-publish-openapi-76-crds test-cr'
Mar 13 09:50:47.055: INFO: stderr: ""
Mar 13 09:50:47.055: INFO: stdout: "e2e-test-crd-publish-openapi-76-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar 13 09:50:47.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-76-crds'
Mar 13 09:50:47.192: INFO: stderr: ""
Mar 13 09:50:47.192: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-76-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:50:50.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6095" for this suite.

• [SLOW TEST:5.415 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":280,"completed":119,"skipped":1951,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:50:50.033: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-864a5b3a-b004-46b7-938f-7bfe1616d0ed
STEP: Creating a pod to test consume configMaps
Mar 13 09:50:50.056: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b" in namespace "configmap-8000" to be "success or failure"
Mar 13 09:50:50.058: INFO: Pod "pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.602305ms
Mar 13 09:50:52.060: INFO: Pod "pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003538337s
STEP: Saw pod success
Mar 13 09:50:52.060: INFO: Pod "pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b" satisfied condition "success or failure"
Mar 13 09:50:52.062: INFO: Trying to get logs from node 172.24.5.5 pod pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:50:52.071: INFO: Waiting for pod pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b to disappear
Mar 13 09:50:52.072: INFO: Pod pod-configmaps-9b077fbb-70f7-4bc3-be46-e3764476731b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:50:52.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8000" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":120,"skipped":1978,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:50:52.077: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:50:52.096: INFO: Waiting up to 5m0s for pod "downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508" in namespace "projected-1516" to be "success or failure"
Mar 13 09:50:52.097: INFO: Pod "downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508": Phase="Pending", Reason="", readiness=false. Elapsed: 1.477678ms
Mar 13 09:50:54.100: INFO: Pod "downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004052275s
STEP: Saw pod success
Mar 13 09:50:54.100: INFO: Pod "downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508" satisfied condition "success or failure"
Mar 13 09:50:54.101: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508 container client-container: <nil>
STEP: delete the pod
Mar 13 09:50:54.109: INFO: Waiting for pod downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508 to disappear
Mar 13 09:50:54.111: INFO: Pod downwardapi-volume-820672ab-81f2-42b0-a594-d0b52237f508 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:50:54.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1516" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":121,"skipped":2002,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:50:54.115: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating all guestbook components
Mar 13 09:50:54.132: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Mar 13 09:50:54.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-5047'
Mar 13 09:50:54.344: INFO: stderr: ""
Mar 13 09:50:54.344: INFO: stdout: "service/agnhost-slave created\n"
Mar 13 09:50:54.344: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Mar 13 09:50:54.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-5047'
Mar 13 09:50:54.478: INFO: stderr: ""
Mar 13 09:50:54.478: INFO: stdout: "service/agnhost-master created\n"
Mar 13 09:50:54.478: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 13 09:50:54.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-5047'
Mar 13 09:50:54.616: INFO: stderr: ""
Mar 13 09:50:54.616: INFO: stdout: "service/frontend created\n"
Mar 13 09:50:54.616: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Mar 13 09:50:54.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-5047'
Mar 13 09:50:54.754: INFO: stderr: ""
Mar 13 09:50:54.754: INFO: stdout: "deployment.apps/frontend created\n"
Mar 13 09:50:54.754: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 13 09:50:54.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-5047'
Mar 13 09:50:54.891: INFO: stderr: ""
Mar 13 09:50:54.891: INFO: stdout: "deployment.apps/agnhost-master created\n"
Mar 13 09:50:54.891: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 13 09:50:54.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-5047'
Mar 13 09:50:55.027: INFO: stderr: ""
Mar 13 09:50:55.027: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Mar 13 09:50:55.027: INFO: Waiting for all frontend pods to be Running.
Mar 13 09:51:00.077: INFO: Waiting for frontend to serve content.
Mar 13 09:51:00.083: INFO: Trying to add a new entry to the guestbook.
Mar 13 09:51:00.089: INFO: Verifying that added entry can be retrieved.
Mar 13 09:51:00.092: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
Mar 13 09:51:05.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-5047'
Mar 13 09:51:05.177: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:51:05.177: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 13 09:51:05.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-5047'
Mar 13 09:51:05.267: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:51:05.267: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 13 09:51:05.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-5047'
Mar 13 09:51:05.351: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:51:05.351: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 13 09:51:05.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-5047'
Mar 13 09:51:05.439: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:51:05.439: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 13 09:51:05.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-5047'
Mar 13 09:51:05.518: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:51:05.518: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 13 09:51:05.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-5047'
Mar 13 09:51:05.598: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 09:51:05.598: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:51:05.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5047" for this suite.

• [SLOW TEST:11.487 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:386
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":280,"completed":122,"skipped":2086,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:51:05.603: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:51:09.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2981" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":123,"skipped":2095,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:51:09.637: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:51:09.653: INFO: Creating deployment "webserver-deployment"
Mar 13 09:51:09.656: INFO: Waiting for observed generation 1
Mar 13 09:51:11.659: INFO: Waiting for all required pods to come up
Mar 13 09:51:11.662: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 13 09:51:15.665: INFO: Waiting for deployment "webserver-deployment" to complete
Mar 13 09:51:15.669: INFO: Updating deployment "webserver-deployment" with a non-existent image
Mar 13 09:51:15.672: INFO: Updating deployment webserver-deployment
Mar 13 09:51:15.673: INFO: Waiting for observed generation 2
Mar 13 09:51:17.676: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 13 09:51:17.678: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 13 09:51:17.679: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar 13 09:51:17.684: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 13 09:51:17.684: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 13 09:51:17.686: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar 13 09:51:17.689: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Mar 13 09:51:17.689: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Mar 13 09:51:17.693: INFO: Updating deployment webserver-deployment
Mar 13 09:51:17.693: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Mar 13 09:51:17.696: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 13 09:51:17.697: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 13 09:51:17.701: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7793 /apis/apps/v1/namespaces/deployment-7793/deployments/webserver-deployment 7b7a272f-f98f-47d7-a73d-d75c2f3ebb96 53787 3 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0032e1ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-03-13 09:51:15 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-13 09:51:17 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Mar 13 09:51:17.703: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-7793 /apis/apps/v1/namespaces/deployment-7793/replicasets/webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 53775 3 2020-03-13 09:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 7b7a272f-f98f-47d7-a73d-d75c2f3ebb96 0xc00383e1d7 0xc00383e1d8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00383e248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:51:17.703: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Mar 13 09:51:17.703: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-7793 /apis/apps/v1/namespaces/deployment-7793/replicasets/webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 53773 3 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 7b7a272f-f98f-47d7-a73d-d75c2f3ebb96 0xc00383e117 0xc00383e118}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00383e178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:51:17.709: INFO: Pod "webserver-deployment-595b5b9587-45gj9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-45gj9 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-45gj9 aeb2aee1-11dd-40b2-a9d8-06af9086d522 53808 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317c847 0xc00317c848}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.709: INFO: Pod "webserver-deployment-595b5b9587-4ln2n" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4ln2n webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-4ln2n f83e7d3f-5ab1-47fa-b196-394daa0ed551 53807 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317c937 0xc00317c938}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.709: INFO: Pod "webserver-deployment-595b5b9587-5wtg2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5wtg2 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-5wtg2 dc3c741d-f32b-46a5-9073-2c9999deb526 53788 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317ca37 0xc00317ca38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.709: INFO: Pod "webserver-deployment-595b5b9587-6mmjg" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6mmjg webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-6mmjg cbb045e7-de3f-4403-a565-534b726045e6 53805 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317cb50 0xc00317cb51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.710: INFO: Pod "webserver-deployment-595b5b9587-7fx7w" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7fx7w webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-7fx7w e0db4978-2371-43c5-a10e-4cb21872dbdb 53816 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317cc37 0xc00317cc38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.710: INFO: Pod "webserver-deployment-595b5b9587-85t9r" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-85t9r webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-85t9r 8c9cef44-442a-482b-9da0-7739d978c3ac 53809 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317cd50 0xc00317cd51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.710: INFO: Pod "webserver-deployment-595b5b9587-94t5b" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-94t5b webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-94t5b a8e7db86-b637-48d4-a2c2-9b1826038be9 53794 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317ce37 0xc00317ce38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.711: INFO: Pod "webserver-deployment-595b5b9587-99v9g" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-99v9g webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-99v9g d31f629f-c3a7-4742-a7c6-5cfec4cfca80 53669 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.0.18/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317cf60 0xc00317cf61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:10.42.0.18,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4e4eae3e44c35fb11d505f0e567cea59c288a60476ad55d5d70681e6307f2304,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.711: INFO: Pod "webserver-deployment-595b5b9587-fb9wj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fb9wj webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-fb9wj f6684ff5-521d-4f3f-a279-7529c3d97b2c 53693 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.1.88/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d0e0 0xc00317d0e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:10.42.1.88,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://00a6f4e2b4131b775a056ee04f9ba89e1ca356e9cc5b917a8b063c43c42bca4a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.711: INFO: Pod "webserver-deployment-595b5b9587-gcrp2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gcrp2 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-gcrp2 d885dc87-b69a-4595-b53b-e5b3c9b2f152 53662 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.1.86/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d260 0xc00317d261}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:10.42.1.86,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://450a582ac5ffa6e3359a4200db9e8399a7f4d50f9b47bc7107b76cbb41d60ab4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.711: INFO: Pod "webserver-deployment-595b5b9587-h6km4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-h6km4 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-h6km4 b2df3cd4-6955-40b5-80a1-b6095b316ead 53678 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.0.17/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d3e0 0xc00317d3e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:10.42.0.17,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f5689beaa1bc8eeffbb2b4e6fdb23989bf12b5f817aa34f95c2b135ff6c352e2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.711: INFO: Pod "webserver-deployment-595b5b9587-hmjcq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hmjcq webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-hmjcq 06843513-ef43-4d94-8d31-9039713a6f88 53806 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d550 0xc00317d551}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.712: INFO: Pod "webserver-deployment-595b5b9587-rtvxg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rtvxg webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-rtvxg 772fc654-247c-4ab9-b228-651f30d6fd3e 53696 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.1.90/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d647 0xc00317d648}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:10.42.1.90,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://01356ebd565d9a99d9adf3b65109b704fe77d56f8f5f1ecfe79011ae894d6de3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.90,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.712: INFO: Pod "webserver-deployment-595b5b9587-rxcqz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rxcqz webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-rxcqz 1306de0c-3479-402b-855f-b6828a1096ba 53811 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d7c0 0xc00317d7c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.712: INFO: Pod "webserver-deployment-595b5b9587-sn4cz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sn4cz webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-sn4cz 44152385-6e5d-463c-b74c-76e593d4c2f1 53659 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.0.15/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317d8e0 0xc00317d8e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:10.42.0.15,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://571c0eb4765352c2662dfefd49beb23bacb0361c4c2ed7a4dd88fcc72d9245df,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.712: INFO: Pod "webserver-deployment-595b5b9587-w28pg" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-w28pg webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-w28pg f07841c3-cd30-4f54-966d-fb34a5a39fdc 53812 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317da50 0xc00317da51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.713: INFO: Pod "webserver-deployment-595b5b9587-wr8r8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wr8r8 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-wr8r8 f5e37ef2-724e-4952-b587-ecb63b075871 53813 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317db60 0xc00317db61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.713: INFO: Pod "webserver-deployment-595b5b9587-x44d2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x44d2 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-x44d2 3de4a026-1d0b-4d1d-8711-ba505a162e81 53649 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.1.87/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317dc90 0xc00317dc91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:10.42.1.87,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9b3d1ed5c6506066c9737667579a807ca59559936790c3b45c1c551f701ebddb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.713: INFO: Pod "webserver-deployment-595b5b9587-zhwd4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zhwd4 webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-zhwd4 24d94c39-215f-41c8-b44a-79207dae5908 53782 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317de00 0xc00317de01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.713: INFO: Pod "webserver-deployment-595b5b9587-zkcfj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zkcfj webserver-deployment-595b5b9587- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-595b5b9587-zkcfj 6e94697b-789f-46f5-8ab4-15f553faae41 53655 0 2020-03-13 09:51:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.42.1.89/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 962b4e3a-8a39-47be-873e-95b1d87e993d 0xc00317df20 0xc00317df21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:10.42.1.89,StartTime:2020-03-13 09:51:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://982c6db3aa96186071b0bf090451dae9aa2b6b5fdc531b4d35352a55d3d44187,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.713: INFO: Pod "webserver-deployment-c7997dcc8-4lbhc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4lbhc webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-4lbhc 3714a0a5-ebf0-4b06-9517-f6c2673ddc4b 53797 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976090 0xc005976091}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.713: INFO: Pod "webserver-deployment-c7997dcc8-4t2mp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4t2mp webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-4t2mp 06cc2829-1bcb-4aa3-bb69-1c63495c20ac 53754 0 2020-03-13 09:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.42.0.19/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc0059761b7 0xc0059761b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:,StartTime:2020-03-13 09:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.714: INFO: Pod "webserver-deployment-c7997dcc8-4wzb4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4wzb4 webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-4wzb4 dbb2c5b8-473f-40b9-acde-d62cae8f91dc 53818 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976330 0xc005976331}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.714: INFO: Pod "webserver-deployment-c7997dcc8-6nhp8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6nhp8 webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-6nhp8 bd38ced3-4577-4102-ab78-ee5e96588e99 53767 0 2020-03-13 09:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.42.1.91/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976460 0xc005976461}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:,StartTime:2020-03-13 09:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.714: INFO: Pod "webserver-deployment-c7997dcc8-gf5sv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gf5sv webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-gf5sv 3366854f-e259-4f73-a7fb-a646232bc191 53755 0 2020-03-13 09:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.42.0.20/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc0059765e0 0xc0059765e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:,StartTime:2020-03-13 09:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.714: INFO: Pod "webserver-deployment-c7997dcc8-gwgrt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gwgrt webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-gwgrt 8a12ae0e-b0a6-4f03-99a7-74ff72664aae 53786 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976750 0xc005976751}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.715: INFO: Pod "webserver-deployment-c7997dcc8-kncvx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kncvx webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-kncvx 66459d51-bfa4-4299-a52b-0662a47ad3d2 53760 0 2020-03-13 09:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.42.1.92/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976880 0xc005976881}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:,StartTime:2020-03-13 09:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.715: INFO: Pod "webserver-deployment-c7997dcc8-knjlm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-knjlm webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-knjlm 26dc7bea-24e6-4440-bb20-6c00b35834c3 53799 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc0059769f0 0xc0059769f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.715: INFO: Pod "webserver-deployment-c7997dcc8-nvkg9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nvkg9 webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-nvkg9 d359fc1e-4b7c-4fdf-8206-f491e5d1ac2a 53815 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976ae7 0xc005976ae8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.715: INFO: Pod "webserver-deployment-c7997dcc8-slz2r" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-slz2r webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-slz2r 596499aa-86c9-4163-8ac3-12ec188aaff2 53801 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976be7 0xc005976be8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.715: INFO: Pod "webserver-deployment-c7997dcc8-tr646" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tr646 webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-tr646 e56c1e80-dd64-4a2e-b96b-bccf35357b47 53800 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976cf7 0xc005976cf8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.716: INFO: Pod "webserver-deployment-c7997dcc8-xgkd9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xgkd9 webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-xgkd9 ac25280d-903f-4ed8-8111-17e859478d15 53761 0 2020-03-13 09:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.42.1.93/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976e30 0xc005976e31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:,StartTime:2020-03-13 09:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:51:17.716: INFO: Pod "webserver-deployment-c7997dcc8-xrqpl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xrqpl webserver-deployment-c7997dcc8- deployment-7793 /api/v1/namespaces/deployment-7793/pods/webserver-deployment-c7997dcc8-xrqpl 9410f60d-59f1-4dce-b8c1-4b3bf4ea9be2 53802 0 2020-03-13 09:51:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 ca9744dc-373d-4fce-acf6-2e04792160f4 0xc005976fa0 0xc005976fa1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wsvj9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wsvj9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wsvj9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:51:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:51:17.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7793" for this suite.

• [SLOW TEST:8.082 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":280,"completed":124,"skipped":2145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:51:17.720: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar 13 09:51:27.764: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0313 09:51:27.764268      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:51:27.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2920" for this suite.

• [SLOW TEST:10.048 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":280,"completed":125,"skipped":2178,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:51:27.768: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:51:35.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2801" for this suite.

• [SLOW TEST:8.030 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":280,"completed":126,"skipped":2188,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:51:35.798: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5296.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5296.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5296.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5296.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 09:51:37.829: INFO: DNS probes using dns-test-577dee9f-6435-4407-99d8-6e6384f78f1f succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5296.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5296.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5296.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5296.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 09:51:39.846: INFO: File wheezy_udp@dns-test-service-3.dns-5296.svc.cluster.local from pod  dns-5296/dns-test-048a00c1-a220-4f8a-813a-210ecc10449c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar 13 09:51:39.848: INFO: File jessie_udp@dns-test-service-3.dns-5296.svc.cluster.local from pod  dns-5296/dns-test-048a00c1-a220-4f8a-813a-210ecc10449c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar 13 09:51:39.848: INFO: Lookups using dns-5296/dns-test-048a00c1-a220-4f8a-813a-210ecc10449c failed for: [wheezy_udp@dns-test-service-3.dns-5296.svc.cluster.local jessie_udp@dns-test-service-3.dns-5296.svc.cluster.local]

Mar 13 09:51:44.853: INFO: DNS probes using dns-test-048a00c1-a220-4f8a-813a-210ecc10449c succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5296.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5296.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5296.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5296.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 09:51:46.874: INFO: DNS probes using dns-test-4eaf6957-321b-4bbc-9a68-864ccc8f7845 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:51:46.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5296" for this suite.

• [SLOW TEST:11.089 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":280,"completed":127,"skipped":2225,"failed":0}
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:51:46.888: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:07.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5075" for this suite.

• [SLOW TEST:21.109 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":280,"completed":128,"skipped":2225,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:07.997: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 13 09:52:08.022: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1149 /api/v1/namespaces/watch-1149/configmaps/e2e-watch-test-label-changed 0e08749b-fe6f-4c84-a48e-93175acc5897 54627 0 2020-03-13 09:52:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 13 09:52:08.022: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1149 /api/v1/namespaces/watch-1149/configmaps/e2e-watch-test-label-changed 0e08749b-fe6f-4c84-a48e-93175acc5897 54628 0 2020-03-13 09:52:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 13 09:52:08.022: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1149 /api/v1/namespaces/watch-1149/configmaps/e2e-watch-test-label-changed 0e08749b-fe6f-4c84-a48e-93175acc5897 54629 0 2020-03-13 09:52:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 13 09:52:18.036: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1149 /api/v1/namespaces/watch-1149/configmaps/e2e-watch-test-label-changed 0e08749b-fe6f-4c84-a48e-93175acc5897 54675 0 2020-03-13 09:52:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 13 09:52:18.036: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1149 /api/v1/namespaces/watch-1149/configmaps/e2e-watch-test-label-changed 0e08749b-fe6f-4c84-a48e-93175acc5897 54676 0 2020-03-13 09:52:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 13 09:52:18.036: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1149 /api/v1/namespaces/watch-1149/configmaps/e2e-watch-test-label-changed 0e08749b-fe6f-4c84-a48e-93175acc5897 54677 0 2020-03-13 09:52:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:18.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1149" for this suite.

• [SLOW TEST:10.044 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":280,"completed":129,"skipped":2245,"failed":0}
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:18.041: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's command
Mar 13 09:52:18.063: INFO: Waiting up to 5m0s for pod "var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf" in namespace "var-expansion-2564" to be "success or failure"
Mar 13 09:52:18.064: INFO: Pod "var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.444691ms
Mar 13 09:52:20.066: INFO: Pod "var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003440384s
STEP: Saw pod success
Mar 13 09:52:20.066: INFO: Pod "var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf" satisfied condition "success or failure"
Mar 13 09:52:20.068: INFO: Trying to get logs from node 172.24.5.5 pod var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf container dapi-container: <nil>
STEP: delete the pod
Mar 13 09:52:20.078: INFO: Waiting for pod var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf to disappear
Mar 13 09:52:20.080: INFO: Pod var-expansion-2e4a0850-e8ea-4631-b45c-6dfd7728a6cf no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:20.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2564" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":280,"completed":130,"skipped":2251,"failed":0}

------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:20.085: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar 13 09:52:22.112: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-141385212 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 13 09:52:27.187: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:27.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7461" for this suite.

• [SLOW TEST:7.110 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should be submitted and removed [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period should be submitted and removed [Conformance]","total":280,"completed":131,"skipped":2251,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:27.194: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 13 09:52:29.221: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:29.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6935" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":132,"skipped":2252,"failed":0}
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:29.231: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 13 09:52:29.248: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 13 09:52:29.254: INFO: Waiting for terminating namespaces to be deleted...
Mar 13 09:52:29.255: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.5 before test
Mar 13 09:52:29.261: INFO: coredns-7c5566588d-9gx44 from kube-system started at 2020-03-13 09:11:16 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.261: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:52:29.261: INFO: sonobuoy-e2e-job-53adb94536da47d3 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:52:29.261: INFO: 	Container e2e ready: true, restart count 0
Mar 13 09:52:29.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:52:29.261: INFO: canal-m4mzr from kube-system started at 2020-03-13 09:11:02 +0000 UTC (2 container statuses recorded)
Mar 13 09:52:29.261: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:52:29.261: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 09:52:29.261: INFO: nginx-ingress-controller-6b2t4 from ingress-nginx started at 2020-03-13 09:11:08 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.261: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:52:29.261: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:52:29.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:52:29.261: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:52:29.261: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.7 before test
Mar 13 09:52:29.267: INFO: rke-ingress-controller-deploy-job-mmxvc from kube-system started at 2020-03-13 06:25:12 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 13 09:52:29.267: INFO: coredns-7c5566588d-dx5r6 from kube-system started at 2020-03-13 06:40:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container coredns ready: true, restart count 0
Mar 13 09:52:29.267: INFO: canal-fd4wb from kube-system started at 2020-03-13 06:22:33 +0000 UTC (2 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 09:52:29.267: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 09:52:29.267: INFO: rke-coredns-addon-deploy-job-frlv2 from kube-system started at 2020-03-13 06:25:02 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Mar 13 09:52:29.267: INFO: coredns-autoscaler-65bfc8d47d-d5vsc from kube-system started at 2020-03-13 06:25:04 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container autoscaler ready: true, restart count 0
Mar 13 09:52:29.267: INFO: default-http-backend-67cf578fc4-rwkbq from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container default-http-backend ready: true, restart count 0
Mar 13 09:52:29.267: INFO: rke-network-plugin-deploy-job-chk5v from kube-system started at 2020-03-13 06:22:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 13 09:52:29.267: INFO: nginx-ingress-controller-mhtcd from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 09:52:29.267: INFO: rke-metrics-addon-deploy-job-w79dp from kube-system started at 2020-03-13 06:25:07 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 13 09:52:29.267: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-6mljq from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 09:52:29.267: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 09:52:29.267: INFO: metrics-server-6b55c64f86-gp7kb from kube-system started at 2020-03-13 06:25:09 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container metrics-server ready: true, restart count 0
Mar 13 09:52:29.267: INFO: sonobuoy from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (1 container statuses recorded)
Mar 13 09:52:29.267: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ff7d69f1-d0f0-427d-9caa-bae25b330e63 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-ff7d69f1-d0f0-427d-9caa-bae25b330e63 off the node 172.24.5.5
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ff7d69f1-d0f0-427d-9caa-bae25b330e63
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:33.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8123" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":280,"completed":133,"skipped":2258,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:33.304: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:49.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3508" for this suite.

• [SLOW TEST:16.039 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":280,"completed":134,"skipped":2266,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:49.343: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-2953905e-b0c8-42b9-b746-7402b9e2d5b0
STEP: Creating a pod to test consume configMaps
Mar 13 09:52:49.366: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609" in namespace "projected-9277" to be "success or failure"
Mar 13 09:52:49.367: INFO: Pod "pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609": Phase="Pending", Reason="", readiness=false. Elapsed: 1.365024ms
Mar 13 09:52:51.369: INFO: Pod "pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003418118s
STEP: Saw pod success
Mar 13 09:52:51.369: INFO: Pod "pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609" satisfied condition "success or failure"
Mar 13 09:52:51.371: INFO: Trying to get logs from node 172.24.5.5 pod pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:52:51.381: INFO: Waiting for pod pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609 to disappear
Mar 13 09:52:51.382: INFO: Pod pod-projected-configmaps-a277a86f-a0f1-4238-9c7f-58210677b609 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:52:51.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9277" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":135,"skipped":2273,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:52:51.386: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating replication controller my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c
Mar 13 09:52:51.406: INFO: Pod name my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c: Found 0 pods out of 1
Mar 13 09:52:56.409: INFO: Pod name my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c: Found 1 pods out of 1
Mar 13 09:52:56.409: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c" are running
Mar 13 09:52:56.410: INFO: Pod "my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c-h7r79" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:52:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:52:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:52:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-13 09:52:51 +0000 UTC Reason: Message:}])
Mar 13 09:52:56.410: INFO: Trying to dial the pod
Mar 13 09:53:01.418: INFO: Controller my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c: Got expected result from replica 1 [my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c-h7r79]: "my-hostname-basic-a1e100d3-babe-416b-b02f-4c25c942643c-h7r79", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:01.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2249" for this suite.

• [SLOW TEST:10.036 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":136,"skipped":2284,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:01.423: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 13 09:53:03.953: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b5fdff27-7473-423e-9ac1-a415248b3acb"
Mar 13 09:53:03.953: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b5fdff27-7473-423e-9ac1-a415248b3acb" in namespace "pods-9580" to be "terminated due to deadline exceeded"
Mar 13 09:53:03.954: INFO: Pod "pod-update-activedeadlineseconds-b5fdff27-7473-423e-9ac1-a415248b3acb": Phase="Running", Reason="", readiness=true. Elapsed: 1.31988ms
Mar 13 09:53:05.956: INFO: Pod "pod-update-activedeadlineseconds-b5fdff27-7473-423e-9ac1-a415248b3acb": Phase="Running", Reason="", readiness=true. Elapsed: 2.003384286s
Mar 13 09:53:07.958: INFO: Pod "pod-update-activedeadlineseconds-b5fdff27-7473-423e-9ac1-a415248b3acb": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.005406815s
Mar 13 09:53:07.958: INFO: Pod "pod-update-activedeadlineseconds-b5fdff27-7473-423e-9ac1-a415248b3acb" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:07.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9580" for this suite.

• [SLOW TEST:6.540 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":280,"completed":137,"skipped":2290,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:07.964: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-43d28aa7-8379-435f-9e8a-7e7dfc70f90c
STEP: Creating a pod to test consume secrets
Mar 13 09:53:07.987: INFO: Waiting up to 5m0s for pod "pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2" in namespace "secrets-3916" to be "success or failure"
Mar 13 09:53:07.988: INFO: Pod "pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.409447ms
Mar 13 09:53:09.990: INFO: Pod "pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003352307s
STEP: Saw pod success
Mar 13 09:53:09.990: INFO: Pod "pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2" satisfied condition "success or failure"
Mar 13 09:53:09.991: INFO: Trying to get logs from node 172.24.5.5 pod pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2 container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 09:53:10.002: INFO: Waiting for pod pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2 to disappear
Mar 13 09:53:10.003: INFO: Pod pod-secrets-903f60b8-09b9-4dfd-9ea2-c23a5d6e7cc2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:10.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3916" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":138,"skipped":2374,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:10.008: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-e632d036-947b-48e3-85e2-f14887adfb86
STEP: Creating a pod to test consume configMaps
Mar 13 09:53:10.029: INFO: Waiting up to 5m0s for pod "pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986" in namespace "configmap-3188" to be "success or failure"
Mar 13 09:53:10.031: INFO: Pod "pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986": Phase="Pending", Reason="", readiness=false. Elapsed: 1.462831ms
Mar 13 09:53:12.033: INFO: Pod "pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003684802s
STEP: Saw pod success
Mar 13 09:53:12.033: INFO: Pod "pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986" satisfied condition "success or failure"
Mar 13 09:53:12.035: INFO: Trying to get logs from node 172.24.5.5 pod pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:53:12.045: INFO: Waiting for pod pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986 to disappear
Mar 13 09:53:12.046: INFO: Pod pod-configmaps-bae54c89-181a-4af0-8135-18006a5fa986 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:12.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3188" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":139,"skipped":2407,"failed":0}
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:12.050: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9412.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9412.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9412.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9412.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9412.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 77.165.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.165.77_udp@PTR;check="$$(dig +tcp +noall +answer +search 77.165.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.165.77_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9412.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9412.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9412.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9412.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9412.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9412.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9412.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 77.165.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.165.77_udp@PTR;check="$$(dig +tcp +noall +answer +search 77.165.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.165.77_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 09:53:14.112: INFO: Unable to read jessie_udp@PodARecord from pod dns-9412/dns-test-f568023d-bc59-4960-a5e1-a6b83b502b29: the server could not find the requested resource (get pods dns-test-f568023d-bc59-4960-a5e1-a6b83b502b29)
Mar 13 09:53:14.114: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9412/dns-test-f568023d-bc59-4960-a5e1-a6b83b502b29: the server could not find the requested resource (get pods dns-test-f568023d-bc59-4960-a5e1-a6b83b502b29)
Mar 13 09:53:14.117: INFO: Lookups using dns-9412/dns-test-f568023d-bc59-4960-a5e1-a6b83b502b29 failed for: [jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar 13 09:53:19.154: INFO: DNS probes using dns-9412/dns-test-f568023d-bc59-4960-a5e1-a6b83b502b29 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:19.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9412" for this suite.

• [SLOW TEST:7.123 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":280,"completed":140,"skipped":2411,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:19.174: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:53:19.194: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df" in namespace "projected-1072" to be "success or failure"
Mar 13 09:53:19.195: INFO: Pod "downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df": Phase="Pending", Reason="", readiness=false. Elapsed: 1.461071ms
Mar 13 09:53:21.197: INFO: Pod "downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003623827s
STEP: Saw pod success
Mar 13 09:53:21.197: INFO: Pod "downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df" satisfied condition "success or failure"
Mar 13 09:53:21.199: INFO: Trying to get logs from node 172.24.5.5 pod downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df container client-container: <nil>
STEP: delete the pod
Mar 13 09:53:21.208: INFO: Waiting for pod downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df to disappear
Mar 13 09:53:21.210: INFO: Pod downwardapi-volume-8c99400a-146d-45cc-96e9-cbd6fe2112df no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:21.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1072" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":280,"completed":141,"skipped":2420,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:21.214: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap that has name configmap-test-emptyKey-ba093245-5a2e-4e6d-9bdd-661894f446d5
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:21.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6419" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":280,"completed":142,"skipped":2429,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:21.237: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service nodeport-service with the type=NodePort in namespace services-455
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-455
STEP: creating replication controller externalsvc in namespace services-455
I0313 09:53:21.261503      26 runners.go:189] Created replication controller with name: externalsvc, namespace: services-455, replica count: 2
I0313 09:53:24.311960      26 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Mar 13 09:53:24.320: INFO: Creating new exec pod
Mar 13 09:53:26.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-455 execpod8ksc7 -- /bin/sh -x -c nslookup nodeport-service'
Mar 13 09:53:26.607: INFO: stderr: "+ nslookup nodeport-service\n"
Mar 13 09:53:26.607: INFO: stdout: "Server:\t\t10.43.0.10\nAddress:\t10.43.0.10#53\n\nnodeport-service.services-455.svc.cluster.local\tcanonical name = externalsvc.services-455.svc.cluster.local.\nName:\texternalsvc.services-455.svc.cluster.local\nAddress: 10.43.204.143\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-455, will wait for the garbage collector to delete the pods
Mar 13 09:53:26.662: INFO: Deleting ReplicationController externalsvc took: 2.873032ms
Mar 13 09:53:27.062: INFO: Terminating ReplicationController externalsvc pods took: 400.233671ms
Mar 13 09:53:42.068: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:53:42.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-455" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:20.840 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":280,"completed":143,"skipped":2435,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:53:42.077: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 13 09:53:42.107: INFO: Number of nodes with available pods: 0
Mar 13 09:53:42.107: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:43.111: INFO: Number of nodes with available pods: 0
Mar 13 09:53:43.111: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:44.111: INFO: Number of nodes with available pods: 2
Mar 13 09:53:44.111: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 13 09:53:44.120: INFO: Number of nodes with available pods: 1
Mar 13 09:53:44.120: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:45.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:45.125: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:46.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:46.125: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:47.124: INFO: Number of nodes with available pods: 1
Mar 13 09:53:47.124: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:48.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:48.125: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:49.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:49.126: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:50.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:50.125: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:51.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:51.125: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:52.125: INFO: Number of nodes with available pods: 1
Mar 13 09:53:52.125: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 09:53:53.125: INFO: Number of nodes with available pods: 2
Mar 13 09:53:53.125: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6598, will wait for the garbage collector to delete the pods
Mar 13 09:53:53.181: INFO: Deleting DaemonSet.extensions daemon-set took: 2.908063ms
Mar 13 09:53:53.582: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.242658ms
Mar 13 09:54:02.084: INFO: Number of nodes with available pods: 0
Mar 13 09:54:02.084: INFO: Number of running nodes: 0, number of available pods: 0
Mar 13 09:54:02.085: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6598/daemonsets","resourceVersion":"55480"},"items":null}

Mar 13 09:54:02.087: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6598/pods","resourceVersion":"55480"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:54:02.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6598" for this suite.

• [SLOW TEST:20.020 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":280,"completed":144,"skipped":2436,"failed":0}
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:54:02.098: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 13 09:54:06.132: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 13 09:54:06.134: INFO: Pod pod-with-prestop-http-hook still exists
Mar 13 09:54:08.135: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 13 09:54:08.137: INFO: Pod pod-with-prestop-http-hook still exists
Mar 13 09:54:10.135: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 13 09:54:10.137: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:54:10.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5990" for this suite.

• [SLOW TEST:8.055 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":280,"completed":145,"skipped":2436,"failed":0}
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:54:10.153: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:54:10.172: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 13 09:54:15.174: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 13 09:54:15.174: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 13 09:54:15.182: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9420 /apis/apps/v1/namespaces/deployment-9420/deployments/test-cleanup-deployment 12b2743e-cc31-4476-8320-f504a32978af 55586 1 2020-03-13 09:54:15 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005903898 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Mar 13 09:54:15.184: INFO: New ReplicaSet "test-cleanup-deployment-55ffc6b7b6" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6  deployment-9420 /apis/apps/v1/namespaces/deployment-9420/replicasets/test-cleanup-deployment-55ffc6b7b6 ebc5e072-803b-47ab-9563-443bd2aa5fce 55590 1 2020-03-13 09:54:15 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 12b2743e-cc31-4476-8320-f504a32978af 0xc005903cb7 0xc005903cb8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55ffc6b7b6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005903d28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:54:15.184: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 13 09:54:15.184: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9420 /apis/apps/v1/namespaces/deployment-9420/replicasets/test-cleanup-controller 1646e24b-cdef-481f-bf15-d8385a6d237b 55588 1 2020-03-13 09:54:10 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 12b2743e-cc31-4476-8320-f504a32978af 0xc005903be7 0xc005903be8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005903c48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:54:15.186: INFO: Pod "test-cleanup-controller-qkwmq" is available:
&Pod{ObjectMeta:{test-cleanup-controller-qkwmq test-cleanup-controller- deployment-9420 /api/v1/namespaces/deployment-9420/pods/test-cleanup-controller-qkwmq 187a69ad-1ade-407e-9e1a-bae935249c92 55573 0 2020-03-13 09:54:10 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.42.0.51/32] [{apps/v1 ReplicaSet test-cleanup-controller 1646e24b-cdef-481f-bf15-d8385a6d237b 0xc005954297 0xc005954298}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nnffm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nnffm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nnffm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:54:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:54:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:54:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:54:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:10.42.0.51,StartTime:2020-03-13 09:54:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:54:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6bb5428652a444742b1e21c56e3c59e08f715c97f52cd6ca0f553bc63a69a06c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 13 09:54:15.186: INFO: Pod "test-cleanup-deployment-55ffc6b7b6-qbrbd" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6-qbrbd test-cleanup-deployment-55ffc6b7b6- deployment-9420 /api/v1/namespaces/deployment-9420/pods/test-cleanup-deployment-55ffc6b7b6-qbrbd 26772834-c126-4e7c-a4d5-d3d51c5b8e51 55593 0 2020-03-13 09:54:15 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-55ffc6b7b6 ebc5e072-803b-47ab-9563-443bd2aa5fce 0xc005954417 0xc005954418}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nnffm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nnffm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nnffm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:54:15.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9420" for this suite.

• [SLOW TEST:5.038 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":280,"completed":146,"skipped":2436,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:54:15.191: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 13 09:54:15.209: INFO: Waiting up to 5m0s for pod "pod-38674066-0d20-4d0c-a90c-91463f69f620" in namespace "emptydir-5967" to be "success or failure"
Mar 13 09:54:15.210: INFO: Pod "pod-38674066-0d20-4d0c-a90c-91463f69f620": Phase="Pending", Reason="", readiness=false. Elapsed: 1.253474ms
Mar 13 09:54:17.212: INFO: Pod "pod-38674066-0d20-4d0c-a90c-91463f69f620": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003641966s
Mar 13 09:54:19.215: INFO: Pod "pod-38674066-0d20-4d0c-a90c-91463f69f620": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005817338s
Mar 13 09:54:21.217: INFO: Pod "pod-38674066-0d20-4d0c-a90c-91463f69f620": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008076445s
STEP: Saw pod success
Mar 13 09:54:21.217: INFO: Pod "pod-38674066-0d20-4d0c-a90c-91463f69f620" satisfied condition "success or failure"
Mar 13 09:54:21.218: INFO: Trying to get logs from node 172.24.5.5 pod pod-38674066-0d20-4d0c-a90c-91463f69f620 container test-container: <nil>
STEP: delete the pod
Mar 13 09:54:21.230: INFO: Waiting for pod pod-38674066-0d20-4d0c-a90c-91463f69f620 to disappear
Mar 13 09:54:21.231: INFO: Pod pod-38674066-0d20-4d0c-a90c-91463f69f620 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:54:21.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5967" for this suite.

• [SLOW TEST:6.046 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":147,"skipped":2438,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:54:21.236: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 13 09:54:25.275: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 13 09:54:25.277: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 13 09:54:27.277: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 13 09:54:27.279: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 13 09:54:29.277: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 13 09:54:29.279: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:54:29.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8052" for this suite.

• [SLOW TEST:8.047 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":280,"completed":148,"skipped":2453,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:54:29.284: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:54:58.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-280" for this suite.
STEP: Destroying namespace "nsdeletetest-7484" for this suite.
Mar 13 09:54:58.346: INFO: Namespace nsdeletetest-7484 was already deleted
STEP: Destroying namespace "nsdeletetest-5650" for this suite.

• [SLOW TEST:29.064 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":280,"completed":149,"skipped":2463,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:54:58.348: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2a314fd9-8d9d-424e-bd28-a20e032e577a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-2a314fd9-8d9d-424e-bd28-a20e032e577a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:04.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9763" for this suite.

• [SLOW TEST:6.058 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":150,"skipped":2466,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:04.407: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting the proxy server
Mar 13 09:55:04.423: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-141385212 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:04.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9682" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":280,"completed":151,"skipped":2478,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:04.503: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-acff3114-55eb-42a2-a318-87ffc73bf954
STEP: Creating a pod to test consume configMaps
Mar 13 09:55:04.525: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf" in namespace "projected-3365" to be "success or failure"
Mar 13 09:55:04.526: INFO: Pod "pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.551148ms
Mar 13 09:55:06.528: INFO: Pod "pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003431139s
STEP: Saw pod success
Mar 13 09:55:06.528: INFO: Pod "pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf" satisfied condition "success or failure"
Mar 13 09:55:06.530: INFO: Trying to get logs from node 172.24.5.5 pod pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 09:55:06.540: INFO: Waiting for pod pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf to disappear
Mar 13 09:55:06.541: INFO: Pod pod-projected-configmaps-074a7208-085c-4ecf-a4e6-2126b13425cf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:06.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3365" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":280,"completed":152,"skipped":2488,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:06.545: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-mm42
STEP: Creating a pod to test atomic-volume-subpath
Mar 13 09:55:06.568: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mm42" in namespace "subpath-5220" to be "success or failure"
Mar 13 09:55:06.569: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Pending", Reason="", readiness=false. Elapsed: 1.349683ms
Mar 13 09:55:08.571: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 2.00331833s
Mar 13 09:55:10.573: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 4.005349422s
Mar 13 09:55:12.575: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 6.007389828s
Mar 13 09:55:14.577: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 8.00929498s
Mar 13 09:55:16.579: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 10.011293487s
Mar 13 09:55:18.581: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 12.013444054s
Mar 13 09:55:20.583: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 14.015568353s
Mar 13 09:55:22.585: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 16.017873487s
Mar 13 09:55:24.587: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 18.019745808s
Mar 13 09:55:26.589: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Running", Reason="", readiness=true. Elapsed: 20.021539305s
Mar 13 09:55:28.591: INFO: Pod "pod-subpath-test-configmap-mm42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.023429424s
STEP: Saw pod success
Mar 13 09:55:28.591: INFO: Pod "pod-subpath-test-configmap-mm42" satisfied condition "success or failure"
Mar 13 09:55:28.593: INFO: Trying to get logs from node 172.24.5.5 pod pod-subpath-test-configmap-mm42 container test-container-subpath-configmap-mm42: <nil>
STEP: delete the pod
Mar 13 09:55:28.603: INFO: Waiting for pod pod-subpath-test-configmap-mm42 to disappear
Mar 13 09:55:28.604: INFO: Pod pod-subpath-test-configmap-mm42 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mm42
Mar 13 09:55:28.604: INFO: Deleting pod "pod-subpath-test-configmap-mm42" in namespace "subpath-5220"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:28.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5220" for this suite.

• [SLOW TEST:22.064 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":280,"completed":153,"skipped":2496,"failed":0}
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:28.610: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-2384
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 13 09:55:28.626: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 13 09:55:46.659: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.126:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2384 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:55:46.659: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:55:46.784: INFO: Found all expected endpoints: [netserver-0]
Mar 13 09:55:46.785: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.55:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2384 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 09:55:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:55:46.889: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:46.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2384" for this suite.

• [SLOW TEST:18.284 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":154,"skipped":2496,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:46.894: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run default
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1596
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 09:55:46.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9832'
Mar 13 09:55:47.009: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 13 09:55:47.009: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1602
Mar 13 09:55:47.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9832'
Mar 13 09:55:47.090: INFO: stderr: ""
Mar 13 09:55:47.090: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:47.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9832" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run default should create an rc or deployment from an image  [Conformance]","total":280,"completed":155,"skipped":2512,"failed":0}
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:47.094: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
Mar 13 09:55:47.619: INFO: created pod pod-service-account-defaultsa
Mar 13 09:55:47.619: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 13 09:55:47.621: INFO: created pod pod-service-account-mountsa
Mar 13 09:55:47.621: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 13 09:55:47.623: INFO: created pod pod-service-account-nomountsa
Mar 13 09:55:47.623: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 13 09:55:47.625: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 13 09:55:47.625: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 13 09:55:47.626: INFO: created pod pod-service-account-mountsa-mountspec
Mar 13 09:55:47.626: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 13 09:55:47.628: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 13 09:55:47.628: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 13 09:55:47.630: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 13 09:55:47.630: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 13 09:55:47.632: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 13 09:55:47.632: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 13 09:55:47.633: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 13 09:55:47.634: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:47.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1356" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":280,"completed":156,"skipped":2517,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:47.638: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 13 09:55:54.214: INFO: Successfully updated pod "annotationupdate0e98e0bb-57ef-4290-a362-e3245c528e4c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:56.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2163" for this suite.

• [SLOW TEST:8.592 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":157,"skipped":2526,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:56.230: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:55:56.249: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1" in namespace "downward-api-5925" to be "success or failure"
Mar 13 09:55:56.250: INFO: Pod "downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.386294ms
Mar 13 09:55:58.253: INFO: Pod "downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003693865s
STEP: Saw pod success
Mar 13 09:55:58.253: INFO: Pod "downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1" satisfied condition "success or failure"
Mar 13 09:55:58.254: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1 container client-container: <nil>
STEP: delete the pod
Mar 13 09:55:58.262: INFO: Waiting for pod downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1 to disappear
Mar 13 09:55:58.264: INFO: Pod downwardapi-volume-72a5dbe7-6196-44bc-94ea-88723e5501c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:55:58.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5925" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":158,"skipped":2544,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:55:58.268: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:55:58.288: INFO: Waiting up to 5m0s for pod "downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae" in namespace "projected-5464" to be "success or failure"
Mar 13 09:55:58.290: INFO: Pod "downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae": Phase="Pending", Reason="", readiness=false. Elapsed: 1.286231ms
Mar 13 09:56:00.292: INFO: Pod "downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003661996s
STEP: Saw pod success
Mar 13 09:56:00.292: INFO: Pod "downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae" satisfied condition "success or failure"
Mar 13 09:56:00.294: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae container client-container: <nil>
STEP: delete the pod
Mar 13 09:56:00.302: INFO: Waiting for pod downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae to disappear
Mar 13 09:56:00.304: INFO: Pod downwardapi-volume-915a34cc-133b-4094-9019-c999224e63ae no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:00.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5464" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":159,"skipped":2548,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:00.309: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:56:00.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1" in namespace "downward-api-266" to be "success or failure"
Mar 13 09:56:00.329: INFO: Pod "downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.264367ms
Mar 13 09:56:02.331: INFO: Pod "downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003733283s
STEP: Saw pod success
Mar 13 09:56:02.331: INFO: Pod "downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1" satisfied condition "success or failure"
Mar 13 09:56:02.333: INFO: Trying to get logs from node 172.24.5.5 pod downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1 container client-container: <nil>
STEP: delete the pod
Mar 13 09:56:02.343: INFO: Waiting for pod downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1 to disappear
Mar 13 09:56:02.345: INFO: Pod downwardapi-volume-c5ae929f-cce0-4044-ae9a-09359dc1e8c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:02.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-266" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":280,"completed":160,"skipped":2549,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:02.349: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 13 09:56:02.368: INFO: Waiting up to 5m0s for pod "pod-a0cc34be-7502-468b-a1cd-0381eb0b815f" in namespace "emptydir-7050" to be "success or failure"
Mar 13 09:56:02.370: INFO: Pod "pod-a0cc34be-7502-468b-a1cd-0381eb0b815f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.296236ms
Mar 13 09:56:04.372: INFO: Pod "pod-a0cc34be-7502-468b-a1cd-0381eb0b815f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003557881s
STEP: Saw pod success
Mar 13 09:56:04.372: INFO: Pod "pod-a0cc34be-7502-468b-a1cd-0381eb0b815f" satisfied condition "success or failure"
Mar 13 09:56:04.373: INFO: Trying to get logs from node 172.24.5.5 pod pod-a0cc34be-7502-468b-a1cd-0381eb0b815f container test-container: <nil>
STEP: delete the pod
Mar 13 09:56:04.384: INFO: Waiting for pod pod-a0cc34be-7502-468b-a1cd-0381eb0b815f to disappear
Mar 13 09:56:04.385: INFO: Pod pod-a0cc34be-7502-468b-a1cd-0381eb0b815f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:04.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7050" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":161,"skipped":2554,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:04.390: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-4875/configmap-test-1cad8fbc-98db-4218-a0dc-00fcc9b8a23c
STEP: Creating a pod to test consume configMaps
Mar 13 09:56:04.412: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1" in namespace "configmap-4875" to be "success or failure"
Mar 13 09:56:04.413: INFO: Pod "pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.248189ms
Mar 13 09:56:06.415: INFO: Pod "pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00346457s
STEP: Saw pod success
Mar 13 09:56:06.415: INFO: Pod "pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1" satisfied condition "success or failure"
Mar 13 09:56:06.417: INFO: Trying to get logs from node 172.24.5.5 pod pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1 container env-test: <nil>
STEP: delete the pod
Mar 13 09:56:06.427: INFO: Waiting for pod pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1 to disappear
Mar 13 09:56:06.428: INFO: Pod pod-configmaps-2ccd54c6-6f24-4bd4-b645-329d401420c1 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:06.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4875" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":162,"skipped":2593,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:06.432: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:56:06.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae" in namespace "projected-549" to be "success or failure"
Mar 13 09:56:06.453: INFO: Pod "downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae": Phase="Pending", Reason="", readiness=false. Elapsed: 1.311463ms
Mar 13 09:56:08.455: INFO: Pod "downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003720653s
STEP: Saw pod success
Mar 13 09:56:08.455: INFO: Pod "downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae" satisfied condition "success or failure"
Mar 13 09:56:08.457: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae container client-container: <nil>
STEP: delete the pod
Mar 13 09:56:08.465: INFO: Waiting for pod downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae to disappear
Mar 13 09:56:08.467: INFO: Pod downwardapi-volume-14ba6a00-1d43-4a2e-8b5a-f35df0a39bae no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:08.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-549" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":163,"skipped":2601,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:08.471: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Mar 13 09:56:08.489: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Mar 13 09:56:19.638: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 09:56:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:31.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-641" for this suite.

• [SLOW TEST:23.226 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":280,"completed":164,"skipped":2633,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:31.698: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:33.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1348" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":165,"skipped":2663,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:33.730: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:56:33.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725" in namespace "downward-api-6374" to be "success or failure"
Mar 13 09:56:33.750: INFO: Pod "downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725": Phase="Pending", Reason="", readiness=false. Elapsed: 1.501764ms
Mar 13 09:56:35.752: INFO: Pod "downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003538334s
STEP: Saw pod success
Mar 13 09:56:35.752: INFO: Pod "downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725" satisfied condition "success or failure"
Mar 13 09:56:35.754: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725 container client-container: <nil>
STEP: delete the pod
Mar 13 09:56:35.762: INFO: Waiting for pod downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725 to disappear
Mar 13 09:56:35.763: INFO: Pod downwardapi-volume-fc0e6c26-774b-446e-b8c6-e29e06a8b725 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:35.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6374" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":166,"skipped":2670,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:35.767: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name secret-emptykey-test-e329f017-a476-408b-b424-5ea65d3dcfd4
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:35.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-202" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":280,"completed":167,"skipped":2710,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:35.788: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8171 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8171;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8171 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8171;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8171.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8171.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8171.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8171.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8171.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 208.160.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.160.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.160.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.160.208_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8171 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8171;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8171 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8171;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8171.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8171.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8171.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8171.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8171.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8171.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8171.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8171.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 208.160.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.160.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.160.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.160.208_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 09:56:37.820: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.822: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.824: INFO: Unable to read wheezy_udp@dns-test-service.dns-8171 from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.827: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8171 from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.829: INFO: Unable to read wheezy_udp@dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.830: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.832: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.834: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.836: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.837: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.839: INFO: Unable to read wheezy_udp@PodARecord from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.841: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.843: INFO: Unable to read 10.43.160.208_udp@PTR from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.844: INFO: Unable to read 10.43.160.208_tcp@PTR from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.846: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.848: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.850: INFO: Unable to read jessie_udp@dns-test-service.dns-8171 from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.852: INFO: Unable to read jessie_tcp@dns-test-service.dns-8171 from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.854: INFO: Unable to read jessie_udp@dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.856: INFO: Unable to read jessie_tcp@dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.857: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.859: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.861: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.863: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.864: INFO: Unable to read jessie_udp@PodARecord from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.866: INFO: Unable to read jessie_tcp@PodARecord from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.868: INFO: Unable to read 10.43.160.208_udp@PTR from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.870: INFO: Unable to read 10.43.160.208_tcp@PTR from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:37.870: INFO: Lookups using dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8171 wheezy_tcp@dns-test-service.dns-8171 wheezy_udp@dns-test-service.dns-8171.svc wheezy_tcp@dns-test-service.dns-8171.svc wheezy_udp@_http._tcp.dns-test-service.dns-8171.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8171.svc wheezy_udp@_http._tcp.test-service-2.dns-8171.svc wheezy_tcp@_http._tcp.test-service-2.dns-8171.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.43.160.208_udp@PTR 10.43.160.208_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8171 jessie_tcp@dns-test-service.dns-8171 jessie_udp@dns-test-service.dns-8171.svc jessie_tcp@dns-test-service.dns-8171.svc jessie_udp@_http._tcp.dns-test-service.dns-8171.svc jessie_tcp@_http._tcp.dns-test-service.dns-8171.svc jessie_udp@_http._tcp.test-service-2.dns-8171.svc jessie_tcp@_http._tcp.test-service-2.dns-8171.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.43.160.208_udp@PTR 10.43.160.208_tcp@PTR]

Mar 13 09:56:42.873: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.875: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.877: INFO: Unable to read wheezy_udp@dns-test-service.dns-8171 from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.878: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8171 from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.880: INFO: Unable to read wheezy_udp@dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.882: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.884: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.885: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.887: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.889: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-8171.svc from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.891: INFO: Unable to read wheezy_udp@PodARecord from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.893: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.898: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.899: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6: the server could not find the requested resource (get pods dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6)
Mar 13 09:56:42.919: INFO: Lookups using dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8171 wheezy_tcp@dns-test-service.dns-8171 wheezy_udp@dns-test-service.dns-8171.svc wheezy_tcp@dns-test-service.dns-8171.svc wheezy_udp@_http._tcp.dns-test-service.dns-8171.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8171.svc wheezy_udp@_http._tcp.test-service-2.dns-8171.svc wheezy_tcp@_http._tcp.test-service-2.dns-8171.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service]

Mar 13 09:56:47.921: INFO: DNS probes using dns-8171/dns-test-95271644-7f6f-4dd2-ba7c-b257a973d1a6 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:47.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8171" for this suite.

• [SLOW TEST:12.152 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":280,"completed":168,"skipped":2719,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:47.940: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:56:47.961: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf" in namespace "projected-912" to be "success or failure"
Mar 13 09:56:47.962: INFO: Pod "downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.522502ms
Mar 13 09:56:49.964: INFO: Pod "downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003700647s
STEP: Saw pod success
Mar 13 09:56:49.964: INFO: Pod "downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf" satisfied condition "success or failure"
Mar 13 09:56:49.966: INFO: Trying to get logs from node 172.24.5.5 pod downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf container client-container: <nil>
STEP: delete the pod
Mar 13 09:56:49.976: INFO: Waiting for pod downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf to disappear
Mar 13 09:56:49.977: INFO: Pod downwardapi-volume-d7889cd5-d06b-4a13-bf61-3e1f65ac49bf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:49.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-912" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":169,"skipped":2733,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:49.982: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5206
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5206
I0313 09:56:50.007894      26 runners.go:189] Created replication controller with name: externalname-service, namespace: services-5206, replica count: 2
Mar 13 09:56:53.058: INFO: Creating new exec pod
I0313 09:56:53.058377      26 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 13 09:56:56.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-5206 execpodzfvww -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar 13 09:56:56.345: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar 13 09:56:56.345: INFO: stdout: ""
Mar 13 09:56:56.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-5206 execpodzfvww -- /bin/sh -x -c nc -zv -t -w 2 10.43.114.73 80'
Mar 13 09:56:56.590: INFO: stderr: "+ nc -zv -t -w 2 10.43.114.73 80\nConnection to 10.43.114.73 80 port [tcp/http] succeeded!\n"
Mar 13 09:56:56.590: INFO: stdout: ""
Mar 13 09:56:56.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-5206 execpodzfvww -- /bin/sh -x -c nc -zv -t -w 2 172.24.5.5 32368'
Mar 13 09:56:56.822: INFO: stderr: "+ nc -zv -t -w 2 172.24.5.5 32368\nConnection to 172.24.5.5 32368 port [tcp/32368] succeeded!\n"
Mar 13 09:56:56.822: INFO: stdout: ""
Mar 13 09:56:56.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=services-5206 execpodzfvww -- /bin/sh -x -c nc -zv -t -w 2 172.24.5.7 32368'
Mar 13 09:56:57.077: INFO: stderr: "+ nc -zv -t -w 2 172.24.5.7 32368\nConnection to 172.24.5.7 32368 port [tcp/32368] succeeded!\n"
Mar 13 09:56:57.077: INFO: stdout: ""
Mar 13 09:56:57.077: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:56:57.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5206" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:7.107 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":280,"completed":170,"skipped":2743,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:56:57.089: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:56:57.591: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:57:00.600: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:57:00.602: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1750-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:01.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6584" for this suite.
STEP: Destroying namespace "webhook-6584-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":280,"completed":171,"skipped":2744,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:01.755: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:57:01.774: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 13 09:57:06.776: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 13 09:57:06.776: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 13 09:57:08.778: INFO: Creating deployment "test-rollover-deployment"
Mar 13 09:57:08.782: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 13 09:57:10.785: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 13 09:57:10.788: INFO: Ensure that both replica sets have 1 created replica
Mar 13 09:57:10.792: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 13 09:57:10.795: INFO: Updating deployment test-rollover-deployment
Mar 13 09:57:10.795: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 13 09:57:12.799: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 13 09:57:12.802: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 13 09:57:12.806: INFO: all replica sets need to contain the pod-template-hash label
Mar 13 09:57:12.806: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690232, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:57:14.810: INFO: all replica sets need to contain the pod-template-hash label
Mar 13 09:57:14.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690232, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:57:16.810: INFO: all replica sets need to contain the pod-template-hash label
Mar 13 09:57:16.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690232, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:57:18.810: INFO: all replica sets need to contain the pod-template-hash label
Mar 13 09:57:18.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690232, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:57:20.810: INFO: all replica sets need to contain the pod-template-hash label
Mar 13 09:57:20.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690232, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690228, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 09:57:22.810: INFO: 
Mar 13 09:57:22.810: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 13 09:57:22.815: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7512 /apis/apps/v1/namespaces/deployment-7512/deployments/test-rollover-deployment bb8722e3-6ce3-4bf9-a62e-3f7435b7faae 57135 2 2020-03-13 09:57:08 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e02f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-13 09:57:08 +0000 UTC,LastTransitionTime:2020-03-13 09:57:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-574d6dfbff" has successfully progressed.,LastUpdateTime:2020-03-13 09:57:22 +0000 UTC,LastTransitionTime:2020-03-13 09:57:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar 13 09:57:22.817: INFO: New ReplicaSet "test-rollover-deployment-574d6dfbff" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-574d6dfbff  deployment-7512 /apis/apps/v1/namespaces/deployment-7512/replicasets/test-rollover-deployment-574d6dfbff 8e5aee1b-dd5c-4156-a08e-d4139d9e3d1e 57124 2 2020-03-13 09:57:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment bb8722e3-6ce3-4bf9-a62e-3f7435b7faae 0xc005e03427 0xc005e03428}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 574d6dfbff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e034a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:57:22.817: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 13 09:57:22.817: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7512 /apis/apps/v1/namespaces/deployment-7512/replicasets/test-rollover-controller b226795d-8eee-4f25-b46c-776b899ee7cc 57134 2 2020-03-13 09:57:01 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment bb8722e3-6ce3-4bf9-a62e-3f7435b7faae 0xc005e03347 0xc005e03348}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005e033b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:57:22.817: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-7512 /apis/apps/v1/namespaces/deployment-7512/replicasets/test-rollover-deployment-f6c94f66c d1fda338-54a8-483b-a037-4ec9a1fe3693 57079 2 2020-03-13 09:57:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment bb8722e3-6ce3-4bf9-a62e-3f7435b7faae 0xc005e03510 0xc005e03511}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e03588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:57:22.819: INFO: Pod "test-rollover-deployment-574d6dfbff-5xp2v" is available:
&Pod{ObjectMeta:{test-rollover-deployment-574d6dfbff-5xp2v test-rollover-deployment-574d6dfbff- deployment-7512 /api/v1/namespaces/deployment-7512/pods/test-rollover-deployment-574d6dfbff-5xp2v 98a89f28-4798-4419-9580-eea5f4c09546 57094 0 2020-03-13 09:57:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[cni.projectcalico.org/podIP:10.42.1.140/32] [{apps/v1 ReplicaSet test-rollover-deployment-574d6dfbff 8e5aee1b-dd5c-4156-a08e-d4139d9e3d1e 0xc005e03c17 0xc005e03c18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lk7xn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lk7xn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lk7xn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.5,PodIP:10.42.1.140,StartTime:2020-03-13 09:57:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:57:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://fb904d646165332bf6be20911b5b214a588d166b52f3d7273ec7c7bfae8fa3bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.1.140,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:22.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7512" for this suite.

• [SLOW TEST:21.069 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":280,"completed":172,"skipped":2770,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:22.824: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:57:22.841: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:24.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-177" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":280,"completed":173,"skipped":2791,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:24.865: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-72zb
STEP: Creating a pod to test atomic-volume-subpath
Mar 13 09:57:24.887: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-72zb" in namespace "subpath-3832" to be "success or failure"
Mar 13 09:57:24.889: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.344673ms
Mar 13 09:57:26.891: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 2.003619126s
Mar 13 09:57:28.893: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 4.005771383s
Mar 13 09:57:30.895: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 6.007832703s
Mar 13 09:57:32.897: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 8.009621064s
Mar 13 09:57:34.899: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 10.011729305s
Mar 13 09:57:36.901: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 12.013818736s
Mar 13 09:57:38.903: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 14.015640571s
Mar 13 09:57:40.905: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 16.01758891s
Mar 13 09:57:42.907: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 18.019470301s
Mar 13 09:57:44.909: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Running", Reason="", readiness=true. Elapsed: 20.021777782s
Mar 13 09:57:46.911: INFO: Pod "pod-subpath-test-configmap-72zb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.023804031s
STEP: Saw pod success
Mar 13 09:57:46.911: INFO: Pod "pod-subpath-test-configmap-72zb" satisfied condition "success or failure"
Mar 13 09:57:46.913: INFO: Trying to get logs from node 172.24.5.5 pod pod-subpath-test-configmap-72zb container test-container-subpath-configmap-72zb: <nil>
STEP: delete the pod
Mar 13 09:57:46.923: INFO: Waiting for pod pod-subpath-test-configmap-72zb to disappear
Mar 13 09:57:46.924: INFO: Pod pod-subpath-test-configmap-72zb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-72zb
Mar 13 09:57:46.924: INFO: Deleting pod "pod-subpath-test-configmap-72zb" in namespace "subpath-3832"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:46.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3832" for this suite.

• [SLOW TEST:22.065 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":280,"completed":174,"skipped":2833,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:46.930: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:51.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7428" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":280,"completed":175,"skipped":2838,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:51.635: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 13 09:57:53.662: INFO: &Pod{ObjectMeta:{send-events-51ec3fe4-f545-40f7-a0ae-a3ee1f64c0f6  events-4051 /api/v1/namespaces/events-4051/pods/send-events-51ec3fe4-f545-40f7-a0ae-a3ee1f64c0f6 7ed1d1bf-f6ce-4ab1-99fa-ad4fc4f162a9 57419 0 2020-03-13 09:57:51 +0000 UTC <nil> <nil> map[name:foo time:652824907] map[cni.projectcalico.org/podIP:10.42.0.72/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gql54,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gql54,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gql54,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:57:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:10.42.0.72,StartTime:2020-03-13 09:57:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-13 09:57:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://e6583ac13f9038a1bae0d0d65414577b0c84617206f1c56c0035b4ad52469599,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.42.0.72,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Mar 13 09:57:55.665: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 13 09:57:57.667: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:57.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4051" for this suite.

• [SLOW TEST:6.039 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":280,"completed":176,"skipped":2850,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:57.674: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 13 09:57:57.693: INFO: Waiting up to 5m0s for pod "pod-48acabba-f39b-4286-8f82-bf4f570ce4b3" in namespace "emptydir-496" to be "success or failure"
Mar 13 09:57:57.695: INFO: Pod "pod-48acabba-f39b-4286-8f82-bf4f570ce4b3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.483927ms
Mar 13 09:57:59.697: INFO: Pod "pod-48acabba-f39b-4286-8f82-bf4f570ce4b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003336683s
STEP: Saw pod success
Mar 13 09:57:59.697: INFO: Pod "pod-48acabba-f39b-4286-8f82-bf4f570ce4b3" satisfied condition "success or failure"
Mar 13 09:57:59.698: INFO: Trying to get logs from node 172.24.5.7 pod pod-48acabba-f39b-4286-8f82-bf4f570ce4b3 container test-container: <nil>
STEP: delete the pod
Mar 13 09:57:59.706: INFO: Waiting for pod pod-48acabba-f39b-4286-8f82-bf4f570ce4b3 to disappear
Mar 13 09:57:59.708: INFO: Pod pod-48acabba-f39b-4286-8f82-bf4f570ce4b3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:57:59.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-496" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":177,"skipped":2872,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:57:59.712: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:05.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9619" for this suite.
STEP: Destroying namespace "nsdeletetest-2525" for this suite.
Mar 13 09:58:05.768: INFO: Namespace nsdeletetest-2525 was already deleted
STEP: Destroying namespace "nsdeletetest-9470" for this suite.

• [SLOW TEST:6.058 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":280,"completed":178,"skipped":2891,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:05.771: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 09:58:06.539: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 09:58:09.548: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Mar 13 09:58:11.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 attach --namespace=webhook-2422 to-be-attached-pod -i -c=container1'
Mar 13 09:58:11.670: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:11.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2422" for this suite.
STEP: Destroying namespace "webhook-2422-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.921 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":280,"completed":179,"skipped":2931,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:11.692: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 09:58:11.709: INFO: Creating deployment "test-recreate-deployment"
Mar 13 09:58:11.711: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 13 09:58:11.713: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 13 09:58:13.717: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 13 09:58:13.719: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 13 09:58:13.722: INFO: Updating deployment test-recreate-deployment
Mar 13 09:58:13.722: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 13 09:58:13.741: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-514 /apis/apps/v1/namespaces/deployment-514/deployments/test-recreate-deployment 934fe1f0-501c-4196-8912-6bd223db019c 57662 2 2020-03-13 09:58:11 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004c154b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-13 09:58:13 +0000 UTC,LastTransitionTime:2020-03-13 09:58:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-03-13 09:58:13 +0000 UTC,LastTransitionTime:2020-03-13 09:58:11 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Mar 13 09:58:13.744: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-514 /apis/apps/v1/namespaces/deployment-514/replicasets/test-recreate-deployment-5f94c574ff 8e7773c0-5a58-4373-8612-98a60ff0d57b 57659 1 2020-03-13 09:58:13 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 934fe1f0-501c-4196-8912-6bd223db019c 0xc004c15867 0xc004c15868}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004c158c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:58:13.744: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 13 09:58:13.744: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-799c574856  deployment-514 /apis/apps/v1/namespaces/deployment-514/replicasets/test-recreate-deployment-799c574856 b5e9c59e-19c8-4327-ab71-60f902ce10d2 57651 2 2020-03-13 09:58:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 934fe1f0-501c-4196-8912-6bd223db019c 0xc004c15937 0xc004c15938}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 799c574856,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004c159a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 13 09:58:13.746: INFO: Pod "test-recreate-deployment-5f94c574ff-lcgpd" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-lcgpd test-recreate-deployment-5f94c574ff- deployment-514 /api/v1/namespaces/deployment-514/pods/test-recreate-deployment-5f94c574ff-lcgpd 08a9eded-9e6e-45ce-b23d-5ace1c303ae3 57663 0 2020-03-13 09:58:13 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 8e7773c0-5a58-4373-8612-98a60ff0d57b 0xc004c15e27 0xc004c15e28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sx7l6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sx7l6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sx7l6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.24.5.7,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:58:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:58:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:58:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-13 09:58:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.24.5.7,PodIP:,StartTime:2020-03-13 09:58:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:13.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-514" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":180,"skipped":2932,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:13.750: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-projected-all-test-volume-ce84949f-9185-4556-bf56-cea0a5bc04d3
STEP: Creating secret with name secret-projected-all-test-volume-23e7f5e7-6d3c-4586-951c-a3069374120b
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 13 09:58:13.773: INFO: Waiting up to 5m0s for pod "projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe" in namespace "projected-178" to be "success or failure"
Mar 13 09:58:13.774: INFO: Pod "projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe": Phase="Pending", Reason="", readiness=false. Elapsed: 1.398213ms
Mar 13 09:58:15.776: INFO: Pod "projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003384649s
STEP: Saw pod success
Mar 13 09:58:15.776: INFO: Pod "projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe" satisfied condition "success or failure"
Mar 13 09:58:15.778: INFO: Trying to get logs from node 172.24.5.7 pod projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 13 09:58:15.786: INFO: Waiting for pod projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe to disappear
Mar 13 09:58:15.787: INFO: Pod projected-volume-c843c338-a9c4-44a5-b6ae-24f4c39adbbe no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:15.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-178" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":280,"completed":181,"skipped":2939,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:15.791: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:28.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-183" for this suite.

• [SLOW TEST:13.046 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":280,"completed":182,"skipped":2941,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:28.838: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:58:28.857: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060" in namespace "downward-api-6472" to be "success or failure"
Mar 13 09:58:28.858: INFO: Pod "downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060": Phase="Pending", Reason="", readiness=false. Elapsed: 1.415227ms
Mar 13 09:58:30.861: INFO: Pod "downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003420139s
STEP: Saw pod success
Mar 13 09:58:30.861: INFO: Pod "downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060" satisfied condition "success or failure"
Mar 13 09:58:30.862: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060 container client-container: <nil>
STEP: delete the pod
Mar 13 09:58:30.870: INFO: Waiting for pod downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060 to disappear
Mar 13 09:58:30.872: INFO: Pod downwardapi-volume-bdf68627-0e94-453c-ba7c-d39c5b86c060 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:30.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6472" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":183,"skipped":2950,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:30.876: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:330
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the initial replication controller
Mar 13 09:58:30.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-6682'
Mar 13 09:58:31.106: INFO: stderr: ""
Mar 13 09:58:31.106: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 13 09:58:31.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6682'
Mar 13 09:58:31.191: INFO: stderr: ""
Mar 13 09:58:31.191: INFO: stdout: "update-demo-nautilus-2vvt7 update-demo-nautilus-whrkw "
Mar 13 09:58:31.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-2vvt7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:31.273: INFO: stderr: ""
Mar 13 09:58:31.274: INFO: stdout: ""
Mar 13 09:58:31.274: INFO: update-demo-nautilus-2vvt7 is created but not running
Mar 13 09:58:36.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6682'
Mar 13 09:58:36.357: INFO: stderr: ""
Mar 13 09:58:36.357: INFO: stdout: "update-demo-nautilus-2vvt7 update-demo-nautilus-whrkw "
Mar 13 09:58:36.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-2vvt7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:36.434: INFO: stderr: ""
Mar 13 09:58:36.434: INFO: stdout: "true"
Mar 13 09:58:36.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-2vvt7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:36.513: INFO: stderr: ""
Mar 13 09:58:36.513: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 09:58:36.513: INFO: validating pod update-demo-nautilus-2vvt7
Mar 13 09:58:36.516: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 09:58:36.516: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 09:58:36.516: INFO: update-demo-nautilus-2vvt7 is verified up and running
Mar 13 09:58:36.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-whrkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:36.592: INFO: stderr: ""
Mar 13 09:58:36.592: INFO: stdout: "true"
Mar 13 09:58:36.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-whrkw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:36.666: INFO: stderr: ""
Mar 13 09:58:36.666: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 09:58:36.666: INFO: validating pod update-demo-nautilus-whrkw
Mar 13 09:58:36.668: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 09:58:36.668: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 09:58:36.668: INFO: update-demo-nautilus-whrkw is verified up and running
STEP: rolling-update to new replication controller
Mar 13 09:58:36.671: INFO: scanned /root for discovery docs: <nil>
Mar 13 09:58:36.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6682'
Mar 13 09:58:58.954: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 13 09:58:58.954: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 13 09:58:58.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6682'
Mar 13 09:58:59.045: INFO: stderr: ""
Mar 13 09:58:59.045: INFO: stdout: "update-demo-kitten-kmcs2 update-demo-kitten-rgg4l "
Mar 13 09:58:59.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-kitten-kmcs2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:59.118: INFO: stderr: ""
Mar 13 09:58:59.118: INFO: stdout: "true"
Mar 13 09:58:59.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-kitten-kmcs2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:59.193: INFO: stderr: ""
Mar 13 09:58:59.193: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 13 09:58:59.193: INFO: validating pod update-demo-kitten-kmcs2
Mar 13 09:58:59.196: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 13 09:58:59.196: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 13 09:58:59.196: INFO: update-demo-kitten-kmcs2 is verified up and running
Mar 13 09:58:59.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-kitten-rgg4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:59.283: INFO: stderr: ""
Mar 13 09:58:59.283: INFO: stdout: "true"
Mar 13 09:58:59.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-kitten-rgg4l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6682'
Mar 13 09:58:59.356: INFO: stderr: ""
Mar 13 09:58:59.356: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 13 09:58:59.356: INFO: validating pod update-demo-kitten-rgg4l
Mar 13 09:58:59.359: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 13 09:58:59.359: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 13 09:58:59.359: INFO: update-demo-kitten-rgg4l is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:58:59.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6682" for this suite.

• [SLOW TEST:28.488 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:328
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should do a rolling update of a replication controller  [Conformance]","total":280,"completed":184,"skipped":2964,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:58:59.364: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 09:58:59.385: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c" in namespace "downward-api-415" to be "success or failure"
Mar 13 09:58:59.386: INFO: Pod "downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.34615ms
Mar 13 09:59:01.388: INFO: Pod "downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003184427s
STEP: Saw pod success
Mar 13 09:59:01.388: INFO: Pod "downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c" satisfied condition "success or failure"
Mar 13 09:59:01.390: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c container client-container: <nil>
STEP: delete the pod
Mar 13 09:59:01.398: INFO: Waiting for pod downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c to disappear
Mar 13 09:59:01.399: INFO: Pod downwardapi-volume-5b927900-3cda-4fa1-b7dd-cc260078434c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 09:59:01.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-415" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":185,"skipped":2983,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 09:59:01.404: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-732
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Mar 13 09:59:01.426: INFO: Found 0 stateful pods, waiting for 3
Mar 13 09:59:11.429: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 09:59:11.429: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 09:59:11.429: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Mar 13 09:59:11.448: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 13 09:59:21.470: INFO: Updating stateful set ss2
Mar 13 09:59:21.474: INFO: Waiting for Pod statefulset-732/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Mar 13 09:59:31.487: INFO: Found 1 stateful pods, waiting for 3
Mar 13 09:59:41.489: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 09:59:41.489: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 09:59:41.489: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 13 09:59:41.507: INFO: Updating stateful set ss2
Mar 13 09:59:41.510: INFO: Waiting for Pod statefulset-732/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 09:59:51.529: INFO: Updating stateful set ss2
Mar 13 09:59:51.532: INFO: Waiting for StatefulSet statefulset-732/ss2 to complete update
Mar 13 09:59:51.532: INFO: Waiting for Pod statefulset-732/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 10:00:01.536: INFO: Waiting for StatefulSet statefulset-732/ss2 to complete update
Mar 13 10:00:01.536: INFO: Waiting for Pod statefulset-732/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 13 10:00:11.536: INFO: Deleting all statefulset in ns statefulset-732
Mar 13 10:00:11.538: INFO: Scaling statefulset ss2 to 0
Mar 13 10:00:31.545: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 10:00:31.547: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:00:31.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-732" for this suite.

• [SLOW TEST:90.152 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":280,"completed":186,"skipped":3019,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:00:31.557: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 10:00:31.576: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660" in namespace "projected-153" to be "success or failure"
Mar 13 10:00:31.578: INFO: Pod "downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660": Phase="Pending", Reason="", readiness=false. Elapsed: 1.413101ms
Mar 13 10:00:33.579: INFO: Pod "downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003167879s
STEP: Saw pod success
Mar 13 10:00:33.579: INFO: Pod "downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660" satisfied condition "success or failure"
Mar 13 10:00:33.581: INFO: Trying to get logs from node 172.24.5.7 pod downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660 container client-container: <nil>
STEP: delete the pod
Mar 13 10:00:33.596: INFO: Waiting for pod downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660 to disappear
Mar 13 10:00:33.597: INFO: Pod downwardapi-volume-5eab321f-f750-4834-9a0a-56aecfe28660 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:00:33.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-153" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":187,"skipped":3035,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:00:33.601: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:00:44.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-997" for this suite.

• [SLOW TEST:11.037 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":280,"completed":188,"skipped":3050,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:00:44.638: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:00:44.656: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Mar 13 10:00:47.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 create -f -'
Mar 13 10:00:47.788: INFO: stderr: ""
Mar 13 10:00:47.788: INFO: stdout: "e2e-test-crd-publish-openapi-6956-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar 13 10:00:47.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 delete e2e-test-crd-publish-openapi-6956-crds test-foo'
Mar 13 10:00:47.867: INFO: stderr: ""
Mar 13 10:00:47.867: INFO: stdout: "e2e-test-crd-publish-openapi-6956-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Mar 13 10:00:47.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 apply -f -'
Mar 13 10:00:48.007: INFO: stderr: ""
Mar 13 10:00:48.007: INFO: stdout: "e2e-test-crd-publish-openapi-6956-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar 13 10:00:48.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 delete e2e-test-crd-publish-openapi-6956-crds test-foo'
Mar 13 10:00:48.088: INFO: stderr: ""
Mar 13 10:00:48.088: INFO: stdout: "e2e-test-crd-publish-openapi-6956-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Mar 13 10:00:48.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 create -f -'
Mar 13 10:00:48.219: INFO: rc: 1
Mar 13 10:00:48.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 apply -f -'
Mar 13 10:00:48.351: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Mar 13 10:00:48.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 create -f -'
Mar 13 10:00:48.482: INFO: rc: 1
Mar 13 10:00:48.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-6054 apply -f -'
Mar 13 10:00:48.614: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Mar 13 10:00:48.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-6956-crds'
Mar 13 10:00:48.752: INFO: stderr: ""
Mar 13 10:00:48.752: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6956-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Mar 13 10:00:48.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-6956-crds.metadata'
Mar 13 10:00:48.885: INFO: stderr: ""
Mar 13 10:00:48.885: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6956-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Mar 13 10:00:48.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-6956-crds.spec'
Mar 13 10:00:49.015: INFO: stderr: ""
Mar 13 10:00:49.015: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6956-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Mar 13 10:00:49.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-6956-crds.spec.bars'
Mar 13 10:00:49.152: INFO: stderr: ""
Mar 13 10:00:49.152: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6956-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Mar 13 10:00:49.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-6956-crds.spec.bars2'
Mar 13 10:00:49.304: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:00:52.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6054" for this suite.

• [SLOW TEST:7.505 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":280,"completed":189,"skipped":3057,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:00:52.143: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1861
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 10:00:52.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9993'
Mar 13 10:00:52.250: INFO: stderr: ""
Mar 13 10:00:52.250: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1866
Mar 13 10:00:52.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete pods e2e-test-httpd-pod --namespace=kubectl-9993'
Mar 13 10:01:01.987: INFO: stderr: ""
Mar 13 10:01:01.987: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:01.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9993" for this suite.

• [SLOW TEST:9.847 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1857
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":280,"completed":190,"skipped":3059,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:01.991: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Mar 13 10:01:02.013: INFO: Created pod &Pod{ObjectMeta:{dns-8502  dns-8502 /api/v1/namespaces/dns-8502/pods/dns-8502 b024e541-ea90-435e-9cb8-69f576f14218 58742 0 2020-03-13 10:01:02 +0000 UTC <nil> <nil> map[] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6pt8q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6pt8q,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6pt8q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
STEP: Verifying customized DNS suffix list is configured on pod...
Mar 13 10:01:04.017: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8502 PodName:dns-8502 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:01:04.017: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Verifying customized DNS server is configured on pod...
Mar 13 10:01:04.147: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8502 PodName:dns-8502 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:01:04.147: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:01:04.254: INFO: Deleting pod dns-8502...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:04.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8502" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":280,"completed":191,"skipped":3076,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:04.264: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:01:04.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 version'
Mar 13 10:01:04.352: INFO: stderr: ""
Mar 13 10:01:04.352: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.2\", GitCommit:\"59603c6e503c87169aea6106f57b9f242f64df89\", GitTreeState:\"clean\", BuildDate:\"2020-01-18T23:30:10Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.2\", GitCommit:\"59603c6e503c87169aea6106f57b9f242f64df89\", GitTreeState:\"clean\", BuildDate:\"2020-01-18T23:22:30Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:04.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2377" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":280,"completed":192,"skipped":3091,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:04.357: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 13 10:01:06.383: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:06.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1196" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":193,"skipped":3120,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:06.393: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 13 10:01:06.412: INFO: Waiting up to 5m0s for pod "pod-338f5523-2fb8-430a-867d-adb97c281a92" in namespace "emptydir-878" to be "success or failure"
Mar 13 10:01:06.413: INFO: Pod "pod-338f5523-2fb8-430a-867d-adb97c281a92": Phase="Pending", Reason="", readiness=false. Elapsed: 1.35068ms
Mar 13 10:01:08.415: INFO: Pod "pod-338f5523-2fb8-430a-867d-adb97c281a92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003475063s
STEP: Saw pod success
Mar 13 10:01:08.415: INFO: Pod "pod-338f5523-2fb8-430a-867d-adb97c281a92" satisfied condition "success or failure"
Mar 13 10:01:08.417: INFO: Trying to get logs from node 172.24.5.5 pod pod-338f5523-2fb8-430a-867d-adb97c281a92 container test-container: <nil>
STEP: delete the pod
Mar 13 10:01:08.439: INFO: Waiting for pod pod-338f5523-2fb8-430a-867d-adb97c281a92 to disappear
Mar 13 10:01:08.440: INFO: Pod pod-338f5523-2fb8-430a-867d-adb97c281a92 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:08.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-878" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":194,"skipped":3127,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:08.444: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:01:08.827: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:01:11.835: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:11.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4050" for this suite.
STEP: Destroying namespace "webhook-4050-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":280,"completed":195,"skipped":3127,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:11.863: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:01:11.888: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 13 10:01:11.893: INFO: Number of nodes with available pods: 0
Mar 13 10:01:11.893: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 10:01:12.898: INFO: Number of nodes with available pods: 0
Mar 13 10:01:12.898: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 10:01:13.898: INFO: Number of nodes with available pods: 2
Mar 13 10:01:13.898: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 13 10:01:13.911: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:13.911: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:14.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:14.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:15.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:15.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:16.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:16.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:16.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:17.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:17.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:17.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:18.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:18.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:18.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:19.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:19.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:19.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:20.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:20.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:20.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:21.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:21.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:21.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:22.914: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:22.914: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:22.914: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:23.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:23.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:23.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:24.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:24.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:24.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:25.915: INFO: Wrong image for pod: daemon-set-45rg9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:25.915: INFO: Pod daemon-set-45rg9 is not available
Mar 13 10:01:25.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:26.915: INFO: Pod daemon-set-7mqlh is not available
Mar 13 10:01:26.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:27.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:28.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:28.915: INFO: Pod daemon-set-mqzjk is not available
Mar 13 10:01:29.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:29.915: INFO: Pod daemon-set-mqzjk is not available
Mar 13 10:01:30.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:30.915: INFO: Pod daemon-set-mqzjk is not available
Mar 13 10:01:31.915: INFO: Wrong image for pod: daemon-set-mqzjk. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 13 10:01:31.915: INFO: Pod daemon-set-mqzjk is not available
Mar 13 10:01:32.915: INFO: Pod daemon-set-552k9 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 13 10:01:32.922: INFO: Number of nodes with available pods: 1
Mar 13 10:01:32.922: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 10:01:33.926: INFO: Number of nodes with available pods: 1
Mar 13 10:01:33.926: INFO: Node 172.24.5.5 is running more than one daemon pod
Mar 13 10:01:34.926: INFO: Number of nodes with available pods: 2
Mar 13 10:01:34.926: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6553, will wait for the garbage collector to delete the pods
Mar 13 10:01:34.990: INFO: Deleting DaemonSet.extensions daemon-set took: 2.769582ms
Mar 13 10:01:35.090: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.318664ms
Mar 13 10:01:38.092: INFO: Number of nodes with available pods: 0
Mar 13 10:01:38.092: INFO: Number of running nodes: 0, number of available pods: 0
Mar 13 10:01:38.094: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6553/daemonsets","resourceVersion":"59066"},"items":null}

Mar 13 10:01:38.095: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6553/pods","resourceVersion":"59066"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:38.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6553" for this suite.

• [SLOW TEST:26.242 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":280,"completed":196,"skipped":3171,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:38.106: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-677.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-677.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-677.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-677.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-677.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-677.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 10:01:40.139: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759: the server could not find the requested resource (get pods dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759)
Mar 13 10:01:40.141: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.dns-677.svc.cluster.local from pod dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759: the server could not find the requested resource (get pods dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759)
Mar 13 10:01:40.143: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759: the server could not find the requested resource (get pods dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759)
Mar 13 10:01:40.144: INFO: Unable to read jessie_udp@PodARecord from pod dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759: the server could not find the requested resource (get pods dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759)
Mar 13 10:01:40.146: INFO: Unable to read jessie_tcp@PodARecord from pod dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759: the server could not find the requested resource (get pods dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759)
Mar 13 10:01:40.146: INFO: Lookups using dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759 failed for: [wheezy_tcp@PodARecord jessie_hosts@dns-querier-1.dns-test-service.dns-677.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar 13 10:01:45.153: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759: the server could not find the requested resource (get pods dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759)
Mar 13 10:01:45.160: INFO: Lookups using dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759 failed for: [wheezy_tcp@PodARecord]

Mar 13 10:01:50.161: INFO: DNS probes using dns-677/dns-test-09e64cb5-2fd0-4774-b41f-4303df6be759 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:50.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-677" for this suite.

• [SLOW TEST:12.062 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":280,"completed":197,"skipped":3202,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:50.168: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:01:50.189: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-838819be-f860-4e42-9ed8-916ede09a50e" in namespace "security-context-test-7834" to be "success or failure"
Mar 13 10:01:50.191: INFO: Pod "alpine-nnp-false-838819be-f860-4e42-9ed8-916ede09a50e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.568465ms
Mar 13 10:01:52.193: INFO: Pod "alpine-nnp-false-838819be-f860-4e42-9ed8-916ede09a50e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003624116s
Mar 13 10:01:54.195: INFO: Pod "alpine-nnp-false-838819be-f860-4e42-9ed8-916ede09a50e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005741914s
Mar 13 10:01:56.197: INFO: Pod "alpine-nnp-false-838819be-f860-4e42-9ed8-916ede09a50e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007753023s
Mar 13 10:01:56.197: INFO: Pod "alpine-nnp-false-838819be-f860-4e42-9ed8-916ede09a50e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:56.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7834" for this suite.

• [SLOW TEST:6.039 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:289
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":198,"skipped":3230,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:56.208: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:01:56.573: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:01:59.582: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:01:59.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6095" for this suite.
STEP: Destroying namespace "webhook-6095-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":280,"completed":199,"skipped":3249,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:01:59.631: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-3a898f80-0196-4a2e-bc39-5e802d88c91e
STEP: Creating a pod to test consume configMaps
Mar 13 10:01:59.650: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c" in namespace "projected-8568" to be "success or failure"
Mar 13 10:01:59.652: INFO: Pod "pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.614475ms
Mar 13 10:02:01.654: INFO: Pod "pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003696451s
STEP: Saw pod success
Mar 13 10:02:01.654: INFO: Pod "pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c" satisfied condition "success or failure"
Mar 13 10:02:01.656: INFO: Trying to get logs from node 172.24.5.5 pod pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 10:02:01.666: INFO: Waiting for pod pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c to disappear
Mar 13 10:02:01.667: INFO: Pod pod-projected-configmaps-ca3272c0-059d-464d-a2fc-fdf5353db84c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:01.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8568" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":200,"skipped":3254,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:01.672: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-77a2f3bd-e820-484a-99a7-504dded1ead5
STEP: Creating a pod to test consume secrets
Mar 13 10:02:01.693: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3" in namespace "projected-9250" to be "success or failure"
Mar 13 10:02:01.694: INFO: Pod "pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.442402ms
Mar 13 10:02:03.697: INFO: Pod "pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003823089s
STEP: Saw pod success
Mar 13 10:02:03.697: INFO: Pod "pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3" satisfied condition "success or failure"
Mar 13 10:02:03.698: INFO: Trying to get logs from node 172.24.5.5 pod pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 13 10:02:03.708: INFO: Waiting for pod pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3 to disappear
Mar 13 10:02:03.710: INFO: Pod pod-projected-secrets-12608a85-3ade-410e-9826-3d69787118b3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:03.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9250" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":201,"skipped":3259,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:03.714: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 13 10:02:03.742: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6388 /api/v1/namespaces/watch-6388/configmaps/e2e-watch-test-resource-version 6fb7f352-bebb-4c5d-838d-3c8c8757a376 59320 0 2020-03-13 10:02:03 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 13 10:02:03.742: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6388 /api/v1/namespaces/watch-6388/configmaps/e2e-watch-test-resource-version 6fb7f352-bebb-4c5d-838d-3c8c8757a376 59321 0 2020-03-13 10:02:03 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:03.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6388" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":280,"completed":202,"skipped":3279,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:03.746: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:10.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7163" for this suite.

• [SLOW TEST:7.026 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":280,"completed":203,"skipped":3283,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:10.773: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 13 10:02:10.792: INFO: Waiting up to 5m0s for pod "pod-95b06d11-9807-4c7e-b46f-7c63520b5495" in namespace "emptydir-9436" to be "success or failure"
Mar 13 10:02:10.794: INFO: Pod "pod-95b06d11-9807-4c7e-b46f-7c63520b5495": Phase="Pending", Reason="", readiness=false. Elapsed: 1.341794ms
Mar 13 10:02:12.796: INFO: Pod "pod-95b06d11-9807-4c7e-b46f-7c63520b5495": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003514488s
STEP: Saw pod success
Mar 13 10:02:12.796: INFO: Pod "pod-95b06d11-9807-4c7e-b46f-7c63520b5495" satisfied condition "success or failure"
Mar 13 10:02:12.797: INFO: Trying to get logs from node 172.24.5.7 pod pod-95b06d11-9807-4c7e-b46f-7c63520b5495 container test-container: <nil>
STEP: delete the pod
Mar 13 10:02:12.813: INFO: Waiting for pod pod-95b06d11-9807-4c7e-b46f-7c63520b5495 to disappear
Mar 13 10:02:12.814: INFO: Pod pod-95b06d11-9807-4c7e-b46f-7c63520b5495 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:12.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9436" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":204,"skipped":3329,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:12.818: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-ea016a25-d3b3-4237-bec3-da7c33336dcd
STEP: Creating a pod to test consume secrets
Mar 13 10:02:12.840: INFO: Waiting up to 5m0s for pod "pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a" in namespace "secrets-5145" to be "success or failure"
Mar 13 10:02:12.841: INFO: Pod "pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.328227ms
Mar 13 10:02:14.843: INFO: Pod "pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00347311s
STEP: Saw pod success
Mar 13 10:02:14.843: INFO: Pod "pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a" satisfied condition "success or failure"
Mar 13 10:02:14.845: INFO: Trying to get logs from node 172.24.5.5 pod pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a container secret-volume-test: <nil>
STEP: delete the pod
Mar 13 10:02:14.854: INFO: Waiting for pod pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a to disappear
Mar 13 10:02:14.856: INFO: Pod pod-secrets-b1068374-ffae-4e02-92e5-aa2e5c6ff18a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:14.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5145" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":205,"skipped":3334,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:14.860: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Mar 13 10:02:17.388: INFO: Successfully updated pod "adopt-release-6zm2t"
STEP: Checking that the Job readopts the Pod
Mar 13 10:02:17.388: INFO: Waiting up to 15m0s for pod "adopt-release-6zm2t" in namespace "job-5165" to be "adopted"
Mar 13 10:02:17.389: INFO: Pod "adopt-release-6zm2t": Phase="Running", Reason="", readiness=true. Elapsed: 1.583758ms
Mar 13 10:02:19.391: INFO: Pod "adopt-release-6zm2t": Phase="Running", Reason="", readiness=true. Elapsed: 2.003603444s
Mar 13 10:02:19.391: INFO: Pod "adopt-release-6zm2t" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Mar 13 10:02:19.895: INFO: Successfully updated pod "adopt-release-6zm2t"
STEP: Checking that the Job releases the Pod
Mar 13 10:02:19.895: INFO: Waiting up to 15m0s for pod "adopt-release-6zm2t" in namespace "job-5165" to be "released"
Mar 13 10:02:19.896: INFO: Pod "adopt-release-6zm2t": Phase="Running", Reason="", readiness=true. Elapsed: 1.35242ms
Mar 13 10:02:21.899: INFO: Pod "adopt-release-6zm2t": Phase="Running", Reason="", readiness=true. Elapsed: 2.003635922s
Mar 13 10:02:21.899: INFO: Pod "adopt-release-6zm2t" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:21.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5165" for this suite.

• [SLOW TEST:7.043 seconds]
[sig-apps] Job
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":280,"completed":206,"skipped":3339,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 13 10:02:21.923: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 13 10:02:26.925: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:02:27.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1502" for this suite.

• [SLOW TEST:6.033 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":280,"completed":207,"skipped":3364,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:02:27.937: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-5673
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5673
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5673
Mar 13 10:02:27.959: INFO: Found 0 stateful pods, waiting for 1
Mar 13 10:02:37.962: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 13 10:02:37.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 10:02:38.254: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 10:02:38.254: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 10:02:38.254: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 10:02:38.256: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 13 10:02:48.258: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 10:02:48.258: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 10:02:48.264: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999523s
Mar 13 10:02:49.267: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998148782s
Mar 13 10:02:50.269: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99592582s
Mar 13 10:02:51.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.993674605s
Mar 13 10:02:52.274: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.991351082s
Mar 13 10:02:53.277: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.988192928s
Mar 13 10:02:54.279: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.985869991s
Mar 13 10:02:55.281: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.983789637s
Mar 13 10:02:56.283: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.981899478s
Mar 13 10:02:57.285: INFO: Verifying statefulset ss doesn't scale past 1 for another 979.911964ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5673
Mar 13 10:02:58.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 10:02:58.537: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 10:02:58.537: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 10:02:58.537: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 10:02:58.540: INFO: Found 1 stateful pods, waiting for 3
Mar 13 10:03:08.542: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 10:03:08.542: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 10:03:08.542: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 13 10:03:08.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 10:03:08.806: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 10:03:08.806: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 10:03:08.806: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 10:03:08.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 10:03:09.035: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 10:03:09.035: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 10:03:09.035: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 10:03:09.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 10:03:09.223: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 10:03:09.223: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 10:03:09.223: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 10:03:09.223: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 10:03:09.225: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 13 10:03:19.229: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 10:03:19.229: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 10:03:19.229: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 13 10:03:19.235: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999944s
Mar 13 10:03:20.238: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99771917s
Mar 13 10:03:21.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995596741s
Mar 13 10:03:22.243: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992621018s
Mar 13 10:03:23.245: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.990420211s
Mar 13 10:03:24.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.988222211s
Mar 13 10:03:25.249: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9859466s
Mar 13 10:03:26.252: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.983709004s
Mar 13 10:03:27.254: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.981519074s
Mar 13 10:03:28.256: INFO: Verifying statefulset ss doesn't scale past 3 for another 978.851664ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5673
Mar 13 10:03:29.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 10:03:29.508: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 10:03:29.508: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 10:03:29.508: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 10:03:29.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 10:03:29.717: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 10:03:29.717: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 10:03:29.717: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 10:03:29.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-5673 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 10:03:29.890: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 10:03:29.890: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 10:03:29.890: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 10:03:29.890: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 13 10:03:49.899: INFO: Deleting all statefulset in ns statefulset-5673
Mar 13 10:03:49.901: INFO: Scaling statefulset ss to 0
Mar 13 10:03:49.906: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 10:03:49.907: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:03:49.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5673" for this suite.

• [SLOW TEST:81.980 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":280,"completed":208,"skipped":3367,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:03:49.918: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Mar 13 10:03:49.934: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the sample API server.
Mar 13 10:03:50.221: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar 13 10:03:52.238: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 10:03:54.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 10:03:56.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 10:03:58.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 10:04:00.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690630, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 13 10:04:04.665: INFO: Waited 2.421080026s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:05.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2780" for this suite.

• [SLOW TEST:15.378 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]","total":280,"completed":209,"skipped":3391,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:05.296: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-a088b022-7216-404c-b64f-59bc34291518
STEP: Creating a pod to test consume configMaps
Mar 13 10:04:05.317: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae" in namespace "projected-909" to be "success or failure"
Mar 13 10:04:05.319: INFO: Pod "pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae": Phase="Pending", Reason="", readiness=false. Elapsed: 1.403731ms
Mar 13 10:04:07.321: INFO: Pod "pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003656716s
STEP: Saw pod success
Mar 13 10:04:07.321: INFO: Pod "pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae" satisfied condition "success or failure"
Mar 13 10:04:07.323: INFO: Trying to get logs from node 172.24.5.5 pod pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 10:04:07.344: INFO: Waiting for pod pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae to disappear
Mar 13 10:04:07.345: INFO: Pod pod-projected-configmaps-22f1086f-b387-4cf3-af88-5ca8846c32ae no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:07.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-909" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":210,"skipped":3416,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:07.350: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:13.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7298" for this suite.

• [SLOW TEST:6.025 seconds]
[sig-apps] Job
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":280,"completed":211,"skipped":3463,"failed":0}
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:13.375: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 13 10:04:13.391: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:18.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9471" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":280,"completed":212,"skipped":3463,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:18.242: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:04:18.690: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 13 10:04:20.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690658, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690658, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690658, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719690658, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:04:23.701: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:23.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2664" for this suite.
STEP: Destroying namespace "webhook-2664-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.502 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":280,"completed":213,"skipped":3487,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:23.745: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service endpoint-test2 in namespace services-2216
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2216 to expose endpoints map[]
Mar 13 10:04:23.765: INFO: Get endpoints failed (1.225383ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 13 10:04:24.767: INFO: successfully validated that service endpoint-test2 in namespace services-2216 exposes endpoints map[] (1.003513002s elapsed)
STEP: Creating pod pod1 in namespace services-2216
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2216 to expose endpoints map[pod1:[80]]
Mar 13 10:04:26.780: INFO: successfully validated that service endpoint-test2 in namespace services-2216 exposes endpoints map[pod1:[80]] (2.009742751s elapsed)
STEP: Creating pod pod2 in namespace services-2216
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2216 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 13 10:04:28.795: INFO: successfully validated that service endpoint-test2 in namespace services-2216 exposes endpoints map[pod1:[80] pod2:[80]] (2.0129716s elapsed)
STEP: Deleting pod pod1 in namespace services-2216
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2216 to expose endpoints map[pod2:[80]]
Mar 13 10:04:29.804: INFO: successfully validated that service endpoint-test2 in namespace services-2216 exposes endpoints map[pod2:[80]] (1.006121553s elapsed)
STEP: Deleting pod pod2 in namespace services-2216
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2216 to expose endpoints map[]
Mar 13 10:04:30.809: INFO: successfully validated that service endpoint-test2 in namespace services-2216 exposes endpoints map[] (1.003210364s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:30.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2216" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:7.075 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":280,"completed":214,"skipped":3502,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:30.820: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:30.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-774" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":280,"completed":215,"skipped":3521,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:30.843: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 13 10:04:30.862: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa" in namespace "downward-api-3644" to be "success or failure"
Mar 13 10:04:30.863: INFO: Pod "downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.403115ms
Mar 13 10:04:32.865: INFO: Pod "downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003430148s
STEP: Saw pod success
Mar 13 10:04:32.866: INFO: Pod "downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa" satisfied condition "success or failure"
Mar 13 10:04:32.867: INFO: Trying to get logs from node 172.24.5.5 pod downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa container client-container: <nil>
STEP: delete the pod
Mar 13 10:04:32.876: INFO: Waiting for pod downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa to disappear
Mar 13 10:04:32.878: INFO: Pod downwardapi-volume-ba1b37a3-6680-4be7-954b-9caf6222c7aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:32.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3644" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":216,"skipped":3526,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:32.882: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-6b84c84b-ba52-4875-ac5f-f62ee354b205 in namespace container-probe-2095
Mar 13 10:04:34.906: INFO: Started pod liveness-6b84c84b-ba52-4875-ac5f-f62ee354b205 in namespace container-probe-2095
STEP: checking the pod's current state and verifying that restartCount is present
Mar 13 10:04:34.908: INFO: Initial restart count of pod liveness-6b84c84b-ba52-4875-ac5f-f62ee354b205 is 0
Mar 13 10:04:54.932: INFO: Restart count of pod container-probe-2095/liveness-6b84c84b-ba52-4875-ac5f-f62ee354b205 is now 1 (20.024085731s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:54.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2095" for this suite.

• [SLOW TEST:22.059 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":217,"skipped":3558,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:54.941: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-b4ab0d8e-896a-4cb5-b0b6-0996d5a1110f
STEP: Creating secret with name s-test-opt-upd-39663249-414d-4162-bd15-825f055366e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b4ab0d8e-896a-4cb5-b0b6-0996d5a1110f
STEP: Updating secret s-test-opt-upd-39663249-414d-4162-bd15-825f055366e3
STEP: Creating secret with name s-test-opt-create-511e3b9f-5cb1-49e2-a24d-3e8e8920ec92
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:04:59.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7080" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":218,"skipped":3562,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:04:59.016: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 13 10:04:59.036: INFO: Waiting up to 5m0s for pod "pod-c6396c6a-05b3-4508-ae36-b212d92a96a7" in namespace "emptydir-3007" to be "success or failure"
Mar 13 10:04:59.037: INFO: Pod "pod-c6396c6a-05b3-4508-ae36-b212d92a96a7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.43353ms
Mar 13 10:05:01.040: INFO: Pod "pod-c6396c6a-05b3-4508-ae36-b212d92a96a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004000918s
STEP: Saw pod success
Mar 13 10:05:01.040: INFO: Pod "pod-c6396c6a-05b3-4508-ae36-b212d92a96a7" satisfied condition "success or failure"
Mar 13 10:05:01.041: INFO: Trying to get logs from node 172.24.5.7 pod pod-c6396c6a-05b3-4508-ae36-b212d92a96a7 container test-container: <nil>
STEP: delete the pod
Mar 13 10:05:01.051: INFO: Waiting for pod pod-c6396c6a-05b3-4508-ae36-b212d92a96a7 to disappear
Mar 13 10:05:01.052: INFO: Pod pod-c6396c6a-05b3-4508-ae36-b212d92a96a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:01.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3007" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":219,"skipped":3587,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:01.056: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-c62b590d-73aa-4181-8b8e-28c6e7daee9e
STEP: Creating a pod to test consume configMaps
Mar 13 10:05:01.077: INFO: Waiting up to 5m0s for pod "pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1" in namespace "configmap-9342" to be "success or failure"
Mar 13 10:05:01.078: INFO: Pod "pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.544712ms
Mar 13 10:05:03.081: INFO: Pod "pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003584128s
STEP: Saw pod success
Mar 13 10:05:03.081: INFO: Pod "pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1" satisfied condition "success or failure"
Mar 13 10:05:03.082: INFO: Trying to get logs from node 172.24.5.7 pod pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 10:05:03.091: INFO: Waiting for pod pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1 to disappear
Mar 13 10:05:03.093: INFO: Pod pod-configmaps-529abd98-c254-4e3b-a690-eb12b18f31b1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:03.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9342" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":220,"skipped":3587,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:03.097: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4617" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":280,"completed":221,"skipped":3605,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:03.119: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 13 10:05:03.139: INFO: Waiting up to 5m0s for pod "downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758" in namespace "downward-api-1792" to be "success or failure"
Mar 13 10:05:03.140: INFO: Pod "downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758": Phase="Pending", Reason="", readiness=false. Elapsed: 1.449285ms
Mar 13 10:05:05.142: INFO: Pod "downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003509934s
STEP: Saw pod success
Mar 13 10:05:05.142: INFO: Pod "downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758" satisfied condition "success or failure"
Mar 13 10:05:05.144: INFO: Trying to get logs from node 172.24.5.5 pod downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758 container dapi-container: <nil>
STEP: delete the pod
Mar 13 10:05:05.155: INFO: Waiting for pod downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758 to disappear
Mar 13 10:05:05.156: INFO: Pod downward-api-5ae3b09a-3ebd-471b-af4e-b3e98d3e3758 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:05.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1792" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":280,"completed":222,"skipped":3609,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:05.161: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-b3ede189-6c8b-4ac3-83b0-1024a53419cb
STEP: Creating a pod to test consume secrets
Mar 13 10:05:05.184: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4" in namespace "projected-9548" to be "success or failure"
Mar 13 10:05:05.186: INFO: Pod "pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.442184ms
Mar 13 10:05:07.188: INFO: Pod "pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003521701s
STEP: Saw pod success
Mar 13 10:05:07.188: INFO: Pod "pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4" satisfied condition "success or failure"
Mar 13 10:05:07.189: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 13 10:05:07.198: INFO: Waiting for pod pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4 to disappear
Mar 13 10:05:07.199: INFO: Pod pod-projected-secrets-90dafd16-a9ab-4526-9f69-c84bb53c5cc4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:07.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9548" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":223,"skipped":3624,"failed":0}
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:07.204: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6477.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6477.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 10:05:23.246: INFO: DNS probes using dns-6477/dns-test-132aa5c8-0dcd-4b7c-8dce-e1f7ad143bc4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:23.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6477" for this suite.

• [SLOW TEST:16.050 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":280,"completed":224,"skipped":3630,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:23.254: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:05:23.276: INFO: (0) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.003115ms)
Mar 13 10:05:23.278: INFO: (1) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.915747ms)
Mar 13 10:05:23.280: INFO: (2) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.89988ms)
Mar 13 10:05:23.282: INFO: (3) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.982135ms)
Mar 13 10:05:23.284: INFO: (4) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.99526ms)
Mar 13 10:05:23.286: INFO: (5) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.8848ms)
Mar 13 10:05:23.288: INFO: (6) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.835166ms)
Mar 13 10:05:23.290: INFO: (7) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.891923ms)
Mar 13 10:05:23.292: INFO: (8) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.047281ms)
Mar 13 10:05:23.294: INFO: (9) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.034953ms)
Mar 13 10:05:23.296: INFO: (10) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.981437ms)
Mar 13 10:05:23.298: INFO: (11) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.048521ms)
Mar 13 10:05:23.300: INFO: (12) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.830439ms)
Mar 13 10:05:23.302: INFO: (13) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.94666ms)
Mar 13 10:05:23.304: INFO: (14) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.964927ms)
Mar 13 10:05:23.306: INFO: (15) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.023008ms)
Mar 13 10:05:23.308: INFO: (16) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.894098ms)
Mar 13 10:05:23.310: INFO: (17) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.249763ms)
Mar 13 10:05:23.312: INFO: (18) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.083096ms)
Mar 13 10:05:23.314: INFO: (19) /api/v1/nodes/172.24.5.7/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.969906ms)
[AfterEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:23.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9769" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":280,"completed":225,"skipped":3649,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:23.319: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:25.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1014" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":280,"completed":226,"skipped":3659,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:25.360: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 13 10:05:25.378: INFO: Waiting up to 5m0s for pod "pod-ba237ae7-eb00-4052-ae4e-5c7f14084917" in namespace "emptydir-7565" to be "success or failure"
Mar 13 10:05:25.379: INFO: Pod "pod-ba237ae7-eb00-4052-ae4e-5c7f14084917": Phase="Pending", Reason="", readiness=false. Elapsed: 1.181861ms
Mar 13 10:05:27.382: INFO: Pod "pod-ba237ae7-eb00-4052-ae4e-5c7f14084917": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003352318s
STEP: Saw pod success
Mar 13 10:05:27.382: INFO: Pod "pod-ba237ae7-eb00-4052-ae4e-5c7f14084917" satisfied condition "success or failure"
Mar 13 10:05:27.383: INFO: Trying to get logs from node 172.24.5.5 pod pod-ba237ae7-eb00-4052-ae4e-5c7f14084917 container test-container: <nil>
STEP: delete the pod
Mar 13 10:05:27.393: INFO: Waiting for pod pod-ba237ae7-eb00-4052-ae4e-5c7f14084917 to disappear
Mar 13 10:05:27.394: INFO: Pod pod-ba237ae7-eb00-4052-ae4e-5c7f14084917 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:27.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7565" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":227,"skipped":3719,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:27.399: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:330
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Mar 13 10:05:27.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-9230'
Mar 13 10:05:27.624: INFO: stderr: ""
Mar 13 10:05:27.624: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 13 10:05:27.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9230'
Mar 13 10:05:27.714: INFO: stderr: ""
Mar 13 10:05:27.714: INFO: stdout: "update-demo-nautilus-c9r8j update-demo-nautilus-lrq8t "
Mar 13 10:05:27.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-c9r8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:27.807: INFO: stderr: ""
Mar 13 10:05:27.807: INFO: stdout: ""
Mar 13 10:05:27.807: INFO: update-demo-nautilus-c9r8j is created but not running
Mar 13 10:05:32.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9230'
Mar 13 10:05:32.890: INFO: stderr: ""
Mar 13 10:05:32.890: INFO: stdout: "update-demo-nautilus-c9r8j update-demo-nautilus-lrq8t "
Mar 13 10:05:32.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-c9r8j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:32.968: INFO: stderr: ""
Mar 13 10:05:32.968: INFO: stdout: "true"
Mar 13 10:05:32.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-c9r8j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:33.050: INFO: stderr: ""
Mar 13 10:05:33.050: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:05:33.051: INFO: validating pod update-demo-nautilus-c9r8j
Mar 13 10:05:33.053: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:05:33.053: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:05:33.053: INFO: update-demo-nautilus-c9r8j is verified up and running
Mar 13 10:05:33.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-lrq8t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:33.127: INFO: stderr: ""
Mar 13 10:05:33.127: INFO: stdout: "true"
Mar 13 10:05:33.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-lrq8t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:33.203: INFO: stderr: ""
Mar 13 10:05:33.203: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:05:33.203: INFO: validating pod update-demo-nautilus-lrq8t
Mar 13 10:05:33.206: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:05:33.206: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:05:33.206: INFO: update-demo-nautilus-lrq8t is verified up and running
STEP: scaling down the replication controller
Mar 13 10:05:33.209: INFO: scanned /root for discovery docs: <nil>
Mar 13 10:05:33.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9230'
Mar 13 10:05:33.297: INFO: stderr: ""
Mar 13 10:05:33.297: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 13 10:05:33.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9230'
Mar 13 10:05:33.378: INFO: stderr: ""
Mar 13 10:05:33.378: INFO: stdout: "update-demo-nautilus-c9r8j update-demo-nautilus-lrq8t "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 13 10:05:38.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9230'
Mar 13 10:05:38.456: INFO: stderr: ""
Mar 13 10:05:38.456: INFO: stdout: "update-demo-nautilus-lrq8t "
Mar 13 10:05:38.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-lrq8t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:38.542: INFO: stderr: ""
Mar 13 10:05:38.542: INFO: stdout: "true"
Mar 13 10:05:38.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-lrq8t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:38.612: INFO: stderr: ""
Mar 13 10:05:38.612: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:05:38.612: INFO: validating pod update-demo-nautilus-lrq8t
Mar 13 10:05:38.614: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:05:38.615: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:05:38.615: INFO: update-demo-nautilus-lrq8t is verified up and running
STEP: scaling up the replication controller
Mar 13 10:05:38.617: INFO: scanned /root for discovery docs: <nil>
Mar 13 10:05:38.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9230'
Mar 13 10:05:38.704: INFO: stderr: ""
Mar 13 10:05:38.704: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 13 10:05:38.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9230'
Mar 13 10:05:38.788: INFO: stderr: ""
Mar 13 10:05:38.788: INFO: stdout: "update-demo-nautilus-74vcr update-demo-nautilus-lrq8t "
Mar 13 10:05:38.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-74vcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:38.872: INFO: stderr: ""
Mar 13 10:05:38.872: INFO: stdout: ""
Mar 13 10:05:38.872: INFO: update-demo-nautilus-74vcr is created but not running
Mar 13 10:05:43.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9230'
Mar 13 10:05:43.954: INFO: stderr: ""
Mar 13 10:05:43.954: INFO: stdout: "update-demo-nautilus-74vcr update-demo-nautilus-lrq8t "
Mar 13 10:05:43.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-74vcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:44.046: INFO: stderr: ""
Mar 13 10:05:44.046: INFO: stdout: "true"
Mar 13 10:05:44.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-74vcr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:44.123: INFO: stderr: ""
Mar 13 10:05:44.123: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:05:44.123: INFO: validating pod update-demo-nautilus-74vcr
Mar 13 10:05:44.126: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:05:44.126: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:05:44.126: INFO: update-demo-nautilus-74vcr is verified up and running
Mar 13 10:05:44.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-lrq8t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:44.207: INFO: stderr: ""
Mar 13 10:05:44.207: INFO: stdout: "true"
Mar 13 10:05:44.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-lrq8t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9230'
Mar 13 10:05:44.282: INFO: stderr: ""
Mar 13 10:05:44.282: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:05:44.282: INFO: validating pod update-demo-nautilus-lrq8t
Mar 13 10:05:44.284: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:05:44.284: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:05:44.284: INFO: update-demo-nautilus-lrq8t is verified up and running
STEP: using delete to clean up resources
Mar 13 10:05:44.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-9230'
Mar 13 10:05:44.365: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 10:05:44.365: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 13 10:05:44.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9230'
Mar 13 10:05:44.440: INFO: stderr: "No resources found in kubectl-9230 namespace.\n"
Mar 13 10:05:44.440: INFO: stdout: ""
Mar 13 10:05:44.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -l name=update-demo --namespace=kubectl-9230 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 13 10:05:44.519: INFO: stderr: ""
Mar 13 10:05:44.519: INFO: stdout: "update-demo-nautilus-74vcr\nupdate-demo-nautilus-lrq8t\n"
Mar 13 10:05:45.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9230'
Mar 13 10:05:45.105: INFO: stderr: "No resources found in kubectl-9230 namespace.\n"
Mar 13 10:05:45.105: INFO: stdout: ""
Mar 13 10:05:45.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -l name=update-demo --namespace=kubectl-9230 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 13 10:05:45.197: INFO: stderr: ""
Mar 13 10:05:45.197: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:45.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9230" for this suite.

• [SLOW TEST:17.804 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:328
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":280,"completed":228,"skipped":3766,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:45.202: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:05:45.219: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar 13 10:05:47.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-5940 create -f -'
Mar 13 10:05:47.344: INFO: stderr: ""
Mar 13 10:05:47.344: INFO: stdout: "e2e-test-crd-publish-openapi-2316-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar 13 10:05:47.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-5940 delete e2e-test-crd-publish-openapi-2316-crds test-cr'
Mar 13 10:05:47.426: INFO: stderr: ""
Mar 13 10:05:47.426: INFO: stdout: "e2e-test-crd-publish-openapi-2316-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Mar 13 10:05:47.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-5940 apply -f -'
Mar 13 10:05:47.572: INFO: stderr: ""
Mar 13 10:05:47.572: INFO: stdout: "e2e-test-crd-publish-openapi-2316-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar 13 10:05:47.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 --namespace=crd-publish-openapi-5940 delete e2e-test-crd-publish-openapi-2316-crds test-cr'
Mar 13 10:05:47.653: INFO: stderr: ""
Mar 13 10:05:47.653: INFO: stdout: "e2e-test-crd-publish-openapi-2316-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar 13 10:05:47.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 explain e2e-test-crd-publish-openapi-2316-crds'
Mar 13 10:05:47.794: INFO: stderr: ""
Mar 13 10:05:47.794: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2316-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:05:50.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5940" for this suite.

• [SLOW TEST:5.442 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":280,"completed":229,"skipped":3773,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:05:50.644: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-3559
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 13 10:05:50.660: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 13 10:06:12.689: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.114:8080/dial?request=hostname&protocol=udp&host=10.42.1.170&port=8081&tries=1'] Namespace:pod-network-test-3559 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:06:12.689: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:06:12.875: INFO: Waiting for responses: map[]
Mar 13 10:06:12.877: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.114:8080/dial?request=hostname&protocol=udp&host=10.42.0.113&port=8081&tries=1'] Namespace:pod-network-test-3559 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:06:12.877: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:06:13.048: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:13.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3559" for this suite.

• [SLOW TEST:22.408 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":230,"skipped":3821,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:13.053: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:24.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4063" for this suite.

• [SLOW TEST:11.041 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":280,"completed":231,"skipped":3877,"failed":0}
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:24.094: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:40.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9117" for this suite.

• [SLOW TEST:16.057 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":280,"completed":232,"skipped":3877,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:40.152: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:06:40.619: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:06:43.628: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:43.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7754" for this suite.
STEP: Destroying namespace "webhook-7754-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":280,"completed":233,"skipped":3880,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:43.666: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:06:43.685: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-3d0cccca-cbd3-461a-a7aa-34e199022de8" in namespace "security-context-test-1735" to be "success or failure"
Mar 13 10:06:43.686: INFO: Pod "busybox-readonly-false-3d0cccca-cbd3-461a-a7aa-34e199022de8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.38873ms
Mar 13 10:06:45.688: INFO: Pod "busybox-readonly-false-3d0cccca-cbd3-461a-a7aa-34e199022de8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003295045s
Mar 13 10:06:45.688: INFO: Pod "busybox-readonly-false-3d0cccca-cbd3-461a-a7aa-34e199022de8" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:45.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1735" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":280,"completed":234,"skipped":3887,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:45.693: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:06:45.709: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar 13 10:06:47.723: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:48.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1685" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":280,"completed":235,"skipped":3906,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:48.730: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Starting the proxy
Mar 13 10:06:48.746: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-141385212 proxy --unix-socket=/tmp/kubectl-proxy-unix044290375/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:48.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-289" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":280,"completed":236,"skipped":3928,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:48.813: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating api versions
Mar 13 10:06:48.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 api-versions'
Mar 13 10:06:48.902: INFO: stderr: ""
Mar 13 10:06:48.902: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:48.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6273" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":280,"completed":237,"skipped":3931,"failed":0}
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:48.906: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 13 10:06:48.922: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 13 10:06:48.928: INFO: Waiting for terminating namespaces to be deleted...
Mar 13 10:06:48.930: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.5 before test
Mar 13 10:06:48.937: INFO: canal-m4mzr from kube-system started at 2020-03-13 09:11:02 +0000 UTC (2 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 10:06:48.937: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 10:06:48.937: INFO: nginx-ingress-controller-6b2t4 from ingress-nginx started at 2020-03-13 09:11:08 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 10:06:48.937: INFO: busybox-readonly-false-3d0cccca-cbd3-461a-a7aa-34e199022de8 from security-context-test-1735 started at 2020-03-13 10:06:43 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container busybox-readonly-false-3d0cccca-cbd3-461a-a7aa-34e199022de8 ready: false, restart count 0
Mar 13 10:06:48.937: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 10:06:48.937: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 10:06:48.937: INFO: condition-test-fvtdn from replication-controller-1685 started at 2020-03-13 10:06:46 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container httpd ready: true, restart count 0
Mar 13 10:06:48.937: INFO: coredns-7c5566588d-9gx44 from kube-system started at 2020-03-13 09:11:16 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container coredns ready: true, restart count 0
Mar 13 10:06:48.937: INFO: sonobuoy-e2e-job-53adb94536da47d3 from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 10:06:48.937: INFO: 	Container e2e ready: true, restart count 0
Mar 13 10:06:48.937: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 10:06:48.937: INFO: 
Logging pods the kubelet thinks is on node 172.24.5.7 before test
Mar 13 10:06:48.944: INFO: rke-network-plugin-deploy-job-chk5v from kube-system started at 2020-03-13 06:22:07 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container rke-network-plugin-pod ready: false, restart count 0
Mar 13 10:06:48.944: INFO: nginx-ingress-controller-mhtcd from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar 13 10:06:48.944: INFO: condition-test-mtvrn from replication-controller-1685 started at 2020-03-13 10:06:46 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container httpd ready: true, restart count 0
Mar 13 10:06:48.944: INFO: rke-metrics-addon-deploy-job-w79dp from kube-system started at 2020-03-13 06:25:07 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container rke-metrics-addon-pod ready: false, restart count 0
Mar 13 10:06:48.944: INFO: sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-6mljq from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (2 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 13 10:06:48.944: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 13 10:06:48.944: INFO: metrics-server-6b55c64f86-gp7kb from kube-system started at 2020-03-13 06:25:09 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container metrics-server ready: true, restart count 0
Mar 13 10:06:48.944: INFO: sonobuoy from sonobuoy started at 2020-03-13 09:15:26 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 13 10:06:48.944: INFO: rke-ingress-controller-deploy-job-mmxvc from kube-system started at 2020-03-13 06:25:12 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container rke-ingress-controller-pod ready: false, restart count 0
Mar 13 10:06:48.944: INFO: coredns-7c5566588d-dx5r6 from kube-system started at 2020-03-13 06:40:26 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container coredns ready: true, restart count 0
Mar 13 10:06:48.944: INFO: canal-fd4wb from kube-system started at 2020-03-13 06:22:33 +0000 UTC (2 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container calico-node ready: true, restart count 0
Mar 13 10:06:48.944: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 13 10:06:48.944: INFO: rke-coredns-addon-deploy-job-frlv2 from kube-system started at 2020-03-13 06:25:02 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container rke-coredns-addon-pod ready: false, restart count 0
Mar 13 10:06:48.944: INFO: coredns-autoscaler-65bfc8d47d-d5vsc from kube-system started at 2020-03-13 06:25:04 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container autoscaler ready: true, restart count 0
Mar 13 10:06:48.944: INFO: default-http-backend-67cf578fc4-rwkbq from ingress-nginx started at 2020-03-13 06:25:13 +0000 UTC (1 container statuses recorded)
Mar 13 10:06:48.944: INFO: 	Container default-http-backend ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: verifying the node has the label node 172.24.5.5
STEP: verifying the node has the label node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod default-http-backend-67cf578fc4-rwkbq requesting resource cpu=10m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod nginx-ingress-controller-6b2t4 requesting resource cpu=0m on Node 172.24.5.5
Mar 13 10:06:48.961: INFO: Pod nginx-ingress-controller-mhtcd requesting resource cpu=0m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod canal-fd4wb requesting resource cpu=250m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod canal-m4mzr requesting resource cpu=250m on Node 172.24.5.5
Mar 13 10:06:48.961: INFO: Pod coredns-7c5566588d-9gx44 requesting resource cpu=100m on Node 172.24.5.5
Mar 13 10:06:48.961: INFO: Pod coredns-7c5566588d-dx5r6 requesting resource cpu=100m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod coredns-autoscaler-65bfc8d47d-d5vsc requesting resource cpu=20m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod metrics-server-6b55c64f86-gp7kb requesting resource cpu=0m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod condition-test-fvtdn requesting resource cpu=0m on Node 172.24.5.5
Mar 13 10:06:48.961: INFO: Pod condition-test-mtvrn requesting resource cpu=0m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod sonobuoy requesting resource cpu=0m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod sonobuoy-e2e-job-53adb94536da47d3 requesting resource cpu=0m on Node 172.24.5.5
Mar 13 10:06:48.961: INFO: Pod sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-6mljq requesting resource cpu=0m on Node 172.24.5.7
Mar 13 10:06:48.961: INFO: Pod sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9 requesting resource cpu=0m on Node 172.24.5.5
STEP: Starting Pods to consume most of the cluster CPU.
Mar 13 10:06:48.961: INFO: Creating a pod which consumes cpu=33355m on Node 172.24.5.5
Mar 13 10:06:48.964: INFO: Creating a pod which consumes cpu=33334m on Node 172.24.5.7
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-395dee64-12f1-4cad-8771-84a31403e608.15fbd51bb70d7283], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8145/filler-pod-395dee64-12f1-4cad-8771-84a31403e608 to 172.24.5.5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-395dee64-12f1-4cad-8771-84a31403e608.15fbd51be23f35b9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-395dee64-12f1-4cad-8771-84a31403e608.15fbd51be3397c62], Reason = [Created], Message = [Created container filler-pod-395dee64-12f1-4cad-8771-84a31403e608]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-395dee64-12f1-4cad-8771-84a31403e608.15fbd51bed189923], Reason = [Started], Message = [Started container filler-pod-395dee64-12f1-4cad-8771-84a31403e608]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8.15fbd51bb724edf5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8145/filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8 to 172.24.5.7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8.15fbd51bdad58472], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8.15fbd51bdb86f737], Reason = [Created], Message = [Created container filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8.15fbd51be1c10a2a], Reason = [Started], Message = [Started container filler-pod-6eaf4320-9e41-4d0e-98f1-6497b1fe80c8]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15fbd51c2edd7ec8], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 172.24.5.5
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 172.24.5.7
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:51.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8145" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":280,"completed":238,"skipped":3936,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:51.996: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-6be74b58-1d4a-49c7-b791-07e92ee14cf4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:06:54.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6350" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":239,"skipped":3941,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:06:54.037: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-9051
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating statefulset ss in namespace statefulset-9051
Mar 13 10:06:54.063: INFO: Found 0 stateful pods, waiting for 1
Mar 13 10:07:04.066: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 13 10:07:04.075: INFO: Deleting all statefulset in ns statefulset-9051
Mar 13 10:07:04.076: INFO: Scaling statefulset ss to 0
Mar 13 10:07:24.086: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 10:07:24.088: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:07:24.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9051" for this suite.

• [SLOW TEST:30.060 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":280,"completed":240,"skipped":3949,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:07:24.098: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:07:24.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-9044'
Mar 13 10:07:24.339: INFO: stderr: ""
Mar 13 10:07:24.339: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Mar 13 10:07:24.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-9044'
Mar 13 10:07:24.493: INFO: stderr: ""
Mar 13 10:07:24.493: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Mar 13 10:07:25.495: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 10:07:25.495: INFO: Found 0 / 1
Mar 13 10:07:26.495: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 10:07:26.495: INFO: Found 1 / 1
Mar 13 10:07:26.495: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 13 10:07:26.497: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 13 10:07:26.497: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 13 10:07:26.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 describe pod agnhost-master-k9bsb --namespace=kubectl-9044'
Mar 13 10:07:26.597: INFO: stderr: ""
Mar 13 10:07:26.597: INFO: stdout: "Name:         agnhost-master-k9bsb\nNamespace:    kubectl-9044\nPriority:     0\nNode:         172.24.5.7/172.24.5.7\nStart Time:   Fri, 13 Mar 2020 10:07:24 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.42.0.121/32\nStatus:       Running\nIP:           10.42.0.121\nIPs:\n  IP:           10.42.0.121\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://28793cfccafd50368137259d7524e5d50995f069ec4d6954b242350e865aeb7e\n    Image:          gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 13 Mar 2020 10:07:25 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-n6wl5 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-n6wl5:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-n6wl5\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                 Message\n  ----    ------     ----       ----                 -------\n  Normal  Scheduled  <unknown>  default-scheduler    Successfully assigned kubectl-9044/agnhost-master-k9bsb to 172.24.5.7\n  Normal  Pulled     2s         kubelet, 172.24.5.7  Container image \"gcr.io/kubernetes-e2e-test-images/agnhost:2.8\" already present on machine\n  Normal  Created    2s         kubelet, 172.24.5.7  Created container agnhost-master\n  Normal  Started    1s         kubelet, 172.24.5.7  Started container agnhost-master\n"
Mar 13 10:07:26.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 describe rc agnhost-master --namespace=kubectl-9044'
Mar 13 10:07:26.698: INFO: stderr: ""
Mar 13 10:07:26.698: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-9044\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-master-k9bsb\n"
Mar 13 10:07:26.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 describe service agnhost-master --namespace=kubectl-9044'
Mar 13 10:07:26.788: INFO: stderr: ""
Mar 13 10:07:26.788: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-9044\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.43.54.108\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.42.0.121:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 13 10:07:26.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 describe node 172.24.5.5'
Mar 13 10:07:26.904: INFO: stderr: ""
Mar 13 10:07:26.904: INFO: stdout: "Name:               172.24.5.5\nRoles:              worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=172.24.5.5\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/worker=true\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"0e:a0:7d:4e:02:6e\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.246.177.5\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.42.1.1\n                    rke.cattle.io/external-ip: 172.24.5.5\n                    rke.cattle.io/internal-ip: 172.24.5.5\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 13 Mar 2020 09:11:02 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  172.24.5.5\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 13 Mar 2020 10:07:22 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 13 Mar 2020 10:06:13 +0000   Fri, 13 Mar 2020 09:11:02 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 13 Mar 2020 10:06:13 +0000   Fri, 13 Mar 2020 09:11:02 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 13 Mar 2020 10:06:13 +0000   Fri, 13 Mar 2020 09:11:02 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 13 Mar 2020 10:06:13 +0000   Fri, 13 Mar 2020 09:11:42 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.24.5.5\n  Hostname:    172.24.5.5\nCapacity:\n  cpu:                48\n  ephemeral-storage:  1152083668Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      2Gi\n  memory:             396167316Ki\n  pods:               110\nAllocatable:\n  cpu:                48\n  ephemeral-storage:  1061760306671\n  hugepages-1Gi:      0\n  hugepages-2Mi:      2Gi\n  memory:             393967764Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 311936e2303b034fe7ef70182235b8cb\n  System UUID:                4c4c4544-0036-4c10-8038-c3c04f474432\n  Boot ID:                    865aac2f-8a9c-48d7-be09-93126982e738\n  Kernel Version:             5.0.0-ors\n  OS Image:                   Ubuntu 18.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.0\n  Kubelet Version:            v1.17.2\n  Kube-Proxy Version:         v1.17.2\nPodCIDR:                      10.42.1.0/24\nPodCIDRs:                     10.42.1.0/24\nNon-terminated Pods:          (5 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx               nginx-ingress-controller-6b2t4                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n  kube-system                 canal-m4mzr                                                250m (0%)     0 (0%)      0 (0%)           0 (0%)         56m\n  kube-system                 coredns-7c5566588d-9gx44                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     56m\n  sonobuoy                    sonobuoy-e2e-job-53adb94536da47d3                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-8e2c965cf6d8424b-h9bn9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                350m (0%)  0 (0%)\n  memory             70Mi (0%)  170Mi (0%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:\n  Type    Reason                   Age   From                    Message\n  ----    ------                   ----  ----                    -------\n  Normal  Starting                 56m   kubelet, 172.24.5.5     Starting kubelet.\n  Normal  NodeHasSufficientMemory  56m   kubelet, 172.24.5.5     Node 172.24.5.5 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    56m   kubelet, 172.24.5.5     Node 172.24.5.5 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     56m   kubelet, 172.24.5.5     Node 172.24.5.5 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  56m   kubelet, 172.24.5.5     Updated Node Allocatable limit across pods\n  Normal  Starting                 56m   kube-proxy, 172.24.5.5  Starting kube-proxy.\n  Normal  NodeReady                55m   kubelet, 172.24.5.5     Node 172.24.5.5 status is now: NodeReady\n"
Mar 13 10:07:26.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 describe namespace kubectl-9044'
Mar 13 10:07:26.996: INFO: stderr: ""
Mar 13 10:07:26.996: INFO: stdout: "Name:         kubectl-9044\nLabels:       e2e-framework=kubectl\n              e2e-run=3f51d3fa-c3d4-45cd-922f-9b1f292eb026\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:07:26.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9044" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":280,"completed":241,"skipped":3972,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:07:27.001: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Mar 13 10:07:27.017: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:07:41.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9563" for this suite.

• [SLOW TEST:14.855 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":280,"completed":242,"skipped":3974,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:07:41.856: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0313 10:07:42.893641      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 13 10:07:42.893: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:07:42.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5753" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":280,"completed":243,"skipped":3985,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:07:42.898: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:163
Mar 13 10:07:42.914: INFO: Waiting up to 1m0s for all nodes to be ready
Mar 13 10:08:42.926: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:08:42.928: INFO: Starting informer...
STEP: Starting pod...
Mar 13 10:08:43.134: INFO: Pod is running on 172.24.5.5. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Mar 13 10:08:43.142: INFO: Pod wasn't evicted. Proceeding
Mar 13 10:08:43.142: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Mar 13 10:09:58.150: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:09:58.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-281" for this suite.

• [SLOW TEST:135.257 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":280,"completed":244,"skipped":3999,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:09:58.156: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:10:24.180: INFO: Container started at 2020-03-13 10:09:59 +0000 UTC, pod became ready at 2020-03-13 10:10:23 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:10:24.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1874" for this suite.

• [SLOW TEST:26.029 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":280,"completed":245,"skipped":4046,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:10:24.185: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:10:24.203: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Creating first CR 
Mar 13 10:10:24.749: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-13T10:10:24Z generation:1 name:name1 resourceVersion:62489 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:d47cf2cd-e7a5-47a6-addb-64936d4e77e7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Mar 13 10:10:34.752: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-13T10:10:34Z generation:1 name:name2 resourceVersion:62526 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7b62cf58-8875-4ada-8c69-690770e8bc30] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Mar 13 10:10:44.755: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-13T10:10:24Z generation:2 name:name1 resourceVersion:62553 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:d47cf2cd-e7a5-47a6-addb-64936d4e77e7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Mar 13 10:10:54.758: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-13T10:10:34Z generation:2 name:name2 resourceVersion:62581 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7b62cf58-8875-4ada-8c69-690770e8bc30] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Mar 13 10:11:04.762: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-13T10:10:24Z generation:2 name:name1 resourceVersion:62606 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:d47cf2cd-e7a5-47a6-addb-64936d4e77e7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Mar 13 10:11:14.767: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-13T10:10:34Z generation:2 name:name2 resourceVersion:62632 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7b62cf58-8875-4ada-8c69-690770e8bc30] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:25.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8744" for this suite.

• [SLOW TEST:61.092 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:41
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":280,"completed":246,"skipped":4050,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:25.277: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 13 10:11:25.300: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8642 /api/v1/namespaces/watch-8642/configmaps/e2e-watch-test-watch-closed 40ad4b0d-a283-4a8a-a986-10b802499d2d 62667 0 2020-03-13 10:11:25 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 13 10:11:25.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8642 /api/v1/namespaces/watch-8642/configmaps/e2e-watch-test-watch-closed 40ad4b0d-a283-4a8a-a986-10b802499d2d 62668 0 2020-03-13 10:11:25 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 13 10:11:25.307: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8642 /api/v1/namespaces/watch-8642/configmaps/e2e-watch-test-watch-closed 40ad4b0d-a283-4a8a-a986-10b802499d2d 62669 0 2020-03-13 10:11:25 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 13 10:11:25.307: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8642 /api/v1/namespaces/watch-8642/configmaps/e2e-watch-test-watch-closed 40ad4b0d-a283-4a8a-a986-10b802499d2d 62670 0 2020-03-13 10:11:25 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:25.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8642" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":280,"completed":247,"skipped":4057,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:25.312: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:11:25.739: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:11:28.747: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:28.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1688" for this suite.
STEP: Destroying namespace "webhook-1688-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":280,"completed":248,"skipped":4057,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:28.829: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 13 10:11:32.875: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 13 10:11:32.876: INFO: Pod pod-with-poststart-http-hook still exists
Mar 13 10:11:34.876: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 13 10:11:34.879: INFO: Pod pod-with-poststart-http-hook still exists
Mar 13 10:11:36.876: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 13 10:11:36.878: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:36.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3100" for this suite.

• [SLOW TEST:8.054 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":280,"completed":249,"skipped":4081,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:36.883: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 13 10:11:39.414: INFO: Successfully updated pod "pod-update-a5fe6a09-1216-4120-9d7e-0bfa5720a46f"
STEP: verifying the updated pod is in kubernetes
Mar 13 10:11:39.417: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:39.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3781" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":280,"completed":250,"skipped":4108,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:39.422: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:11:40.282: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:11:43.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:11:43.295: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2481-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:44.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5704" for this suite.
STEP: Destroying namespace "webhook-5704-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":280,"completed":251,"skipped":4110,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:44.394: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:11:44.409: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:50.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7029" for this suite.

• [SLOW TEST:6.131 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:47
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":280,"completed":252,"skipped":4112,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:50.525: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:11:50.782: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:11:53.792: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:11:53.794: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:54.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7624" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":280,"completed":253,"skipped":4116,"failed":0}

------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:54.899: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 13 10:11:54.927: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:11:58.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5988" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":280,"completed":254,"skipped":4116,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:11:58.616: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-e14a9d65-d2f4-428f-bbfb-17b890f14586
STEP: Creating a pod to test consume configMaps
Mar 13 10:11:58.638: INFO: Waiting up to 5m0s for pod "pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16" in namespace "configmap-9843" to be "success or failure"
Mar 13 10:11:58.640: INFO: Pod "pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16": Phase="Pending", Reason="", readiness=false. Elapsed: 1.499774ms
Mar 13 10:12:00.642: INFO: Pod "pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003536311s
STEP: Saw pod success
Mar 13 10:12:00.642: INFO: Pod "pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16" satisfied condition "success or failure"
Mar 13 10:12:00.643: INFO: Trying to get logs from node 172.24.5.5 pod pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 13 10:12:00.665: INFO: Waiting for pod pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16 to disappear
Mar 13 10:12:00.666: INFO: Pod pod-configmaps-36295fdd-e321-44dc-8220-70a92a105b16 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:12:00.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9843" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":255,"skipped":4136,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:12:00.670: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod test-webserver-a4e4fe66-48e6-4294-927c-4fe3c685a8ab in namespace container-probe-5416
Mar 13 10:12:02.694: INFO: Started pod test-webserver-a4e4fe66-48e6-4294-927c-4fe3c685a8ab in namespace container-probe-5416
STEP: checking the pod's current state and verifying that restartCount is present
Mar 13 10:12:02.695: INFO: Initial restart count of pod test-webserver-a4e4fe66-48e6-4294-927c-4fe3c685a8ab is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:16:02.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5416" for this suite.

• [SLOW TEST:242.281 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":256,"skipped":4151,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:16:02.951: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:16:04.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-449" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":280,"completed":257,"skipped":4195,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:16:04.998: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-1512
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Mar 13 10:16:05.019: INFO: Found 0 stateful pods, waiting for 3
Mar 13 10:16:15.021: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 10:16:15.021: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 10:16:15.021: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 13 10:16:15.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1512 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 10:16:15.273: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 10:16:15.273: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 10:16:15.273: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Mar 13 10:16:25.294: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 13 10:16:35.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1512 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 10:16:35.506: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 10:16:35.506: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 10:16:35.506: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 10:16:45.518: INFO: Waiting for StatefulSet statefulset-1512/ss2 to complete update
Mar 13 10:16:45.518: INFO: Waiting for Pod statefulset-1512/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 10:16:45.518: INFO: Waiting for Pod statefulset-1512/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 10:16:45.518: INFO: Waiting for Pod statefulset-1512/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 10:16:55.522: INFO: Waiting for StatefulSet statefulset-1512/ss2 to complete update
Mar 13 10:16:55.522: INFO: Waiting for Pod statefulset-1512/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 10:16:55.522: INFO: Waiting for Pod statefulset-1512/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 13 10:17:05.522: INFO: Waiting for StatefulSet statefulset-1512/ss2 to complete update
Mar 13 10:17:05.522: INFO: Waiting for Pod statefulset-1512/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Mar 13 10:17:15.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1512 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 13 10:17:15.741: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 13 10:17:15.741: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 13 10:17:15.741: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 13 10:17:25.763: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 13 10:17:35.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 exec --namespace=statefulset-1512 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 13 10:17:35.985: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 13 10:17:35.985: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 13 10:17:35.985: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 13 10:18:05.996: INFO: Waiting for StatefulSet statefulset-1512/ss2 to complete update
Mar 13 10:18:05.996: INFO: Waiting for Pod statefulset-1512/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 13 10:18:16.000: INFO: Deleting all statefulset in ns statefulset-1512
Mar 13 10:18:16.002: INFO: Scaling statefulset ss2 to 0
Mar 13 10:18:26.009: INFO: Waiting for statefulset status.replicas updated to 0
Mar 13 10:18:26.011: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:18:26.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1512" for this suite.

• [SLOW TEST:141.023 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":280,"completed":258,"skipped":4197,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:18:26.021: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating cluster-info
Mar 13 10:18:26.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 cluster-info'
Mar 13 10:18:26.121: INFO: stderr: ""
Mar 13 10:18:26.121: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:18:26.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8310" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":280,"completed":259,"skipped":4201,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:18:26.127: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-projected-pbl8
STEP: Creating a pod to test atomic-volume-subpath
Mar 13 10:18:26.150: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pbl8" in namespace "subpath-2616" to be "success or failure"
Mar 13 10:18:26.152: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.359727ms
Mar 13 10:18:28.153: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 2.003252852s
Mar 13 10:18:30.155: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 4.005070407s
Mar 13 10:18:32.157: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 6.006819658s
Mar 13 10:18:34.159: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 8.008932415s
Mar 13 10:18:36.161: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 10.010962439s
Mar 13 10:18:38.164: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 12.01346522s
Mar 13 10:18:40.166: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 14.015390045s
Mar 13 10:18:42.168: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 16.017571322s
Mar 13 10:18:44.170: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 18.019901296s
Mar 13 10:18:46.172: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Running", Reason="", readiness=true. Elapsed: 20.021943718s
Mar 13 10:18:48.174: INFO: Pod "pod-subpath-test-projected-pbl8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.024101142s
STEP: Saw pod success
Mar 13 10:18:48.174: INFO: Pod "pod-subpath-test-projected-pbl8" satisfied condition "success or failure"
Mar 13 10:18:48.176: INFO: Trying to get logs from node 172.24.5.7 pod pod-subpath-test-projected-pbl8 container test-container-subpath-projected-pbl8: <nil>
STEP: delete the pod
Mar 13 10:18:48.192: INFO: Waiting for pod pod-subpath-test-projected-pbl8 to disappear
Mar 13 10:18:48.193: INFO: Pod pod-subpath-test-projected-pbl8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-pbl8
Mar 13 10:18:48.194: INFO: Deleting pod "pod-subpath-test-projected-pbl8" in namespace "subpath-2616"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:18:48.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2616" for this suite.

• [SLOW TEST:22.072 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":280,"completed":260,"skipped":4204,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:18:48.199: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-5492
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 13 10:18:48.216: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 13 10:19:10.247: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.188:8080/dial?request=hostname&protocol=http&host=10.42.1.187&port=8080&tries=1'] Namespace:pod-network-test-5492 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:19:10.247: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:19:10.374: INFO: Waiting for responses: map[]
Mar 13 10:19:10.376: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.188:8080/dial?request=hostname&protocol=http&host=10.42.0.134&port=8080&tries=1'] Namespace:pod-network-test-5492 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:19:10.376: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:19:10.477: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:10.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5492" for this suite.

• [SLOW TEST:22.282 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":261,"skipped":4233,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:10.482: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:46
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:10.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-6555" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":280,"completed":262,"skipped":4247,"failed":0}
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:10.504: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:12.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-584" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":280,"completed":263,"skipped":4251,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:12.536: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar 13 10:19:16.564: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9681 PodName:pod-sharedvolume-5e4c8164-9d33-4827-a0d0-ca67a2a2fdba ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:19:16.564: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:19:16.712: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:16.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9681" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":280,"completed":264,"skipped":4266,"failed":0}
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:16.717: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 13 10:19:16.736: INFO: Waiting up to 5m0s for pod "downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289" in namespace "downward-api-9909" to be "success or failure"
Mar 13 10:19:16.737: INFO: Pod "downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289": Phase="Pending", Reason="", readiness=false. Elapsed: 1.216683ms
Mar 13 10:19:18.739: INFO: Pod "downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003038516s
STEP: Saw pod success
Mar 13 10:19:18.739: INFO: Pod "downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289" satisfied condition "success or failure"
Mar 13 10:19:18.740: INFO: Trying to get logs from node 172.24.5.7 pod downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289 container dapi-container: <nil>
STEP: delete the pod
Mar 13 10:19:18.748: INFO: Waiting for pod downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289 to disappear
Mar 13 10:19:18.750: INFO: Pod downward-api-b73cbcfb-f420-427b-a334-1bf6e2565289 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:18.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9909" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":280,"completed":265,"skipped":4271,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:18.754: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar 13 10:19:21.280: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4644 pod-service-account-53123709-01f5-4523-b766-a565b800f78a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar 13 10:19:21.482: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4644 pod-service-account-53123709-01f5-4523-b766-a565b800f78a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar 13 10:19:21.658: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4644 pod-service-account-53123709-01f5-4523-b766-a565b800f78a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:21.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4644" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":280,"completed":266,"skipped":4284,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:21.846: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 10:19:21.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9633'
Mar 13 10:19:21.956: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 13 10:19:21.956: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Mar 13 10:19:21.959: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-tkqv9]
Mar 13 10:19:21.959: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-tkqv9" in namespace "kubectl-9633" to be "running and ready"
Mar 13 10:19:21.961: INFO: Pod "e2e-test-httpd-rc-tkqv9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.401271ms
Mar 13 10:19:23.962: INFO: Pod "e2e-test-httpd-rc-tkqv9": Phase="Running", Reason="", readiness=true. Elapsed: 2.00337756s
Mar 13 10:19:23.963: INFO: Pod "e2e-test-httpd-rc-tkqv9" satisfied condition "running and ready"
Mar 13 10:19:23.963: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-tkqv9]
Mar 13 10:19:23.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 logs rc/e2e-test-httpd-rc --namespace=kubectl-9633'
Mar 13 10:19:24.068: INFO: stderr: ""
Mar 13 10:19:24.068: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.42.0.138. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.42.0.138. Set the 'ServerName' directive globally to suppress this message\n[Fri Mar 13 10:19:22.642883 2020] [mpm_event:notice] [pid 1:tid 140537135967080] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Fri Mar 13 10:19:22.642918 2020] [core:notice] [pid 1:tid 140537135967080] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1637
Mar 13 10:19:24.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete rc e2e-test-httpd-rc --namespace=kubectl-9633'
Mar 13 10:19:24.146: INFO: stderr: ""
Mar 13 10:19:24.146: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:24.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9633" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run rc should create an rc from an image  [Conformance]","total":280,"completed":267,"skipped":4290,"failed":0}
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:24.151: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-2003/configmap-test-a506b55a-0378-4cb0-876b-289aed58df45
STEP: Creating a pod to test consume configMaps
Mar 13 10:19:24.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4" in namespace "configmap-2003" to be "success or failure"
Mar 13 10:19:24.172: INFO: Pod "pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.3386ms
Mar 13 10:19:26.175: INFO: Pod "pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003420207s
STEP: Saw pod success
Mar 13 10:19:26.175: INFO: Pod "pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4" satisfied condition "success or failure"
Mar 13 10:19:26.176: INFO: Trying to get logs from node 172.24.5.7 pod pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4 container env-test: <nil>
STEP: delete the pod
Mar 13 10:19:26.184: INFO: Waiting for pod pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4 to disappear
Mar 13 10:19:26.186: INFO: Pod pod-configmaps-874dc2d5-bc7c-4c36-8452-c6a9e5d1aee4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:26.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2003" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":280,"completed":268,"skipped":4295,"failed":0}

------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:26.190: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:330
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Mar 13 10:19:26.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 create -f - --namespace=kubectl-7896'
Mar 13 10:19:26.419: INFO: stderr: ""
Mar 13 10:19:26.419: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 13 10:19:26.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7896'
Mar 13 10:19:26.496: INFO: stderr: ""
Mar 13 10:19:26.496: INFO: stdout: "update-demo-nautilus-rksb4 update-demo-nautilus-vv7xb "
Mar 13 10:19:26.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-rksb4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7896'
Mar 13 10:19:26.571: INFO: stderr: ""
Mar 13 10:19:26.571: INFO: stdout: ""
Mar 13 10:19:26.571: INFO: update-demo-nautilus-rksb4 is created but not running
Mar 13 10:19:31.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7896'
Mar 13 10:19:31.660: INFO: stderr: ""
Mar 13 10:19:31.660: INFO: stdout: "update-demo-nautilus-rksb4 update-demo-nautilus-vv7xb "
Mar 13 10:19:31.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-rksb4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7896'
Mar 13 10:19:31.737: INFO: stderr: ""
Mar 13 10:19:31.737: INFO: stdout: "true"
Mar 13 10:19:31.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-rksb4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7896'
Mar 13 10:19:31.816: INFO: stderr: ""
Mar 13 10:19:31.816: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:19:31.816: INFO: validating pod update-demo-nautilus-rksb4
Mar 13 10:19:31.819: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:19:31.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:19:31.819: INFO: update-demo-nautilus-rksb4 is verified up and running
Mar 13 10:19:31.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-vv7xb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7896'
Mar 13 10:19:31.904: INFO: stderr: ""
Mar 13 10:19:31.904: INFO: stdout: "true"
Mar 13 10:19:31.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods update-demo-nautilus-vv7xb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7896'
Mar 13 10:19:31.983: INFO: stderr: ""
Mar 13 10:19:31.983: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 13 10:19:31.983: INFO: validating pod update-demo-nautilus-vv7xb
Mar 13 10:19:31.986: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 13 10:19:31.986: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 13 10:19:31.986: INFO: update-demo-nautilus-vv7xb is verified up and running
STEP: using delete to clean up resources
Mar 13 10:19:31.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete --grace-period=0 --force -f - --namespace=kubectl-7896'
Mar 13 10:19:32.063: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 13 10:19:32.063: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 13 10:19:32.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7896'
Mar 13 10:19:32.151: INFO: stderr: "No resources found in kubectl-7896 namespace.\n"
Mar 13 10:19:32.151: INFO: stdout: ""
Mar 13 10:19:32.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 get pods -l name=update-demo --namespace=kubectl-7896 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 13 10:19:32.235: INFO: stderr: ""
Mar 13 10:19:32.235: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:19:32.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7896" for this suite.

• [SLOW TEST:6.050 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:328
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":280,"completed":269,"skipped":4295,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:19:32.241: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 in namespace container-probe-225
Mar 13 10:19:34.264: INFO: Started pod liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 in namespace container-probe-225
STEP: checking the pod's current state and verifying that restartCount is present
Mar 13 10:19:34.265: INFO: Initial restart count of pod liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 is 0
Mar 13 10:19:54.286: INFO: Restart count of pod container-probe-225/liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 is now 1 (20.021025188s elapsed)
Mar 13 10:20:14.308: INFO: Restart count of pod container-probe-225/liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 is now 2 (40.042423394s elapsed)
Mar 13 10:20:34.328: INFO: Restart count of pod container-probe-225/liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 is now 3 (1m0.062396203s elapsed)
Mar 13 10:20:54.349: INFO: Restart count of pod container-probe-225/liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 is now 4 (1m20.083735275s elapsed)
Mar 13 10:22:08.423: INFO: Restart count of pod container-probe-225/liveness-57f34851-bb66-4f71-bdf7-5b227a229d49 is now 5 (2m34.157342237s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:22:08.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-225" for this suite.

• [SLOW TEST:156.190 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":280,"completed":270,"skipped":4347,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:22:08.431: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:22:08.448: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:22:09.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5932" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":280,"completed":271,"skipped":4356,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:22:09.593: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:22:09.905: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:22:12.914: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 13 10:22:12.916: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6778-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:22:13.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8685" for this suite.
STEP: Destroying namespace "webhook-8685-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":280,"completed":272,"skipped":4384,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:22:14.008: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Mar 13 10:22:14.024: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:22:16.879: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:22:28.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9387" for this suite.

• [SLOW TEST:14.199 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":280,"completed":273,"skipped":4411,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:22:28.207: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 13 10:22:28.647: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 13 10:22:31.658: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:22:43.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9009" for this suite.
STEP: Destroying namespace "webhook-9009-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.528 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":280,"completed":274,"skipped":4418,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:22:43.736: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 13 10:22:46.768: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:22:47.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8913" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":280,"completed":275,"skipped":4448,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:22:47.780: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-7953
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 13 10:22:47.797: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 13 10:23:05.829: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.1.192 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7953 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:23:05.829: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:23:06.945: INFO: Found all expected endpoints: [netserver-0]
Mar 13 10:23:06.947: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.42.0.145 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7953 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 13 10:23:06.947: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
Mar 13 10:23:08.062: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:23:08.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7953" for this suite.

• [SLOW TEST:20.286 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":276,"skipped":4457,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:23:08.067: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-09cdd8b8-0e49-4109-b8ee-e764b6f347f2
STEP: Creating a pod to test consume secrets
Mar 13 10:23:08.089: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182" in namespace "projected-1261" to be "success or failure"
Mar 13 10:23:08.090: INFO: Pod "pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182": Phase="Pending", Reason="", readiness=false. Elapsed: 1.389184ms
Mar 13 10:23:10.092: INFO: Pod "pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003602689s
STEP: Saw pod success
Mar 13 10:23:10.093: INFO: Pod "pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182" satisfied condition "success or failure"
Mar 13 10:23:10.094: INFO: Trying to get logs from node 172.24.5.7 pod pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 13 10:23:10.110: INFO: Waiting for pod pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182 to disappear
Mar 13 10:23:10.111: INFO: Pod pod-projected-secrets-4209e753-2ae0-43bc-8816-d7bfcd3a8182 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:23:10.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1261" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":277,"skipped":4508,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:23:10.116: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5882.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5882.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5882.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5882.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5882.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5882.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 13 10:23:12.159: INFO: DNS probes using dns-5882/dns-test-2dfa8fc6-8104-4796-a0a7-63cae80d81bb succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:23:12.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5882" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":280,"completed":278,"skipped":4521,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:23:12.171: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 13 10:23:12.190: INFO: Waiting up to 5m0s for pod "pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b" in namespace "emptydir-6358" to be "success or failure"
Mar 13 10:23:12.192: INFO: Pod "pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.161693ms
Mar 13 10:23:14.194: INFO: Pod "pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003351625s
STEP: Saw pod success
Mar 13 10:23:14.194: INFO: Pod "pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b" satisfied condition "success or failure"
Mar 13 10:23:14.195: INFO: Trying to get logs from node 172.24.5.7 pod pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b container test-container: <nil>
STEP: delete the pod
Mar 13 10:23:14.204: INFO: Waiting for pod pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b to disappear
Mar 13 10:23:14.205: INFO: Pod pod-8e6b5e0a-e4a9-4e29-bcc8-b08fbc1d5c4b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:23:14.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6358" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":279,"skipped":4535,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 13 10:23:14.210: INFO: >>> kubeConfig: /tmp/kubeconfig-141385212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1788
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 13 10:23:14.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-299'
Mar 13 10:23:14.312: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 13 10:23:14.312: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1793
Mar 13 10:23:14.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-141385212 delete jobs e2e-test-httpd-job --namespace=kubectl-299'
Mar 13 10:23:14.390: INFO: stderr: ""
Mar 13 10:23:14.390: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 13 10:23:14.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-299" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run job should create a job from an image when restart is OnFailure  [Conformance]","total":280,"completed":280,"skipped":4540,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSMar 13 10:23:14.394: INFO: Running AfterSuite actions on all nodes
Mar 13 10:23:14.394: INFO: Running AfterSuite actions on node 1
Mar 13 10:23:14.394: INFO: Skipping dumping logs from cluster
{"msg":"Test Suite completed","total":280,"completed":280,"skipped":4563,"failed":0}

Ran 280 of 4843 Specs in 4047.368 seconds
SUCCESS! -- 280 Passed | 0 Failed | 0 Pending | 4563 Skipped
PASS

Ginkgo ran 1 suite in 1h7m28.583894091s
Test Suite Passed
