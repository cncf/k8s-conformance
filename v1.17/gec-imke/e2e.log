I1102 18:00:28.022846      24 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-142776444
I1102 18:00:28.022884      24 test_context.go:419] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I1102 18:00:28.023127      24 e2e.go:109] Starting e2e run "820bafbe-c8db-4d6e-9e86-7a891d62c4ed" on Ginkgo node 1
{"msg":"Test Suite starting","total":280,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1604340026 - Will randomize all specs
Will run 280 of 4843 specs

Nov  2 18:00:28.037: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:00:28.061: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1102 18:00:28.064109      24 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post http://localhost:8099/progress: dial tcp 127.0.0.1:8099: connect: connection refused
Nov  2 18:00:28.093: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  2 18:00:28.150: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  2 18:00:28.155: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Nov  2 18:00:28.155: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  2 18:00:28.177: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin-centos' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin-coreos' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin-ubuntu' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'logrotate' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'user-ssh-keys-agent' (0 seconds elapsed)
Nov  2 18:00:28.177: INFO: e2e test version: v1.17.9
Nov  2 18:00:28.183: INFO: kube-apiserver version: v1.17.9
Nov  2 18:00:28.183: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:00:28.197: INFO: Cluster IP family: ipv4
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:00:28.197: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
Nov  2 18:00:28.307: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov  2 18:00:28.346: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-27937a38-473d-4d88-bf76-8351b7a4cd21
STEP: Creating a pod to test consume configMaps
Nov  2 18:00:28.515: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb" in namespace "projected-5915" to be "success or failure"
Nov  2 18:00:28.536: INFO: Pod "pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb": Phase="Pending", Reason="", readiness=false. Elapsed: 21.469776ms
Nov  2 18:00:30.544: INFO: Pod "pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029095023s
Nov  2 18:00:32.558: INFO: Pod "pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043040843s
STEP: Saw pod success
Nov  2 18:00:32.558: INFO: Pod "pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb" satisfied condition "success or failure"
Nov  2 18:00:32.564: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:00:32.813: INFO: Waiting for pod pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb to disappear
Nov  2 18:00:32.824: INFO: Pod pod-projected-configmaps-96421e22-435c-4b70-bba6-281f57bf4aeb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:00:32.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5915" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":1,"skipped":4,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:00:32.859: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the initial replication controller
Nov  2 18:00:33.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-7599'
Nov  2 18:00:33.881: INFO: stderr: ""
Nov  2 18:00:33.881: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  2 18:00:33.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7599'
Nov  2 18:00:34.004: INFO: stderr: ""
Nov  2 18:00:34.004: INFO: stdout: "update-demo-nautilus-9hwk9 update-demo-nautilus-cr67l "
Nov  2 18:00:34.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-9hwk9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:00:34.098: INFO: stderr: ""
Nov  2 18:00:34.098: INFO: stdout: ""
Nov  2 18:00:34.098: INFO: update-demo-nautilus-9hwk9 is created but not running
Nov  2 18:00:39.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7599'
Nov  2 18:00:39.224: INFO: stderr: ""
Nov  2 18:00:39.224: INFO: stdout: "update-demo-nautilus-9hwk9 update-demo-nautilus-cr67l "
Nov  2 18:00:39.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-9hwk9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:00:39.363: INFO: stderr: ""
Nov  2 18:00:39.363: INFO: stdout: "true"
Nov  2 18:00:39.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-9hwk9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:00:39.466: INFO: stderr: ""
Nov  2 18:00:39.466: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:00:39.467: INFO: validating pod update-demo-nautilus-9hwk9
Nov  2 18:00:39.566: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:00:39.566: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:00:39.566: INFO: update-demo-nautilus-9hwk9 is verified up and running
Nov  2 18:00:39.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-cr67l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:00:39.668: INFO: stderr: ""
Nov  2 18:00:39.668: INFO: stdout: "true"
Nov  2 18:00:39.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-cr67l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:00:39.766: INFO: stderr: ""
Nov  2 18:00:39.766: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:00:39.766: INFO: validating pod update-demo-nautilus-cr67l
Nov  2 18:00:39.870: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:00:39.870: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:00:39.870: INFO: update-demo-nautilus-cr67l is verified up and running
STEP: rolling-update to new replication controller
Nov  2 18:00:39.872: INFO: scanned /root for discovery docs: <nil>
Nov  2 18:00:39.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7599'
Nov  2 18:01:02.626: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  2 18:01:02.626: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  2 18:01:02.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7599'
Nov  2 18:01:02.740: INFO: stderr: ""
Nov  2 18:01:02.740: INFO: stdout: "update-demo-kitten-8l4rn update-demo-kitten-tvz4z "
Nov  2 18:01:02.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-kitten-8l4rn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:01:02.858: INFO: stderr: ""
Nov  2 18:01:02.858: INFO: stdout: "true"
Nov  2 18:01:02.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-kitten-8l4rn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:01:02.962: INFO: stderr: ""
Nov  2 18:01:02.962: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  2 18:01:02.962: INFO: validating pod update-demo-kitten-8l4rn
Nov  2 18:01:03.064: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  2 18:01:03.064: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  2 18:01:03.064: INFO: update-demo-kitten-8l4rn is verified up and running
Nov  2 18:01:03.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-kitten-tvz4z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:01:03.166: INFO: stderr: ""
Nov  2 18:01:03.166: INFO: stdout: "true"
Nov  2 18:01:03.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-kitten-tvz4z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7599'
Nov  2 18:01:03.277: INFO: stderr: ""
Nov  2 18:01:03.277: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  2 18:01:03.277: INFO: validating pod update-demo-kitten-tvz4z
Nov  2 18:01:03.380: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  2 18:01:03.380: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  2 18:01:03.380: INFO: update-demo-kitten-tvz4z is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:03.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7599" for this suite.

• [SLOW TEST:30.546 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should do a rolling update of a replication controller  [Conformance]","total":280,"completed":2,"skipped":14,"failed":0}
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:03.405: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name projected-secret-test-61449bba-0340-4690-9a84-e9c1e09cdcc6
STEP: Creating a pod to test consume secrets
Nov  2 18:01:03.639: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0" in namespace "projected-8112" to be "success or failure"
Nov  2 18:01:03.648: INFO: Pod "pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.635357ms
Nov  2 18:01:05.657: INFO: Pod "pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018083316s
Nov  2 18:01:07.666: INFO: Pod "pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026689489s
STEP: Saw pod success
Nov  2 18:01:07.666: INFO: Pod "pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0" satisfied condition "success or failure"
Nov  2 18:01:07.692: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0 container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:01:07.787: INFO: Waiting for pod pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0 to disappear
Nov  2 18:01:07.793: INFO: Pod pod-projected-secrets-0b203d28-7627-4329-95ac-dfec093142f0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:07.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8112" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":3,"skipped":16,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:07.815: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6684
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:01:08.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1" in namespace "projected-6684" to be "success or failure"
Nov  2 18:01:08.097: INFO: Pod "downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.072795ms
Nov  2 18:01:10.110: INFO: Pod "downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025734463s
Nov  2 18:01:12.120: INFO: Pod "downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035710114s
STEP: Saw pod success
Nov  2 18:01:12.120: INFO: Pod "downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1" satisfied condition "success or failure"
Nov  2 18:01:12.127: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1 container client-container: <nil>
STEP: delete the pod
Nov  2 18:01:12.192: INFO: Waiting for pod downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1 to disappear
Nov  2 18:01:12.204: INFO: Pod downwardapi-volume-3566d1fc-4e62-4af6-a393-768b74b874b1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:12.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6684" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":4,"skipped":46,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:12.237: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5193
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1626
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 18:01:12.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-5193'
Nov  2 18:01:12.556: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  2 18:01:12.556: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1631
Nov  2 18:01:16.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5193'
Nov  2 18:01:16.706: INFO: stderr: ""
Nov  2 18:01:16.706: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:16.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5193" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run deployment should create a deployment from an image  [Conformance]","total":280,"completed":5,"skipped":56,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:16.730: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov  2 18:01:17.121: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:25.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4279" for this suite.

• [SLOW TEST:9.280 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":280,"completed":6,"skipped":61,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:26.011: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:01:46.290: INFO: Container started at 2020-11-02 18:01:29 +0000 UTC, pod became ready at 2020-11-02 18:01:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:46.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3896" for this suite.

• [SLOW TEST:20.302 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":280,"completed":7,"skipped":81,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:46.314: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:01:47.618: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:01:49.643: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:01:51.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:01:53.652: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936907, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:01:56.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:01:56.686: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7072-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:01:58.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7607" for this suite.
STEP: Destroying namespace "webhook-7607-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:12.059 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":280,"completed":8,"skipped":127,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:01:58.374: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3308
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-9cf8b321-92fd-44c8-9d57-db6fa0e64492
STEP: Creating a pod to test consume secrets
Nov  2 18:01:58.638: INFO: Waiting up to 5m0s for pod "pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013" in namespace "secrets-3308" to be "success or failure"
Nov  2 18:01:58.653: INFO: Pod "pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013": Phase="Pending", Reason="", readiness=false. Elapsed: 14.420655ms
Nov  2 18:02:00.661: INFO: Pod "pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022213615s
Nov  2 18:02:02.668: INFO: Pod "pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029437024s
STEP: Saw pod success
Nov  2 18:02:02.668: INFO: Pod "pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013" satisfied condition "success or failure"
Nov  2 18:02:02.678: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013 container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:02:02.741: INFO: Waiting for pod pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013 to disappear
Nov  2 18:02:02.751: INFO: Pod pod-secrets-88646fd2-6884-4617-a05b-163b88fb0013 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:02.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3308" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":9,"skipped":136,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:02.790: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-cb6f8c9e-fe97-4959-8963-376226681364
STEP: Creating a pod to test consume configMaps
Nov  2 18:02:03.037: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a" in namespace "configmap-2535" to be "success or failure"
Nov  2 18:02:03.045: INFO: Pod "pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.427634ms
Nov  2 18:02:05.053: INFO: Pod "pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015431269s
Nov  2 18:02:07.063: INFO: Pod "pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025417245s
STEP: Saw pod success
Nov  2 18:02:07.063: INFO: Pod "pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a" satisfied condition "success or failure"
Nov  2 18:02:07.071: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:02:07.166: INFO: Waiting for pod pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a to disappear
Nov  2 18:02:07.174: INFO: Pod pod-configmaps-ce1631e7-d5fa-4f15-a7bf-adbaa21c6c2a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:07.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2535" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":10,"skipped":146,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:07.197: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:02:08.384: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:02:10.406: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:02:12.418: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739936928, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:02:15.466: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the crd webhook via the AdmissionRegistration API
Nov  2 18:02:15.538: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource definition that should be denied by the webhook
Nov  2 18:02:15.789: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:15.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5306" for this suite.
STEP: Destroying namespace "webhook-5306-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.847 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":280,"completed":11,"skipped":146,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:16.044: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-8660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test hostPath mode
Nov  2 18:02:16.290: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8660" to be "success or failure"
Nov  2 18:02:16.296: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.256333ms
Nov  2 18:02:18.308: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018170175s
Nov  2 18:02:20.317: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027096608s
Nov  2 18:02:22.330: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039829432s
STEP: Saw pod success
Nov  2 18:02:22.330: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  2 18:02:22.336: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  2 18:02:22.629: INFO: Waiting for pod pod-host-path-test to disappear
Nov  2 18:02:22.635: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:22.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8660" for this suite.

• [SLOW TEST:6.620 seconds]
[sig-storage] HostPath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":12,"skipped":155,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:22.664: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6441
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  2 18:02:23.016: INFO: Waiting up to 5m0s for pod "pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420" in namespace "emptydir-6441" to be "success or failure"
Nov  2 18:02:23.031: INFO: Pod "pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420": Phase="Pending", Reason="", readiness=false. Elapsed: 14.656955ms
Nov  2 18:02:25.047: INFO: Pod "pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03060987s
Nov  2 18:02:27.055: INFO: Pod "pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038806502s
STEP: Saw pod success
Nov  2 18:02:27.055: INFO: Pod "pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420" satisfied condition "success or failure"
Nov  2 18:02:27.062: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420 container test-container: <nil>
STEP: delete the pod
Nov  2 18:02:27.111: INFO: Waiting for pod pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420 to disappear
Nov  2 18:02:27.120: INFO: Pod pod-1f45cbc3-77a2-4e00-acd5-a3dc35d6d420 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:27.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6441" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":13,"skipped":157,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:27.146: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: executing a command with run --rm and attach with stdin
Nov  2 18:02:27.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=kubectl-2766 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  2 18:02:30.478: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  2 18:02:30.478: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:32.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2766" for this suite.

• [SLOW TEST:5.385 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1837
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run --rm job should create a job from an image, then delete the job  [Conformance]","total":280,"completed":14,"skipped":170,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:32.532: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  2 18:02:36.923: INFO: &Pod{ObjectMeta:{send-events-35dcb87a-1e0e-47c2-b2cf-cd2cb72b4e61  events-4463 /api/v1/namespaces/events-4463/pods/send-events-35dcb87a-1e0e-47c2-b2cf-cd2cb72b4e61 1e181bf7-3cf7-4d13-8a65-0e6c86bf454e 142894 0 2020-11-02 18:02:32 +0000 UTC <nil> <nil> map[name:foo time:818652284] map[cni.projectcalico.org/podIP:172.25.1.18/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-b5rwk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-b5rwk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-b5rwk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:02:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:02:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:02:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:02:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:172.25.1.18,StartTime:2020-11-02 18:02:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 18:02:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://32d4c06b402f93ff52be49e423259709476b6bbbbe96bd6ea96a7261e738266f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov  2 18:02:38.933: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  2 18:02:40.941: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:02:40.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4463" for this suite.

• [SLOW TEST:8.454 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":280,"completed":15,"skipped":236,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:02:40.987: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9034
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:02:41.271: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  2 18:02:41.373: INFO: Number of nodes with available pods: 0
Nov  2 18:02:41.373: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:42.390: INFO: Number of nodes with available pods: 0
Nov  2 18:02:42.390: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:43.390: INFO: Number of nodes with available pods: 0
Nov  2 18:02:43.390: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:44.396: INFO: Number of nodes with available pods: 1
Nov  2 18:02:44.396: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:45.391: INFO: Number of nodes with available pods: 1
Nov  2 18:02:45.391: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:46.394: INFO: Number of nodes with available pods: 1
Nov  2 18:02:46.394: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:47.397: INFO: Number of nodes with available pods: 1
Nov  2 18:02:47.397: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:48.391: INFO: Number of nodes with available pods: 1
Nov  2 18:02:48.391: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:49.415: INFO: Number of nodes with available pods: 1
Nov  2 18:02:49.415: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:02:50.393: INFO: Number of nodes with available pods: 3
Nov  2 18:02:50.393: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  2 18:02:50.471: INFO: Wrong image for pod: daemon-set-drrp2. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:50.471: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:50.471: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:51.495: INFO: Wrong image for pod: daemon-set-drrp2. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:51.495: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:51.495: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:52.493: INFO: Wrong image for pod: daemon-set-drrp2. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:52.493: INFO: Pod daemon-set-drrp2 is not available
Nov  2 18:02:52.493: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:52.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:53.493: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:53.493: INFO: Pod daemon-set-vptv6 is not available
Nov  2 18:02:53.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:54.492: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:54.492: INFO: Pod daemon-set-vptv6 is not available
Nov  2 18:02:54.492: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:55.493: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:55.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:56.493: INFO: Wrong image for pod: daemon-set-rj6sd. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:56.493: INFO: Pod daemon-set-rj6sd is not available
Nov  2 18:02:56.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:57.499: INFO: Pod daemon-set-7sk44 is not available
Nov  2 18:02:57.499: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:58.503: INFO: Pod daemon-set-7sk44 is not available
Nov  2 18:02:58.503: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:02:59.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:03:00.496: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:03:01.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:03:01.493: INFO: Pod daemon-set-zqsbt is not available
Nov  2 18:03:02.493: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:03:02.493: INFO: Pod daemon-set-zqsbt is not available
Nov  2 18:03:03.503: INFO: Wrong image for pod: daemon-set-zqsbt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Nov  2 18:03:03.503: INFO: Pod daemon-set-zqsbt is not available
Nov  2 18:03:05.495: INFO: Pod daemon-set-q8fgf is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  2 18:03:05.523: INFO: Number of nodes with available pods: 2
Nov  2 18:03:05.523: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:03:06.540: INFO: Number of nodes with available pods: 2
Nov  2 18:03:06.541: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:03:07.544: INFO: Number of nodes with available pods: 2
Nov  2 18:03:07.544: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:03:08.540: INFO: Number of nodes with available pods: 2
Nov  2 18:03:08.540: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:03:09.541: INFO: Number of nodes with available pods: 2
Nov  2 18:03:09.541: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:03:10.543: INFO: Number of nodes with available pods: 3
Nov  2 18:03:10.543: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9034, will wait for the garbage collector to delete the pods
Nov  2 18:03:10.657: INFO: Deleting DaemonSet.extensions daemon-set took: 21.785694ms
Nov  2 18:03:11.158: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.235634ms
Nov  2 18:03:24.571: INFO: Number of nodes with available pods: 0
Nov  2 18:03:24.571: INFO: Number of running nodes: 0, number of available pods: 0
Nov  2 18:03:24.578: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9034/daemonsets","resourceVersion":"143280"},"items":null}

Nov  2 18:03:24.587: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9034/pods","resourceVersion":"143280"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:03:24.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9034" for this suite.

• [SLOW TEST:43.659 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":280,"completed":16,"skipped":238,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:03:24.650: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-d9330120-3b7a-4742-b541-000900b932b7
STEP: Creating a pod to test consume secrets
Nov  2 18:03:24.892: INFO: Waiting up to 5m0s for pod "pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821" in namespace "secrets-5464" to be "success or failure"
Nov  2 18:03:24.906: INFO: Pod "pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821": Phase="Pending", Reason="", readiness=false. Elapsed: 13.830224ms
Nov  2 18:03:26.914: INFO: Pod "pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021839603s
Nov  2 18:03:28.923: INFO: Pod "pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030120354s
STEP: Saw pod success
Nov  2 18:03:28.923: INFO: Pod "pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821" satisfied condition "success or failure"
Nov  2 18:03:28.930: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821 container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:03:29.012: INFO: Waiting for pod pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821 to disappear
Nov  2 18:03:29.019: INFO: Pod pod-secrets-c11ac3b8-eee6-4e9f-a5bd-b28c4a547821 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:03:29.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5464" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":17,"skipped":252,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:03:29.049: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:03:29.383: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530" in namespace "downward-api-3376" to be "success or failure"
Nov  2 18:03:29.406: INFO: Pod "downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530": Phase="Pending", Reason="", readiness=false. Elapsed: 22.682393ms
Nov  2 18:03:31.413: INFO: Pod "downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030125853s
Nov  2 18:03:33.421: INFO: Pod "downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038534221s
STEP: Saw pod success
Nov  2 18:03:33.422: INFO: Pod "downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530" satisfied condition "success or failure"
Nov  2 18:03:33.428: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530 container client-container: <nil>
STEP: delete the pod
Nov  2 18:03:33.515: INFO: Waiting for pod downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530 to disappear
Nov  2 18:03:33.529: INFO: Pod downwardapi-volume-cfc58e3a-7371-4549-ad81-ad6258935530 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:03:33.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3376" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":18,"skipped":265,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:03:33.563: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:03:33.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6922" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":280,"completed":19,"skipped":340,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:03:33.891: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1585
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 18:03:34.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9078'
Nov  2 18:03:34.269: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  2 18:03:34.270: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Nov  2 18:03:34.289: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov  2 18:03:34.295: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  2 18:03:34.313: INFO: scanned /root for discovery docs: <nil>
Nov  2 18:03:34.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9078'
Nov  2 18:03:50.289: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  2 18:03:50.289: INFO: stdout: "Created e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263\nScaling up e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov  2 18:03:50.289: INFO: stdout: "Created e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263\nScaling up e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov  2 18:03:50.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9078'
Nov  2 18:03:50.399: INFO: stderr: ""
Nov  2 18:03:50.399: INFO: stdout: "e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263-hk4bh e2e-test-httpd-rc-79shx "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Nov  2 18:03:55.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9078'
Nov  2 18:03:55.576: INFO: stderr: ""
Nov  2 18:03:55.576: INFO: stdout: "e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263-hk4bh "
Nov  2 18:03:55.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263-hk4bh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9078'
Nov  2 18:03:55.670: INFO: stderr: ""
Nov  2 18:03:55.670: INFO: stdout: "true"
Nov  2 18:03:55.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263-hk4bh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9078'
Nov  2 18:03:55.766: INFO: stderr: ""
Nov  2 18:03:55.766: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov  2 18:03:55.766: INFO: e2e-test-httpd-rc-3cbc238a8e40ee722d158344d4732263-hk4bh is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
Nov  2 18:03:55.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete rc e2e-test-httpd-rc --namespace=kubectl-9078'
Nov  2 18:03:55.891: INFO: stderr: ""
Nov  2 18:03:55.891: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:03:55.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9078" for this suite.

• [SLOW TEST:22.047 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1580
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl rolling-update should support rolling-update to same image  [Conformance]","total":280,"completed":20,"skipped":348,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:03:55.938: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3076
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-3076.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-3076.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3076.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-3076.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-3076.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-3076.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3076.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 18:04:10.394: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.445: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.551: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.744: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.765: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.776: INFO: Unable to read jessie_udp@dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.788: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-3076.svc.cluster.local from pod dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9: the server could not find the requested resource (get pods dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9)
Nov  2 18:04:10.928: INFO: Lookups using dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-3076.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-3076.svc.cluster.local jessie_udp@dns-test-service-2.dns-3076.svc.cluster.local jessie_tcp@dns-test-service-2.dns-3076.svc.cluster.local]

Nov  2 18:04:16.922: INFO: DNS probes using dns-3076/dns-test-a6e8af67-7fbc-4f0f-b55e-116428450cb9 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:17.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3076" for this suite.

• [SLOW TEST:21.145 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":280,"completed":21,"skipped":351,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:17.084: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-66f92904-c6dc-4e1a-812c-a2ee6f01bcc2
STEP: Creating a pod to test consume secrets
Nov  2 18:04:17.352: INFO: Waiting up to 5m0s for pod "pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14" in namespace "secrets-7273" to be "success or failure"
Nov  2 18:04:17.357: INFO: Pod "pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14": Phase="Pending", Reason="", readiness=false. Elapsed: 5.707773ms
Nov  2 18:04:19.365: INFO: Pod "pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013315223s
Nov  2 18:04:21.372: INFO: Pod "pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020727348s
STEP: Saw pod success
Nov  2 18:04:21.372: INFO: Pod "pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14" satisfied condition "success or failure"
Nov  2 18:04:21.381: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14 container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:04:21.437: INFO: Waiting for pod pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14 to disappear
Nov  2 18:04:21.453: INFO: Pod pod-secrets-6c637529-83bd-42ba-91f4-f94a513aea14 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:21.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7273" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":22,"skipped":355,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:21.493: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  2 18:04:24.817: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:24.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8756" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":23,"skipped":374,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:24.873: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6162
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating all guestbook components
Nov  2 18:04:25.088: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Nov  2 18:04:25.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-6162'
Nov  2 18:04:25.430: INFO: stderr: ""
Nov  2 18:04:25.430: INFO: stdout: "service/agnhost-slave created\n"
Nov  2 18:04:25.430: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Nov  2 18:04:25.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-6162'
Nov  2 18:04:25.695: INFO: stderr: ""
Nov  2 18:04:25.696: INFO: stdout: "service/agnhost-master created\n"
Nov  2 18:04:25.696: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  2 18:04:25.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-6162'
Nov  2 18:04:26.040: INFO: stderr: ""
Nov  2 18:04:26.040: INFO: stdout: "service/frontend created\n"
Nov  2 18:04:26.040: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov  2 18:04:26.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-6162'
Nov  2 18:04:26.315: INFO: stderr: ""
Nov  2 18:04:26.315: INFO: stdout: "deployment.apps/frontend created\n"
Nov  2 18:04:26.315: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  2 18:04:26.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-6162'
Nov  2 18:04:26.648: INFO: stderr: ""
Nov  2 18:04:26.649: INFO: stdout: "deployment.apps/agnhost-master created\n"
Nov  2 18:04:26.649: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  2 18:04:26.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-6162'
Nov  2 18:04:26.917: INFO: stderr: ""
Nov  2 18:04:26.917: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Nov  2 18:04:26.917: INFO: Waiting for all frontend pods to be Running.
Nov  2 18:04:31.968: INFO: Waiting for frontend to serve content.
Nov  2 18:04:32.070: INFO: Trying to add a new entry to the guestbook.
Nov  2 18:04:32.203: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov  2 18:04:32.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-6162'
Nov  2 18:04:32.494: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:04:32.494: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  2 18:04:32.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-6162'
Nov  2 18:04:32.680: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:04:32.680: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  2 18:04:32.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-6162'
Nov  2 18:04:32.832: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:04:32.832: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  2 18:04:32.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-6162'
Nov  2 18:04:32.978: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:04:32.978: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  2 18:04:32.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-6162'
Nov  2 18:04:33.114: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:04:33.115: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  2 18:04:33.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-6162'
Nov  2 18:04:33.283: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:04:33.283: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:33.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6162" for this suite.

• [SLOW TEST:8.433 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:380
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":280,"completed":24,"skipped":376,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:33.306: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov  2 18:04:38.170: INFO: Successfully updated pod "labelsupdatee8f3582b-4247-4482-b69d-76ccbadddb3a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:40.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2833" for this suite.

• [SLOW TEST:6.935 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":25,"skipped":387,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:40.243: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:04:40.483: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0" in namespace "projected-9703" to be "success or failure"
Nov  2 18:04:40.491: INFO: Pod "downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.690305ms
Nov  2 18:04:42.500: INFO: Pod "downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017452814s
Nov  2 18:04:44.507: INFO: Pod "downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024547454s
STEP: Saw pod success
Nov  2 18:04:44.507: INFO: Pod "downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0" satisfied condition "success or failure"
Nov  2 18:04:44.560: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0 container client-container: <nil>
STEP: delete the pod
Nov  2 18:04:44.751: INFO: Waiting for pod downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0 to disappear
Nov  2 18:04:44.762: INFO: Pod downwardapi-volume-e4d66ad6-f001-4a1c-8e13-b7d6117d90f0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:44.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9703" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":26,"skipped":413,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:44.839: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:04:45.154: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fa669cf6-b7ad-4493-bcda-ff2488a8c551", Controller:(*bool)(0xc001caed72), BlockOwnerDeletion:(*bool)(0xc001caed73)}}
Nov  2 18:04:45.168: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"89105bfe-858e-46c3-86b3-57c482cc059e", Controller:(*bool)(0xc003a1feb2), BlockOwnerDeletion:(*bool)(0xc003a1feb3)}}
Nov  2 18:04:45.187: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8435eeae-1cea-4532-a15b-5ee9157ec309", Controller:(*bool)(0xc002ca3eca), BlockOwnerDeletion:(*bool)(0xc002ca3ecb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:50.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3026" for this suite.

• [SLOW TEST:5.413 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":280,"completed":27,"skipped":447,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:50.253: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-627.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-627.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 18:04:55.306: INFO: DNS probes using dns-627/dns-test-b6d2fc72-61c5-43ce-b0e7-6dbfc05c8239 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:04:55.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-627" for this suite.

• [SLOW TEST:5.145 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":280,"completed":28,"skipped":470,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:04:55.399: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Nov  2 18:04:55.696: INFO: namespace kubectl-8715
Nov  2 18:04:55.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-8715'
Nov  2 18:04:56.034: INFO: stderr: ""
Nov  2 18:04:56.034: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov  2 18:04:57.042: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:04:57.042: INFO: Found 0 / 1
Nov  2 18:04:58.043: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:04:58.043: INFO: Found 0 / 1
Nov  2 18:04:59.042: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:04:59.042: INFO: Found 1 / 1
Nov  2 18:04:59.042: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  2 18:04:59.049: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:04:59.049: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  2 18:04:59.049: INFO: wait on agnhost-master startup in kubectl-8715 
Nov  2 18:04:59.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs agnhost-master-qc4bw agnhost-master --namespace=kubectl-8715'
Nov  2 18:04:59.172: INFO: stderr: ""
Nov  2 18:04:59.172: INFO: stdout: "Paused\n"
STEP: exposing RC
Nov  2 18:04:59.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8715'
Nov  2 18:04:59.313: INFO: stderr: ""
Nov  2 18:04:59.313: INFO: stdout: "service/rm2 exposed\n"
Nov  2 18:04:59.327: INFO: Service rm2 in namespace kubectl-8715 found.
STEP: exposing service
Nov  2 18:05:01.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8715'
Nov  2 18:05:01.478: INFO: stderr: ""
Nov  2 18:05:01.478: INFO: stdout: "service/rm3 exposed\n"
Nov  2 18:05:01.486: INFO: Service rm3 in namespace kubectl-8715 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:03.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8715" for this suite.

• [SLOW TEST:8.127 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1188
    should create services for rc  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":280,"completed":29,"skipped":491,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:03.526: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-8c7eebb6-eb1c-45d2-9a15-877fe5ae7388
STEP: Creating a pod to test consume secrets
Nov  2 18:05:03.882: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195" in namespace "projected-1445" to be "success or failure"
Nov  2 18:05:03.898: INFO: Pod "pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195": Phase="Pending", Reason="", readiness=false. Elapsed: 15.808128ms
Nov  2 18:05:05.906: INFO: Pod "pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023655736s
Nov  2 18:05:07.914: INFO: Pod "pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031343071s
STEP: Saw pod success
Nov  2 18:05:07.914: INFO: Pod "pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195" satisfied condition "success or failure"
Nov  2 18:05:07.922: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:05:07.968: INFO: Waiting for pod pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195 to disappear
Nov  2 18:05:07.975: INFO: Pod pod-projected-secrets-86b931ff-5617-44b3-af3d-469cffe04195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:07.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1445" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":30,"skipped":507,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:08.024: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:05:08.313: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695" in namespace "projected-6515" to be "success or failure"
Nov  2 18:05:08.326: INFO: Pod "downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695": Phase="Pending", Reason="", readiness=false. Elapsed: 13.260874ms
Nov  2 18:05:10.356: INFO: Pod "downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042406825s
Nov  2 18:05:12.367: INFO: Pod "downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053328349s
STEP: Saw pod success
Nov  2 18:05:12.367: INFO: Pod "downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695" satisfied condition "success or failure"
Nov  2 18:05:12.378: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695 container client-container: <nil>
STEP: delete the pod
Nov  2 18:05:12.493: INFO: Waiting for pod downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695 to disappear
Nov  2 18:05:12.512: INFO: Pod downwardapi-volume-52a8590b-fff1-4798-b639-5ff3024c8695 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:12.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6515" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":31,"skipped":510,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:12.535: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4461
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:05:12.860: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2" in namespace "downward-api-4461" to be "success or failure"
Nov  2 18:05:12.870: INFO: Pod "downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.635729ms
Nov  2 18:05:14.879: INFO: Pod "downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018900063s
Nov  2 18:05:16.891: INFO: Pod "downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031068157s
STEP: Saw pod success
Nov  2 18:05:16.891: INFO: Pod "downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2" satisfied condition "success or failure"
Nov  2 18:05:16.899: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2 container client-container: <nil>
STEP: delete the pod
Nov  2 18:05:16.945: INFO: Waiting for pod downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2 to disappear
Nov  2 18:05:16.965: INFO: Pod downwardapi-volume-0c1d78b2-9d8b-4d7c-849e-c92fff900dc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:16.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4461" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":32,"skipped":512,"failed":0}

------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:16.990: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7868
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-17964f4b-4d9b-4dfb-ad2f-1bbca8fc5fff
STEP: Creating secret with name s-test-opt-upd-8b6f2031-7034-416a-83e7-8096c18d0912
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-17964f4b-4d9b-4dfb-ad2f-1bbca8fc5fff
STEP: Updating secret s-test-opt-upd-8b6f2031-7034-416a-83e7-8096c18d0912
STEP: Creating secret with name s-test-opt-create-1a142bc3-8ed8-4a05-a9da-ace05c221f90
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:23.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7868" for this suite.

• [SLOW TEST:6.835 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":33,"skipped":512,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:23.826: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:29.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2291" for this suite.

• [SLOW TEST:5.577 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":280,"completed":34,"skipped":530,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:29.403: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-0f2bd47b-63bf-4305-a6e5-937cd185334d
STEP: Creating a pod to test consume secrets
Nov  2 18:05:29.679: INFO: Waiting up to 5m0s for pod "pod-secrets-0930bebc-b741-4178-ac7c-e87896863060" in namespace "secrets-5313" to be "success or failure"
Nov  2 18:05:29.696: INFO: Pod "pod-secrets-0930bebc-b741-4178-ac7c-e87896863060": Phase="Pending", Reason="", readiness=false. Elapsed: 17.554066ms
Nov  2 18:05:31.706: INFO: Pod "pod-secrets-0930bebc-b741-4178-ac7c-e87896863060": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027373211s
Nov  2 18:05:33.715: INFO: Pod "pod-secrets-0930bebc-b741-4178-ac7c-e87896863060": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036146214s
STEP: Saw pod success
Nov  2 18:05:33.715: INFO: Pod "pod-secrets-0930bebc-b741-4178-ac7c-e87896863060" satisfied condition "success or failure"
Nov  2 18:05:33.722: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-secrets-0930bebc-b741-4178-ac7c-e87896863060 container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:05:33.775: INFO: Waiting for pod pod-secrets-0930bebc-b741-4178-ac7c-e87896863060 to disappear
Nov  2 18:05:33.781: INFO: Pod pod-secrets-0930bebc-b741-4178-ac7c-e87896863060 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:33.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5313" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":35,"skipped":538,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:33.840: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:05:34.735: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:05:36.767: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937134, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937134, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937134, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937134, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:05:39.806: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:39.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3286" for this suite.
STEP: Destroying namespace "webhook-3286-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.137 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":280,"completed":36,"skipped":547,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:39.977: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1357
STEP: creating an pod
Nov  2 18:05:40.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.8 --namespace=kubectl-8393 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov  2 18:05:40.332: INFO: stderr: ""
Nov  2 18:05:40.332: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Waiting for log generator to start.
Nov  2 18:05:40.332: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov  2 18:05:40.332: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8393" to be "running and ready, or succeeded"
Nov  2 18:05:40.341: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.524549ms
Nov  2 18:05:42.349: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016926192s
Nov  2 18:05:44.359: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.027195304s
Nov  2 18:05:44.360: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov  2 18:05:44.360: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov  2 18:05:44.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs logs-generator logs-generator --namespace=kubectl-8393'
Nov  2 18:05:44.531: INFO: stderr: ""
Nov  2 18:05:44.531: INFO: stdout: "I1102 18:05:41.949527       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/5pgr 483\nI1102 18:05:42.149689       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/rlq9 376\nI1102 18:05:42.349682       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/mbwp 418\nI1102 18:05:42.550035       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/g68m 221\nI1102 18:05:42.749682       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/xfmb 380\nI1102 18:05:42.949690       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/wqbk 464\nI1102 18:05:43.149714       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/jjf2 280\nI1102 18:05:43.349692       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/9wsk 394\nI1102 18:05:43.549730       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/stgf 278\nI1102 18:05:43.749696       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/z66t 284\nI1102 18:05:43.949697       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/fg2t 203\nI1102 18:05:44.149697       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/v2p 445\nI1102 18:05:44.349695       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/pw54 457\n"
STEP: limiting log lines
Nov  2 18:05:44.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs logs-generator logs-generator --namespace=kubectl-8393 --tail=1'
Nov  2 18:05:44.691: INFO: stderr: ""
Nov  2 18:05:44.691: INFO: stdout: "I1102 18:05:44.549742       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/k9w 553\n"
Nov  2 18:05:44.691: INFO: got output "I1102 18:05:44.549742       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/k9w 553\n"
STEP: limiting log bytes
Nov  2 18:05:44.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs logs-generator logs-generator --namespace=kubectl-8393 --limit-bytes=1'
Nov  2 18:05:44.808: INFO: stderr: ""
Nov  2 18:05:44.808: INFO: stdout: "I"
Nov  2 18:05:44.808: INFO: got output "I"
STEP: exposing timestamps
Nov  2 18:05:44.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs logs-generator logs-generator --namespace=kubectl-8393 --tail=1 --timestamps'
Nov  2 18:05:44.953: INFO: stderr: ""
Nov  2 18:05:44.953: INFO: stdout: "2020-11-02T18:05:44.751794971Z I1102 18:05:44.751617       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/f4lp 483\n"
Nov  2 18:05:44.953: INFO: got output "2020-11-02T18:05:44.751794971Z I1102 18:05:44.751617       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/f4lp 483\n"
STEP: restricting to a time range
Nov  2 18:05:47.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs logs-generator logs-generator --namespace=kubectl-8393 --since=1s'
Nov  2 18:05:47.633: INFO: stderr: ""
Nov  2 18:05:47.633: INFO: stdout: "I1102 18:05:46.749709       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/jgj 542\nI1102 18:05:46.949667       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/z482 561\nI1102 18:05:47.149866       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/prr7 570\nI1102 18:05:47.349714       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/czw 397\nI1102 18:05:47.549745       1 logs_generator.go:76] 28 GET /api/v1/namespaces/default/pods/wjr 565\n"
Nov  2 18:05:47.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs logs-generator logs-generator --namespace=kubectl-8393 --since=24h'
Nov  2 18:05:47.764: INFO: stderr: ""
Nov  2 18:05:47.765: INFO: stdout: "I1102 18:05:41.949527       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/5pgr 483\nI1102 18:05:42.149689       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/rlq9 376\nI1102 18:05:42.349682       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/mbwp 418\nI1102 18:05:42.550035       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/g68m 221\nI1102 18:05:42.749682       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/xfmb 380\nI1102 18:05:42.949690       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/wqbk 464\nI1102 18:05:43.149714       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/jjf2 280\nI1102 18:05:43.349692       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/9wsk 394\nI1102 18:05:43.549730       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/stgf 278\nI1102 18:05:43.749696       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/z66t 284\nI1102 18:05:43.949697       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/fg2t 203\nI1102 18:05:44.149697       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/v2p 445\nI1102 18:05:44.349695       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/pw54 457\nI1102 18:05:44.549742       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/k9w 553\nI1102 18:05:44.751617       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/f4lp 483\nI1102 18:05:44.949661       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/4jsf 510\nI1102 18:05:45.149743       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/njld 392\nI1102 18:05:45.349729       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/d4h 564\nI1102 18:05:45.549729       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/2z2 352\nI1102 18:05:45.749699       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/vvv 336\nI1102 18:05:45.949736       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/lvvs 465\nI1102 18:05:46.149724       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/wbsl 539\nI1102 18:05:46.349704       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/7lfq 247\nI1102 18:05:46.549734       1 logs_generator.go:76] 23 GET /api/v1/namespaces/ns/pods/zcd2 460\nI1102 18:05:46.749709       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/jgj 542\nI1102 18:05:46.949667       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/z482 561\nI1102 18:05:47.149866       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/prr7 570\nI1102 18:05:47.349714       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/czw 397\nI1102 18:05:47.549745       1 logs_generator.go:76] 28 GET /api/v1/namespaces/default/pods/wjr 565\nI1102 18:05:47.749709       1 logs_generator.go:76] 29 GET /api/v1/namespaces/kube-system/pods/dpf 546\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1363
Nov  2 18:05:47.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete pod logs-generator --namespace=kubectl-8393'
Nov  2 18:05:56.931: INFO: stderr: ""
Nov  2 18:05:56.931: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:05:56.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8393" for this suite.

• [SLOW TEST:16.997 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1353
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":280,"completed":37,"skipped":550,"failed":0}
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:05:56.975: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating pod
Nov  2 18:06:01.272: INFO: Pod pod-hostip-bacf4520-8a64-47fb-9fb6-52c9ec4fa0b8 has hostIP: 192.168.1.15
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:06:01.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6945" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":280,"completed":38,"skipped":555,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:06:01.297: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:06:02.761: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:06:04.781: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937162, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937162, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937162, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937162, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:06:07.819: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov  2 18:06:12.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 attach --namespace=webhook-3512 to-be-attached-pod -i -c=container1'
Nov  2 18:06:12.308: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:06:12.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3512" for this suite.
STEP: Destroying namespace "webhook-3512-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:11.241 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":280,"completed":39,"skipped":576,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:06:12.538: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-projected-all-test-volume-1e05f4ab-f8ee-43a8-9a2c-d2a33f70f821
STEP: Creating secret with name secret-projected-all-test-volume-fa702e4d-8a38-4f34-8b74-81e99ae44044
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  2 18:06:12.806: INFO: Waiting up to 5m0s for pod "projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43" in namespace "projected-3067" to be "success or failure"
Nov  2 18:06:12.817: INFO: Pod "projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43": Phase="Pending", Reason="", readiness=false. Elapsed: 11.713265ms
Nov  2 18:06:14.826: INFO: Pod "projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020301374s
Nov  2 18:06:16.833: INFO: Pod "projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027703612s
STEP: Saw pod success
Nov  2 18:06:16.833: INFO: Pod "projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43" satisfied condition "success or failure"
Nov  2 18:06:16.841: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  2 18:06:16.911: INFO: Waiting for pod projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43 to disappear
Nov  2 18:06:16.916: INFO: Pod projected-volume-63c0949e-a09a-488b-97bd-74bcdb0e1c43 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:06:16.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3067" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":280,"completed":40,"skipped":593,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:06:16.938: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6479
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:06:17.139: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:06:17.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6479" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":280,"completed":41,"skipped":636,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:06:17.308: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:06:18.237: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov  2 18:06:20.264: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937178, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937178, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937178, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937178, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:06:23.301: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:06:23.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1778" for this suite.
STEP: Destroying namespace "webhook-1778-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.458 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":280,"completed":42,"skipped":674,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:06:23.767: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3062
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  2 18:06:24.007: INFO: Waiting up to 5m0s for pod "pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb" in namespace "emptydir-3062" to be "success or failure"
Nov  2 18:06:24.021: INFO: Pod "pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.858251ms
Nov  2 18:06:26.029: INFO: Pod "pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021959752s
Nov  2 18:06:28.037: INFO: Pod "pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030546928s
STEP: Saw pod success
Nov  2 18:06:28.037: INFO: Pod "pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb" satisfied condition "success or failure"
Nov  2 18:06:28.044: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb container test-container: <nil>
STEP: delete the pod
Nov  2 18:06:28.103: INFO: Waiting for pod pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb to disappear
Nov  2 18:06:28.110: INFO: Pod pod-6c9ce67f-17ce-4ba6-b46d-b0d52ddfefbb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:06:28.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3062" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":43,"skipped":712,"failed":0}
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:06:28.131: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod test-webserver-75c3d61b-6f81-47fa-a5bc-afc3acaffcb5 in namespace container-probe-9216
Nov  2 18:06:32.370: INFO: Started pod test-webserver-75c3d61b-6f81-47fa-a5bc-afc3acaffcb5 in namespace container-probe-9216
STEP: checking the pod's current state and verifying that restartCount is present
Nov  2 18:06:32.377: INFO: Initial restart count of pod test-webserver-75c3d61b-6f81-47fa-a5bc-afc3acaffcb5 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:10:33.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9216" for this suite.

• [SLOW TEST:245.479 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":44,"skipped":714,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:10:33.611: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9565
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-caf899e1-c22b-4d6d-9200-3c831b99fd9c
STEP: Creating a pod to test consume secrets
Nov  2 18:10:33.867: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2" in namespace "projected-9565" to be "success or failure"
Nov  2 18:10:33.877: INFO: Pod "pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.761409ms
Nov  2 18:10:35.887: INFO: Pod "pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020172853s
Nov  2 18:10:37.896: INFO: Pod "pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029340682s
STEP: Saw pod success
Nov  2 18:10:37.896: INFO: Pod "pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2" satisfied condition "success or failure"
Nov  2 18:10:37.909: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:10:38.105: INFO: Waiting for pod pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2 to disappear
Nov  2 18:10:38.111: INFO: Pod pod-projected-secrets-df493eb2-6f62-4d09-9576-3812d3bd6eb2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:10:38.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9565" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":45,"skipped":726,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:10:38.156: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2132
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:10:39.149: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:10:41.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937439, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937439, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937439, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937439, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:10:44.224: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:10:44.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2132" for this suite.
STEP: Destroying namespace "webhook-2132-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.907 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":280,"completed":46,"skipped":749,"failed":0}
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:10:45.063: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:10:49.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6704" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":280,"completed":47,"skipped":753,"failed":0}
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:10:49.363: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4075
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:10:57.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4075" for this suite.

• [SLOW TEST:8.291 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":280,"completed":48,"skipped":756,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:10:57.655: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-725
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov  2 18:10:57.889: INFO: Waiting up to 5m0s for pod "downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d" in namespace "downward-api-725" to be "success or failure"
Nov  2 18:10:57.907: INFO: Pod "downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.830344ms
Nov  2 18:10:59.915: INFO: Pod "downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02597606s
Nov  2 18:11:01.927: INFO: Pod "downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038009559s
STEP: Saw pod success
Nov  2 18:11:01.927: INFO: Pod "downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d" satisfied condition "success or failure"
Nov  2 18:11:01.934: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:11:02.175: INFO: Waiting for pod downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d to disappear
Nov  2 18:11:02.182: INFO: Pod downward-api-8685c90f-ca33-4a62-be1e-7a94b7e79c1d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:11:02.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-725" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":280,"completed":49,"skipped":758,"failed":0}

------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:11:02.206: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service endpoint-test2 in namespace services-1911
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1911 to expose endpoints map[]
Nov  2 18:11:02.502: INFO: Get endpoints failed (17.119368ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov  2 18:11:03.515: INFO: successfully validated that service endpoint-test2 in namespace services-1911 exposes endpoints map[] (1.030646232s elapsed)
STEP: Creating pod pod1 in namespace services-1911
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1911 to expose endpoints map[pod1:[80]]
Nov  2 18:11:06.603: INFO: successfully validated that service endpoint-test2 in namespace services-1911 exposes endpoints map[pod1:[80]] (3.065767109s elapsed)
STEP: Creating pod pod2 in namespace services-1911
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1911 to expose endpoints map[pod1:[80] pod2:[80]]
Nov  2 18:11:09.742: INFO: successfully validated that service endpoint-test2 in namespace services-1911 exposes endpoints map[pod1:[80] pod2:[80]] (3.123559112s elapsed)
STEP: Deleting pod pod1 in namespace services-1911
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1911 to expose endpoints map[pod2:[80]]
Nov  2 18:11:10.818: INFO: successfully validated that service endpoint-test2 in namespace services-1911 exposes endpoints map[pod2:[80]] (1.059974264s elapsed)
STEP: Deleting pod pod2 in namespace services-1911
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1911 to expose endpoints map[]
Nov  2 18:11:11.856: INFO: successfully validated that service endpoint-test2 in namespace services-1911 exposes endpoints map[] (1.013834787s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:11:11.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1911" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:9.739 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":280,"completed":50,"skipped":758,"failed":0}
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:11:11.946: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-3693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  2 18:11:18.304: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:18.304: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:18.824: INFO: Exec stderr: ""
Nov  2 18:11:18.824: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:18.824: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:19.176: INFO: Exec stderr: ""
Nov  2 18:11:19.176: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:19.176: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:19.774: INFO: Exec stderr: ""
Nov  2 18:11:19.774: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:19.774: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:20.382: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  2 18:11:20.382: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:20.382: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:20.988: INFO: Exec stderr: ""
Nov  2 18:11:20.988: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:20.988: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:21.457: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  2 18:11:21.457: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:21.457: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:22.017: INFO: Exec stderr: ""
Nov  2 18:11:22.018: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:22.018: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:22.592: INFO: Exec stderr: ""
Nov  2 18:11:22.592: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:22.592: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:23.160: INFO: Exec stderr: ""
Nov  2 18:11:23.161: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3693 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:11:23.161: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:11:23.661: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:11:23.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3693" for this suite.

• [SLOW TEST:11.746 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":51,"skipped":759,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:11:23.692: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:11:23.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb" in namespace "downward-api-6849" to be "success or failure"
Nov  2 18:11:23.985: INFO: Pod "downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 22.681152ms
Nov  2 18:11:25.995: INFO: Pod "downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031982486s
Nov  2 18:11:28.003: INFO: Pod "downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040170776s
STEP: Saw pod success
Nov  2 18:11:28.003: INFO: Pod "downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb" satisfied condition "success or failure"
Nov  2 18:11:28.010: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb container client-container: <nil>
STEP: delete the pod
Nov  2 18:11:28.069: INFO: Waiting for pod downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb to disappear
Nov  2 18:11:28.077: INFO: Pod downwardapi-volume-eb24dc1a-76ba-4457-a38b-fd3180612eeb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:11:28.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6849" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":52,"skipped":760,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:11:28.099: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:11:29.292: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5f65f8c764\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:11:31.303: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937489, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:11:34.350: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Nov  2 18:11:34.414: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:11:34.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1926" for this suite.
STEP: Destroying namespace "webhook-1926-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.004 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":280,"completed":53,"skipped":763,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:11:35.105: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:11:51.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8010" for this suite.

• [SLOW TEST:16.595 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":280,"completed":54,"skipped":773,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:11:51.699: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:12:03.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8449" for this suite.

• [SLOW TEST:11.408 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":280,"completed":55,"skipped":783,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:12:03.108: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7083
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-be24c9f2-0909-459a-83dc-d2d402623bdf
STEP: Creating a pod to test consume configMaps
Nov  2 18:12:03.386: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77" in namespace "projected-7083" to be "success or failure"
Nov  2 18:12:03.394: INFO: Pod "pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77": Phase="Pending", Reason="", readiness=false. Elapsed: 7.549463ms
Nov  2 18:12:05.401: INFO: Pod "pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014624656s
Nov  2 18:12:07.409: INFO: Pod "pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022715903s
STEP: Saw pod success
Nov  2 18:12:07.409: INFO: Pod "pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77" satisfied condition "success or failure"
Nov  2 18:12:07.416: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:12:07.486: INFO: Waiting for pod pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77 to disappear
Nov  2 18:12:07.492: INFO: Pod pod-projected-configmaps-5e116a12-0cdd-4cda-95e4-24ff5ea67c77 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:12:07.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7083" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":56,"skipped":823,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:12:07.515: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6785
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6496
STEP: Creating secret with name secret-test-85cacad0-6cb6-4b65-8640-d782b17cae11
STEP: Creating a pod to test consume secrets
Nov  2 18:12:08.048: INFO: Waiting up to 5m0s for pod "pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc" in namespace "secrets-6785" to be "success or failure"
Nov  2 18:12:08.075: INFO: Pod "pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 26.976934ms
Nov  2 18:12:10.084: INFO: Pod "pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036305431s
Nov  2 18:12:12.092: INFO: Pod "pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044244619s
STEP: Saw pod success
Nov  2 18:12:12.092: INFO: Pod "pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc" satisfied condition "success or failure"
Nov  2 18:12:12.099: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:12:12.201: INFO: Waiting for pod pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc to disappear
Nov  2 18:12:12.208: INFO: Pod pod-secrets-174e0836-54ce-4993-95d4-685039c40cdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:12:12.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6785" for this suite.
STEP: Destroying namespace "secret-namespace-6496" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":280,"completed":57,"skipped":853,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:12:12.257: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9623
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:12:12.459: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:12:13.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9623" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":280,"completed":58,"skipped":858,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:12:13.956: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-7128942b-2904-4fb2-a139-1dd4d886788e
STEP: Creating a pod to test consume configMaps
Nov  2 18:12:14.207: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8" in namespace "projected-2382" to be "success or failure"
Nov  2 18:12:14.214: INFO: Pod "pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.157028ms
Nov  2 18:12:16.224: INFO: Pod "pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016603217s
Nov  2 18:12:18.232: INFO: Pod "pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025417488s
STEP: Saw pod success
Nov  2 18:12:18.232: INFO: Pod "pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8" satisfied condition "success or failure"
Nov  2 18:12:18.246: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:12:18.291: INFO: Waiting for pod pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8 to disappear
Nov  2 18:12:18.302: INFO: Pod pod-projected-configmaps-d314391b-db46-4b5c-94b4-a7f95f942de8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:12:18.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2382" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":59,"skipped":866,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:12:18.337: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6415
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-c51981d2-0720-485d-bbea-b681fc24ff4d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-c51981d2-0720-485d-bbea-b681fc24ff4d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:13:29.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6415" for this suite.

• [SLOW TEST:71.644 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":60,"skipped":871,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:13:29.982: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6686
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-13bc2397-37a7-49b3-a5f0-e379d2f4a9b1
STEP: Creating a pod to test consume configMaps
Nov  2 18:13:30.309: INFO: Waiting up to 5m0s for pod "pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b" in namespace "configmap-6686" to be "success or failure"
Nov  2 18:13:30.336: INFO: Pod "pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.448259ms
Nov  2 18:13:32.344: INFO: Pod "pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034724936s
Nov  2 18:13:34.352: INFO: Pod "pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043060949s
STEP: Saw pod success
Nov  2 18:13:34.352: INFO: Pod "pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b" satisfied condition "success or failure"
Nov  2 18:13:34.362: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:13:34.591: INFO: Waiting for pod pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b to disappear
Nov  2 18:13:34.609: INFO: Pod pod-configmaps-64cdd5a1-1a14-4dcb-a671-61f4b0df2f8b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:13:34.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6686" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":61,"skipped":898,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:13:34.642: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3665
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-034d9d47-db8b-4437-8a37-7f355e6f55a5
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:13:39.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3665" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":62,"skipped":954,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:13:39.166: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating cluster-info
Nov  2 18:13:39.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 cluster-info'
Nov  2 18:13:40.095: INFO: stderr: ""
Nov  2 18:13:40.095: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.240.16.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.240.16.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:13:40.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4702" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":280,"completed":63,"skipped":973,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:13:40.128: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  2 18:13:40.405: INFO: Waiting up to 5m0s for pod "pod-f0d13005-e494-4e17-a58c-ce5543225339" in namespace "emptydir-9252" to be "success or failure"
Nov  2 18:13:40.426: INFO: Pod "pod-f0d13005-e494-4e17-a58c-ce5543225339": Phase="Pending", Reason="", readiness=false. Elapsed: 21.081875ms
Nov  2 18:13:42.435: INFO: Pod "pod-f0d13005-e494-4e17-a58c-ce5543225339": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029889503s
Nov  2 18:13:44.443: INFO: Pod "pod-f0d13005-e494-4e17-a58c-ce5543225339": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038720773s
STEP: Saw pod success
Nov  2 18:13:44.443: INFO: Pod "pod-f0d13005-e494-4e17-a58c-ce5543225339" satisfied condition "success or failure"
Nov  2 18:13:44.459: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-f0d13005-e494-4e17-a58c-ce5543225339 container test-container: <nil>
STEP: delete the pod
Nov  2 18:13:44.508: INFO: Waiting for pod pod-f0d13005-e494-4e17-a58c-ce5543225339 to disappear
Nov  2 18:13:44.514: INFO: Pod pod-f0d13005-e494-4e17-a58c-ce5543225339 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:13:44.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9252" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":64,"skipped":1018,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:13:44.544: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6018
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  2 18:13:44.818: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148525 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  2 18:13:44.818: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148525 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  2 18:13:54.845: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148606 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  2 18:13:54.846: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148606 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  2 18:14:04.869: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148652 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  2 18:14:04.869: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148652 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  2 18:14:14.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148696 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  2 18:14:14.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-a fcfbc9bf-a936-4fd8-9951-01d09adb69cf 148696 0 2020-11-02 18:13:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  2 18:14:24.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-b bc7662d7-2c5b-4332-b67d-5590df2297e7 148738 0 2020-11-02 18:14:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  2 18:14:24.917: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-b bc7662d7-2c5b-4332-b67d-5590df2297e7 148738 0 2020-11-02 18:14:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  2 18:14:34.939: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-b bc7662d7-2c5b-4332-b67d-5590df2297e7 148785 0 2020-11-02 18:14:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  2 18:14:34.940: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6018 /api/v1/namespaces/watch-6018/configmaps/e2e-watch-test-configmap-b bc7662d7-2c5b-4332-b67d-5590df2297e7 148785 0 2020-11-02 18:14:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:14:44.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6018" for this suite.

• [SLOW TEST:60.481 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":280,"completed":65,"skipped":1062,"failed":0}
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:14:45.025: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  2 18:14:48.326: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:14:48.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9499" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":66,"skipped":1066,"failed":0}
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:14:48.414: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov  2 18:14:48.668: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  2 18:14:48.690: INFO: Waiting for terminating namespaces to be deleted...
Nov  2 18:14:48.698: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-brzmg before test
Nov  2 18:14:48.835: INFO: dashboard-metrics-scraper-59bfc65dc9-vv6zf from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.835: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:14:48.835: INFO: openvpn-client-84ccd8596d-qps5z from kube-system started at 2020-11-02 09:28:26 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  2 18:14:48.836: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  2 18:14:48.836: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:14:48.836: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:14:48.836: INFO: kube-proxy-gk2s6 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:14:48.836: INFO: csi-cinder-nodeplugin-ubuntu-xqnfj from kube-system started at 2020-11-02 09:26:48 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:14:48.836: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:14:48.836: INFO: coredns-57f944bd9f-h8sb4 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:14:48.836: INFO: logrotate-vdk6h from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:14:48.836: INFO: user-ssh-keys-agent-wklnz from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:14:48.836: INFO: dashboard-metrics-scraper-59bfc65dc9-mx5wv from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:14:48.836: INFO: node-local-dns-nwqv9 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:14:48.836: INFO: canal-c64t7 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.836: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:14:48.837: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:14:48.837: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-11-02 09:26:48 +0000 UTC (5 container statuses recorded)
Nov  2 18:14:48.837: INFO: 	Container cinder-csi-plugin ready: true, restart count 2
Nov  2 18:14:48.837: INFO: 	Container csi-attacher ready: true, restart count 0
Nov  2 18:14:48.837: INFO: 	Container csi-provisioner ready: true, restart count 0
Nov  2 18:14:48.837: INFO: 	Container csi-resizer ready: true, restart count 0
Nov  2 18:14:48.837: INFO: 	Container csi-snapshotter ready: true, restart count 0
Nov  2 18:14:48.837: INFO: coredns-57f944bd9f-492kl from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.837: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:14:48.837: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-dc8qz before test
Nov  2 18:14:48.931: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-9c9cl from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.931: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:14:48.931: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:14:48.931: INFO: kube-proxy-4bdvn from kube-system started at 2020-11-02 09:31:11 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:14:48.932: INFO: node-local-dns-7m96x from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:14:48.932: INFO: csi-cinder-nodeplugin-ubuntu-rwf9k from kube-system started at 2020-11-02 09:31:41 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:14:48.932: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:14:48.932: INFO: logrotate-6plw5 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:14:48.932: INFO: canal-6x859 from kube-system started at 2020-11-02 09:31:11 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:14:48.932: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:14:48.932: INFO: user-ssh-keys-agent-99zc9 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:14:48.932: INFO: sonobuoy-e2e-job-4da6a1ac755345e8 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.932: INFO: 	Container e2e ready: true, restart count 0
Nov  2 18:14:48.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:14:48.932: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-drfqf before test
Nov  2 18:14:48.998: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-h8fmt from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.998: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:14:48.998: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:14:48.998: INFO: csi-cinder-nodeplugin-ubuntu-2cjm4 from kube-system started at 2020-11-02 09:28:35 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.998: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:14:48.998: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:14:48.998: INFO: logrotate-qqksv from kube-system started at 2020-11-02 09:28:52 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.998: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:14:48.998: INFO: sonobuoy from sonobuoy started at 2020-11-02 17:59:56 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.998: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  2 18:14:48.998: INFO: node-local-dns-5qzt2 from kube-system started at 2020-11-02 09:28:52 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.998: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:14:48.998: INFO: canal-l9xkd from kube-system started at 2020-11-02 09:28:06 +0000 UTC (2 container statuses recorded)
Nov  2 18:14:48.999: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:14:48.999: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:14:48.999: INFO: kube-proxy-h49pz from kube-system started at 2020-11-02 09:28:06 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.999: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:14:48.999: INFO: user-ssh-keys-agent-ckw88 from kube-system started at 2020-11-02 09:28:52 +0000 UTC (1 container statuses recorded)
Nov  2 18:14:48.999: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2a49fb6b-48f5-4c2e-8107-dad2e5d12f05 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-2a49fb6b-48f5-4c2e-8107-dad2e5d12f05 off the node awesome-shannon-698f584c96-drfqf
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2a49fb6b-48f5-4c2e-8107-dad2e5d12f05
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:14:57.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6779" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:8.816 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":280,"completed":67,"skipped":1070,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:14:57.230: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-87
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  2 18:15:05.557: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  2 18:15:05.564: INFO: Pod pod-with-prestop-http-hook still exists
Nov  2 18:15:07.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  2 18:15:07.573: INFO: Pod pod-with-prestop-http-hook still exists
Nov  2 18:15:09.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  2 18:15:09.571: INFO: Pod pod-with-prestop-http-hook still exists
Nov  2 18:15:11.564: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  2 18:15:11.574: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:15:11.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-87" for this suite.

• [SLOW TEST:14.430 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":280,"completed":68,"skipped":1109,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:15:11.662: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-888f4d69-64a0-4676-9794-49f30089b2eb
STEP: Creating a pod to test consume secrets
Nov  2 18:15:11.907: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037" in namespace "projected-3922" to be "success or failure"
Nov  2 18:15:11.922: INFO: Pod "pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037": Phase="Pending", Reason="", readiness=false. Elapsed: 15.163978ms
Nov  2 18:15:13.958: INFO: Pod "pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051108807s
Nov  2 18:15:15.967: INFO: Pod "pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059653423s
STEP: Saw pod success
Nov  2 18:15:15.967: INFO: Pod "pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037" satisfied condition "success or failure"
Nov  2 18:15:15.975: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:15:16.038: INFO: Waiting for pod pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037 to disappear
Nov  2 18:15:16.045: INFO: Pod pod-projected-secrets-a13ac5e0-5745-44f7-9f99-f735921aa037 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:15:16.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3922" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":69,"skipped":1137,"failed":0}
SSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:15:16.083: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap that has name configmap-test-emptyKey-12d32077-1caa-459b-9ac5-9e4bf4a14f6a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:15:16.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-680" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":280,"completed":70,"skipped":1141,"failed":0}

------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:15:16.329: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:15:20.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6583" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":71,"skipped":1141,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:15:20.691: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3853
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  2 18:15:20.955: INFO: Waiting up to 5m0s for pod "pod-fbbbebd8-6b5b-49e0-a10c-332793873b48" in namespace "emptydir-3853" to be "success or failure"
Nov  2 18:15:20.966: INFO: Pod "pod-fbbbebd8-6b5b-49e0-a10c-332793873b48": Phase="Pending", Reason="", readiness=false. Elapsed: 10.695905ms
Nov  2 18:15:22.981: INFO: Pod "pod-fbbbebd8-6b5b-49e0-a10c-332793873b48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02523692s
Nov  2 18:15:24.992: INFO: Pod "pod-fbbbebd8-6b5b-49e0-a10c-332793873b48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036726781s
STEP: Saw pod success
Nov  2 18:15:24.992: INFO: Pod "pod-fbbbebd8-6b5b-49e0-a10c-332793873b48" satisfied condition "success or failure"
Nov  2 18:15:25.004: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-fbbbebd8-6b5b-49e0-a10c-332793873b48 container test-container: <nil>
STEP: delete the pod
Nov  2 18:15:25.093: INFO: Waiting for pod pod-fbbbebd8-6b5b-49e0-a10c-332793873b48 to disappear
Nov  2 18:15:25.099: INFO: Pod pod-fbbbebd8-6b5b-49e0-a10c-332793873b48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:15:25.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3853" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":72,"skipped":1181,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:15:25.127: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-9863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:344
Nov  2 18:15:25.446: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  2 18:16:25.488: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:16:25.496: INFO: Starting informer...
STEP: Starting pods...
Nov  2 18:16:25.750: INFO: Pod1 is running on awesome-shannon-698f584c96-drfqf. Tainting Node
Nov  2 18:16:30.004: INFO: Pod2 is running on awesome-shannon-698f584c96-drfqf. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov  2 18:16:40.779: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov  2 18:16:57.116: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:16:57.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9863" for this suite.

• [SLOW TEST:92.156 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":280,"completed":73,"skipped":1206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:16:57.284: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:16:58.105: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:17:00.149: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:17:02.157: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:17:04.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937818, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:17:07.186: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:17:07.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3367" for this suite.
STEP: Destroying namespace "webhook-3367-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.439 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":280,"completed":74,"skipped":1229,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:17:07.723: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5230
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:17:08.849: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:17:10.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937828, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937828, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937828, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739937828, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:17:13.932: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:17:26.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5230" for this suite.
STEP: Destroying namespace "webhook-5230-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:19.206 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":280,"completed":75,"skipped":1238,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:17:26.930: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov  2 18:17:31.957: INFO: Successfully updated pod "annotationupdate54095102-bfb9-44df-b83d-e6a31041a61d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:17:34.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2234" for this suite.

• [SLOW TEST:7.119 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":76,"skipped":1244,"failed":0}
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:17:34.049: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-6170
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Nov  2 18:17:34.333: INFO: Found 0 stateful pods, waiting for 3
Nov  2 18:17:44.342: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:17:44.342: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:17:44.342: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:17:44.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-6170 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 18:17:45.096: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 18:17:45.096: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 18:17:45.096: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  2 18:17:55.169: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  2 18:18:05.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-6170 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:18:05.908: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  2 18:18:05.908: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 18:18:05.908: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 18:18:15.962: INFO: Waiting for StatefulSet statefulset-6170/ss2 to complete update
Nov  2 18:18:15.962: INFO: Waiting for Pod statefulset-6170/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  2 18:18:15.962: INFO: Waiting for Pod statefulset-6170/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  2 18:18:25.978: INFO: Waiting for StatefulSet statefulset-6170/ss2 to complete update
Nov  2 18:18:25.978: INFO: Waiting for Pod statefulset-6170/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  2 18:18:35.979: INFO: Waiting for StatefulSet statefulset-6170/ss2 to complete update
Nov  2 18:18:35.979: INFO: Waiting for Pod statefulset-6170/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  2 18:18:45.984: INFO: Waiting for StatefulSet statefulset-6170/ss2 to complete update
STEP: Rolling back to a previous revision
Nov  2 18:18:55.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-6170 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 18:18:56.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 18:18:56.611: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 18:18:56.611: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 18:19:06.679: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  2 18:19:16.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-6170 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:19:17.398: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  2 18:19:17.398: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 18:19:17.398: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 18:19:27.458: INFO: Waiting for StatefulSet statefulset-6170/ss2 to complete update
Nov  2 18:19:27.458: INFO: Waiting for Pod statefulset-6170/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  2 18:19:27.458: INFO: Waiting for Pod statefulset-6170/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  2 18:19:37.475: INFO: Waiting for StatefulSet statefulset-6170/ss2 to complete update
Nov  2 18:19:37.475: INFO: Waiting for Pod statefulset-6170/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov  2 18:19:47.473: INFO: Deleting all statefulset in ns statefulset-6170
Nov  2 18:19:47.480: INFO: Scaling statefulset ss2 to 0
Nov  2 18:20:07.524: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:20:07.532: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:20:07.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6170" for this suite.

• [SLOW TEST:153.550 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":280,"completed":77,"skipped":1248,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:20:07.603: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9986
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov  2 18:20:07.811: INFO: PodSpec: initContainers in spec.initContainers
Nov  2 18:20:50.708: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-330a42c2-685c-4aed-b90b-9a0fcef665cc", GenerateName:"", Namespace:"init-container-9986", SelfLink:"/api/v1/namespaces/init-container-9986/pods/pod-init-330a42c2-685c-4aed-b90b-9a0fcef665cc", UID:"add88476-1190-41ec-8d54-1f92ba5889ce", ResourceVersion:"151513", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63739938007, loc:(*time.Location)(0x7925260)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"811312780"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"172.25.1.72/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-llx44", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002cd0fc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-llx44", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-llx44", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-llx44", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002609238), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"awesome-shannon-698f584c96-drfqf", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00349f8c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0026092b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0026092d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0026092d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0026092dc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739938007, loc:(*time.Location)(0x7925260)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739938007, loc:(*time.Location)(0x7925260)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739938007, loc:(*time.Location)(0x7925260)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739938007, loc:(*time.Location)(0x7925260)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.15", PodIP:"172.25.1.72", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.25.1.72"}}, StartTime:(*v1.Time)(0xc002c440a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00301b340)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00301b3b0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://845fef34637fefa6aba57205fd3d80998f55c76e02277a7e3c56e80c6c48ab4d", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c440e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c440c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00260945f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:20:50.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9986" for this suite.

• [SLOW TEST:43.157 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":280,"completed":78,"skipped":1253,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:20:50.761: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9897
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov  2 18:20:51.022: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov  2 18:21:05.534: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:21:09.337: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:21:23.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9897" for this suite.

• [SLOW TEST:33.258 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":280,"completed":79,"skipped":1305,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:21:24.019: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov  2 18:21:34.335: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1102 18:21:34.334989      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:21:34.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9264" for this suite.

• [SLOW TEST:10.339 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":280,"completed":80,"skipped":1315,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:21:34.360: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:21:34.602: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov  2 18:21:36.730: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:21:36.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2100" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":280,"completed":81,"skipped":1326,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:21:36.761: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1002
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating api versions
Nov  2 18:21:37.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 api-versions'
Nov  2 18:21:37.154: INFO: stderr: ""
Nov  2 18:21:37.154: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:21:37.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1002" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":280,"completed":82,"skipped":1328,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:21:37.183: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1754
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 18:21:37.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1154'
Nov  2 18:21:37.510: INFO: stderr: ""
Nov  2 18:21:37.510: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
Nov  2 18:21:37.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete pods e2e-test-httpd-pod --namespace=kubectl-1154'
Nov  2 18:21:43.119: INFO: stderr: ""
Nov  2 18:21:43.119: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:21:43.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1154" for this suite.

• [SLOW TEST:5.963 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1750
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":280,"completed":83,"skipped":1418,"failed":0}
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:21:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service multi-endpoint-test in namespace services-4551
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4551 to expose endpoints map[]
Nov  2 18:21:43.448: INFO: successfully validated that service multi-endpoint-test in namespace services-4551 exposes endpoints map[] (13.24383ms elapsed)
STEP: Creating pod pod1 in namespace services-4551
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4551 to expose endpoints map[pod1:[100]]
Nov  2 18:21:46.541: INFO: successfully validated that service multi-endpoint-test in namespace services-4551 exposes endpoints map[pod1:[100]] (3.074769631s elapsed)
STEP: Creating pod pod2 in namespace services-4551
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4551 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  2 18:21:49.675: INFO: successfully validated that service multi-endpoint-test in namespace services-4551 exposes endpoints map[pod1:[100] pod2:[101]] (3.118038066s elapsed)
STEP: Deleting pod pod1 in namespace services-4551
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4551 to expose endpoints map[pod2:[101]]
Nov  2 18:21:49.726: INFO: successfully validated that service multi-endpoint-test in namespace services-4551 exposes endpoints map[pod2:[101]] (31.782064ms elapsed)
STEP: Deleting pod pod2 in namespace services-4551
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4551 to expose endpoints map[]
Nov  2 18:21:50.769: INFO: successfully validated that service multi-endpoint-test in namespace services-4551 exposes endpoints map[] (1.020521257s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:21:50.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4551" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:7.703 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":280,"completed":84,"skipped":1420,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:21:50.849: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-7051
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:21:51.060: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Creating first CR 
Nov  2 18:21:51.731: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-02T18:21:51Z generation:1 name:name1 resourceVersion:152097 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0f0c2457-bfdf-4b42-91c4-10ce60dd434a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov  2 18:22:01.744: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-02T18:22:01Z generation:1 name:name2 resourceVersion:152166 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e20602ee-c484-4413-be13-7269db0ac2ed] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov  2 18:22:11.767: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-02T18:21:51Z generation:2 name:name1 resourceVersion:152214 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0f0c2457-bfdf-4b42-91c4-10ce60dd434a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov  2 18:22:21.782: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-02T18:22:01Z generation:2 name:name2 resourceVersion:152257 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e20602ee-c484-4413-be13-7269db0ac2ed] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov  2 18:22:31.804: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-02T18:21:51Z generation:2 name:name1 resourceVersion:152301 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0f0c2457-bfdf-4b42-91c4-10ce60dd434a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov  2 18:22:41.826: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-11-02T18:22:01Z generation:2 name:name2 resourceVersion:152347 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e20602ee-c484-4413-be13-7269db0ac2ed] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:22:52.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7051" for this suite.

• [SLOW TEST:61.543 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:41
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":280,"completed":85,"skipped":1435,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:22:52.395: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov  2 18:22:56.706: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-142776444 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  2 18:23:01.945: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:23:01.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4699" for this suite.

• [SLOW TEST:9.608 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should be submitted and removed [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period should be submitted and removed [Conformance]","total":280,"completed":86,"skipped":1446,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:23:02.003: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7339
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7339
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7339
I1102 18:23:02.319372      24 runners.go:189] Created replication controller with name: externalname-service, namespace: services-7339, replica count: 2
Nov  2 18:23:05.370: INFO: Creating new exec pod
I1102 18:23:05.369997      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  2 18:23:10.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-7339 execpod8qgzh -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  2 18:23:11.063: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  2 18:23:11.063: INFO: stdout: ""
Nov  2 18:23:11.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-7339 execpod8qgzh -- /bin/sh -x -c nc -zv -t -w 2 10.240.16.241 80'
Nov  2 18:23:11.732: INFO: stderr: "+ nc -zv -t -w 2 10.240.16.241 80\nConnection to 10.240.16.241 80 port [tcp/http] succeeded!\n"
Nov  2 18:23:11.732: INFO: stdout: ""
Nov  2 18:23:11.732: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:23:11.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7339" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:9.906 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":280,"completed":87,"skipped":1454,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:23:11.909: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6953
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov  2 18:23:12.150: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:23:15.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6953" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":280,"completed":88,"skipped":1459,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:23:15.739: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7202
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  2 18:23:24.090: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  2 18:23:24.098: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  2 18:23:26.098: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  2 18:23:26.111: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  2 18:23:28.098: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  2 18:23:28.108: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  2 18:23:30.098: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  2 18:23:30.108: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  2 18:23:32.098: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  2 18:23:32.115: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:23:32.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7202" for this suite.

• [SLOW TEST:16.559 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":280,"completed":89,"skipped":1465,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:23:32.300: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-a215c87e-afb3-4abe-a575-1945556de1b4
STEP: Creating a pod to test consume configMaps
Nov  2 18:23:32.543: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a" in namespace "projected-7460" to be "success or failure"
Nov  2 18:23:32.557: INFO: Pod "pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.337998ms
Nov  2 18:23:34.564: INFO: Pod "pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020659831s
Nov  2 18:23:36.572: INFO: Pod "pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02884058s
STEP: Saw pod success
Nov  2 18:23:36.572: INFO: Pod "pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a" satisfied condition "success or failure"
Nov  2 18:23:36.579: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:23:36.634: INFO: Waiting for pod pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a to disappear
Nov  2 18:23:36.641: INFO: Pod pod-projected-configmaps-d4a781d8-d3fb-46b6-8ef8-6e7b84dc1b3a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:23:36.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7460" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":280,"completed":90,"skipped":1534,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:23:36.675: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5070
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Nov  2 18:23:36.899: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:23:56.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5070" for this suite.

• [SLOW TEST:19.879 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":280,"completed":91,"skipped":1541,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:23:56.555: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:24:03.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8329" for this suite.

• [SLOW TEST:7.295 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":280,"completed":92,"skipped":1602,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:24:03.850: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1275
STEP: creating the pod
Nov  2 18:24:04.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-9195'
Nov  2 18:24:05.048: INFO: stderr: ""
Nov  2 18:24:05.048: INFO: stdout: "pod/pause created\n"
Nov  2 18:24:05.048: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  2 18:24:05.049: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9195" to be "running and ready"
Nov  2 18:24:05.062: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.434974ms
Nov  2 18:24:07.071: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02285907s
Nov  2 18:24:09.079: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.030844153s
Nov  2 18:24:09.079: INFO: Pod "pause" satisfied condition "running and ready"
Nov  2 18:24:09.079: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  2 18:24:09.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 label pods pause testing-label=testing-label-value --namespace=kubectl-9195'
Nov  2 18:24:09.238: INFO: stderr: ""
Nov  2 18:24:09.238: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  2 18:24:09.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pod pause -L testing-label --namespace=kubectl-9195'
Nov  2 18:24:09.407: INFO: stderr: ""
Nov  2 18:24:09.407: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  2 18:24:09.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 label pods pause testing-label- --namespace=kubectl-9195'
Nov  2 18:24:09.543: INFO: stderr: ""
Nov  2 18:24:09.543: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  2 18:24:09.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pod pause -L testing-label --namespace=kubectl-9195'
Nov  2 18:24:09.653: INFO: stderr: ""
Nov  2 18:24:09.653: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
STEP: using delete to clean up resources
Nov  2 18:24:09.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-9195'
Nov  2 18:24:09.821: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:24:09.821: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  2 18:24:09.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get rc,svc -l name=pause --no-headers --namespace=kubectl-9195'
Nov  2 18:24:09.944: INFO: stderr: "No resources found in kubectl-9195 namespace.\n"
Nov  2 18:24:09.944: INFO: stdout: ""
Nov  2 18:24:09.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -l name=pause --namespace=kubectl-9195 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  2 18:24:10.044: INFO: stderr: ""
Nov  2 18:24:10.044: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:24:10.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9195" for this suite.

• [SLOW TEST:6.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1272
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":280,"completed":93,"skipped":1656,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:24:10.075: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8851
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8851
STEP: creating replication controller externalsvc in namespace services-8851
I1102 18:24:10.424687      24 runners.go:189] Created replication controller with name: externalsvc, namespace: services-8851, replica count: 2
I1102 18:24:13.475159      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov  2 18:24:13.531: INFO: Creating new exec pod
Nov  2 18:24:17.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-8851 execpod6tl9w -- /bin/sh -x -c nslookup nodeport-service'
Nov  2 18:24:18.200: INFO: stderr: "+ nslookup nodeport-service\n"
Nov  2 18:24:18.201: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nnodeport-service.services-8851.svc.cluster.local\tcanonical name = externalsvc.services-8851.svc.cluster.local.\nName:\texternalsvc.services-8851.svc.cluster.local\nAddress: 10.240.24.29\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8851, will wait for the garbage collector to delete the pods
Nov  2 18:24:18.275: INFO: Deleting ReplicationController externalsvc took: 16.705493ms
Nov  2 18:24:18.776: INFO: Terminating ReplicationController externalsvc pods took: 500.54248ms
Nov  2 18:24:23.421: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:24:23.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8851" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:13.419 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":280,"completed":94,"skipped":1676,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:24:23.495: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-9129
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating statefulset ss in namespace statefulset-9129
Nov  2 18:24:23.755: INFO: Found 0 stateful pods, waiting for 1
Nov  2 18:24:33.765: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov  2 18:24:33.815: INFO: Deleting all statefulset in ns statefulset-9129
Nov  2 18:24:33.824: INFO: Scaling statefulset ss to 0
Nov  2 18:24:53.892: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:24:53.899: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:24:53.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9129" for this suite.

• [SLOW TEST:30.472 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":280,"completed":95,"skipped":1739,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:24:53.968: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-d2bbc135-f13e-4937-8afb-dedbbeb5a8a7
STEP: Creating a pod to test consume secrets
Nov  2 18:24:54.279: INFO: Waiting up to 5m0s for pod "pod-secrets-f698261f-0403-4f61-9c47-65594750efdc" in namespace "secrets-3763" to be "success or failure"
Nov  2 18:24:54.285: INFO: Pod "pod-secrets-f698261f-0403-4f61-9c47-65594750efdc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.431809ms
Nov  2 18:24:56.296: INFO: Pod "pod-secrets-f698261f-0403-4f61-9c47-65594750efdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017258415s
Nov  2 18:24:58.305: INFO: Pod "pod-secrets-f698261f-0403-4f61-9c47-65594750efdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026159017s
STEP: Saw pod success
Nov  2 18:24:58.305: INFO: Pod "pod-secrets-f698261f-0403-4f61-9c47-65594750efdc" satisfied condition "success or failure"
Nov  2 18:24:58.315: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-f698261f-0403-4f61-9c47-65594750efdc container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:24:58.361: INFO: Waiting for pod pod-secrets-f698261f-0403-4f61-9c47-65594750efdc to disappear
Nov  2 18:24:58.375: INFO: Pod pod-secrets-f698261f-0403-4f61-9c47-65594750efdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:24:58.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3763" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":96,"skipped":1746,"failed":0}

------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:24:58.409: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-2458
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating stateful set ss in namespace statefulset-2458
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2458
Nov  2 18:24:58.666: INFO: Found 0 stateful pods, waiting for 1
Nov  2 18:25:08.675: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  2 18:25:08.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 18:25:09.301: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 18:25:09.301: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 18:25:09.301: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 18:25:09.349: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  2 18:25:19.358: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 18:25:19.358: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:25:19.397: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:19.397: INFO: ss-0  awesome-shannon-698f584c96-drfqf  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:24:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:09 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:09 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:24:58 +0000 UTC  }]
Nov  2 18:25:19.397: INFO: ss-1                                    Pending         []
Nov  2 18:25:19.397: INFO: 
Nov  2 18:25:19.397: INFO: StatefulSet ss has not reached scale 3, at 2
Nov  2 18:25:20.407: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989470284s
Nov  2 18:25:21.417: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979324192s
Nov  2 18:25:22.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.969680977s
Nov  2 18:25:23.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.96119026s
Nov  2 18:25:24.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.948212133s
Nov  2 18:25:25.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.937879812s
Nov  2 18:25:26.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.927136304s
Nov  2 18:25:27.489: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.913818995s
Nov  2 18:25:28.505: INFO: Verifying statefulset ss doesn't scale past 3 for another 897.056987ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2458
Nov  2 18:25:29.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:25:30.186: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  2 18:25:30.186: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 18:25:30.186: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 18:25:30.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:25:30.805: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  2 18:25:30.805: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 18:25:30.805: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 18:25:30.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:25:31.418: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  2 18:25:31.418: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 18:25:31.418: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 18:25:31.430: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:25:31.430: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:25:31.430: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  2 18:25:31.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 18:25:32.060: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 18:25:32.060: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 18:25:32.060: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 18:25:32.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 18:25:32.700: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 18:25:32.700: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 18:25:32.700: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 18:25:32.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 18:25:33.302: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 18:25:33.302: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 18:25:33.302: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 18:25:33.302: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:25:33.310: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  2 18:25:43.326: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 18:25:43.326: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 18:25:43.326: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 18:25:43.355: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:43.355: INFO: ss-0  awesome-shannon-698f584c96-drfqf  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:24:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:24:58 +0000 UTC  }]
Nov  2 18:25:43.355: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:43.355: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:43.355: INFO: 
Nov  2 18:25:43.355: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  2 18:25:44.363: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:44.364: INFO: ss-0  awesome-shannon-698f584c96-drfqf  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:24:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:24:58 +0000 UTC  }]
Nov  2 18:25:44.364: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:44.364: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:44.364: INFO: 
Nov  2 18:25:44.364: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  2 18:25:45.373: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:45.373: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:45.373: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:45.373: INFO: 
Nov  2 18:25:45.373: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:46.381: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:46.381: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:46.381: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:46.381: INFO: 
Nov  2 18:25:46.381: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:47.390: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:47.391: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:47.391: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:47.391: INFO: 
Nov  2 18:25:47.391: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:48.400: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:48.400: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:48.400: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:48.400: INFO: 
Nov  2 18:25:48.400: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:49.410: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:49.410: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:49.410: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:49.410: INFO: 
Nov  2 18:25:49.410: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:50.420: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:50.420: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:50.420: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:50.420: INFO: 
Nov  2 18:25:50.420: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:51.429: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:51.429: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:51.429: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:51.429: INFO: 
Nov  2 18:25:51.429: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  2 18:25:52.438: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Nov  2 18:25:52.438: INFO: ss-1  awesome-shannon-698f584c96-dc8qz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:52.439: INFO: ss-2  awesome-shannon-698f584c96-brzmg  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-11-02 18:25:19 +0000 UTC  }]
Nov  2 18:25:52.439: INFO: 
Nov  2 18:25:52.439: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2458
Nov  2 18:25:53.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:25:53.725: INFO: rc: 1
Nov  2 18:25:53.725: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Nov  2 18:26:03.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:26:03.915: INFO: rc: 1
Nov  2 18:26:03.916: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:26:13.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:26:14.019: INFO: rc: 1
Nov  2 18:26:14.019: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:26:24.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:26:24.116: INFO: rc: 1
Nov  2 18:26:24.116: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:26:34.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:26:34.222: INFO: rc: 1
Nov  2 18:26:34.222: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:26:44.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:26:44.387: INFO: rc: 1
Nov  2 18:26:44.387: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:26:54.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:26:54.511: INFO: rc: 1
Nov  2 18:26:54.511: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:27:04.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:27:04.618: INFO: rc: 1
Nov  2 18:27:04.618: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:27:14.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:27:14.721: INFO: rc: 1
Nov  2 18:27:14.721: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:27:24.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:27:24.836: INFO: rc: 1
Nov  2 18:27:24.836: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:27:34.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:27:34.957: INFO: rc: 1
Nov  2 18:27:34.957: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:27:44.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:27:45.094: INFO: rc: 1
Nov  2 18:27:45.094: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:27:55.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:27:55.206: INFO: rc: 1
Nov  2 18:27:55.206: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:28:05.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:28:05.308: INFO: rc: 1
Nov  2 18:28:05.308: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:28:15.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:28:15.408: INFO: rc: 1
Nov  2 18:28:15.408: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:28:25.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:28:25.520: INFO: rc: 1
Nov  2 18:28:25.520: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:28:35.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:28:35.624: INFO: rc: 1
Nov  2 18:28:35.624: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:28:45.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:28:45.726: INFO: rc: 1
Nov  2 18:28:45.726: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:28:55.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:28:55.840: INFO: rc: 1
Nov  2 18:28:55.840: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:29:05.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:29:05.952: INFO: rc: 1
Nov  2 18:29:05.952: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:29:15.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:29:16.053: INFO: rc: 1
Nov  2 18:29:16.053: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:29:26.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:29:26.225: INFO: rc: 1
Nov  2 18:29:26.225: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:29:36.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:29:36.333: INFO: rc: 1
Nov  2 18:29:36.333: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:29:46.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:29:46.431: INFO: rc: 1
Nov  2 18:29:46.431: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:29:56.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:29:56.571: INFO: rc: 1
Nov  2 18:29:56.571: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:30:06.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:30:06.729: INFO: rc: 1
Nov  2 18:30:06.730: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:30:16.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:30:16.844: INFO: rc: 1
Nov  2 18:30:16.844: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:30:26.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:30:26.956: INFO: rc: 1
Nov  2 18:30:26.956: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:30:36.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:30:37.065: INFO: rc: 1
Nov  2 18:30:37.065: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:30:47.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:30:47.202: INFO: rc: 1
Nov  2 18:30:47.202: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov  2 18:30:57.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-2458 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 18:30:57.316: INFO: rc: 1
Nov  2 18:30:57.316: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Nov  2 18:30:57.316: INFO: Scaling statefulset ss to 0
Nov  2 18:30:57.346: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov  2 18:30:57.353: INFO: Deleting all statefulset in ns statefulset-2458
Nov  2 18:30:57.359: INFO: Scaling statefulset ss to 0
Nov  2 18:30:57.391: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:30:57.396: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:30:57.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2458" for this suite.

• [SLOW TEST:359.053 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":280,"completed":97,"skipped":1746,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:30:57.462: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9947
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov  2 18:31:02.313: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9947 pod-service-account-d8b40c9a-3330-46b7-8f3a-68718f227d42 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov  2 18:31:02.952: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9947 pod-service-account-d8b40c9a-3330-46b7-8f3a-68718f227d42 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov  2 18:31:03.593: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9947 pod-service-account-d8b40c9a-3330-46b7-8f3a-68718f227d42 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:31:04.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9947" for this suite.

• [SLOW TEST:6.782 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":280,"completed":98,"skipped":1753,"failed":0}
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:31:04.243: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:31:04.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9236" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":280,"completed":99,"skipped":1758,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:31:04.566: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-ec868d7b-ce61-41d9-ae20-040162050ea9 in namespace container-probe-512
Nov  2 18:31:08.808: INFO: Started pod busybox-ec868d7b-ce61-41d9-ae20-040162050ea9 in namespace container-probe-512
STEP: checking the pod's current state and verifying that restartCount is present
Nov  2 18:31:08.825: INFO: Initial restart count of pod busybox-ec868d7b-ce61-41d9-ae20-040162050ea9 is 0
Nov  2 18:31:55.036: INFO: Restart count of pod container-probe-512/busybox-ec868d7b-ce61-41d9-ae20-040162050ea9 is now 1 (46.21150457s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:31:55.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-512" for this suite.

• [SLOW TEST:50.542 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":100,"skipped":1769,"failed":0}
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:31:55.109: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-297f2219-39f5-4cc1-ae1e-7df059e9d047 in namespace container-probe-9832
Nov  2 18:31:59.416: INFO: Started pod busybox-297f2219-39f5-4cc1-ae1e-7df059e9d047 in namespace container-probe-9832
STEP: checking the pod's current state and verifying that restartCount is present
Nov  2 18:31:59.423: INFO: Initial restart count of pod busybox-297f2219-39f5-4cc1-ae1e-7df059e9d047 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:36:00.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9832" for this suite.

• [SLOW TEST:245.653 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":101,"skipped":1771,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:36:00.763: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  2 18:36:00.982: INFO: Waiting up to 5m0s for pod "pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2" in namespace "emptydir-8397" to be "success or failure"
Nov  2 18:36:01.003: INFO: Pod "pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.550382ms
Nov  2 18:36:03.013: INFO: Pod "pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030599944s
Nov  2 18:36:05.021: INFO: Pod "pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038469736s
STEP: Saw pod success
Nov  2 18:36:05.021: INFO: Pod "pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2" satisfied condition "success or failure"
Nov  2 18:36:05.029: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2 container test-container: <nil>
STEP: delete the pod
Nov  2 18:36:05.108: INFO: Waiting for pod pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2 to disappear
Nov  2 18:36:05.117: INFO: Pod pod-e166321c-1cf4-4beb-b92b-9b3ac25bd9b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:36:05.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8397" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":102,"skipped":1774,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:36:05.146: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Nov  2 18:36:06.057: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1102 18:36:06.057438      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:36:06.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4878" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":280,"completed":103,"skipped":1786,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:36:06.080: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7447
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d0dc0f38-dda9-4c7f-8bc1-461c4b24bd02
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d0dc0f38-dda9-4c7f-8bc1-461c4b24bd02
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:37:29.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7447" for this suite.

• [SLOW TEST:83.608 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":104,"skipped":1787,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:37:29.688: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4975.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4975.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4975.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4975.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4975.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4975.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 18:37:34.704: INFO: DNS probes using dns-4975/dns-test-60cee6c2-9cf6-4826-8448-c902f95c432b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:37:34.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4975" for this suite.

• [SLOW TEST:5.079 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":280,"completed":105,"skipped":1796,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:37:34.768: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8361
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:37:35.695: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:37:37.717: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939055, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939055, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939055, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939055, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:37:40.756: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:37:41.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8361" for this suite.
STEP: Destroying namespace "webhook-8361-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.514 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":280,"completed":106,"skipped":1796,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:37:41.282: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:37:52.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4766" for this suite.

• [SLOW TEST:11.393 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":280,"completed":107,"skipped":1802,"failed":0}
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:37:52.676: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override arguments
Nov  2 18:37:52.989: INFO: Waiting up to 5m0s for pod "client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d" in namespace "containers-8236" to be "success or failure"
Nov  2 18:37:53.000: INFO: Pod "client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.558024ms
Nov  2 18:37:55.009: INFO: Pod "client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019573992s
Nov  2 18:37:57.017: INFO: Pod "client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02713325s
STEP: Saw pod success
Nov  2 18:37:57.017: INFO: Pod "client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d" satisfied condition "success or failure"
Nov  2 18:37:57.024: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d container test-container: <nil>
STEP: delete the pod
Nov  2 18:37:57.091: INFO: Waiting for pod client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d to disappear
Nov  2 18:37:57.098: INFO: Pod client-containers-7c1df7c6-3649-45fd-858d-ab267843e90d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:37:57.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8236" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":280,"completed":108,"skipped":1804,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:37:57.155: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:37:57.421: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb" in namespace "projected-5616" to be "success or failure"
Nov  2 18:37:57.436: INFO: Pod "downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.739323ms
Nov  2 18:37:59.446: INFO: Pod "downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024863897s
Nov  2 18:38:01.456: INFO: Pod "downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035371543s
STEP: Saw pod success
Nov  2 18:38:01.456: INFO: Pod "downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb" satisfied condition "success or failure"
Nov  2 18:38:01.464: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb container client-container: <nil>
STEP: delete the pod
Nov  2 18:38:01.537: INFO: Waiting for pod downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb to disappear
Nov  2 18:38:01.544: INFO: Pod downwardapi-volume-93663b70-7454-4059-be9e-27c1dcf20beb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:01.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5616" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":109,"skipped":1818,"failed":0}
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:01.566: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  2 18:38:10.029: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:10.038: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  2 18:38:12.038: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:12.051: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  2 18:38:14.038: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:14.048: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  2 18:38:16.038: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:16.046: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  2 18:38:18.038: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:18.048: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  2 18:38:20.038: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:20.046: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  2 18:38:22.038: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  2 18:38:22.048: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:22.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8192" for this suite.

• [SLOW TEST:20.507 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":280,"completed":110,"skipped":1822,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:22.075: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-463e1457-261b-400b-8bfc-c1b823c38837
STEP: Creating a pod to test consume configMaps
Nov  2 18:38:22.306: INFO: Waiting up to 5m0s for pod "pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd" in namespace "configmap-2573" to be "success or failure"
Nov  2 18:38:22.312: INFO: Pod "pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.144208ms
Nov  2 18:38:24.321: INFO: Pod "pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01482278s
Nov  2 18:38:26.330: INFO: Pod "pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023649272s
STEP: Saw pod success
Nov  2 18:38:26.330: INFO: Pod "pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd" satisfied condition "success or failure"
Nov  2 18:38:26.337: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:38:26.398: INFO: Waiting for pod pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd to disappear
Nov  2 18:38:26.405: INFO: Pod pod-configmaps-dfd32a41-b68b-4fff-bae8-3d0907fddcbd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:26.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2573" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":111,"skipped":1851,"failed":0}
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:26.443: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Nov  2 18:38:26.652: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:31.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-677" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":280,"completed":112,"skipped":1854,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:31.136: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-9299/configmap-test-a503cacd-67e1-4341-9baf-9121ba6dfc6d
STEP: Creating a pod to test consume configMaps
Nov  2 18:38:31.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49" in namespace "configmap-9299" to be "success or failure"
Nov  2 18:38:31.478: INFO: Pod "pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49": Phase="Pending", Reason="", readiness=false. Elapsed: 8.34602ms
Nov  2 18:38:33.491: INFO: Pod "pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021064317s
Nov  2 18:38:35.509: INFO: Pod "pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0390848s
STEP: Saw pod success
Nov  2 18:38:35.509: INFO: Pod "pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49" satisfied condition "success or failure"
Nov  2 18:38:35.516: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49 container env-test: <nil>
STEP: delete the pod
Nov  2 18:38:35.577: INFO: Waiting for pod pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49 to disappear
Nov  2 18:38:35.584: INFO: Pod pod-configmaps-f9ae8ad2-eb91-4534-9cfb-20f6ee2a6c49 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:35.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9299" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":113,"skipped":1896,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:35.609: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-413
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-dc844dcd-060a-42e6-86b9-2acca3353891
STEP: Creating secret with name s-test-opt-upd-f07521ac-e1d5-44c6-b0e5-da34e9160fd7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dc844dcd-060a-42e6-86b9-2acca3353891
STEP: Updating secret s-test-opt-upd-f07521ac-e1d5-44c6-b0e5-da34e9160fd7
STEP: Creating secret with name s-test-opt-create-49668f29-2068-4b63-ac94-fe85f5b5a668
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:44.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-413" for this suite.

• [SLOW TEST:8.878 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":114,"skipped":1913,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:44.490: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:38:44.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9" in namespace "downward-api-4421" to be "success or failure"
Nov  2 18:38:44.754: INFO: Pod "downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.297328ms
Nov  2 18:38:46.763: INFO: Pod "downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023011495s
Nov  2 18:38:48.770: INFO: Pod "downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030485328s
STEP: Saw pod success
Nov  2 18:38:48.770: INFO: Pod "downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9" satisfied condition "success or failure"
Nov  2 18:38:48.777: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9 container client-container: <nil>
STEP: delete the pod
Nov  2 18:38:48.833: INFO: Waiting for pod downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9 to disappear
Nov  2 18:38:48.840: INFO: Pod downwardapi-volume-a0fc3e79-e13a-4a20-8afd-d31d995a20b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:48.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4421" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":280,"completed":115,"skipped":1937,"failed":0}

------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:48.867: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1729
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:38:53.166: INFO: Waiting up to 5m0s for pod "client-envvars-904430e9-748d-4c93-bda6-43b48461c48b" in namespace "pods-1729" to be "success or failure"
Nov  2 18:38:53.185: INFO: Pod "client-envvars-904430e9-748d-4c93-bda6-43b48461c48b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.074812ms
Nov  2 18:38:55.197: INFO: Pod "client-envvars-904430e9-748d-4c93-bda6-43b48461c48b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031154259s
Nov  2 18:38:57.208: INFO: Pod "client-envvars-904430e9-748d-4c93-bda6-43b48461c48b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042781646s
STEP: Saw pod success
Nov  2 18:38:57.209: INFO: Pod "client-envvars-904430e9-748d-4c93-bda6-43b48461c48b" satisfied condition "success or failure"
Nov  2 18:38:57.216: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod client-envvars-904430e9-748d-4c93-bda6-43b48461c48b container env3cont: <nil>
STEP: delete the pod
Nov  2 18:38:57.282: INFO: Waiting for pod client-envvars-904430e9-748d-4c93-bda6-43b48461c48b to disappear
Nov  2 18:38:57.288: INFO: Pod client-envvars-904430e9-748d-4c93-bda6-43b48461c48b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:38:57.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1729" for this suite.

• [SLOW TEST:8.449 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":280,"completed":116,"skipped":1937,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:38:57.321: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov  2 18:39:02.116: INFO: Successfully updated pod "adopt-release-nnbfc"
STEP: Checking that the Job readopts the Pod
Nov  2 18:39:02.116: INFO: Waiting up to 15m0s for pod "adopt-release-nnbfc" in namespace "job-6456" to be "adopted"
Nov  2 18:39:02.123: INFO: Pod "adopt-release-nnbfc": Phase="Running", Reason="", readiness=true. Elapsed: 7.041378ms
Nov  2 18:39:04.133: INFO: Pod "adopt-release-nnbfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.016219504s
Nov  2 18:39:04.133: INFO: Pod "adopt-release-nnbfc" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov  2 18:39:04.665: INFO: Successfully updated pod "adopt-release-nnbfc"
STEP: Checking that the Job releases the Pod
Nov  2 18:39:04.665: INFO: Waiting up to 15m0s for pod "adopt-release-nnbfc" in namespace "job-6456" to be "released"
Nov  2 18:39:04.671: INFO: Pod "adopt-release-nnbfc": Phase="Running", Reason="", readiness=true. Elapsed: 5.89593ms
Nov  2 18:39:04.671: INFO: Pod "adopt-release-nnbfc" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:04.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6456" for this suite.

• [SLOW TEST:7.373 seconds]
[sig-apps] Job
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":280,"completed":117,"skipped":1943,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:04.696: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov  2 18:39:04.934: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  2 18:39:04.962: INFO: Waiting for terminating namespaces to be deleted...
Nov  2 18:39:04.970: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-brzmg before test
Nov  2 18:39:05.007: INFO: dashboard-metrics-scraper-59bfc65dc9-mx5wv from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.007: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:39:05.007: INFO: node-local-dns-nwqv9 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.007: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:39:05.007: INFO: canal-c64t7 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.007: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:39:05.007: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:39:05.007: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-11-02 09:26:48 +0000 UTC (5 container statuses recorded)
Nov  2 18:39:05.007: INFO: 	Container cinder-csi-plugin ready: true, restart count 2
Nov  2 18:39:05.007: INFO: 	Container csi-attacher ready: true, restart count 0
Nov  2 18:39:05.007: INFO: 	Container csi-provisioner ready: true, restart count 0
Nov  2 18:39:05.007: INFO: 	Container csi-resizer ready: true, restart count 0
Nov  2 18:39:05.007: INFO: 	Container csi-snapshotter ready: true, restart count 0
Nov  2 18:39:05.007: INFO: coredns-57f944bd9f-492kl from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:39:05.008: INFO: dashboard-metrics-scraper-59bfc65dc9-vv6zf from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:39:05.008: INFO: openvpn-client-84ccd8596d-qps5z from kube-system started at 2020-11-02 09:28:26 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  2 18:39:05.008: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  2 18:39:05.008: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:39:05.008: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:39:05.008: INFO: logrotate-vdk6h from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:39:05.008: INFO: user-ssh-keys-agent-wklnz from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:39:05.008: INFO: kube-proxy-gk2s6 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:39:05.008: INFO: csi-cinder-nodeplugin-ubuntu-xqnfj from kube-system started at 2020-11-02 09:26:48 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:39:05.008: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:39:05.008: INFO: coredns-57f944bd9f-h8sb4 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.008: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:39:05.008: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-dc8qz before test
Nov  2 18:39:05.091: INFO: logrotate-6plw5 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:39:05.091: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-9c9cl from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:39:05.091: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:39:05.091: INFO: server-envvars-54241f94-7f9b-4cb3-995c-99d685f74646 from pods-1729 started at 2020-11-02 18:38:49 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container srv ready: false, restart count 0
Nov  2 18:39:05.091: INFO: kube-proxy-4bdvn from kube-system started at 2020-11-02 09:31:11 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:39:05.091: INFO: node-local-dns-7m96x from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:39:05.091: INFO: csi-cinder-nodeplugin-ubuntu-rwf9k from kube-system started at 2020-11-02 09:31:41 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:39:05.091: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:39:05.091: INFO: canal-6x859 from kube-system started at 2020-11-02 09:31:11 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:39:05.091: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:39:05.091: INFO: user-ssh-keys-agent-99zc9 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:39:05.091: INFO: sonobuoy-e2e-job-4da6a1ac755345e8 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.091: INFO: 	Container e2e ready: true, restart count 0
Nov  2 18:39:05.092: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:39:05.092: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-drfqf before test
Nov  2 18:39:05.183: INFO: user-ssh-keys-agent-8898v from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.183: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:39:05.183: INFO: node-local-dns-wbdvv from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.183: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:39:05.183: INFO: sonobuoy from sonobuoy started at 2020-11-02 17:59:56 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.183: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  2 18:39:05.183: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-h8fmt from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.183: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:39:05.183: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:39:05.183: INFO: adopt-release-nnbfc from job-6456 started at 2020-11-02 18:38:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.183: INFO: 	Container c ready: true, restart count 0
Nov  2 18:39:05.183: INFO: canal-l9xkd from kube-system started at 2020-11-02 09:28:06 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.183: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:39:05.183: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:39:05.184: INFO: kube-proxy-h49pz from kube-system started at 2020-11-02 09:28:06 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.184: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:39:05.184: INFO: csi-cinder-nodeplugin-ubuntu-879qh from kube-system started at 2020-11-02 18:16:57 +0000 UTC (2 container statuses recorded)
Nov  2 18:39:05.184: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:39:05.184: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:39:05.184: INFO: logrotate-28zzm from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.184: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:39:05.184: INFO: adopt-release-vmw5h from job-6456 started at 2020-11-02 18:38:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:39:05.184: INFO: 	Container c ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b6ce99c8-1dde-4879-b84b-b649d114abf4 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-b6ce99c8-1dde-4879-b84b-b649d114abf4 off the node awesome-shannon-698f584c96-drfqf
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b6ce99c8-1dde-4879-b84b-b649d114abf4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:21.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7420" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:16.845 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":280,"completed":118,"skipped":1946,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:21.542: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:39:21.768: INFO: Creating deployment "test-recreate-deployment"
Nov  2 18:39:21.782: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  2 18:39:21.806: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov  2 18:39:23.840: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  2 18:39:23.853: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939161, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939161, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939161, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939161, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:39:25.862: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  2 18:39:25.888: INFO: Updating deployment test-recreate-deployment
Nov  2 18:39:25.888: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov  2 18:39:26.079: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9911 /apis/apps/v1/namespaces/deployment-9911/deployments/test-recreate-deployment 0ffe50f3-ba84-4be4-b81e-9bcb902e086b 158544 2 2020-11-02 18:39:21 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00343aa58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-11-02 18:39:26 +0000 UTC,LastTransitionTime:2020-11-02 18:39:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-11-02 18:39:26 +0000 UTC,LastTransitionTime:2020-11-02 18:39:21 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov  2 18:39:26.099: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-9911 /apis/apps/v1/namespaces/deployment-9911/replicasets/test-recreate-deployment-5f94c574ff f24ea892-0299-4d49-b461-fbc3c1dd4c6d 158543 1 2020-11-02 18:39:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 0ffe50f3-ba84-4be4-b81e-9bcb902e086b 0xc003cbb177 0xc003cbb178}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cbb1d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:39:26.099: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  2 18:39:26.099: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-799c574856  deployment-9911 /apis/apps/v1/namespaces/deployment-9911/replicasets/test-recreate-deployment-799c574856 2971155c-b46e-4f42-8ea0-fb1a3abc1c7d 158532 2 2020-11-02 18:39:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 0ffe50f3-ba84-4be4-b81e-9bcb902e086b 0xc003cbb247 0xc003cbb248}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 799c574856,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cbb2b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:39:26.107: INFO: Pod "test-recreate-deployment-5f94c574ff-kndkn" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-kndkn test-recreate-deployment-5f94c574ff- deployment-9911 /api/v1/namespaces/deployment-9911/pods/test-recreate-deployment-5f94c574ff-kndkn 7507f784-2e70-4b0a-8439-fd5e0d69a5bb 158545 0 2020-11-02 18:39:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff f24ea892-0299-4d49-b461-fbc3c1dd4c6d 0xc003cbb737 0xc003cbb738}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jggnw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jggnw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jggnw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2020-11-02 18:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:26.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9911" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":119,"skipped":1984,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:26.143: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  2 18:39:34.540: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  2 18:39:34.554: INFO: Pod pod-with-poststart-http-hook still exists
Nov  2 18:39:36.555: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  2 18:39:36.562: INFO: Pod pod-with-poststart-http-hook still exists
Nov  2 18:39:38.555: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  2 18:39:38.568: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:38.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2756" for this suite.

• [SLOW TEST:12.458 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":280,"completed":120,"skipped":1998,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:38.601: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-1e20f8f3-1822-4d63-ba04-3e1235fd5acd
STEP: Creating a pod to test consume configMaps
Nov  2 18:39:38.847: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f" in namespace "projected-5807" to be "success or failure"
Nov  2 18:39:38.863: INFO: Pod "pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.126737ms
Nov  2 18:39:40.870: INFO: Pod "pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022908026s
Nov  2 18:39:42.881: INFO: Pod "pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03363525s
STEP: Saw pod success
Nov  2 18:39:42.881: INFO: Pod "pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f" satisfied condition "success or failure"
Nov  2 18:39:42.891: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:39:42.973: INFO: Waiting for pod pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f to disappear
Nov  2 18:39:42.980: INFO: Pod pod-projected-configmaps-c4ef069f-219e-48b8-973a-7486444b664f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:42.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5807" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":280,"completed":121,"skipped":2003,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:43.020: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override all
Nov  2 18:39:43.258: INFO: Waiting up to 5m0s for pod "client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746" in namespace "containers-2682" to be "success or failure"
Nov  2 18:39:43.265: INFO: Pod "client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746": Phase="Pending", Reason="", readiness=false. Elapsed: 7.379693ms
Nov  2 18:39:45.273: INFO: Pod "client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015384898s
Nov  2 18:39:47.282: INFO: Pod "client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024594608s
STEP: Saw pod success
Nov  2 18:39:47.282: INFO: Pod "client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746" satisfied condition "success or failure"
Nov  2 18:39:47.290: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746 container test-container: <nil>
STEP: delete the pod
Nov  2 18:39:47.392: INFO: Waiting for pod client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746 to disappear
Nov  2 18:39:47.400: INFO: Pod client-containers-52e3a83b-10e5-493b-9abf-7a4b692a1746 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:47.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2682" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":280,"completed":122,"skipped":2021,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:47.435: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:39:47.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72" in namespace "downward-api-9299" to be "success or failure"
Nov  2 18:39:47.680: INFO: Pod "downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72": Phase="Pending", Reason="", readiness=false. Elapsed: 19.732297ms
Nov  2 18:39:49.688: INFO: Pod "downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028023823s
Nov  2 18:39:51.696: INFO: Pod "downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035720637s
STEP: Saw pod success
Nov  2 18:39:51.696: INFO: Pod "downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72" satisfied condition "success or failure"
Nov  2 18:39:51.704: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72 container client-container: <nil>
STEP: delete the pod
Nov  2 18:39:51.755: INFO: Waiting for pod downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72 to disappear
Nov  2 18:39:51.762: INFO: Pod downwardapi-volume-d124a720-6cd6-4ac6-a41d-db7c0bb2cf72 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:51.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9299" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":123,"skipped":2023,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:51.808: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov  2 18:39:52.057: INFO: Waiting up to 5m0s for pod "downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a" in namespace "downward-api-3623" to be "success or failure"
Nov  2 18:39:52.071: INFO: Pod "downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.935809ms
Nov  2 18:39:54.082: INFO: Pod "downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024944778s
Nov  2 18:39:56.093: INFO: Pod "downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035497163s
STEP: Saw pod success
Nov  2 18:39:56.093: INFO: Pod "downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a" satisfied condition "success or failure"
Nov  2 18:39:56.100: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:39:56.157: INFO: Waiting for pod downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a to disappear
Nov  2 18:39:56.163: INFO: Pod downward-api-a21c5b05-9981-4c08-b7b9-d0f68cc8a04a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:39:56.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3623" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":280,"completed":124,"skipped":2040,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:39:56.200: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating replication controller my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227
Nov  2 18:39:56.437: INFO: Pod name my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227: Found 0 pods out of 1
Nov  2 18:40:01.448: INFO: Pod name my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227: Found 1 pods out of 1
Nov  2 18:40:01.448: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227" are running
Nov  2 18:40:01.455: INFO: Pod "my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227-b9j7g" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 18:39:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 18:39:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 18:39:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 18:39:56 +0000 UTC Reason: Message:}])
Nov  2 18:40:01.455: INFO: Trying to dial the pod
Nov  2 18:40:06.574: INFO: Controller my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227: Got expected result from replica 1 [my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227-b9j7g]: "my-hostname-basic-d65b16c0-5fd5-43f0-8839-6f67e35c7227-b9j7g", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:06.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9633" for this suite.

• [SLOW TEST:10.420 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":125,"skipped":2061,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:06.621: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  2 18:40:11.462: INFO: Successfully updated pod "pod-update-activedeadlineseconds-105bcea4-752c-44e9-8ecf-2f6d45cc6cc1"
Nov  2 18:40:11.462: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-105bcea4-752c-44e9-8ecf-2f6d45cc6cc1" in namespace "pods-1277" to be "terminated due to deadline exceeded"
Nov  2 18:40:11.469: INFO: Pod "pod-update-activedeadlineseconds-105bcea4-752c-44e9-8ecf-2f6d45cc6cc1": Phase="Running", Reason="", readiness=true. Elapsed: 6.953076ms
Nov  2 18:40:13.482: INFO: Pod "pod-update-activedeadlineseconds-105bcea4-752c-44e9-8ecf-2f6d45cc6cc1": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.019553864s
Nov  2 18:40:13.482: INFO: Pod "pod-update-activedeadlineseconds-105bcea4-752c-44e9-8ecf-2f6d45cc6cc1" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:13.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1277" for this suite.

• [SLOW TEST:6.889 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":280,"completed":126,"skipped":2134,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:13.512: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:21.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1100" for this suite.

• [SLOW TEST:8.271 seconds]
[sig-apps] Job
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":280,"completed":127,"skipped":2140,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:21.784: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-667
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:40:21.982: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  2 18:40:25.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-667 create -f -'
Nov  2 18:40:26.529: INFO: stderr: ""
Nov  2 18:40:26.529: INFO: stdout: "e2e-test-crd-publish-openapi-7118-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  2 18:40:26.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-667 delete e2e-test-crd-publish-openapi-7118-crds test-cr'
Nov  2 18:40:26.686: INFO: stderr: ""
Nov  2 18:40:26.686: INFO: stdout: "e2e-test-crd-publish-openapi-7118-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov  2 18:40:26.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-667 apply -f -'
Nov  2 18:40:26.978: INFO: stderr: ""
Nov  2 18:40:26.978: INFO: stdout: "e2e-test-crd-publish-openapi-7118-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  2 18:40:26.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-667 delete e2e-test-crd-publish-openapi-7118-crds test-cr'
Nov  2 18:40:27.102: INFO: stderr: ""
Nov  2 18:40:27.102: INFO: stdout: "e2e-test-crd-publish-openapi-7118-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  2 18:40:27.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-7118-crds'
Nov  2 18:40:27.399: INFO: stderr: ""
Nov  2 18:40:27.399: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7118-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:31.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-667" for this suite.

• [SLOW TEST:9.449 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":280,"completed":128,"skipped":2149,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:31.234: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Nov  2 18:40:31.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-4970'
Nov  2 18:40:31.818: INFO: stderr: ""
Nov  2 18:40:31.818: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  2 18:40:31.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4970'
Nov  2 18:40:31.942: INFO: stderr: ""
Nov  2 18:40:31.942: INFO: stdout: "update-demo-nautilus-4ww4k update-demo-nautilus-65cld "
Nov  2 18:40:31.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-4ww4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4970'
Nov  2 18:40:32.045: INFO: stderr: ""
Nov  2 18:40:32.045: INFO: stdout: ""
Nov  2 18:40:32.045: INFO: update-demo-nautilus-4ww4k is created but not running
Nov  2 18:40:37.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4970'
Nov  2 18:40:37.145: INFO: stderr: ""
Nov  2 18:40:37.146: INFO: stdout: "update-demo-nautilus-4ww4k update-demo-nautilus-65cld "
Nov  2 18:40:37.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-4ww4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4970'
Nov  2 18:40:37.245: INFO: stderr: ""
Nov  2 18:40:37.245: INFO: stdout: "true"
Nov  2 18:40:37.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-4ww4k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4970'
Nov  2 18:40:37.354: INFO: stderr: ""
Nov  2 18:40:37.354: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:40:37.354: INFO: validating pod update-demo-nautilus-4ww4k
Nov  2 18:40:37.454: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:40:37.454: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:40:37.454: INFO: update-demo-nautilus-4ww4k is verified up and running
Nov  2 18:40:37.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-65cld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4970'
Nov  2 18:40:37.559: INFO: stderr: ""
Nov  2 18:40:37.559: INFO: stdout: "true"
Nov  2 18:40:37.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-65cld -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4970'
Nov  2 18:40:37.655: INFO: stderr: ""
Nov  2 18:40:37.655: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:40:37.655: INFO: validating pod update-demo-nautilus-65cld
Nov  2 18:40:37.756: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:40:37.756: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:40:37.756: INFO: update-demo-nautilus-65cld is verified up and running
STEP: using delete to clean up resources
Nov  2 18:40:37.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-4970'
Nov  2 18:40:37.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:40:37.878: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  2 18:40:37.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4970'
Nov  2 18:40:37.993: INFO: stderr: "No resources found in kubectl-4970 namespace.\n"
Nov  2 18:40:37.994: INFO: stdout: ""
Nov  2 18:40:37.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -l name=update-demo --namespace=kubectl-4970 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  2 18:40:38.190: INFO: stderr: ""
Nov  2 18:40:38.191: INFO: stdout: "update-demo-nautilus-4ww4k\nupdate-demo-nautilus-65cld\n"
Nov  2 18:40:38.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4970'
Nov  2 18:40:38.809: INFO: stderr: "No resources found in kubectl-4970 namespace.\n"
Nov  2 18:40:38.809: INFO: stdout: ""
Nov  2 18:40:38.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -l name=update-demo --namespace=kubectl-4970 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  2 18:40:38.917: INFO: stderr: ""
Nov  2 18:40:38.917: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:38.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4970" for this suite.

• [SLOW TEST:7.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":280,"completed":129,"skipped":2155,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:38.944: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:44.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1237" for this suite.

• [SLOW TEST:5.378 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":280,"completed":130,"skipped":2169,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:44.324: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:40:44.718: INFO: (0) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 154.610008ms)
Nov  2 18:40:44.741: INFO: (1) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.705105ms)
Nov  2 18:40:44.755: INFO: (2) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.329937ms)
Nov  2 18:40:44.767: INFO: (3) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.334901ms)
Nov  2 18:40:44.781: INFO: (4) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.880208ms)
Nov  2 18:40:44.796: INFO: (5) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.314069ms)
Nov  2 18:40:44.810: INFO: (6) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.437129ms)
Nov  2 18:40:44.824: INFO: (7) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.207155ms)
Nov  2 18:40:44.839: INFO: (8) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.298406ms)
Nov  2 18:40:44.858: INFO: (9) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.523779ms)
Nov  2 18:40:44.873: INFO: (10) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.366609ms)
Nov  2 18:40:44.888: INFO: (11) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.478681ms)
Nov  2 18:40:44.901: INFO: (12) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.186134ms)
Nov  2 18:40:44.920: INFO: (13) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.639037ms)
Nov  2 18:40:44.934: INFO: (14) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.404032ms)
Nov  2 18:40:44.948: INFO: (15) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.50595ms)
Nov  2 18:40:44.962: INFO: (16) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.732821ms)
Nov  2 18:40:44.975: INFO: (17) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.297454ms)
Nov  2 18:40:44.988: INFO: (18) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.59802ms)
Nov  2 18:40:45.002: INFO: (19) /api/v1/nodes/awesome-shannon-698f584c96-drfqf/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.15658ms)
[AfterEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:45.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2548" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":280,"completed":131,"skipped":2184,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:45.034: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2916
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:172
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating server pod server in namespace prestop-2916
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2916
STEP: Deleting pre-stop pod
Nov  2 18:40:58.500: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:40:58.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2916" for this suite.

• [SLOW TEST:13.530 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":280,"completed":132,"skipped":2208,"failed":0}
SSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:40:58.563: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:40:58.816: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-0fe54844-43be-4a94-822e-567b83296d73" in namespace "security-context-test-2152" to be "success or failure"
Nov  2 18:40:58.827: INFO: Pod "alpine-nnp-false-0fe54844-43be-4a94-822e-567b83296d73": Phase="Pending", Reason="", readiness=false. Elapsed: 10.7745ms
Nov  2 18:41:00.836: INFO: Pod "alpine-nnp-false-0fe54844-43be-4a94-822e-567b83296d73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01987334s
Nov  2 18:41:02.845: INFO: Pod "alpine-nnp-false-0fe54844-43be-4a94-822e-567b83296d73": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028553814s
Nov  2 18:41:04.859: INFO: Pod "alpine-nnp-false-0fe54844-43be-4a94-822e-567b83296d73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042957192s
Nov  2 18:41:04.859: INFO: Pod "alpine-nnp-false-0fe54844-43be-4a94-822e-567b83296d73" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:41:04.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2152" for this suite.

• [SLOW TEST:6.338 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:289
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":133,"skipped":2212,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:41:04.903: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:41:05.133: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  2 18:41:05.157: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  2 18:41:10.167: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  2 18:41:10.167: INFO: Creating deployment "test-rolling-update-deployment"
Nov  2 18:41:10.191: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  2 18:41:10.214: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  2 18:41:12.237: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  2 18:41:12.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939270, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939270, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939270, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939270, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:41:14.257: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov  2 18:41:14.297: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7604 /apis/apps/v1/namespaces/deployment-7604/deployments/test-rolling-update-deployment a5488e6a-76f5-4afc-8d8d-99cccca4a68b 159781 1 2020-11-02 18:41:10 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002864468 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-02 18:41:10 +0000 UTC,LastTransitionTime:2020-11-02 18:41:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67cf4f6444" has successfully progressed.,LastUpdateTime:2020-11-02 18:41:13 +0000 UTC,LastTransitionTime:2020-11-02 18:41:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  2 18:41:14.305: INFO: New ReplicaSet "test-rolling-update-deployment-67cf4f6444" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67cf4f6444  deployment-7604 /apis/apps/v1/namespaces/deployment-7604/replicasets/test-rolling-update-deployment-67cf4f6444 32a42175-e59a-40bd-8450-04a1c042b1fb 159768 1 2020-11-02 18:41:10 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment a5488e6a-76f5-4afc-8d8d-99cccca4a68b 0xc002864c47 0xc002864c48}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67cf4f6444,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002864d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:41:14.305: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  2 18:41:14.305: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7604 /apis/apps/v1/namespaces/deployment-7604/replicasets/test-rolling-update-controller f6c54004-5539-49c0-bc4c-b60302bf8fac 159780 2 2020-11-02 18:41:05 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment a5488e6a-76f5-4afc-8d8d-99cccca4a68b 0xc002864b47 0xc002864b48}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002864bb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:41:14.339: INFO: Pod "test-rolling-update-deployment-67cf4f6444-r8kl4" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67cf4f6444-r8kl4 test-rolling-update-deployment-67cf4f6444- deployment-7604 /api/v1/namespaces/deployment-7604/pods/test-rolling-update-deployment-67cf4f6444-r8kl4 3704756e-fee5-4567-a1ab-4c1f73221dfa 159767 0 2020-11-02 18:41:10 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[cni.projectcalico.org/podIP:172.25.2.53/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-67cf4f6444 32a42175-e59a-40bd-8450-04a1c042b1fb 0xc002865287 0xc002865288}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cqxng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cqxng,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cqxng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:41:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:41:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:41:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:41:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.2.53,StartTime:2020-11-02 18:41:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 18:41:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://76104fe34cb1b02ce80e071eb01f26ba09429cd15cc29ac5a1e230824094d268,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:41:14.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7604" for this suite.

• [SLOW TEST:9.487 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":134,"skipped":2231,"failed":0}
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:41:14.391: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:41:18.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7557" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":280,"completed":135,"skipped":2234,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:41:18.782: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-7209
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  2 18:41:19.017: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  2 18:41:43.324: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.123:8080/dial?request=hostname&protocol=http&host=172.25.0.17&port=8080&tries=1'] Namespace:pod-network-test-7209 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:41:43.326: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:41:43.813: INFO: Waiting for responses: map[]
Nov  2 18:41:43.822: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.123:8080/dial?request=hostname&protocol=http&host=172.25.2.54&port=8080&tries=1'] Namespace:pod-network-test-7209 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:41:43.822: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:41:44.402: INFO: Waiting for responses: map[]
Nov  2 18:41:44.413: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.123:8080/dial?request=hostname&protocol=http&host=172.25.1.122&port=8080&tries=1'] Namespace:pod-network-test-7209 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:41:44.413: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:41:44.953: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:41:44.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7209" for this suite.

• [SLOW TEST:26.198 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":136,"skipped":2242,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:41:44.980: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2714
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:41:45.187: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov  2 18:41:48.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 create -f -'
Nov  2 18:41:49.484: INFO: stderr: ""
Nov  2 18:41:49.484: INFO: stdout: "e2e-test-crd-publish-openapi-282-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  2 18:41:49.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 delete e2e-test-crd-publish-openapi-282-crds test-foo'
Nov  2 18:41:49.656: INFO: stderr: ""
Nov  2 18:41:49.656: INFO: stdout: "e2e-test-crd-publish-openapi-282-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov  2 18:41:49.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 apply -f -'
Nov  2 18:41:50.018: INFO: stderr: ""
Nov  2 18:41:50.018: INFO: stdout: "e2e-test-crd-publish-openapi-282-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  2 18:41:50.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 delete e2e-test-crd-publish-openapi-282-crds test-foo'
Nov  2 18:41:50.195: INFO: stderr: ""
Nov  2 18:41:50.195: INFO: stdout: "e2e-test-crd-publish-openapi-282-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov  2 18:41:50.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 create -f -'
Nov  2 18:41:50.477: INFO: rc: 1
Nov  2 18:41:50.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 apply -f -'
Nov  2 18:41:50.855: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov  2 18:41:50.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 create -f -'
Nov  2 18:41:51.088: INFO: rc: 1
Nov  2 18:41:51.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-2714 apply -f -'
Nov  2 18:41:51.386: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov  2 18:41:51.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-282-crds'
Nov  2 18:41:51.606: INFO: stderr: ""
Nov  2 18:41:51.606: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-282-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov  2 18:41:51.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-282-crds.metadata'
Nov  2 18:41:51.901: INFO: stderr: ""
Nov  2 18:41:51.901: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-282-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov  2 18:41:51.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-282-crds.spec'
Nov  2 18:41:52.199: INFO: stderr: ""
Nov  2 18:41:52.199: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-282-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov  2 18:41:52.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-282-crds.spec.bars'
Nov  2 18:41:52.526: INFO: stderr: ""
Nov  2 18:41:52.526: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-282-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov  2 18:41:52.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-282-crds.spec.bars2'
Nov  2 18:41:52.818: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:41:56.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2714" for this suite.

• [SLOW TEST:11.649 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":280,"completed":137,"skipped":2263,"failed":0}
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:41:56.630: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4034
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:41:56.936: INFO: Create a RollingUpdate DaemonSet
Nov  2 18:41:56.951: INFO: Check that daemon pods launch on every node of the cluster
Nov  2 18:41:56.969: INFO: Number of nodes with available pods: 0
Nov  2 18:41:56.969: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:41:57.999: INFO: Number of nodes with available pods: 0
Nov  2 18:41:57.999: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:41:58.988: INFO: Number of nodes with available pods: 0
Nov  2 18:41:58.988: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:41:59.987: INFO: Number of nodes with available pods: 3
Nov  2 18:41:59.987: INFO: Number of running nodes: 3, number of available pods: 3
Nov  2 18:41:59.987: INFO: Update the DaemonSet to trigger a rollout
Nov  2 18:42:00.016: INFO: Updating DaemonSet daemon-set
Nov  2 18:42:15.055: INFO: Roll back the DaemonSet before rollout is complete
Nov  2 18:42:15.081: INFO: Updating DaemonSet daemon-set
Nov  2 18:42:15.081: INFO: Make sure DaemonSet rollback is complete
Nov  2 18:42:15.093: INFO: Wrong image for pod: daemon-set-tvq8n. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  2 18:42:15.093: INFO: Pod daemon-set-tvq8n is not available
Nov  2 18:42:16.114: INFO: Wrong image for pod: daemon-set-tvq8n. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  2 18:42:16.114: INFO: Pod daemon-set-tvq8n is not available
Nov  2 18:42:17.113: INFO: Pod daemon-set-8pbth is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4034, will wait for the garbage collector to delete the pods
Nov  2 18:42:17.217: INFO: Deleting DaemonSet.extensions daemon-set took: 19.887216ms
Nov  2 18:42:17.818: INFO: Terminating DaemonSet.extensions daemon-set pods took: 601.371816ms
Nov  2 18:42:30.726: INFO: Number of nodes with available pods: 0
Nov  2 18:42:30.726: INFO: Number of running nodes: 0, number of available pods: 0
Nov  2 18:42:30.733: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4034/daemonsets","resourceVersion":"160426"},"items":null}

Nov  2 18:42:30.743: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4034/pods","resourceVersion":"160426"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:42:30.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4034" for this suite.

• [SLOW TEST:34.187 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":280,"completed":138,"skipped":2267,"failed":0}
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:42:30.816: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1681
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 18:42:31.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2739'
Nov  2 18:42:31.185: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  2 18:42:31.185: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
Nov  2 18:42:31.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete jobs e2e-test-httpd-job --namespace=kubectl-2739'
Nov  2 18:42:31.358: INFO: stderr: ""
Nov  2 18:42:31.358: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:42:31.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2739" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run job should create a job from an image when restart is OnFailure  [Conformance]","total":280,"completed":139,"skipped":2267,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:42:31.386: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:42:31.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-9443'
Nov  2 18:42:31.934: INFO: stderr: ""
Nov  2 18:42:31.934: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Nov  2 18:42:31.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-9443'
Nov  2 18:42:32.274: INFO: stderr: ""
Nov  2 18:42:32.274: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov  2 18:42:33.286: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:42:33.286: INFO: Found 0 / 1
Nov  2 18:42:34.286: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:42:34.286: INFO: Found 1 / 1
Nov  2 18:42:34.286: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  2 18:42:34.305: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 18:42:34.305: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  2 18:42:34.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 describe pod agnhost-master-h99kx --namespace=kubectl-9443'
Nov  2 18:42:34.433: INFO: stderr: ""
Nov  2 18:42:34.433: INFO: stdout: "Name:         agnhost-master-h99kx\nNamespace:    kubectl-9443\nPriority:     0\nNode:         awesome-shannon-698f584c96-dc8qz/192.168.1.11\nStart Time:   Mon, 02 Nov 2020 18:42:31 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 172.25.2.56/32\nStatus:       Running\nIP:           172.25.2.56\nIPs:\n  IP:           172.25.2.56\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://98b42fb28875ca6a22163f5529401f2c9865f11b558156c0bd355641bb51d672\n    Image:          gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 02 Nov 2020 18:42:33 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7tk5d (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7tk5d:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7tk5d\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                       Message\n  ----    ------     ----       ----                                       -------\n  Normal  Scheduled  <unknown>  default-scheduler                          Successfully assigned kubectl-9443/agnhost-master-h99kx to awesome-shannon-698f584c96-dc8qz\n  Normal  Pulled     1s         kubelet, awesome-shannon-698f584c96-dc8qz  Container image \"gcr.io/kubernetes-e2e-test-images/agnhost:2.8\" already present on machine\n  Normal  Created    1s         kubelet, awesome-shannon-698f584c96-dc8qz  Created container agnhost-master\n  Normal  Started    1s         kubelet, awesome-shannon-698f584c96-dc8qz  Started container agnhost-master\n"
Nov  2 18:42:34.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 describe rc agnhost-master --namespace=kubectl-9443'
Nov  2 18:42:34.590: INFO: stderr: ""
Nov  2 18:42:34.590: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-9443\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-master-h99kx\n"
Nov  2 18:42:34.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 describe service agnhost-master --namespace=kubectl-9443'
Nov  2 18:42:34.719: INFO: stderr: ""
Nov  2 18:42:34.719: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-9443\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.240.17.227\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.25.2.56:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  2 18:42:34.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 describe node awesome-shannon-698f584c96-brzmg'
Nov  2 18:42:34.894: INFO: stderr: ""
Nov  2 18:42:34.894: INFO: stdout: "Name:               awesome-shannon-698f584c96-brzmg\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=090bcc91-6207-465d-aff0-bfcc10a9e063\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/zone=ix2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=awesome-shannon-698f584c96-brzmg\n                    kubernetes.io/os=linux\n                    machine-controller/owned-by=4b9e1ddc-3f0e-418f-9410-0e6c80c11bdd\n                    node.kubernetes.io/instance-type=090bcc91-6207-465d-aff0-bfcc10a9e063\n                    system/cluster=zqfkd4tzr7\n                    system/project=2dwzzgghlv\n                    topology.cinder.csi.openstack.org/zone=ix2\n                    topology.kubernetes.io/zone=ix2\n                    x-kubernetes.io/distribution=ubuntu\nAnnotations:        cluster.k8s.io/machine: kube-system/awesome-shannon-698f584c96-brzmg\n                    csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"6c39d193-376d-4d50-8819-fceb9fa41531\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"2e:e3:00:08:5c:9e\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.1.8\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.25.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 02 Nov 2020 09:26:28 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  awesome-shannon-698f584c96-brzmg\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 02 Nov 2020 18:42:25 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 02 Nov 2020 18:38:31 +0000   Mon, 02 Nov 2020 09:26:29 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 02 Nov 2020 18:38:31 +0000   Mon, 02 Nov 2020 09:26:29 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 02 Nov 2020 18:38:31 +0000   Mon, 02 Nov 2020 09:26:29 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 02 Nov 2020 18:38:31 +0000   Mon, 02 Nov 2020 09:26:48 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.1.8\n  Hostname:    awesome-shannon-698f584c96-brzmg\nCapacity:\n  cpu:                4\n  ephemeral-storage:  20145724Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8167556Ki\n  pods:               110\nAllocatable:\n  cpu:                3800m\n  ephemeral-storage:  16418815560\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7860356Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 6c39d193376d4d508819fceb9fa41531\n  System UUID:                6C39D193-376D-4D50-8819-FCEB9FA41531\n  Boot ID:                    03840c94-800f-45f5-a264-8459ca739be5\n  Kernel Version:             4.15.0-122-generic\n  OS Image:                   Ubuntu 18.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.9.2\n  Kubelet Version:            v1.17.9\n  Kube-Proxy Version:         v1.17.9\nPodCIDR:                      172.25.0.0/24\nPodCIDRs:                     172.25.0.0/24\nProviderID:                   openstack:///6c39d193-376d-4d50-8819-fceb9fa41531\nNon-terminated Pods:          (13 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-c64t7                                                250m (6%)     0 (0%)      0 (0%)           0 (0%)         9h\n  kube-system                 coredns-57f944bd9f-492kl                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     9h\n  kube-system                 coredns-57f944bd9f-h8sb4                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     9h\n  kube-system                 csi-cinder-controllerplugin-0                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         9h\n  kube-system                 csi-cinder-nodeplugin-ubuntu-xqnfj                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         9h\n  kube-system                 kube-proxy-gk2s6                                           75m (1%)      250m (6%)   50Mi (0%)        250Mi (3%)     9h\n  kube-system                 logrotate-vdk6h                                            75m (1%)      250m (6%)   50Mi (0%)        250Mi (3%)     9h\n  kube-system                 node-local-dns-nwqv9                                       25m (0%)      0 (0%)      5Mi (0%)         0 (0%)         9h\n  kube-system                 openvpn-client-84ccd8596d-qps5z                            30m (0%)      200m (5%)   30Mi (0%)        82Mi (1%)      9h\n  kube-system                 user-ssh-keys-agent-wklnz                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         9h\n  kubernetes-dashboard        dashboard-metrics-scraper-59bfc65dc9-mx5wv                 50m (1%)      100m (2%)   32Mi (0%)        64Mi (0%)      9h\n  kubernetes-dashboard        dashboard-metrics-scraper-59bfc65dc9-vv6zf                 50m (1%)      100m (2%)   32Mi (0%)        64Mi (0%)      9h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                755m (19%)  900m (23%)\n  memory             339Mi (4%)  1050Mi (13%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Nov  2 18:42:34.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 describe namespace kubectl-9443'
Nov  2 18:42:35.018: INFO: stderr: ""
Nov  2 18:42:35.018: INFO: stdout: "Name:         kubectl-9443\nLabels:       e2e-framework=kubectl\n              e2e-run=820bafbe-c8db-4d6e-9e86-7a891d62c4ed\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:42:35.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9443" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":280,"completed":140,"skipped":2285,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:42:35.055: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov  2 18:42:35.312: INFO: Waiting up to 5m0s for pod "downward-api-4563f96e-6e15-437f-8d04-98b423517df7" in namespace "downward-api-7716" to be "success or failure"
Nov  2 18:42:35.322: INFO: Pod "downward-api-4563f96e-6e15-437f-8d04-98b423517df7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.154015ms
Nov  2 18:42:37.329: INFO: Pod "downward-api-4563f96e-6e15-437f-8d04-98b423517df7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016740192s
Nov  2 18:42:39.338: INFO: Pod "downward-api-4563f96e-6e15-437f-8d04-98b423517df7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025096799s
STEP: Saw pod success
Nov  2 18:42:39.338: INFO: Pod "downward-api-4563f96e-6e15-437f-8d04-98b423517df7" satisfied condition "success or failure"
Nov  2 18:42:39.351: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downward-api-4563f96e-6e15-437f-8d04-98b423517df7 container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:42:39.420: INFO: Waiting for pod downward-api-4563f96e-6e15-437f-8d04-98b423517df7 to disappear
Nov  2 18:42:39.429: INFO: Pod downward-api-4563f96e-6e15-437f-8d04-98b423517df7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:42:39.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7716" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":280,"completed":141,"skipped":2297,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:42:39.456: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-8598
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Nov  2 18:42:39.684: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the sample API server.
Nov  2 18:42:40.109: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov  2 18:42:42.226: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:42:44.242: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:42:46.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:42:48.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:42:50.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939360, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:42:53.205: INFO: Waited 935.041875ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:42:54.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8598" for this suite.

• [SLOW TEST:14.973 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]","total":280,"completed":142,"skipped":2303,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:42:54.430: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:43:11.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1541" for this suite.

• [SLOW TEST:17.369 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":280,"completed":143,"skipped":2305,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:43:11.800: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2160
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:43:12.737: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:43:14.761: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939392, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939392, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939392, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939392, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:43:17.814: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:43:18.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2160" for this suite.
STEP: Destroying namespace "webhook-2160-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.401 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":280,"completed":144,"skipped":2313,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:43:18.203: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:43:18.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8110" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":280,"completed":145,"skipped":2324,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:43:18.581: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9549
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  2 18:43:18.879: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9549 /api/v1/namespaces/watch-9549/configmaps/e2e-watch-test-watch-closed f57feb80-e7c4-4dd7-93cf-ecec0d62a0b5 160979 0 2020-11-02 18:43:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  2 18:43:18.879: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9549 /api/v1/namespaces/watch-9549/configmaps/e2e-watch-test-watch-closed f57feb80-e7c4-4dd7-93cf-ecec0d62a0b5 160980 0 2020-11-02 18:43:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  2 18:43:18.928: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9549 /api/v1/namespaces/watch-9549/configmaps/e2e-watch-test-watch-closed f57feb80-e7c4-4dd7-93cf-ecec0d62a0b5 160981 0 2020-11-02 18:43:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  2 18:43:18.928: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9549 /api/v1/namespaces/watch-9549/configmaps/e2e-watch-test-watch-closed f57feb80-e7c4-4dd7-93cf-ecec0d62a0b5 160982 0 2020-11-02 18:43:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:43:18.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9549" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":280,"completed":146,"skipped":2325,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:43:18.955: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:43:23.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-158" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":280,"completed":147,"skipped":2329,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:43:23.444: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2613
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:43:23.690: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:43:29.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2613" for this suite.

• [SLOW TEST:5.717 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:47
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":280,"completed":148,"skipped":2334,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:43:29.162: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8773
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-8773
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Nov  2 18:43:29.527: INFO: Found 0 stateful pods, waiting for 3
Nov  2 18:43:39.537: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:43:39.537: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:43:39.537: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  2 18:43:39.596: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  2 18:43:49.691: INFO: Updating stateful set ss2
Nov  2 18:43:49.728: INFO: Waiting for Pod statefulset-8773/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov  2 18:43:59.866: INFO: Found 2 stateful pods, waiting for 3
Nov  2 18:44:09.876: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:44:09.876: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 18:44:09.876: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  2 18:44:09.933: INFO: Updating stateful set ss2
Nov  2 18:44:09.953: INFO: Waiting for Pod statefulset-8773/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  2 18:44:19.999: INFO: Updating stateful set ss2
Nov  2 18:44:20.022: INFO: Waiting for StatefulSet statefulset-8773/ss2 to complete update
Nov  2 18:44:20.022: INFO: Waiting for Pod statefulset-8773/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  2 18:44:30.046: INFO: Waiting for StatefulSet statefulset-8773/ss2 to complete update
Nov  2 18:44:30.046: INFO: Waiting for Pod statefulset-8773/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov  2 18:44:40.041: INFO: Deleting all statefulset in ns statefulset-8773
Nov  2 18:44:40.047: INFO: Scaling statefulset ss2 to 0
Nov  2 18:45:00.084: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:45:00.093: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:45:00.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8773" for this suite.

• [SLOW TEST:90.997 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":280,"completed":149,"skipped":2377,"failed":0}
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:45:00.160: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's command
Nov  2 18:45:00.396: INFO: Waiting up to 5m0s for pod "var-expansion-622ce41a-eace-4202-b26b-fcf93a481469" in namespace "var-expansion-8392" to be "success or failure"
Nov  2 18:45:00.406: INFO: Pod "var-expansion-622ce41a-eace-4202-b26b-fcf93a481469": Phase="Pending", Reason="", readiness=false. Elapsed: 9.398094ms
Nov  2 18:45:02.414: INFO: Pod "var-expansion-622ce41a-eace-4202-b26b-fcf93a481469": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017480242s
Nov  2 18:45:04.433: INFO: Pod "var-expansion-622ce41a-eace-4202-b26b-fcf93a481469": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036957702s
STEP: Saw pod success
Nov  2 18:45:04.433: INFO: Pod "var-expansion-622ce41a-eace-4202-b26b-fcf93a481469" satisfied condition "success or failure"
Nov  2 18:45:04.450: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod var-expansion-622ce41a-eace-4202-b26b-fcf93a481469 container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:45:04.650: INFO: Waiting for pod var-expansion-622ce41a-eace-4202-b26b-fcf93a481469 to disappear
Nov  2 18:45:04.660: INFO: Pod var-expansion-622ce41a-eace-4202-b26b-fcf93a481469 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:45:04.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8392" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":280,"completed":150,"skipped":2377,"failed":0}
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:45:04.688: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-3693
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  2 18:45:04.914: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  2 18:45:31.145: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.0.24 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3693 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:45:31.145: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:45:32.678: INFO: Found all expected endpoints: [netserver-0]
Nov  2 18:45:32.686: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.2.59 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3693 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:45:32.686: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:45:34.258: INFO: Found all expected endpoints: [netserver-1]
Nov  2 18:45:34.267: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.1.134 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3693 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:45:34.267: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:45:35.805: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:45:35.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3693" for this suite.

• [SLOW TEST:31.143 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":151,"skipped":2378,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:45:35.832: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-85vm
STEP: Creating a pod to test atomic-volume-subpath
Nov  2 18:45:36.082: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-85vm" in namespace "subpath-5599" to be "success or failure"
Nov  2 18:45:36.093: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Pending", Reason="", readiness=false. Elapsed: 11.173278ms
Nov  2 18:45:38.102: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019468724s
Nov  2 18:45:40.110: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 4.027767024s
Nov  2 18:45:42.118: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 6.035317736s
Nov  2 18:45:44.131: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 8.04836157s
Nov  2 18:45:46.142: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 10.059711801s
Nov  2 18:45:48.152: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 12.070054329s
Nov  2 18:45:50.163: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 14.080880254s
Nov  2 18:45:52.171: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 16.088688804s
Nov  2 18:45:54.179: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 18.096610402s
Nov  2 18:45:56.191: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 20.108883926s
Nov  2 18:45:58.202: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Running", Reason="", readiness=true. Elapsed: 22.119673777s
Nov  2 18:46:00.211: INFO: Pod "pod-subpath-test-configmap-85vm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.129060388s
STEP: Saw pod success
Nov  2 18:46:00.211: INFO: Pod "pod-subpath-test-configmap-85vm" satisfied condition "success or failure"
Nov  2 18:46:00.223: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-subpath-test-configmap-85vm container test-container-subpath-configmap-85vm: <nil>
STEP: delete the pod
Nov  2 18:46:00.422: INFO: Waiting for pod pod-subpath-test-configmap-85vm to disappear
Nov  2 18:46:00.432: INFO: Pod pod-subpath-test-configmap-85vm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-85vm
Nov  2 18:46:00.432: INFO: Deleting pod "pod-subpath-test-configmap-85vm" in namespace "subpath-5599"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:46:00.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5599" for this suite.

• [SLOW TEST:24.651 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":280,"completed":152,"skipped":2392,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:46:00.483: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4872
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  2 18:46:03.778: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:46:03.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4872" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":153,"skipped":2407,"failed":0}
SSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:46:03.842: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:46:04.097: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-0f97cb84-706c-4de5-a173-d7be496166c7" in namespace "security-context-test-2682" to be "success or failure"
Nov  2 18:46:04.109: INFO: Pod "busybox-readonly-false-0f97cb84-706c-4de5-a173-d7be496166c7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.161985ms
Nov  2 18:46:06.116: INFO: Pod "busybox-readonly-false-0f97cb84-706c-4de5-a173-d7be496166c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01949869s
Nov  2 18:46:08.125: INFO: Pod "busybox-readonly-false-0f97cb84-706c-4de5-a173-d7be496166c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028535356s
Nov  2 18:46:08.125: INFO: Pod "busybox-readonly-false-0f97cb84-706c-4de5-a173-d7be496166c7" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:46:08.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2682" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":280,"completed":154,"skipped":2410,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:46:08.163: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:46:08.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125" in namespace "projected-7231" to be "success or failure"
Nov  2 18:46:08.423: INFO: Pod "downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125": Phase="Pending", Reason="", readiness=false. Elapsed: 12.34949ms
Nov  2 18:46:10.430: INFO: Pod "downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020235173s
Nov  2 18:46:12.440: INFO: Pod "downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029884977s
STEP: Saw pod success
Nov  2 18:46:12.440: INFO: Pod "downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125" satisfied condition "success or failure"
Nov  2 18:46:12.448: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125 container client-container: <nil>
STEP: delete the pod
Nov  2 18:46:12.516: INFO: Waiting for pod downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125 to disappear
Nov  2 18:46:12.523: INFO: Pod downwardapi-volume-eaff61b9-7db2-4436-aff5-a33e4fe3f125 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:46:12.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7231" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":155,"skipped":2412,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:46:12.562: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Nov  2 18:46:12.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-9254'
Nov  2 18:46:13.121: INFO: stderr: ""
Nov  2 18:46:13.121: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  2 18:46:13.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:13.313: INFO: stderr: ""
Nov  2 18:46:13.313: INFO: stdout: "update-demo-nautilus-wb2fd update-demo-nautilus-z6d29 "
Nov  2 18:46:13.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-wb2fd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:13.416: INFO: stderr: ""
Nov  2 18:46:13.416: INFO: stdout: ""
Nov  2 18:46:13.416: INFO: update-demo-nautilus-wb2fd is created but not running
Nov  2 18:46:18.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:18.517: INFO: stderr: ""
Nov  2 18:46:18.517: INFO: stdout: "update-demo-nautilus-wb2fd update-demo-nautilus-z6d29 "
Nov  2 18:46:18.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-wb2fd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:18.632: INFO: stderr: ""
Nov  2 18:46:18.632: INFO: stdout: "true"
Nov  2 18:46:18.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-wb2fd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:18.727: INFO: stderr: ""
Nov  2 18:46:18.727: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:46:18.727: INFO: validating pod update-demo-nautilus-wb2fd
Nov  2 18:46:18.837: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:46:18.837: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:46:18.837: INFO: update-demo-nautilus-wb2fd is verified up and running
Nov  2 18:46:18.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-z6d29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:18.960: INFO: stderr: ""
Nov  2 18:46:18.960: INFO: stdout: "true"
Nov  2 18:46:18.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-z6d29 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:19.057: INFO: stderr: ""
Nov  2 18:46:19.057: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:46:19.057: INFO: validating pod update-demo-nautilus-z6d29
Nov  2 18:46:19.164: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:46:19.164: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:46:19.164: INFO: update-demo-nautilus-z6d29 is verified up and running
STEP: scaling down the replication controller
Nov  2 18:46:19.166: INFO: scanned /root for discovery docs: <nil>
Nov  2 18:46:19.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9254'
Nov  2 18:46:20.338: INFO: stderr: ""
Nov  2 18:46:20.338: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  2 18:46:20.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:20.452: INFO: stderr: ""
Nov  2 18:46:20.452: INFO: stdout: "update-demo-nautilus-wb2fd update-demo-nautilus-z6d29 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  2 18:46:25.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:25.555: INFO: stderr: ""
Nov  2 18:46:25.555: INFO: stdout: "update-demo-nautilus-wb2fd update-demo-nautilus-z6d29 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  2 18:46:30.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:30.665: INFO: stderr: ""
Nov  2 18:46:30.665: INFO: stdout: "update-demo-nautilus-wb2fd update-demo-nautilus-z6d29 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  2 18:46:35.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:35.773: INFO: stderr: ""
Nov  2 18:46:35.777: INFO: stdout: "update-demo-nautilus-z6d29 "
Nov  2 18:46:35.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-z6d29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:35.871: INFO: stderr: ""
Nov  2 18:46:35.871: INFO: stdout: "true"
Nov  2 18:46:35.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-z6d29 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:35.970: INFO: stderr: ""
Nov  2 18:46:35.970: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:46:35.970: INFO: validating pod update-demo-nautilus-z6d29
Nov  2 18:46:35.996: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:46:35.996: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:46:35.996: INFO: update-demo-nautilus-z6d29 is verified up and running
STEP: scaling up the replication controller
Nov  2 18:46:35.998: INFO: scanned /root for discovery docs: <nil>
Nov  2 18:46:35.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9254'
Nov  2 18:46:37.156: INFO: stderr: ""
Nov  2 18:46:37.156: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  2 18:46:37.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:37.255: INFO: stderr: ""
Nov  2 18:46:37.255: INFO: stdout: "update-demo-nautilus-xf7md update-demo-nautilus-z6d29 "
Nov  2 18:46:37.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-xf7md -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:37.355: INFO: stderr: ""
Nov  2 18:46:37.355: INFO: stdout: ""
Nov  2 18:46:37.355: INFO: update-demo-nautilus-xf7md is created but not running
Nov  2 18:46:42.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9254'
Nov  2 18:46:42.457: INFO: stderr: ""
Nov  2 18:46:42.457: INFO: stdout: "update-demo-nautilus-xf7md update-demo-nautilus-z6d29 "
Nov  2 18:46:42.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-xf7md -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:42.554: INFO: stderr: ""
Nov  2 18:46:42.554: INFO: stdout: "true"
Nov  2 18:46:42.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-xf7md -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:42.662: INFO: stderr: ""
Nov  2 18:46:42.662: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:46:42.662: INFO: validating pod update-demo-nautilus-xf7md
Nov  2 18:46:42.765: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:46:42.765: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:46:42.765: INFO: update-demo-nautilus-xf7md is verified up and running
Nov  2 18:46:42.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-z6d29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:42.911: INFO: stderr: ""
Nov  2 18:46:42.911: INFO: stdout: "true"
Nov  2 18:46:42.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods update-demo-nautilus-z6d29 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9254'
Nov  2 18:46:43.029: INFO: stderr: ""
Nov  2 18:46:43.029: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  2 18:46:43.029: INFO: validating pod update-demo-nautilus-z6d29
Nov  2 18:46:43.045: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  2 18:46:43.045: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  2 18:46:43.045: INFO: update-demo-nautilus-z6d29 is verified up and running
STEP: using delete to clean up resources
Nov  2 18:46:43.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete --grace-period=0 --force -f - --namespace=kubectl-9254'
Nov  2 18:46:43.211: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  2 18:46:43.211: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  2 18:46:43.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9254'
Nov  2 18:46:43.352: INFO: stderr: "No resources found in kubectl-9254 namespace.\n"
Nov  2 18:46:43.352: INFO: stdout: ""
Nov  2 18:46:43.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -l name=update-demo --namespace=kubectl-9254 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  2 18:46:43.457: INFO: stderr: ""
Nov  2 18:46:43.457: INFO: stdout: "update-demo-nautilus-xf7md\nupdate-demo-nautilus-z6d29\n"
Nov  2 18:46:43.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9254'
Nov  2 18:46:44.094: INFO: stderr: "No resources found in kubectl-9254 namespace.\n"
Nov  2 18:46:44.094: INFO: stdout: ""
Nov  2 18:46:44.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pods -l name=update-demo --namespace=kubectl-9254 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  2 18:46:44.216: INFO: stderr: ""
Nov  2 18:46:44.216: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:46:44.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9254" for this suite.

• [SLOW TEST:31.696 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":280,"completed":156,"skipped":2414,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:46:44.258: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7000 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7000;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7000 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7000;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7000.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7000.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7000.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7000.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7000.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7000.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7000.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7000.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7000.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 115.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.115_udp@PTR;check="$$(dig +tcp +noall +answer +search 115.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.115_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7000 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7000;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7000 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7000;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7000.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7000.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7000.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7000.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7000.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7000.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7000.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7000.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7000.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7000.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 115.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.115_udp@PTR;check="$$(dig +tcp +noall +answer +search 115.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.115_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 18:46:48.714: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:48.762: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:48.886: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7000 from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:48.987: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.066: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.095: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.703: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.721: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.752: INFO: Unable to read jessie_udp@dns-test-service.dns-7000 from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.769: INFO: Unable to read jessie_tcp@dns-test-service.dns-7000 from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.799: INFO: Unable to read jessie_udp@dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.825: INFO: Unable to read jessie_tcp@dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.841: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:49.868: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7000.svc from pod dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192: the server could not find the requested resource (get pods dns-test-0536ed06-3706-42a0-a329-4dcfd4374192)
Nov  2 18:46:50.367: INFO: Lookups using dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.dns-7000 wheezy_tcp@dns-test-service.dns-7000.svc wheezy_udp@_http._tcp.dns-test-service.dns-7000.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7000.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7000 jessie_tcp@dns-test-service.dns-7000 jessie_udp@dns-test-service.dns-7000.svc jessie_tcp@dns-test-service.dns-7000.svc jessie_udp@_http._tcp.dns-test-service.dns-7000.svc jessie_tcp@_http._tcp.dns-test-service.dns-7000.svc]

Nov  2 18:46:57.831: INFO: DNS probes using dns-7000/dns-test-0536ed06-3706-42a0-a329-4dcfd4374192 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:46:58.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7000" for this suite.

• [SLOW TEST:13.818 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":280,"completed":157,"skipped":2437,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:46:58.077: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test env composition
Nov  2 18:46:58.309: INFO: Waiting up to 5m0s for pod "var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8" in namespace "var-expansion-2158" to be "success or failure"
Nov  2 18:46:58.323: INFO: Pod "var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.828648ms
Nov  2 18:47:00.331: INFO: Pod "var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021776971s
Nov  2 18:47:02.350: INFO: Pod "var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040437921s
STEP: Saw pod success
Nov  2 18:47:02.350: INFO: Pod "var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8" satisfied condition "success or failure"
Nov  2 18:47:02.358: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8 container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:47:02.412: INFO: Waiting for pod var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8 to disappear
Nov  2 18:47:02.422: INFO: Pod var-expansion-f57f5272-9195-4096-9e1f-3fff21159ba8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:47:02.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2158" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":280,"completed":158,"skipped":2456,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:47:02.487: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  2 18:47:02.746: INFO: Waiting up to 5m0s for pod "pod-b149028a-0bd4-42db-bc35-a18c0a790d83" in namespace "emptydir-1756" to be "success or failure"
Nov  2 18:47:02.765: INFO: Pod "pod-b149028a-0bd4-42db-bc35-a18c0a790d83": Phase="Pending", Reason="", readiness=false. Elapsed: 19.329837ms
Nov  2 18:47:04.774: INFO: Pod "pod-b149028a-0bd4-42db-bc35-a18c0a790d83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028630646s
Nov  2 18:47:06.782: INFO: Pod "pod-b149028a-0bd4-42db-bc35-a18c0a790d83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036528609s
STEP: Saw pod success
Nov  2 18:47:06.782: INFO: Pod "pod-b149028a-0bd4-42db-bc35-a18c0a790d83" satisfied condition "success or failure"
Nov  2 18:47:06.791: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-b149028a-0bd4-42db-bc35-a18c0a790d83 container test-container: <nil>
STEP: delete the pod
Nov  2 18:47:06.856: INFO: Waiting for pod pod-b149028a-0bd4-42db-bc35-a18c0a790d83 to disappear
Nov  2 18:47:06.865: INFO: Pod pod-b149028a-0bd4-42db-bc35-a18c0a790d83 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:47:06.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1756" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":159,"skipped":2512,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:47:06.900: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9058.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9058.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9058.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9058.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 18:47:11.976: INFO: DNS probes using dns-9058/dns-test-890b5fdc-3f54-4eaf-b1ab-841d60295d87 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:47:12.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9058" for this suite.

• [SLOW TEST:5.256 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":280,"completed":160,"skipped":2536,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:47:12.160: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-projected-4lqq
STEP: Creating a pod to test atomic-volume-subpath
Nov  2 18:47:12.503: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4lqq" in namespace "subpath-7625" to be "success or failure"
Nov  2 18:47:12.517: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Pending", Reason="", readiness=false. Elapsed: 13.661356ms
Nov  2 18:47:14.527: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02343295s
Nov  2 18:47:16.547: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.044318998s
Nov  2 18:47:18.556: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 6.052502988s
Nov  2 18:47:20.567: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 8.063714715s
Nov  2 18:47:22.576: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 10.07291402s
Nov  2 18:47:24.585: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 12.081805906s
Nov  2 18:47:26.593: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 14.089472263s
Nov  2 18:47:28.601: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 16.098009658s
Nov  2 18:47:30.613: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 18.110083002s
Nov  2 18:47:32.622: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 20.118506678s
Nov  2 18:47:34.631: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Running", Reason="", readiness=true. Elapsed: 22.12753544s
Nov  2 18:47:36.653: INFO: Pod "pod-subpath-test-projected-4lqq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.150017834s
STEP: Saw pod success
Nov  2 18:47:36.653: INFO: Pod "pod-subpath-test-projected-4lqq" satisfied condition "success or failure"
Nov  2 18:47:36.662: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-subpath-test-projected-4lqq container test-container-subpath-projected-4lqq: <nil>
STEP: delete the pod
Nov  2 18:47:36.717: INFO: Waiting for pod pod-subpath-test-projected-4lqq to disappear
Nov  2 18:47:36.724: INFO: Pod pod-subpath-test-projected-4lqq no longer exists
STEP: Deleting pod pod-subpath-test-projected-4lqq
Nov  2 18:47:36.724: INFO: Deleting pod "pod-subpath-test-projected-4lqq" in namespace "subpath-7625"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:47:36.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7625" for this suite.

• [SLOW TEST:24.604 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":280,"completed":161,"skipped":2596,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:47:36.766: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3944
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov  2 18:47:37.061: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  2 18:47:46.169: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:47:46.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3944" for this suite.

• [SLOW TEST:9.446 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":280,"completed":162,"skipped":2605,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:47:46.212: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:47:46.462: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  2 18:47:51.476: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  2 18:47:51.476: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  2 18:47:53.489: INFO: Creating deployment "test-rollover-deployment"
Nov  2 18:47:53.507: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  2 18:47:55.526: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  2 18:47:55.542: INFO: Ensure that both replica sets have 1 created replica
Nov  2 18:47:55.570: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  2 18:47:55.590: INFO: Updating deployment test-rollover-deployment
Nov  2 18:47:55.590: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  2 18:47:57.613: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  2 18:47:57.632: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  2 18:47:57.651: INFO: all replica sets need to contain the pod-template-hash label
Nov  2 18:47:57.651: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939675, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:47:59.676: INFO: all replica sets need to contain the pod-template-hash label
Nov  2 18:47:59.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939677, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:48:01.667: INFO: all replica sets need to contain the pod-template-hash label
Nov  2 18:48:01.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939677, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:48:03.668: INFO: all replica sets need to contain the pod-template-hash label
Nov  2 18:48:03.668: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939677, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:48:05.670: INFO: all replica sets need to contain the pod-template-hash label
Nov  2 18:48:05.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939677, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:48:07.670: INFO: all replica sets need to contain the pod-template-hash label
Nov  2 18:48:07.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939677, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939673, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  2 18:48:09.677: INFO: 
Nov  2 18:48:09.677: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov  2 18:48:09.700: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4609 /apis/apps/v1/namespaces/deployment-4609/deployments/test-rollover-deployment 1daca3fb-c054-4456-98fe-5a8653a137d6 163438 2 2020-11-02 18:47:53 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004016b18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-11-02 18:47:53 +0000 UTC,LastTransitionTime:2020-11-02 18:47:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-574d6dfbff" has successfully progressed.,LastUpdateTime:2020-11-02 18:48:08 +0000 UTC,LastTransitionTime:2020-11-02 18:47:53 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  2 18:48:09.714: INFO: New ReplicaSet "test-rollover-deployment-574d6dfbff" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-574d6dfbff  deployment-4609 /apis/apps/v1/namespaces/deployment-4609/replicasets/test-rollover-deployment-574d6dfbff f4f83631-5e6e-4b3b-9c82-abea60470b75 163427 2 2020-11-02 18:47:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 1daca3fb-c054-4456-98fe-5a8653a137d6 0xc004016fd7 0xc004016fd8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 574d6dfbff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004017048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:48:09.714: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  2 18:48:09.714: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4609 /apis/apps/v1/namespaces/deployment-4609/replicasets/test-rollover-controller 59744339-3bd8-4eb7-9326-1c808ceb838b 163436 2 2020-11-02 18:47:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 1daca3fb-c054-4456-98fe-5a8653a137d6 0xc004016f07 0xc004016f08}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004016f68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:48:09.714: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4609 /apis/apps/v1/namespaces/deployment-4609/replicasets/test-rollover-deployment-f6c94f66c b30f4e98-c69c-4aaf-9b67-fc95f63adf1b 163357 2 2020-11-02 18:47:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 1daca3fb-c054-4456-98fe-5a8653a137d6 0xc0040170b0 0xc0040170b1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004017128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:48:09.725: INFO: Pod "test-rollover-deployment-574d6dfbff-b4vvl" is available:
&Pod{ObjectMeta:{test-rollover-deployment-574d6dfbff-b4vvl test-rollover-deployment-574d6dfbff- deployment-4609 /api/v1/namespaces/deployment-4609/pods/test-rollover-deployment-574d6dfbff-b4vvl c70c2053-392e-450f-b121-94665ef5ea38 163378 0 2020-11-02 18:47:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[cni.projectcalico.org/podIP:172.25.1.148/32] [{apps/v1 ReplicaSet test-rollover-deployment-574d6dfbff f4f83631-5e6e-4b3b-9c82-abea60470b75 0xc0040176b7 0xc0040176b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-s6mrz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-s6mrz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-s6mrz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:47:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:47:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:47:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:47:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:172.25.1.148,StartTime:2020-11-02 18:47:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 18:47:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://26d5af8b09086a4523ec296b81f5b27685e3953438583262bc9cd4162627dd9a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:48:09.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4609" for this suite.

• [SLOW TEST:23.543 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":280,"completed":163,"skipped":2657,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:48:09.759: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-j7s5s in namespace proxy-7925
I1102 18:48:10.057272      24 runners.go:189] Created replication controller with name: proxy-service-j7s5s, namespace: proxy-7925, replica count: 1
I1102 18:48:11.107737      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1102 18:48:12.107911      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1102 18:48:13.108887      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:14.109099      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:15.109305      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:16.109582      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:17.109804      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:18.110051      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:19.110254      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:20.110460      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1102 18:48:21.110670      24 runners.go:189] proxy-service-j7s5s Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  2 18:48:21.126: INFO: setup took 11.121932634s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  2 18:48:21.160: INFO: (0) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 33.494188ms)
Nov  2 18:48:21.160: INFO: (0) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 33.564711ms)
Nov  2 18:48:21.160: INFO: (0) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 33.320842ms)
Nov  2 18:48:21.162: INFO: (0) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 34.866529ms)
Nov  2 18:48:21.162: INFO: (0) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 35.289916ms)
Nov  2 18:48:21.162: INFO: (0) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 35.256512ms)
Nov  2 18:48:21.164: INFO: (0) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 37.580811ms)
Nov  2 18:48:21.166: INFO: (0) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 39.76014ms)
Nov  2 18:48:21.168: INFO: (0) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 40.578918ms)
Nov  2 18:48:21.168: INFO: (0) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 40.778922ms)
Nov  2 18:48:21.172: INFO: (0) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 45.318829ms)
Nov  2 18:48:21.172: INFO: (0) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 44.843061ms)
Nov  2 18:48:21.172: INFO: (0) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 45.246138ms)
Nov  2 18:48:21.194: INFO: (0) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 67.261396ms)
Nov  2 18:48:21.194: INFO: (0) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 66.925809ms)
Nov  2 18:48:21.194: INFO: (0) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 67.595216ms)
Nov  2 18:48:21.210: INFO: (1) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 15.925541ms)
Nov  2 18:48:21.212: INFO: (1) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 16.925163ms)
Nov  2 18:48:21.212: INFO: (1) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 17.246733ms)
Nov  2 18:48:21.213: INFO: (1) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 18.723427ms)
Nov  2 18:48:21.214: INFO: (1) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 19.95318ms)
Nov  2 18:48:21.214: INFO: (1) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 20.06808ms)
Nov  2 18:48:21.216: INFO: (1) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 20.791769ms)
Nov  2 18:48:21.217: INFO: (1) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 21.556163ms)
Nov  2 18:48:21.217: INFO: (1) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 22.453566ms)
Nov  2 18:48:21.219: INFO: (1) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 24.158812ms)
Nov  2 18:48:21.220: INFO: (1) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 24.733144ms)
Nov  2 18:48:21.220: INFO: (1) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 24.679657ms)
Nov  2 18:48:21.224: INFO: (1) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 30.311848ms)
Nov  2 18:48:21.225: INFO: (1) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 30.820379ms)
Nov  2 18:48:21.225: INFO: (1) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 30.769361ms)
Nov  2 18:48:21.226: INFO: (1) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 30.829542ms)
Nov  2 18:48:21.244: INFO: (2) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 17.776548ms)
Nov  2 18:48:21.249: INFO: (2) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 22.585928ms)
Nov  2 18:48:21.249: INFO: (2) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 22.886676ms)
Nov  2 18:48:21.249: INFO: (2) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 22.95521ms)
Nov  2 18:48:21.249: INFO: (2) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 23.120639ms)
Nov  2 18:48:21.249: INFO: (2) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 23.130864ms)
Nov  2 18:48:21.249: INFO: (2) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 22.647488ms)
Nov  2 18:48:21.254: INFO: (2) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 27.737147ms)
Nov  2 18:48:21.254: INFO: (2) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 27.691782ms)
Nov  2 18:48:21.258: INFO: (2) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 31.27327ms)
Nov  2 18:48:21.261: INFO: (2) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 35.046098ms)
Nov  2 18:48:21.262: INFO: (2) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 35.737299ms)
Nov  2 18:48:21.286: INFO: (2) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 59.649643ms)
Nov  2 18:48:21.286: INFO: (2) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 59.774892ms)
Nov  2 18:48:21.286: INFO: (2) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 59.760497ms)
Nov  2 18:48:21.286: INFO: (2) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 59.781612ms)
Nov  2 18:48:21.303: INFO: (3) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 15.218111ms)
Nov  2 18:48:21.304: INFO: (3) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 16.491475ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 17.518265ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 17.653924ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 17.771428ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 18.315834ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 18.024802ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 17.394843ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 18.828499ms)
Nov  2 18:48:21.305: INFO: (3) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 18.156336ms)
Nov  2 18:48:21.310: INFO: (3) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 22.796059ms)
Nov  2 18:48:21.310: INFO: (3) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 23.061853ms)
Nov  2 18:48:21.387: INFO: (3) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 100.019829ms)
Nov  2 18:48:21.391: INFO: (3) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 104.819297ms)
Nov  2 18:48:21.392: INFO: (3) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 105.424161ms)
Nov  2 18:48:21.392: INFO: (3) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 104.543169ms)
Nov  2 18:48:21.410: INFO: (4) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 17.651332ms)
Nov  2 18:48:21.410: INFO: (4) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 17.59224ms)
Nov  2 18:48:21.410: INFO: (4) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 17.203648ms)
Nov  2 18:48:21.410: INFO: (4) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 17.854262ms)
Nov  2 18:48:21.410: INFO: (4) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 17.903098ms)
Nov  2 18:48:21.411: INFO: (4) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 18.961679ms)
Nov  2 18:48:21.411: INFO: (4) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 19.106634ms)
Nov  2 18:48:21.411: INFO: (4) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 18.798754ms)
Nov  2 18:48:21.411: INFO: (4) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 19.195714ms)
Nov  2 18:48:21.411: INFO: (4) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 19.038105ms)
Nov  2 18:48:21.411: INFO: (4) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 18.973324ms)
Nov  2 18:48:21.416: INFO: (4) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 23.499566ms)
Nov  2 18:48:21.416: INFO: (4) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 23.568385ms)
Nov  2 18:48:21.416: INFO: (4) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 23.05336ms)
Nov  2 18:48:21.416: INFO: (4) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 23.858529ms)
Nov  2 18:48:21.416: INFO: (4) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 23.707793ms)
Nov  2 18:48:21.432: INFO: (5) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 15.614717ms)
Nov  2 18:48:21.434: INFO: (5) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 17.133015ms)
Nov  2 18:48:21.434: INFO: (5) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 17.230148ms)
Nov  2 18:48:21.434: INFO: (5) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 17.047243ms)
Nov  2 18:48:21.434: INFO: (5) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 16.993058ms)
Nov  2 18:48:21.434: INFO: (5) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 17.254756ms)
Nov  2 18:48:21.434: INFO: (5) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 17.36659ms)
Nov  2 18:48:21.435: INFO: (5) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 18.567207ms)
Nov  2 18:48:21.435: INFO: (5) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 18.609224ms)
Nov  2 18:48:21.436: INFO: (5) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 19.101898ms)
Nov  2 18:48:21.491: INFO: (5) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 74.933164ms)
Nov  2 18:48:21.491: INFO: (5) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 74.830142ms)
Nov  2 18:48:21.492: INFO: (5) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 74.902891ms)
Nov  2 18:48:21.492: INFO: (5) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 75.062082ms)
Nov  2 18:48:21.492: INFO: (5) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 75.28788ms)
Nov  2 18:48:21.492: INFO: (5) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 75.477255ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 22.620836ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 22.964384ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 22.477403ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 22.702839ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 22.865561ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 22.392613ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 22.343615ms)
Nov  2 18:48:21.515: INFO: (6) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 22.796098ms)
Nov  2 18:48:21.556: INFO: (6) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 63.429646ms)
Nov  2 18:48:21.556: INFO: (6) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 62.548669ms)
Nov  2 18:48:21.556: INFO: (6) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 62.818456ms)
Nov  2 18:48:21.567: INFO: (6) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 74.219104ms)
Nov  2 18:48:21.567: INFO: (6) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 73.710552ms)
Nov  2 18:48:21.567: INFO: (6) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 73.822772ms)
Nov  2 18:48:21.567: INFO: (6) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 74.707253ms)
Nov  2 18:48:21.608: INFO: (6) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 114.932209ms)
Nov  2 18:48:21.625: INFO: (7) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 17.546086ms)
Nov  2 18:48:21.626: INFO: (7) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 15.977218ms)
Nov  2 18:48:21.626: INFO: (7) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 17.357851ms)
Nov  2 18:48:21.626: INFO: (7) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 16.776525ms)
Nov  2 18:48:21.627: INFO: (7) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 18.706713ms)
Nov  2 18:48:21.631: INFO: (7) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 23.088291ms)
Nov  2 18:48:21.631: INFO: (7) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 21.929242ms)
Nov  2 18:48:21.631: INFO: (7) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 22.780577ms)
Nov  2 18:48:21.631: INFO: (7) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 21.895271ms)
Nov  2 18:48:21.633: INFO: (7) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 23.864714ms)
Nov  2 18:48:21.633: INFO: (7) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 24.180485ms)
Nov  2 18:48:21.633: INFO: (7) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 25.197005ms)
Nov  2 18:48:21.660: INFO: (7) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 51.080885ms)
Nov  2 18:48:21.660: INFO: (7) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 50.954548ms)
Nov  2 18:48:21.662: INFO: (7) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 51.984833ms)
Nov  2 18:48:21.666: INFO: (7) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 57.38495ms)
Nov  2 18:48:21.684: INFO: (8) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 18.506655ms)
Nov  2 18:48:21.685: INFO: (8) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 19.23969ms)
Nov  2 18:48:21.685: INFO: (8) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 19.051399ms)
Nov  2 18:48:21.685: INFO: (8) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 19.447307ms)
Nov  2 18:48:21.685: INFO: (8) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 19.315963ms)
Nov  2 18:48:21.686: INFO: (8) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 20.054006ms)
Nov  2 18:48:21.686: INFO: (8) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 20.029948ms)
Nov  2 18:48:21.686: INFO: (8) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 20.215324ms)
Nov  2 18:48:21.687: INFO: (8) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 21.070589ms)
Nov  2 18:48:21.687: INFO: (8) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 21.120655ms)
Nov  2 18:48:21.693: INFO: (8) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 26.277994ms)
Nov  2 18:48:21.693: INFO: (8) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 26.367094ms)
Nov  2 18:48:21.695: INFO: (8) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 28.554037ms)
Nov  2 18:48:21.698: INFO: (8) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 31.882399ms)
Nov  2 18:48:21.699: INFO: (8) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 32.742538ms)
Nov  2 18:48:21.702: INFO: (8) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 36.043505ms)
Nov  2 18:48:21.717: INFO: (9) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 13.842333ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 15.270745ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 15.685622ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 15.121989ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 15.080641ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 16.290514ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 16.575785ms)
Nov  2 18:48:21.719: INFO: (9) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 16.579907ms)
Nov  2 18:48:21.722: INFO: (9) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 18.977272ms)
Nov  2 18:48:21.726: INFO: (9) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 22.807894ms)
Nov  2 18:48:21.726: INFO: (9) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 22.318868ms)
Nov  2 18:48:21.726: INFO: (9) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 23.518405ms)
Nov  2 18:48:21.727: INFO: (9) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 23.317823ms)
Nov  2 18:48:21.727: INFO: (9) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 23.918923ms)
Nov  2 18:48:21.729: INFO: (9) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 25.413406ms)
Nov  2 18:48:21.736: INFO: (9) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 32.451231ms)
Nov  2 18:48:21.760: INFO: (10) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 23.145568ms)
Nov  2 18:48:21.760: INFO: (10) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 23.221506ms)
Nov  2 18:48:21.761: INFO: (10) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 23.902852ms)
Nov  2 18:48:21.761: INFO: (10) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 24.109598ms)
Nov  2 18:48:21.761: INFO: (10) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 24.243787ms)
Nov  2 18:48:21.761: INFO: (10) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 24.092451ms)
Nov  2 18:48:21.761: INFO: (10) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 24.202255ms)
Nov  2 18:48:21.761: INFO: (10) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 24.305261ms)
Nov  2 18:48:21.810: INFO: (10) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 73.070344ms)
Nov  2 18:48:21.810: INFO: (10) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 73.27537ms)
Nov  2 18:48:21.810: INFO: (10) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 73.443139ms)
Nov  2 18:48:21.810: INFO: (10) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 73.432982ms)
Nov  2 18:48:21.810: INFO: (10) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 73.609295ms)
Nov  2 18:48:21.811: INFO: (10) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 73.983633ms)
Nov  2 18:48:21.811: INFO: (10) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 74.146873ms)
Nov  2 18:48:21.857: INFO: (10) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 120.280141ms)
Nov  2 18:48:21.883: INFO: (11) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 26.288407ms)
Nov  2 18:48:21.884: INFO: (11) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 27.203832ms)
Nov  2 18:48:21.884: INFO: (11) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 27.079403ms)
Nov  2 18:48:21.884: INFO: (11) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 26.909201ms)
Nov  2 18:48:21.884: INFO: (11) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 26.874939ms)
Nov  2 18:48:21.884: INFO: (11) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 27.165003ms)
Nov  2 18:48:21.887: INFO: (11) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 29.41327ms)
Nov  2 18:48:21.887: INFO: (11) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 29.421538ms)
Nov  2 18:48:21.887: INFO: (11) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 29.391218ms)
Nov  2 18:48:21.888: INFO: (11) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 30.996627ms)
Nov  2 18:48:21.891: INFO: (11) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 34.218588ms)
Nov  2 18:48:21.891: INFO: (11) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 34.422198ms)
Nov  2 18:48:21.891: INFO: (11) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 34.201386ms)
Nov  2 18:48:21.892: INFO: (11) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 35.151254ms)
Nov  2 18:48:21.896: INFO: (11) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 38.891582ms)
Nov  2 18:48:21.897: INFO: (11) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 39.363728ms)
Nov  2 18:48:21.913: INFO: (12) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 16.089964ms)
Nov  2 18:48:21.915: INFO: (12) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 18.132444ms)
Nov  2 18:48:21.915: INFO: (12) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 17.923169ms)
Nov  2 18:48:21.915: INFO: (12) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 17.546402ms)
Nov  2 18:48:21.916: INFO: (12) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 18.394824ms)
Nov  2 18:48:21.916: INFO: (12) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 18.843687ms)
Nov  2 18:48:21.918: INFO: (12) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 20.933771ms)
Nov  2 18:48:21.919: INFO: (12) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 20.812841ms)
Nov  2 18:48:21.919: INFO: (12) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 21.223479ms)
Nov  2 18:48:21.921: INFO: (12) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 24.095799ms)
Nov  2 18:48:21.923: INFO: (12) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 25.890567ms)
Nov  2 18:48:21.924: INFO: (12) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 26.473688ms)
Nov  2 18:48:21.926: INFO: (12) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 27.662589ms)
Nov  2 18:48:21.926: INFO: (12) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 27.776542ms)
Nov  2 18:48:21.928: INFO: (12) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 30.386239ms)
Nov  2 18:48:21.932: INFO: (12) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 34.894668ms)
Nov  2 18:48:21.999: INFO: (13) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 66.761738ms)
Nov  2 18:48:21.999: INFO: (13) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 66.577193ms)
Nov  2 18:48:21.999: INFO: (13) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 66.811963ms)
Nov  2 18:48:21.999: INFO: (13) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 66.783135ms)
Nov  2 18:48:21.999: INFO: (13) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 67.688993ms)
Nov  2 18:48:22.006: INFO: (13) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 74.141009ms)
Nov  2 18:48:22.006: INFO: (13) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 74.176531ms)
Nov  2 18:48:22.006: INFO: (13) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 74.382978ms)
Nov  2 18:48:22.007: INFO: (13) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 74.35117ms)
Nov  2 18:48:22.007: INFO: (13) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 74.272889ms)
Nov  2 18:48:22.007: INFO: (13) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 74.629381ms)
Nov  2 18:48:22.007: INFO: (13) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 74.480026ms)
Nov  2 18:48:22.008: INFO: (13) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 75.771832ms)
Nov  2 18:48:22.008: INFO: (13) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 75.733678ms)
Nov  2 18:48:22.011: INFO: (13) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 78.910521ms)
Nov  2 18:48:22.013: INFO: (13) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 80.91723ms)
Nov  2 18:48:22.033: INFO: (14) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 18.232585ms)
Nov  2 18:48:22.033: INFO: (14) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 19.599556ms)
Nov  2 18:48:22.033: INFO: (14) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 20.239851ms)
Nov  2 18:48:22.033: INFO: (14) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 19.76326ms)
Nov  2 18:48:22.033: INFO: (14) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 19.968831ms)
Nov  2 18:48:22.037: INFO: (14) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 22.295124ms)
Nov  2 18:48:22.037: INFO: (14) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 22.651599ms)
Nov  2 18:48:22.037: INFO: (14) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 22.113795ms)
Nov  2 18:48:22.049: INFO: (14) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 35.085575ms)
Nov  2 18:48:22.049: INFO: (14) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 34.676866ms)
Nov  2 18:48:22.061: INFO: (14) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 46.08931ms)
Nov  2 18:48:22.061: INFO: (14) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 46.621211ms)
Nov  2 18:48:22.061: INFO: (14) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 46.405879ms)
Nov  2 18:48:22.063: INFO: (14) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 49.153779ms)
Nov  2 18:48:22.069: INFO: (14) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 55.193058ms)
Nov  2 18:48:22.072: INFO: (14) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 58.737288ms)
Nov  2 18:48:22.097: INFO: (15) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 24.857031ms)
Nov  2 18:48:22.099: INFO: (15) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 25.990946ms)
Nov  2 18:48:22.099: INFO: (15) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 26.695803ms)
Nov  2 18:48:22.099: INFO: (15) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 26.742789ms)
Nov  2 18:48:22.099: INFO: (15) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 26.890344ms)
Nov  2 18:48:22.099: INFO: (15) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 27.06754ms)
Nov  2 18:48:22.099: INFO: (15) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 26.936239ms)
Nov  2 18:48:22.106: INFO: (15) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 33.513074ms)
Nov  2 18:48:22.107: INFO: (15) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 34.202298ms)
Nov  2 18:48:22.107: INFO: (15) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 34.322842ms)
Nov  2 18:48:22.107: INFO: (15) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 34.292472ms)
Nov  2 18:48:22.107: INFO: (15) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 34.41873ms)
Nov  2 18:48:22.107: INFO: (15) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 34.707667ms)
Nov  2 18:48:22.107: INFO: (15) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 34.586999ms)
Nov  2 18:48:22.111: INFO: (15) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 38.077886ms)
Nov  2 18:48:22.198: INFO: (15) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 125.151763ms)
Nov  2 18:48:22.214: INFO: (16) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 15.972124ms)
Nov  2 18:48:22.214: INFO: (16) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 16.706664ms)
Nov  2 18:48:22.214: INFO: (16) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 16.822773ms)
Nov  2 18:48:22.215: INFO: (16) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 16.654131ms)
Nov  2 18:48:22.215: INFO: (16) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 16.604177ms)
Nov  2 18:48:22.215: INFO: (16) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 16.765798ms)
Nov  2 18:48:22.215: INFO: (16) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 16.948597ms)
Nov  2 18:48:22.215: INFO: (16) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 16.9776ms)
Nov  2 18:48:22.217: INFO: (16) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 19.142855ms)
Nov  2 18:48:22.251: INFO: (16) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 53.056519ms)
Nov  2 18:48:22.251: INFO: (16) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 53.405893ms)
Nov  2 18:48:22.251: INFO: (16) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 53.170549ms)
Nov  2 18:48:22.254: INFO: (16) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 56.274662ms)
Nov  2 18:48:22.254: INFO: (16) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 56.209697ms)
Nov  2 18:48:22.254: INFO: (16) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 56.582874ms)
Nov  2 18:48:22.254: INFO: (16) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 56.584041ms)
Nov  2 18:48:22.277: INFO: (17) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 22.098384ms)
Nov  2 18:48:22.277: INFO: (17) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 22.310186ms)
Nov  2 18:48:22.277: INFO: (17) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 22.152777ms)
Nov  2 18:48:22.277: INFO: (17) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 22.226829ms)
Nov  2 18:48:22.277: INFO: (17) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 22.426642ms)
Nov  2 18:48:22.277: INFO: (17) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 22.204745ms)
Nov  2 18:48:22.278: INFO: (17) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 22.718074ms)
Nov  2 18:48:22.278: INFO: (17) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 22.915172ms)
Nov  2 18:48:22.278: INFO: (17) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 23.459603ms)
Nov  2 18:48:22.278: INFO: (17) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 23.371386ms)
Nov  2 18:48:22.282: INFO: (17) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 27.30516ms)
Nov  2 18:48:22.286: INFO: (17) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 31.407312ms)
Nov  2 18:48:22.320: INFO: (17) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 64.988255ms)
Nov  2 18:48:22.320: INFO: (17) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 65.03995ms)
Nov  2 18:48:22.320: INFO: (17) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 64.973027ms)
Nov  2 18:48:22.320: INFO: (17) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 65.10721ms)
Nov  2 18:48:22.336: INFO: (18) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 15.934971ms)
Nov  2 18:48:22.337: INFO: (18) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 16.524529ms)
Nov  2 18:48:22.337: INFO: (18) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 17.223198ms)
Nov  2 18:48:22.337: INFO: (18) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 17.020579ms)
Nov  2 18:48:22.340: INFO: (18) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 19.390876ms)
Nov  2 18:48:22.340: INFO: (18) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 19.530158ms)
Nov  2 18:48:22.340: INFO: (18) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 19.392802ms)
Nov  2 18:48:22.341: INFO: (18) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 20.013869ms)
Nov  2 18:48:22.341: INFO: (18) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 20.086092ms)
Nov  2 18:48:22.341: INFO: (18) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 19.981964ms)
Nov  2 18:48:22.341: INFO: (18) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 20.303666ms)
Nov  2 18:48:22.347: INFO: (18) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 26.487117ms)
Nov  2 18:48:22.348: INFO: (18) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 27.236678ms)
Nov  2 18:48:22.349: INFO: (18) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 28.434647ms)
Nov  2 18:48:22.349: INFO: (18) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 28.240773ms)
Nov  2 18:48:22.350: INFO: (18) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 29.531073ms)
Nov  2 18:48:22.366: INFO: (19) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c/proxy/rewriteme">test</a> (200; 15.370168ms)
Nov  2 18:48:22.367: INFO: (19) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname1/proxy/: foo (200; 15.57679ms)
Nov  2 18:48:22.367: INFO: (19) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">... (200; 14.94218ms)
Nov  2 18:48:22.367: INFO: (19) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:462/proxy/: tls qux (200; 15.879388ms)
Nov  2 18:48:22.367: INFO: (19) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 15.985144ms)
Nov  2 18:48:22.367: INFO: (19) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 15.305476ms)
Nov  2 18:48:22.367: INFO: (19) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:443/proxy/tlsrewritem... (200; 15.797313ms)
Nov  2 18:48:22.370: INFO: (19) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname2/proxy/: bar (200; 18.30118ms)
Nov  2 18:48:22.370: INFO: (19) /api/v1/namespaces/proxy-7925/pods/https:proxy-service-j7s5s-7z29c:460/proxy/: tls baz (200; 19.708785ms)
Nov  2 18:48:22.370: INFO: (19) /api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/: <a href="/api/v1/namespaces/proxy-7925/pods/proxy-service-j7s5s-7z29c:1080/proxy/rewriteme">test<... (200; 18.289192ms)
Nov  2 18:48:22.370: INFO: (19) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname1/proxy/: tls baz (200; 18.716782ms)
Nov  2 18:48:22.370: INFO: (19) /api/v1/namespaces/proxy-7925/services/https:proxy-service-j7s5s:tlsportname2/proxy/: tls qux (200; 18.611118ms)
Nov  2 18:48:22.374: INFO: (19) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:162/proxy/: bar (200; 22.182088ms)
Nov  2 18:48:22.374: INFO: (19) /api/v1/namespaces/proxy-7925/pods/http:proxy-service-j7s5s-7z29c:160/proxy/: foo (200; 23.358909ms)
Nov  2 18:48:22.374: INFO: (19) /api/v1/namespaces/proxy-7925/services/proxy-service-j7s5s:portname1/proxy/: foo (200; 23.076859ms)
Nov  2 18:48:22.377: INFO: (19) /api/v1/namespaces/proxy-7925/services/http:proxy-service-j7s5s:portname2/proxy/: bar (200; 26.786432ms)
STEP: deleting ReplicationController proxy-service-j7s5s in namespace proxy-7925, will wait for the garbage collector to delete the pods
Nov  2 18:48:22.454: INFO: Deleting ReplicationController proxy-service-j7s5s took: 19.051513ms
Nov  2 18:48:22.555: INFO: Terminating ReplicationController proxy-service-j7s5s pods took: 100.854809ms
[AfterEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:48:26.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7925" for this suite.

• [SLOW TEST:17.225 seconds]
[sig-network] Proxy
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":280,"completed":164,"skipped":2697,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:48:26.984: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-598
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-674
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:48:43.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7095" for this suite.
STEP: Destroying namespace "nsdeletetest-598" for this suite.
Nov  2 18:48:43.753: INFO: Namespace nsdeletetest-598 was already deleted
STEP: Destroying namespace "nsdeletetest-674" for this suite.

• [SLOW TEST:16.787 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":280,"completed":165,"skipped":2711,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:48:43.773: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  2 18:48:44.133: INFO: Number of nodes with available pods: 0
Nov  2 18:48:44.133: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:48:45.160: INFO: Number of nodes with available pods: 0
Nov  2 18:48:45.160: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:48:46.157: INFO: Number of nodes with available pods: 0
Nov  2 18:48:46.157: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:48:47.152: INFO: Number of nodes with available pods: 3
Nov  2 18:48:47.152: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  2 18:48:47.225: INFO: Number of nodes with available pods: 2
Nov  2 18:48:47.225: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:48.254: INFO: Number of nodes with available pods: 2
Nov  2 18:48:48.254: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:49.251: INFO: Number of nodes with available pods: 2
Nov  2 18:48:49.251: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:50.249: INFO: Number of nodes with available pods: 2
Nov  2 18:48:50.249: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:51.245: INFO: Number of nodes with available pods: 2
Nov  2 18:48:51.245: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:52.243: INFO: Number of nodes with available pods: 2
Nov  2 18:48:52.244: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:53.244: INFO: Number of nodes with available pods: 2
Nov  2 18:48:53.244: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:54.252: INFO: Number of nodes with available pods: 2
Nov  2 18:48:54.252: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:55.251: INFO: Number of nodes with available pods: 2
Nov  2 18:48:55.251: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:56.276: INFO: Number of nodes with available pods: 2
Nov  2 18:48:56.276: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:57.245: INFO: Number of nodes with available pods: 2
Nov  2 18:48:57.245: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:58.254: INFO: Number of nodes with available pods: 2
Nov  2 18:48:58.254: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:48:59.259: INFO: Number of nodes with available pods: 3
Nov  2 18:48:59.259: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-227, will wait for the garbage collector to delete the pods
Nov  2 18:48:59.357: INFO: Deleting DaemonSet.extensions daemon-set took: 29.109664ms
Nov  2 18:48:59.859: INFO: Terminating DaemonSet.extensions daemon-set pods took: 501.17091ms
Nov  2 18:49:10.767: INFO: Number of nodes with available pods: 0
Nov  2 18:49:10.767: INFO: Number of running nodes: 0, number of available pods: 0
Nov  2 18:49:10.775: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-227/daemonsets","resourceVersion":"163961"},"items":null}

Nov  2 18:49:10.783: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-227/pods","resourceVersion":"163961"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:49:10.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-227" for this suite.

• [SLOW TEST:27.071 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":280,"completed":166,"skipped":2718,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:49:10.845: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1544
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov  2 18:49:41.703: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1102 18:49:41.703633      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:49:41.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1544" for this suite.

• [SLOW TEST:30.881 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":280,"completed":167,"skipped":2729,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:49:41.726: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:49:41.940: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2478
I1102 18:49:41.967089      24 runners.go:189] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2478, replica count: 1
I1102 18:49:43.017529      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1102 18:49:44.017851      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1102 18:49:45.018080      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  2 18:49:45.146: INFO: Created: latency-svc-l2g6h
Nov  2 18:49:45.176: INFO: Got endpoints: latency-svc-l2g6h [58.430947ms]
Nov  2 18:49:45.220: INFO: Created: latency-svc-w4sc4
Nov  2 18:49:45.238: INFO: Got endpoints: latency-svc-w4sc4 [61.293912ms]
Nov  2 18:49:45.241: INFO: Created: latency-svc-2qlpj
Nov  2 18:49:45.249: INFO: Got endpoints: latency-svc-2qlpj [72.709692ms]
Nov  2 18:49:45.255: INFO: Created: latency-svc-klpn5
Nov  2 18:49:45.275: INFO: Created: latency-svc-br4q9
Nov  2 18:49:45.286: INFO: Got endpoints: latency-svc-klpn5 [109.068623ms]
Nov  2 18:49:45.290: INFO: Got endpoints: latency-svc-br4q9 [112.585482ms]
Nov  2 18:49:45.297: INFO: Created: latency-svc-swwf7
Nov  2 18:49:45.306: INFO: Got endpoints: latency-svc-swwf7 [129.372989ms]
Nov  2 18:49:45.310: INFO: Created: latency-svc-x645h
Nov  2 18:49:45.323: INFO: Got endpoints: latency-svc-x645h [146.136184ms]
Nov  2 18:49:45.354: INFO: Created: latency-svc-nn5p2
Nov  2 18:49:45.354: INFO: Got endpoints: latency-svc-nn5p2 [176.714375ms]
Nov  2 18:49:45.369: INFO: Created: latency-svc-dgg8z
Nov  2 18:49:45.382: INFO: Got endpoints: latency-svc-dgg8z [204.814642ms]
Nov  2 18:49:45.388: INFO: Created: latency-svc-6cd4j
Nov  2 18:49:45.400: INFO: Got endpoints: latency-svc-6cd4j [222.646013ms]
Nov  2 18:49:45.411: INFO: Created: latency-svc-h7vhv
Nov  2 18:49:45.422: INFO: Got endpoints: latency-svc-h7vhv [244.320901ms]
Nov  2 18:49:45.425: INFO: Created: latency-svc-x8x72
Nov  2 18:49:45.441: INFO: Got endpoints: latency-svc-x8x72 [263.665682ms]
Nov  2 18:49:45.441: INFO: Created: latency-svc-8rf95
Nov  2 18:49:45.462: INFO: Got endpoints: latency-svc-8rf95 [284.399906ms]
Nov  2 18:49:45.483: INFO: Created: latency-svc-z2wqw
Nov  2 18:49:45.493: INFO: Got endpoints: latency-svc-z2wqw [315.45653ms]
Nov  2 18:49:45.567: INFO: Created: latency-svc-nzk5b
Nov  2 18:49:45.579: INFO: Got endpoints: latency-svc-nzk5b [401.812009ms]
Nov  2 18:49:45.583: INFO: Created: latency-svc-x2l5g
Nov  2 18:49:45.600: INFO: Got endpoints: latency-svc-x2l5g [422.770926ms]
Nov  2 18:49:45.630: INFO: Created: latency-svc-wj7xc
Nov  2 18:49:45.637: INFO: Got endpoints: latency-svc-wj7xc [399.622967ms]
Nov  2 18:49:45.644: INFO: Created: latency-svc-64bkm
Nov  2 18:49:45.650: INFO: Got endpoints: latency-svc-64bkm [401.066895ms]
Nov  2 18:49:45.667: INFO: Created: latency-svc-qkccd
Nov  2 18:49:45.680: INFO: Got endpoints: latency-svc-qkccd [394.497481ms]
Nov  2 18:49:45.687: INFO: Created: latency-svc-5mfw6
Nov  2 18:49:45.699: INFO: Got endpoints: latency-svc-5mfw6 [409.520826ms]
Nov  2 18:49:45.726: INFO: Created: latency-svc-t6g6v
Nov  2 18:49:45.735: INFO: Got endpoints: latency-svc-t6g6v [428.215604ms]
Nov  2 18:49:45.742: INFO: Created: latency-svc-cqrjg
Nov  2 18:49:45.772: INFO: Got endpoints: latency-svc-cqrjg [449.083461ms]
Nov  2 18:49:45.780: INFO: Created: latency-svc-59zpc
Nov  2 18:49:45.787: INFO: Got endpoints: latency-svc-59zpc [433.145533ms]
Nov  2 18:49:45.791: INFO: Created: latency-svc-c22bt
Nov  2 18:49:45.800: INFO: Got endpoints: latency-svc-c22bt [417.913888ms]
Nov  2 18:49:45.804: INFO: Created: latency-svc-bwxgj
Nov  2 18:49:45.829: INFO: Got endpoints: latency-svc-bwxgj [429.109804ms]
Nov  2 18:49:45.830: INFO: Created: latency-svc-msn96
Nov  2 18:49:45.838: INFO: Created: latency-svc-jnbsj
Nov  2 18:49:45.850: INFO: Got endpoints: latency-svc-msn96 [428.046175ms]
Nov  2 18:49:45.854: INFO: Got endpoints: latency-svc-jnbsj [413.350625ms]
Nov  2 18:49:45.856: INFO: Created: latency-svc-mwf6l
Nov  2 18:49:45.865: INFO: Got endpoints: latency-svc-mwf6l [403.012537ms]
Nov  2 18:49:45.875: INFO: Created: latency-svc-62sfz
Nov  2 18:49:45.883: INFO: Created: latency-svc-kpzxw
Nov  2 18:49:45.889: INFO: Got endpoints: latency-svc-62sfz [395.772919ms]
Nov  2 18:49:45.898: INFO: Got endpoints: latency-svc-kpzxw [319.12071ms]
Nov  2 18:49:45.901: INFO: Created: latency-svc-x94q9
Nov  2 18:49:45.913: INFO: Got endpoints: latency-svc-x94q9 [312.719786ms]
Nov  2 18:49:45.937: INFO: Created: latency-svc-mv6x2
Nov  2 18:49:45.945: INFO: Got endpoints: latency-svc-mv6x2 [307.352378ms]
Nov  2 18:49:45.956: INFO: Created: latency-svc-rwxn6
Nov  2 18:49:45.971: INFO: Got endpoints: latency-svc-rwxn6 [320.023787ms]
Nov  2 18:49:45.973: INFO: Created: latency-svc-5rclk
Nov  2 18:49:45.985: INFO: Got endpoints: latency-svc-5rclk [304.127383ms]
Nov  2 18:49:46.002: INFO: Created: latency-svc-k868l
Nov  2 18:49:46.005: INFO: Got endpoints: latency-svc-k868l [306.097346ms]
Nov  2 18:49:46.030: INFO: Created: latency-svc-6klc9
Nov  2 18:49:46.033: INFO: Got endpoints: latency-svc-6klc9 [297.916874ms]
Nov  2 18:49:46.043: INFO: Created: latency-svc-4gwn2
Nov  2 18:49:46.044: INFO: Got endpoints: latency-svc-4gwn2 [271.865939ms]
Nov  2 18:49:46.062: INFO: Created: latency-svc-hcrh6
Nov  2 18:49:46.073: INFO: Got endpoints: latency-svc-hcrh6 [286.069316ms]
Nov  2 18:49:46.075: INFO: Created: latency-svc-m4x2d
Nov  2 18:49:46.093: INFO: Got endpoints: latency-svc-m4x2d [292.865036ms]
Nov  2 18:49:46.096: INFO: Created: latency-svc-8nlxr
Nov  2 18:49:46.116: INFO: Got endpoints: latency-svc-8nlxr [286.61771ms]
Nov  2 18:49:46.125: INFO: Created: latency-svc-wltfg
Nov  2 18:49:46.140: INFO: Got endpoints: latency-svc-wltfg [290.727949ms]
Nov  2 18:49:46.165: INFO: Created: latency-svc-m7l9f
Nov  2 18:49:46.181: INFO: Got endpoints: latency-svc-m7l9f [326.544792ms]
Nov  2 18:49:46.192: INFO: Created: latency-svc-fjf5m
Nov  2 18:49:46.219: INFO: Got endpoints: latency-svc-fjf5m [353.929388ms]
Nov  2 18:49:46.229: INFO: Created: latency-svc-wb95f
Nov  2 18:49:46.239: INFO: Got endpoints: latency-svc-wb95f [350.566687ms]
Nov  2 18:49:46.254: INFO: Created: latency-svc-xq5jk
Nov  2 18:49:46.273: INFO: Created: latency-svc-nfg6x
Nov  2 18:49:46.273: INFO: Got endpoints: latency-svc-xq5jk [374.986521ms]
Nov  2 18:49:46.287: INFO: Got endpoints: latency-svc-nfg6x [373.992552ms]
Nov  2 18:49:46.296: INFO: Created: latency-svc-f9z7f
Nov  2 18:49:46.305: INFO: Got endpoints: latency-svc-f9z7f [360.241127ms]
Nov  2 18:49:46.318: INFO: Created: latency-svc-srrb9
Nov  2 18:49:46.334: INFO: Got endpoints: latency-svc-srrb9 [363.790253ms]
Nov  2 18:49:46.335: INFO: Created: latency-svc-xgx9x
Nov  2 18:49:46.348: INFO: Got endpoints: latency-svc-xgx9x [363.477042ms]
Nov  2 18:49:46.366: INFO: Created: latency-svc-42d5c
Nov  2 18:49:46.380: INFO: Got endpoints: latency-svc-42d5c [374.655813ms]
Nov  2 18:49:46.382: INFO: Created: latency-svc-pgm8s
Nov  2 18:49:46.394: INFO: Got endpoints: latency-svc-pgm8s [361.894796ms]
Nov  2 18:49:46.399: INFO: Created: latency-svc-kxvdd
Nov  2 18:49:46.416: INFO: Got endpoints: latency-svc-kxvdd [372.696592ms]
Nov  2 18:49:46.424: INFO: Created: latency-svc-lmzvr
Nov  2 18:49:46.434: INFO: Got endpoints: latency-svc-lmzvr [360.646542ms]
Nov  2 18:49:46.442: INFO: Created: latency-svc-xmxlb
Nov  2 18:49:46.476: INFO: Got endpoints: latency-svc-xmxlb [383.597567ms]
Nov  2 18:49:46.477: INFO: Created: latency-svc-q2cj8
Nov  2 18:49:46.487: INFO: Got endpoints: latency-svc-q2cj8 [365.125868ms]
Nov  2 18:49:46.529: INFO: Created: latency-svc-9l247
Nov  2 18:49:46.541: INFO: Got endpoints: latency-svc-9l247 [400.708421ms]
Nov  2 18:49:46.550: INFO: Created: latency-svc-vllmt
Nov  2 18:49:46.559: INFO: Got endpoints: latency-svc-vllmt [378.066508ms]
Nov  2 18:49:46.563: INFO: Created: latency-svc-8tp4s
Nov  2 18:49:46.584: INFO: Got endpoints: latency-svc-8tp4s [365.08796ms]
Nov  2 18:49:46.598: INFO: Created: latency-svc-dr4fv
Nov  2 18:49:46.608: INFO: Created: latency-svc-9vpm5
Nov  2 18:49:46.621: INFO: Created: latency-svc-s4nqj
Nov  2 18:49:46.640: INFO: Got endpoints: latency-svc-dr4fv [400.998062ms]
Nov  2 18:49:46.653: INFO: Created: latency-svc-hzmbc
Nov  2 18:49:46.661: INFO: Created: latency-svc-tfgbs
Nov  2 18:49:46.672: INFO: Created: latency-svc-9tbww
Nov  2 18:49:46.682: INFO: Got endpoints: latency-svc-9vpm5 [409.1622ms]
Nov  2 18:49:46.695: INFO: Created: latency-svc-8r6gv
Nov  2 18:49:46.708: INFO: Created: latency-svc-vtwt7
Nov  2 18:49:46.725: INFO: Created: latency-svc-czbcn
Nov  2 18:49:46.729: INFO: Got endpoints: latency-svc-s4nqj [442.000759ms]
Nov  2 18:49:46.750: INFO: Created: latency-svc-cwjjn
Nov  2 18:49:46.765: INFO: Created: latency-svc-7c8bc
Nov  2 18:49:46.816: INFO: Created: latency-svc-fshft
Nov  2 18:49:46.817: INFO: Got endpoints: latency-svc-hzmbc [511.686565ms]
Nov  2 18:49:46.841: INFO: Got endpoints: latency-svc-tfgbs [506.612868ms]
Nov  2 18:49:46.850: INFO: Created: latency-svc-lbd8r
Nov  2 18:49:46.874: INFO: Created: latency-svc-8bxrp
Nov  2 18:49:46.886: INFO: Got endpoints: latency-svc-9tbww [537.338983ms]
Nov  2 18:49:46.898: INFO: Created: latency-svc-8snjg
Nov  2 18:49:46.935: INFO: Created: latency-svc-7tbfw
Nov  2 18:49:46.941: INFO: Got endpoints: latency-svc-8r6gv [560.709888ms]
Nov  2 18:49:46.973: INFO: Created: latency-svc-wpq6j
Nov  2 18:49:46.981: INFO: Got endpoints: latency-svc-vtwt7 [586.876384ms]
Nov  2 18:49:47.006: INFO: Created: latency-svc-c8lz9
Nov  2 18:49:47.034: INFO: Created: latency-svc-vdbqs
Nov  2 18:49:47.043: INFO: Got endpoints: latency-svc-czbcn [626.151818ms]
Nov  2 18:49:47.133: INFO: Got endpoints: latency-svc-7c8bc [656.657022ms]
Nov  2 18:49:47.134: INFO: Got endpoints: latency-svc-cwjjn [699.853595ms]
Nov  2 18:49:47.134: INFO: Created: latency-svc-d6fqj
Nov  2 18:49:47.158: INFO: Created: latency-svc-5p5nk
Nov  2 18:49:47.177: INFO: Created: latency-svc-mq5bw
Nov  2 18:49:47.179: INFO: Got endpoints: latency-svc-fshft [692.302695ms]
Nov  2 18:49:47.197: INFO: Created: latency-svc-84ch8
Nov  2 18:49:47.210: INFO: Created: latency-svc-rsps6
Nov  2 18:49:47.230: INFO: Got endpoints: latency-svc-lbd8r [689.267421ms]
Nov  2 18:49:47.241: INFO: Created: latency-svc-94xlq
Nov  2 18:49:47.252: INFO: Created: latency-svc-hvqkb
Nov  2 18:49:47.290: INFO: Got endpoints: latency-svc-8bxrp [730.692769ms]
Nov  2 18:49:47.291: INFO: Created: latency-svc-b7tf5
Nov  2 18:49:47.318: INFO: Created: latency-svc-dkt7w
Nov  2 18:49:47.331: INFO: Created: latency-svc-pwfxq
Nov  2 18:49:47.342: INFO: Got endpoints: latency-svc-8snjg [758.597618ms]
Nov  2 18:49:47.375: INFO: Created: latency-svc-zdcwl
Nov  2 18:49:47.380: INFO: Got endpoints: latency-svc-7tbfw [739.301392ms]
Nov  2 18:49:47.402: INFO: Created: latency-svc-vkrcs
Nov  2 18:49:47.435: INFO: Got endpoints: latency-svc-wpq6j [752.494615ms]
Nov  2 18:49:47.478: INFO: Got endpoints: latency-svc-c8lz9 [749.271529ms]
Nov  2 18:49:47.530: INFO: Got endpoints: latency-svc-vdbqs [712.973612ms]
Nov  2 18:49:47.585: INFO: Created: latency-svc-nrgjs
Nov  2 18:49:47.589: INFO: Got endpoints: latency-svc-d6fqj [747.658311ms]
Nov  2 18:49:47.603: INFO: Created: latency-svc-dmljh
Nov  2 18:49:47.631: INFO: Got endpoints: latency-svc-5p5nk [745.697978ms]
Nov  2 18:49:47.632: INFO: Created: latency-svc-lwf5x
Nov  2 18:49:47.651: INFO: Created: latency-svc-ndb42
Nov  2 18:49:47.661: INFO: Created: latency-svc-vhr2q
Nov  2 18:49:47.681: INFO: Got endpoints: latency-svc-mq5bw [740.175971ms]
Nov  2 18:49:47.716: INFO: Created: latency-svc-frbxr
Nov  2 18:49:47.732: INFO: Got endpoints: latency-svc-84ch8 [750.89098ms]
Nov  2 18:49:47.768: INFO: Created: latency-svc-ff944
Nov  2 18:49:47.780: INFO: Got endpoints: latency-svc-rsps6 [737.625417ms]
Nov  2 18:49:47.809: INFO: Created: latency-svc-7vclb
Nov  2 18:49:47.832: INFO: Got endpoints: latency-svc-94xlq [698.894642ms]
Nov  2 18:49:47.869: INFO: Created: latency-svc-ff7cm
Nov  2 18:49:47.880: INFO: Got endpoints: latency-svc-hvqkb [746.283343ms]
Nov  2 18:49:47.903: INFO: Created: latency-svc-6474k
Nov  2 18:49:47.931: INFO: Got endpoints: latency-svc-b7tf5 [751.526881ms]
Nov  2 18:49:47.956: INFO: Created: latency-svc-r5ft9
Nov  2 18:49:47.981: INFO: Got endpoints: latency-svc-dkt7w [750.245855ms]
Nov  2 18:49:48.011: INFO: Created: latency-svc-6w2g9
Nov  2 18:49:48.033: INFO: Got endpoints: latency-svc-pwfxq [742.752938ms]
Nov  2 18:49:48.068: INFO: Created: latency-svc-vnvbk
Nov  2 18:49:48.081: INFO: Got endpoints: latency-svc-zdcwl [738.743965ms]
Nov  2 18:49:48.109: INFO: Created: latency-svc-r4t5z
Nov  2 18:49:48.140: INFO: Got endpoints: latency-svc-vkrcs [760.255831ms]
Nov  2 18:49:48.164: INFO: Created: latency-svc-nw6f8
Nov  2 18:49:48.196: INFO: Got endpoints: latency-svc-nrgjs [761.252106ms]
Nov  2 18:49:48.238: INFO: Got endpoints: latency-svc-dmljh [759.85717ms]
Nov  2 18:49:48.262: INFO: Created: latency-svc-xnxf8
Nov  2 18:49:48.292: INFO: Got endpoints: latency-svc-lwf5x [762.302354ms]
Nov  2 18:49:48.304: INFO: Created: latency-svc-7chv5
Nov  2 18:49:48.321: INFO: Created: latency-svc-7jcz9
Nov  2 18:49:48.343: INFO: Got endpoints: latency-svc-ndb42 [753.934289ms]
Nov  2 18:49:48.372: INFO: Created: latency-svc-sdnxd
Nov  2 18:49:48.380: INFO: Got endpoints: latency-svc-vhr2q [748.386697ms]
Nov  2 18:49:48.412: INFO: Created: latency-svc-tggr6
Nov  2 18:49:48.440: INFO: Got endpoints: latency-svc-frbxr [758.791127ms]
Nov  2 18:49:48.480: INFO: Created: latency-svc-62hgl
Nov  2 18:49:48.484: INFO: Got endpoints: latency-svc-ff944 [751.221949ms]
Nov  2 18:49:48.512: INFO: Created: latency-svc-tcrfr
Nov  2 18:49:48.529: INFO: Got endpoints: latency-svc-7vclb [749.130324ms]
Nov  2 18:49:48.554: INFO: Created: latency-svc-9hxcr
Nov  2 18:49:48.579: INFO: Got endpoints: latency-svc-ff7cm [747.082002ms]
Nov  2 18:49:48.615: INFO: Created: latency-svc-vmtg6
Nov  2 18:49:48.629: INFO: Got endpoints: latency-svc-6474k [748.934746ms]
Nov  2 18:49:48.665: INFO: Created: latency-svc-kgrj2
Nov  2 18:49:48.679: INFO: Got endpoints: latency-svc-r5ft9 [748.013938ms]
Nov  2 18:49:48.713: INFO: Created: latency-svc-5q586
Nov  2 18:49:48.730: INFO: Got endpoints: latency-svc-6w2g9 [749.612043ms]
Nov  2 18:49:48.766: INFO: Created: latency-svc-dllhl
Nov  2 18:49:48.792: INFO: Got endpoints: latency-svc-vnvbk [759.399528ms]
Nov  2 18:49:48.829: INFO: Got endpoints: latency-svc-r4t5z [748.146543ms]
Nov  2 18:49:48.838: INFO: Created: latency-svc-wxmrd
Nov  2 18:49:48.856: INFO: Created: latency-svc-ddw88
Nov  2 18:49:48.880: INFO: Got endpoints: latency-svc-nw6f8 [740.132259ms]
Nov  2 18:49:48.930: INFO: Got endpoints: latency-svc-xnxf8 [733.610661ms]
Nov  2 18:49:48.932: INFO: Created: latency-svc-5vhdw
Nov  2 18:49:48.953: INFO: Created: latency-svc-6zbll
Nov  2 18:49:48.978: INFO: Got endpoints: latency-svc-7chv5 [739.885589ms]
Nov  2 18:49:49.021: INFO: Created: latency-svc-v7shg
Nov  2 18:49:49.034: INFO: Got endpoints: latency-svc-7jcz9 [741.32561ms]
Nov  2 18:49:49.070: INFO: Created: latency-svc-6s8nd
Nov  2 18:49:49.079: INFO: Got endpoints: latency-svc-sdnxd [736.113032ms]
Nov  2 18:49:49.099: INFO: Created: latency-svc-hbwzs
Nov  2 18:49:49.131: INFO: Got endpoints: latency-svc-tggr6 [751.654775ms]
Nov  2 18:49:49.164: INFO: Created: latency-svc-4jrvf
Nov  2 18:49:49.189: INFO: Got endpoints: latency-svc-62hgl [749.522214ms]
Nov  2 18:49:49.228: INFO: Created: latency-svc-kwqv8
Nov  2 18:49:49.254: INFO: Got endpoints: latency-svc-tcrfr [770.728946ms]
Nov  2 18:49:49.281: INFO: Got endpoints: latency-svc-9hxcr [751.144519ms]
Nov  2 18:49:49.287: INFO: Created: latency-svc-7p9tq
Nov  2 18:49:49.304: INFO: Created: latency-svc-v7pp5
Nov  2 18:49:49.332: INFO: Got endpoints: latency-svc-vmtg6 [753.09006ms]
Nov  2 18:49:49.369: INFO: Created: latency-svc-dwv8m
Nov  2 18:49:49.378: INFO: Got endpoints: latency-svc-kgrj2 [749.097426ms]
Nov  2 18:49:49.399: INFO: Created: latency-svc-58kgt
Nov  2 18:49:49.430: INFO: Got endpoints: latency-svc-5q586 [751.439718ms]
Nov  2 18:49:49.477: INFO: Got endpoints: latency-svc-dllhl [746.535634ms]
Nov  2 18:49:49.533: INFO: Created: latency-svc-b95l6
Nov  2 18:49:49.541: INFO: Got endpoints: latency-svc-wxmrd [748.770482ms]
Nov  2 18:49:49.556: INFO: Created: latency-svc-szmxw
Nov  2 18:49:49.577: INFO: Created: latency-svc-74dsw
Nov  2 18:49:49.582: INFO: Got endpoints: latency-svc-ddw88 [752.518266ms]
Nov  2 18:49:49.616: INFO: Created: latency-svc-kdn8n
Nov  2 18:49:49.630: INFO: Got endpoints: latency-svc-5vhdw [749.661254ms]
Nov  2 18:49:49.657: INFO: Created: latency-svc-plbdp
Nov  2 18:49:49.683: INFO: Got endpoints: latency-svc-6zbll [753.009173ms]
Nov  2 18:49:49.704: INFO: Created: latency-svc-lv8t9
Nov  2 18:49:49.733: INFO: Got endpoints: latency-svc-v7shg [754.807165ms]
Nov  2 18:49:49.762: INFO: Created: latency-svc-ljfhf
Nov  2 18:49:49.791: INFO: Got endpoints: latency-svc-6s8nd [755.837396ms]
Nov  2 18:49:49.814: INFO: Created: latency-svc-htsl8
Nov  2 18:49:49.828: INFO: Got endpoints: latency-svc-hbwzs [748.993921ms]
Nov  2 18:49:49.854: INFO: Created: latency-svc-9fbtt
Nov  2 18:49:49.880: INFO: Got endpoints: latency-svc-4jrvf [748.473243ms]
Nov  2 18:49:49.902: INFO: Created: latency-svc-2ks7c
Nov  2 18:49:49.927: INFO: Got endpoints: latency-svc-kwqv8 [737.866521ms]
Nov  2 18:49:49.960: INFO: Created: latency-svc-mfk2m
Nov  2 18:49:49.978: INFO: Got endpoints: latency-svc-7p9tq [723.325142ms]
Nov  2 18:49:50.006: INFO: Created: latency-svc-8qp97
Nov  2 18:49:50.028: INFO: Got endpoints: latency-svc-v7pp5 [747.234159ms]
Nov  2 18:49:50.049: INFO: Created: latency-svc-6zcxm
Nov  2 18:49:50.086: INFO: Got endpoints: latency-svc-dwv8m [753.935369ms]
Nov  2 18:49:50.110: INFO: Created: latency-svc-w4m7g
Nov  2 18:49:50.133: INFO: Got endpoints: latency-svc-58kgt [754.501175ms]
Nov  2 18:49:50.166: INFO: Created: latency-svc-8qd4q
Nov  2 18:49:50.185: INFO: Got endpoints: latency-svc-b95l6 [754.160048ms]
Nov  2 18:49:50.218: INFO: Created: latency-svc-c5p22
Nov  2 18:49:50.230: INFO: Got endpoints: latency-svc-szmxw [752.924137ms]
Nov  2 18:49:50.258: INFO: Created: latency-svc-twsvb
Nov  2 18:49:50.290: INFO: Got endpoints: latency-svc-74dsw [749.374921ms]
Nov  2 18:49:50.332: INFO: Created: latency-svc-j62d8
Nov  2 18:49:50.336: INFO: Got endpoints: latency-svc-kdn8n [753.862096ms]
Nov  2 18:49:50.379: INFO: Got endpoints: latency-svc-plbdp [749.508829ms]
Nov  2 18:49:50.389: INFO: Created: latency-svc-mzcf6
Nov  2 18:49:50.406: INFO: Created: latency-svc-g5cfp
Nov  2 18:49:50.429: INFO: Got endpoints: latency-svc-lv8t9 [745.87378ms]
Nov  2 18:49:50.457: INFO: Created: latency-svc-445lq
Nov  2 18:49:50.481: INFO: Got endpoints: latency-svc-ljfhf [747.812982ms]
Nov  2 18:49:50.515: INFO: Created: latency-svc-8kj8k
Nov  2 18:49:50.534: INFO: Got endpoints: latency-svc-htsl8 [742.256474ms]
Nov  2 18:49:50.573: INFO: Created: latency-svc-hlznf
Nov  2 18:49:50.578: INFO: Got endpoints: latency-svc-9fbtt [750.325454ms]
Nov  2 18:49:50.601: INFO: Created: latency-svc-4m7nk
Nov  2 18:49:50.627: INFO: Got endpoints: latency-svc-2ks7c [746.403062ms]
Nov  2 18:49:50.649: INFO: Created: latency-svc-zcvbs
Nov  2 18:49:50.683: INFO: Got endpoints: latency-svc-mfk2m [755.973643ms]
Nov  2 18:49:50.705: INFO: Created: latency-svc-qcbwl
Nov  2 18:49:50.729: INFO: Got endpoints: latency-svc-8qp97 [750.331344ms]
Nov  2 18:49:50.752: INFO: Created: latency-svc-s8pk4
Nov  2 18:49:50.787: INFO: Got endpoints: latency-svc-6zcxm [759.560402ms]
Nov  2 18:49:50.826: INFO: Created: latency-svc-sxjdg
Nov  2 18:49:50.898: INFO: Got endpoints: latency-svc-8qd4q [764.967058ms]
Nov  2 18:49:50.898: INFO: Got endpoints: latency-svc-w4m7g [811.441801ms]
Nov  2 18:49:50.925: INFO: Created: latency-svc-nbmlx
Nov  2 18:49:50.939: INFO: Got endpoints: latency-svc-c5p22 [754.100464ms]
Nov  2 18:49:50.942: INFO: Created: latency-svc-lrm92
Nov  2 18:49:50.973: INFO: Created: latency-svc-8n7wv
Nov  2 18:49:50.978: INFO: Got endpoints: latency-svc-twsvb [747.257893ms]
Nov  2 18:49:51.004: INFO: Created: latency-svc-8dvqs
Nov  2 18:49:51.030: INFO: Got endpoints: latency-svc-j62d8 [739.907044ms]
Nov  2 18:49:51.052: INFO: Created: latency-svc-s26bt
Nov  2 18:49:51.077: INFO: Got endpoints: latency-svc-mzcf6 [741.13141ms]
Nov  2 18:49:51.101: INFO: Created: latency-svc-q7rfq
Nov  2 18:49:51.127: INFO: Got endpoints: latency-svc-g5cfp [747.951032ms]
Nov  2 18:49:51.156: INFO: Created: latency-svc-bz9qw
Nov  2 18:49:51.178: INFO: Got endpoints: latency-svc-445lq [749.372985ms]
Nov  2 18:49:51.204: INFO: Created: latency-svc-fvlrv
Nov  2 18:49:51.255: INFO: Got endpoints: latency-svc-8kj8k [773.440847ms]
Nov  2 18:49:51.292: INFO: Got endpoints: latency-svc-hlznf [758.485797ms]
Nov  2 18:49:51.297: INFO: Created: latency-svc-lrspc
Nov  2 18:49:51.324: INFO: Created: latency-svc-vxzlv
Nov  2 18:49:51.328: INFO: Got endpoints: latency-svc-4m7nk [748.761427ms]
Nov  2 18:49:51.385: INFO: Created: latency-svc-zmwjx
Nov  2 18:49:51.389: INFO: Got endpoints: latency-svc-zcvbs [762.314308ms]
Nov  2 18:49:51.424: INFO: Created: latency-svc-p97wr
Nov  2 18:49:51.448: INFO: Got endpoints: latency-svc-qcbwl [764.435385ms]
Nov  2 18:49:51.485: INFO: Got endpoints: latency-svc-s8pk4 [756.565483ms]
Nov  2 18:49:51.485: INFO: Created: latency-svc-5xmgv
Nov  2 18:49:51.512: INFO: Created: latency-svc-68rr5
Nov  2 18:49:51.540: INFO: Got endpoints: latency-svc-sxjdg [752.64111ms]
Nov  2 18:49:51.576: INFO: Created: latency-svc-mvzkh
Nov  2 18:49:51.601: INFO: Got endpoints: latency-svc-nbmlx [703.142888ms]
Nov  2 18:49:51.639: INFO: Got endpoints: latency-svc-lrm92 [740.280123ms]
Nov  2 18:49:51.648: INFO: Created: latency-svc-mzs2v
Nov  2 18:49:51.674: INFO: Created: latency-svc-s4jqb
Nov  2 18:49:51.681: INFO: Got endpoints: latency-svc-8n7wv [741.776554ms]
Nov  2 18:49:51.722: INFO: Created: latency-svc-z926d
Nov  2 18:49:51.732: INFO: Got endpoints: latency-svc-8dvqs [754.480314ms]
Nov  2 18:49:51.767: INFO: Created: latency-svc-c7tm7
Nov  2 18:49:51.783: INFO: Got endpoints: latency-svc-s26bt [752.462422ms]
Nov  2 18:49:51.805: INFO: Created: latency-svc-zrffc
Nov  2 18:49:51.832: INFO: Got endpoints: latency-svc-q7rfq [754.826189ms]
Nov  2 18:49:51.861: INFO: Created: latency-svc-kqbnz
Nov  2 18:49:51.883: INFO: Got endpoints: latency-svc-bz9qw [755.974719ms]
Nov  2 18:49:51.913: INFO: Created: latency-svc-fkpdr
Nov  2 18:49:51.941: INFO: Got endpoints: latency-svc-fvlrv [762.882434ms]
Nov  2 18:49:51.968: INFO: Created: latency-svc-nv88t
Nov  2 18:49:51.978: INFO: Got endpoints: latency-svc-lrspc [723.517341ms]
Nov  2 18:49:51.999: INFO: Created: latency-svc-8qcn8
Nov  2 18:49:52.034: INFO: Got endpoints: latency-svc-vxzlv [741.531829ms]
Nov  2 18:49:52.068: INFO: Created: latency-svc-2f5th
Nov  2 18:49:52.080: INFO: Got endpoints: latency-svc-zmwjx [752.02635ms]
Nov  2 18:49:52.110: INFO: Created: latency-svc-kcrsd
Nov  2 18:49:52.132: INFO: Got endpoints: latency-svc-p97wr [742.526519ms]
Nov  2 18:49:52.174: INFO: Created: latency-svc-sd9lt
Nov  2 18:49:52.179: INFO: Got endpoints: latency-svc-5xmgv [731.625756ms]
Nov  2 18:49:52.203: INFO: Created: latency-svc-dztpr
Nov  2 18:49:52.230: INFO: Got endpoints: latency-svc-68rr5 [744.842657ms]
Nov  2 18:49:52.252: INFO: Created: latency-svc-g6b7w
Nov  2 18:49:52.289: INFO: Got endpoints: latency-svc-mvzkh [748.430498ms]
Nov  2 18:49:52.310: INFO: Created: latency-svc-45hfn
Nov  2 18:49:52.328: INFO: Got endpoints: latency-svc-mzs2v [726.649899ms]
Nov  2 18:49:52.362: INFO: Created: latency-svc-zwg5n
Nov  2 18:49:52.398: INFO: Got endpoints: latency-svc-s4jqb [759.834792ms]
Nov  2 18:49:52.432: INFO: Created: latency-svc-l5dsm
Nov  2 18:49:52.433: INFO: Got endpoints: latency-svc-z926d [752.083509ms]
Nov  2 18:49:52.453: INFO: Created: latency-svc-68llb
Nov  2 18:49:52.479: INFO: Got endpoints: latency-svc-c7tm7 [747.075256ms]
Nov  2 18:49:52.508: INFO: Created: latency-svc-5jmjq
Nov  2 18:49:52.531: INFO: Got endpoints: latency-svc-zrffc [748.262118ms]
Nov  2 18:49:52.552: INFO: Created: latency-svc-dftrs
Nov  2 18:49:52.578: INFO: Got endpoints: latency-svc-kqbnz [745.745694ms]
Nov  2 18:49:52.612: INFO: Created: latency-svc-jxjfw
Nov  2 18:49:52.631: INFO: Got endpoints: latency-svc-fkpdr [747.786244ms]
Nov  2 18:49:52.656: INFO: Created: latency-svc-gchc4
Nov  2 18:49:52.679: INFO: Got endpoints: latency-svc-nv88t [737.77416ms]
Nov  2 18:49:52.705: INFO: Created: latency-svc-qj8cm
Nov  2 18:49:52.730: INFO: Got endpoints: latency-svc-8qcn8 [751.540973ms]
Nov  2 18:49:52.755: INFO: Created: latency-svc-clrd4
Nov  2 18:49:52.779: INFO: Got endpoints: latency-svc-2f5th [744.54712ms]
Nov  2 18:49:52.803: INFO: Created: latency-svc-fffw4
Nov  2 18:49:52.838: INFO: Got endpoints: latency-svc-kcrsd [758.489866ms]
Nov  2 18:49:52.892: INFO: Got endpoints: latency-svc-sd9lt [760.248826ms]
Nov  2 18:49:52.900: INFO: Created: latency-svc-gv7fl
Nov  2 18:49:52.918: INFO: Created: latency-svc-tlhcj
Nov  2 18:49:52.929: INFO: Got endpoints: latency-svc-dztpr [750.007425ms]
Nov  2 18:49:52.962: INFO: Created: latency-svc-mkffz
Nov  2 18:49:52.977: INFO: Got endpoints: latency-svc-g6b7w [747.235851ms]
Nov  2 18:49:53.003: INFO: Created: latency-svc-lw6nt
Nov  2 18:49:53.031: INFO: Got endpoints: latency-svc-45hfn [742.601208ms]
Nov  2 18:49:53.085: INFO: Got endpoints: latency-svc-zwg5n [757.070193ms]
Nov  2 18:49:53.131: INFO: Got endpoints: latency-svc-l5dsm [732.773825ms]
Nov  2 18:49:53.180: INFO: Got endpoints: latency-svc-68llb [746.924658ms]
Nov  2 18:49:53.229: INFO: Got endpoints: latency-svc-5jmjq [749.619989ms]
Nov  2 18:49:53.283: INFO: Got endpoints: latency-svc-dftrs [751.75174ms]
Nov  2 18:49:53.341: INFO: Got endpoints: latency-svc-jxjfw [762.728452ms]
Nov  2 18:49:53.384: INFO: Got endpoints: latency-svc-gchc4 [752.614364ms]
Nov  2 18:49:53.429: INFO: Got endpoints: latency-svc-qj8cm [749.633611ms]
Nov  2 18:49:53.487: INFO: Got endpoints: latency-svc-clrd4 [757.463952ms]
Nov  2 18:49:53.528: INFO: Got endpoints: latency-svc-fffw4 [749.828103ms]
Nov  2 18:49:53.578: INFO: Got endpoints: latency-svc-gv7fl [739.843627ms]
Nov  2 18:49:53.629: INFO: Got endpoints: latency-svc-tlhcj [737.413038ms]
Nov  2 18:49:53.679: INFO: Got endpoints: latency-svc-mkffz [749.03037ms]
Nov  2 18:49:53.730: INFO: Got endpoints: latency-svc-lw6nt [752.456323ms]
Nov  2 18:49:53.730: INFO: Latencies: [61.293912ms 72.709692ms 109.068623ms 112.585482ms 129.372989ms 146.136184ms 176.714375ms 204.814642ms 222.646013ms 244.320901ms 263.665682ms 271.865939ms 284.399906ms 286.069316ms 286.61771ms 290.727949ms 292.865036ms 297.916874ms 304.127383ms 306.097346ms 307.352378ms 312.719786ms 315.45653ms 319.12071ms 320.023787ms 326.544792ms 350.566687ms 353.929388ms 360.241127ms 360.646542ms 361.894796ms 363.477042ms 363.790253ms 365.08796ms 365.125868ms 372.696592ms 373.992552ms 374.655813ms 374.986521ms 378.066508ms 383.597567ms 394.497481ms 395.772919ms 399.622967ms 400.708421ms 400.998062ms 401.066895ms 401.812009ms 403.012537ms 409.1622ms 409.520826ms 413.350625ms 417.913888ms 422.770926ms 428.046175ms 428.215604ms 429.109804ms 433.145533ms 442.000759ms 449.083461ms 506.612868ms 511.686565ms 537.338983ms 560.709888ms 586.876384ms 626.151818ms 656.657022ms 689.267421ms 692.302695ms 698.894642ms 699.853595ms 703.142888ms 712.973612ms 723.325142ms 723.517341ms 726.649899ms 730.692769ms 731.625756ms 732.773825ms 733.610661ms 736.113032ms 737.413038ms 737.625417ms 737.77416ms 737.866521ms 738.743965ms 739.301392ms 739.843627ms 739.885589ms 739.907044ms 740.132259ms 740.175971ms 740.280123ms 741.13141ms 741.32561ms 741.531829ms 741.776554ms 742.256474ms 742.526519ms 742.601208ms 742.752938ms 744.54712ms 744.842657ms 745.697978ms 745.745694ms 745.87378ms 746.283343ms 746.403062ms 746.535634ms 746.924658ms 747.075256ms 747.082002ms 747.234159ms 747.235851ms 747.257893ms 747.658311ms 747.786244ms 747.812982ms 747.951032ms 748.013938ms 748.146543ms 748.262118ms 748.386697ms 748.430498ms 748.473243ms 748.761427ms 748.770482ms 748.934746ms 748.993921ms 749.03037ms 749.097426ms 749.130324ms 749.271529ms 749.372985ms 749.374921ms 749.508829ms 749.522214ms 749.612043ms 749.619989ms 749.633611ms 749.661254ms 749.828103ms 750.007425ms 750.245855ms 750.325454ms 750.331344ms 750.89098ms 751.144519ms 751.221949ms 751.439718ms 751.526881ms 751.540973ms 751.654775ms 751.75174ms 752.02635ms 752.083509ms 752.456323ms 752.462422ms 752.494615ms 752.518266ms 752.614364ms 752.64111ms 752.924137ms 753.009173ms 753.09006ms 753.862096ms 753.934289ms 753.935369ms 754.100464ms 754.160048ms 754.480314ms 754.501175ms 754.807165ms 754.826189ms 755.837396ms 755.973643ms 755.974719ms 756.565483ms 757.070193ms 757.463952ms 758.485797ms 758.489866ms 758.597618ms 758.791127ms 759.399528ms 759.560402ms 759.834792ms 759.85717ms 760.248826ms 760.255831ms 761.252106ms 762.302354ms 762.314308ms 762.728452ms 762.882434ms 764.435385ms 764.967058ms 770.728946ms 773.440847ms 811.441801ms]
Nov  2 18:49:53.730: INFO: 50 %ile: 742.752938ms
Nov  2 18:49:53.730: INFO: 90 %ile: 758.485797ms
Nov  2 18:49:53.730: INFO: 99 %ile: 773.440847ms
Nov  2 18:49:53.730: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:49:53.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2478" for this suite.

• [SLOW TEST:12.039 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":280,"completed":168,"skipped":2776,"failed":0}
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:49:53.766: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-tzjt
STEP: Creating a pod to test atomic-volume-subpath
Nov  2 18:49:54.050: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tzjt" in namespace "subpath-5613" to be "success or failure"
Nov  2 18:49:54.067: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Pending", Reason="", readiness=false. Elapsed: 16.390361ms
Nov  2 18:49:56.082: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031955687s
Nov  2 18:49:58.091: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 4.040483906s
Nov  2 18:50:00.101: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 6.050224872s
Nov  2 18:50:02.110: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 8.059612851s
Nov  2 18:50:04.154: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 10.103794272s
Nov  2 18:50:06.169: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 12.118304568s
Nov  2 18:50:08.177: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 14.126604911s
Nov  2 18:50:10.189: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 16.138226415s
Nov  2 18:50:12.198: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 18.147459575s
Nov  2 18:50:14.206: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 20.155746595s
Nov  2 18:50:16.219: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Running", Reason="", readiness=true. Elapsed: 22.168288482s
Nov  2 18:50:18.229: INFO: Pod "pod-subpath-test-configmap-tzjt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.178637926s
STEP: Saw pod success
Nov  2 18:50:18.229: INFO: Pod "pod-subpath-test-configmap-tzjt" satisfied condition "success or failure"
Nov  2 18:50:18.243: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-subpath-test-configmap-tzjt container test-container-subpath-configmap-tzjt: <nil>
STEP: delete the pod
Nov  2 18:50:18.394: INFO: Waiting for pod pod-subpath-test-configmap-tzjt to disappear
Nov  2 18:50:18.403: INFO: Pod pod-subpath-test-configmap-tzjt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tzjt
Nov  2 18:50:18.403: INFO: Deleting pod "pod-subpath-test-configmap-tzjt" in namespace "subpath-5613"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:50:18.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5613" for this suite.

• [SLOW TEST:24.688 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":280,"completed":169,"skipped":2782,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:50:18.454: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov  2 18:50:18.691: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  2 18:50:18.720: INFO: Waiting for terminating namespaces to be deleted...
Nov  2 18:50:18.730: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-brzmg before test
Nov  2 18:50:18.882: INFO: kube-proxy-gk2s6 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:50:18.882: INFO: csi-cinder-nodeplugin-ubuntu-xqnfj from kube-system started at 2020-11-02 09:26:48 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:50:18.882: INFO: coredns-57f944bd9f-h8sb4 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:50:18.882: INFO: logrotate-vdk6h from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:50:18.882: INFO: user-ssh-keys-agent-wklnz from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:50:18.882: INFO: dashboard-metrics-scraper-59bfc65dc9-mx5wv from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:50:18.882: INFO: node-local-dns-nwqv9 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:50:18.882: INFO: canal-c64t7 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:50:18.882: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-11-02 09:26:48 +0000 UTC (5 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container cinder-csi-plugin ready: true, restart count 2
Nov  2 18:50:18.882: INFO: 	Container csi-attacher ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container csi-provisioner ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container csi-resizer ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container csi-snapshotter ready: true, restart count 0
Nov  2 18:50:18.882: INFO: coredns-57f944bd9f-492kl from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:50:18.882: INFO: dashboard-metrics-scraper-59bfc65dc9-vv6zf from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:50:18.882: INFO: openvpn-client-84ccd8596d-qps5z from kube-system started at 2020-11-02 09:28:26 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  2 18:50:18.882: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:18.882: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:50:18.882: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-dc8qz before test
Nov  2 18:50:19.091: INFO: canal-6x859 from kube-system started at 2020-11-02 09:31:11 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:50:19.091: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:50:19.091: INFO: user-ssh-keys-agent-99zc9 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:50:19.091: INFO: sonobuoy-e2e-job-4da6a1ac755345e8 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container e2e ready: true, restart count 0
Nov  2 18:50:19.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:50:19.091: INFO: kube-proxy-4bdvn from kube-system started at 2020-11-02 09:31:11 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:50:19.091: INFO: node-local-dns-7m96x from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:50:19.091: INFO: csi-cinder-nodeplugin-ubuntu-rwf9k from kube-system started at 2020-11-02 09:31:41 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:50:19.091: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:50:19.091: INFO: logrotate-6plw5 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:50:19.091: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-9c9cl from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:50:19.091: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:50:19.091: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-drfqf before test
Nov  2 18:50:19.153: INFO: canal-l9xkd from kube-system started at 2020-11-02 09:28:06 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:50:19.153: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:50:19.153: INFO: kube-proxy-h49pz from kube-system started at 2020-11-02 09:28:06 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:50:19.153: INFO: csi-cinder-nodeplugin-ubuntu-879qh from kube-system started at 2020-11-02 18:16:57 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:50:19.153: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:50:19.153: INFO: logrotate-28zzm from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:50:19.153: INFO: user-ssh-keys-agent-8898v from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:50:19.153: INFO: node-local-dns-wbdvv from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:50:19.153: INFO: sonobuoy from sonobuoy started at 2020-11-02 17:59:56 +0000 UTC (1 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  2 18:50:19.153: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-h8fmt from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:50:19.153: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:50:19.153: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1643c579cf3bb62d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:50:20.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8718" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":280,"completed":170,"skipped":2793,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:50:20.281: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:50:20.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f" in namespace "downward-api-4781" to be "success or failure"
Nov  2 18:50:20.538: INFO: Pod "downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.771ms
Nov  2 18:50:22.550: INFO: Pod "downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023513887s
Nov  2 18:50:24.559: INFO: Pod "downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03210947s
STEP: Saw pod success
Nov  2 18:50:24.559: INFO: Pod "downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f" satisfied condition "success or failure"
Nov  2 18:50:24.568: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f container client-container: <nil>
STEP: delete the pod
Nov  2 18:50:24.675: INFO: Waiting for pod downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f to disappear
Nov  2 18:50:24.691: INFO: Pod downwardapi-volume-e76b0c79-7f4d-44c4-821a-28abef9cdc2f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:50:24.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4781" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":171,"skipped":2841,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:50:24.799: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1790
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 18:50:25.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6725'
Nov  2 18:50:25.160: INFO: stderr: ""
Nov  2 18:50:25.160: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov  2 18:50:30.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 get pod e2e-test-httpd-pod --namespace=kubectl-6725 -o json'
Nov  2 18:50:30.312: INFO: stderr: ""
Nov  2 18:50:30.312: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"172.25.1.155/32\"\n        },\n        \"creationTimestamp\": \"2020-11-02T18:50:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6725\",\n        \"resourceVersion\": \"165827\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6725/pods/e2e-test-httpd-pod\",\n        \"uid\": \"cfd1051d-0b95-42ee-a13b-425b005b590f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4sfpk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"awesome-shannon-698f584c96-drfqf\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4sfpk\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4sfpk\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-02T18:50:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-02T18:50:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-02T18:50:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-11-02T18:50:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f8511ae455e108b311a24f4b765ae1837197333f33aff8d7795d472a18934e2f\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-11-02T18:50:27Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.15\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.25.1.155\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.25.1.155\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-11-02T18:50:25Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  2 18:50:30.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 replace -f - --namespace=kubectl-6725'
Nov  2 18:50:30.592: INFO: stderr: ""
Nov  2 18:50:30.592: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1795
Nov  2 18:50:30.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete pods e2e-test-httpd-pod --namespace=kubectl-6725'
Nov  2 18:50:32.982: INFO: stderr: ""
Nov  2 18:50:32.982: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:50:32.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6725" for this suite.

• [SLOW TEST:8.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1786
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":280,"completed":172,"skipped":2856,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:50:33.016: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:50:33.263: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:50:37.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5041" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":280,"completed":173,"skipped":2865,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:50:37.382: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:50:37.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3" in namespace "downward-api-6763" to be "success or failure"
Nov  2 18:50:37.688: INFO: Pod "downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.475028ms
Nov  2 18:50:39.696: INFO: Pod "downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021923259s
Nov  2 18:50:41.705: INFO: Pod "downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030841773s
STEP: Saw pod success
Nov  2 18:50:41.705: INFO: Pod "downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3" satisfied condition "success or failure"
Nov  2 18:50:41.713: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3 container client-container: <nil>
STEP: delete the pod
Nov  2 18:50:41.769: INFO: Waiting for pod downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3 to disappear
Nov  2 18:50:41.775: INFO: Pod downwardapi-volume-d1dce509-88f4-42f3-911f-3a31c442fbf3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:50:41.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6763" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":174,"skipped":2873,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:50:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2743
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov  2 18:50:42.889: INFO: Pod name wrapped-volume-race-5bda01f6-7582-4246-bd4f-dd4a2836a3a5: Found 0 pods out of 5
Nov  2 18:50:47.902: INFO: Pod name wrapped-volume-race-5bda01f6-7582-4246-bd4f-dd4a2836a3a5: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5bda01f6-7582-4246-bd4f-dd4a2836a3a5 in namespace emptydir-wrapper-2743, will wait for the garbage collector to delete the pods
Nov  2 18:51:00.057: INFO: Deleting ReplicationController wrapped-volume-race-5bda01f6-7582-4246-bd4f-dd4a2836a3a5 took: 23.168241ms
Nov  2 18:51:00.657: INFO: Terminating ReplicationController wrapped-volume-race-5bda01f6-7582-4246-bd4f-dd4a2836a3a5 pods took: 600.282012ms
STEP: Creating RC which spawns configmap-volume pods
Nov  2 18:51:11.254: INFO: Pod name wrapped-volume-race-90fec3fa-00c2-423f-a79e-d5d080a0e166: Found 0 pods out of 5
Nov  2 18:51:16.268: INFO: Pod name wrapped-volume-race-90fec3fa-00c2-423f-a79e-d5d080a0e166: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-90fec3fa-00c2-423f-a79e-d5d080a0e166 in namespace emptydir-wrapper-2743, will wait for the garbage collector to delete the pods
Nov  2 18:51:28.411: INFO: Deleting ReplicationController wrapped-volume-race-90fec3fa-00c2-423f-a79e-d5d080a0e166 took: 27.028039ms
Nov  2 18:51:29.011: INFO: Terminating ReplicationController wrapped-volume-race-90fec3fa-00c2-423f-a79e-d5d080a0e166 pods took: 600.299456ms
STEP: Creating RC which spawns configmap-volume pods
Nov  2 18:51:37.083: INFO: Pod name wrapped-volume-race-8506691a-fd68-4375-832f-85cc1926f80a: Found 1 pods out of 5
Nov  2 18:51:42.105: INFO: Pod name wrapped-volume-race-8506691a-fd68-4375-832f-85cc1926f80a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8506691a-fd68-4375-832f-85cc1926f80a in namespace emptydir-wrapper-2743, will wait for the garbage collector to delete the pods
Nov  2 18:51:54.245: INFO: Deleting ReplicationController wrapped-volume-race-8506691a-fd68-4375-832f-85cc1926f80a took: 30.965571ms
Nov  2 18:51:54.846: INFO: Terminating ReplicationController wrapped-volume-race-8506691a-fd68-4375-832f-85cc1926f80a pods took: 600.495133ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:52:12.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2743" for this suite.

• [SLOW TEST:90.437 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":280,"completed":175,"skipped":2904,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:52:12.246: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4781
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4435
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:52:19.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8404" for this suite.
STEP: Destroying namespace "nsdeletetest-4781" for this suite.
Nov  2 18:52:19.134: INFO: Namespace nsdeletetest-4781 was already deleted
STEP: Destroying namespace "nsdeletetest-4435" for this suite.

• [SLOW TEST:6.906 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":280,"completed":176,"skipped":2932,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:52:19.152: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4555.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4555.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4555.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4555.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4555.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 67.19.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.19.67_udp@PTR;check="$$(dig +tcp +noall +answer +search 67.19.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.19.67_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4555.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4555.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4555.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4555.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4555.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4555.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 67.19.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.19.67_udp@PTR;check="$$(dig +tcp +noall +answer +search 67.19.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.19.67_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 18:52:23.639: INFO: Unable to read wheezy_udp@dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:23.686: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:23.702: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:23.716: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:24.254: INFO: Unable to read jessie_udp@dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:24.272: INFO: Unable to read jessie_tcp@dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:24.295: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:24.322: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local from pod dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd: the server could not find the requested resource (get pods dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd)
Nov  2 18:52:24.825: INFO: Lookups using dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd failed for: [wheezy_udp@dns-test-service.dns-4555.svc.cluster.local wheezy_tcp@dns-test-service.dns-4555.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local jessie_udp@dns-test-service.dns-4555.svc.cluster.local jessie_tcp@dns-test-service.dns-4555.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4555.svc.cluster.local]

Nov  2 18:52:31.559: INFO: DNS probes using dns-4555/dns-test-84546935-e1a0-4fd6-ad12-f5624d9d16cd succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:52:31.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4555" for this suite.

• [SLOW TEST:12.686 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":280,"completed":177,"skipped":2934,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:52:31.839: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov  2 18:52:36.867: INFO: Successfully updated pod "labelsupdate7300b0e9-b19a-4be7-bf7d-e35d1f4b2cfa"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:52:38.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6548" for this suite.

• [SLOW TEST:7.194 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":178,"skipped":2940,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:52:39.035: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5952
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-9b4368f9-a81f-4b5d-b942-4d6004b1d384
STEP: Creating a pod to test consume secrets
Nov  2 18:52:39.348: INFO: Waiting up to 5m0s for pod "pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e" in namespace "secrets-5952" to be "success or failure"
Nov  2 18:52:39.363: INFO: Pod "pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.084371ms
Nov  2 18:52:41.371: INFO: Pod "pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02339168s
Nov  2 18:52:43.380: INFO: Pod "pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032476783s
STEP: Saw pod success
Nov  2 18:52:43.380: INFO: Pod "pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e" satisfied condition "success or failure"
Nov  2 18:52:43.389: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e container secret-env-test: <nil>
STEP: delete the pod
Nov  2 18:52:43.524: INFO: Waiting for pod pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e to disappear
Nov  2 18:52:43.531: INFO: Pod pod-secrets-c645d4a9-ea32-4dbe-95a4-9723c2d41f2e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:52:43.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5952" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":280,"completed":179,"skipped":2960,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:52:43.555: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6851
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:53:09.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6851" for this suite.

• [SLOW TEST:25.916 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":280,"completed":180,"skipped":2961,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:53:09.472: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9137
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov  2 18:53:13.800: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-9137 PodName:pod-sharedvolume-0aa09c4c-435e-49dc-9c3e-e69490f9efc7 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 18:53:13.800: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 18:53:14.345: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:53:14.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9137" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":280,"completed":181,"skipped":3011,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:53:14.370: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9363
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  2 18:53:17.662: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:53:17.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9363" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":280,"completed":182,"skipped":3017,"failed":0}

------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:53:17.727: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:53:18.889: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  2 18:53:20.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939998, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939998, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939999, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739939998, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:53:23.982: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:53:23.995: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:53:25.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4014" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:7.455 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":280,"completed":183,"skipped":3017,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:53:25.184: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-2095/configmap-test-d3766ab9-f148-4869-82bc-7afcd7a180f2
STEP: Creating a pod to test consume configMaps
Nov  2 18:53:25.447: INFO: Waiting up to 5m0s for pod "pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f" in namespace "configmap-2095" to be "success or failure"
Nov  2 18:53:25.467: INFO: Pod "pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.147549ms
Nov  2 18:53:27.479: INFO: Pod "pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031678152s
Nov  2 18:53:29.487: INFO: Pod "pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040055928s
STEP: Saw pod success
Nov  2 18:53:29.487: INFO: Pod "pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f" satisfied condition "success or failure"
Nov  2 18:53:29.494: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f container env-test: <nil>
STEP: delete the pod
Nov  2 18:53:29.576: INFO: Waiting for pod pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f to disappear
Nov  2 18:53:29.584: INFO: Pod pod-configmaps-741f906d-b21f-4c49-ade7-af1a360d9d4f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:53:29.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2095" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":280,"completed":184,"skipped":3059,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:53:29.620: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-959
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-c95fb3a0-8f28-4e3b-9ac3-a66dd4466029
STEP: Creating configMap with name cm-test-opt-upd-2bf27af7-7dd7-4c4d-b797-4b447d6f3df1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c95fb3a0-8f28-4e3b-9ac3-a66dd4466029
STEP: Updating configmap cm-test-opt-upd-2bf27af7-7dd7-4c4d-b797-4b447d6f3df1
STEP: Creating configMap with name cm-test-opt-create-e19abe11-2165-4d34-93ae-af22acaf73b6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:54:41.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-959" for this suite.

• [SLOW TEST:72.127 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":185,"skipped":3117,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:54:41.747: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:54:42.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-498" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":280,"completed":186,"skipped":3132,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:54:42.031: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3625
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-3625
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3625
STEP: Creating statefulset with conflicting port in namespace statefulset-3625
STEP: Waiting until pod test-pod will start running in namespace statefulset-3625
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3625
Nov  2 18:54:46.384: INFO: Observed stateful pod in namespace: statefulset-3625, name: ss-0, uid: c2fd4566-bfa6-454d-86a0-d0e61996676b, status phase: Pending. Waiting for statefulset controller to delete.
Nov  2 18:54:46.565: INFO: Observed stateful pod in namespace: statefulset-3625, name: ss-0, uid: c2fd4566-bfa6-454d-86a0-d0e61996676b, status phase: Failed. Waiting for statefulset controller to delete.
Nov  2 18:54:46.587: INFO: Observed stateful pod in namespace: statefulset-3625, name: ss-0, uid: c2fd4566-bfa6-454d-86a0-d0e61996676b, status phase: Failed. Waiting for statefulset controller to delete.
Nov  2 18:54:46.597: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3625
STEP: Removing pod with conflicting port in namespace statefulset-3625
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3625 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov  2 18:54:50.752: INFO: Deleting all statefulset in ns statefulset-3625
Nov  2 18:54:50.767: INFO: Scaling statefulset ss to 0
Nov  2 18:55:00.810: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 18:55:00.817: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:00.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3625" for this suite.

• [SLOW TEST:18.848 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":280,"completed":187,"skipped":3158,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:00.879: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1196
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:55:01.108: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  2 18:55:04.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-1196 create -f -'
Nov  2 18:55:05.809: INFO: stderr: ""
Nov  2 18:55:05.809: INFO: stdout: "e2e-test-crd-publish-openapi-7363-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  2 18:55:05.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-1196 delete e2e-test-crd-publish-openapi-7363-crds test-cr'
Nov  2 18:55:05.994: INFO: stderr: ""
Nov  2 18:55:05.994: INFO: stdout: "e2e-test-crd-publish-openapi-7363-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov  2 18:55:05.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-1196 apply -f -'
Nov  2 18:55:06.247: INFO: stderr: ""
Nov  2 18:55:06.247: INFO: stdout: "e2e-test-crd-publish-openapi-7363-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  2 18:55:06.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-1196 delete e2e-test-crd-publish-openapi-7363-crds test-cr'
Nov  2 18:55:06.380: INFO: stderr: ""
Nov  2 18:55:06.380: INFO: stdout: "e2e-test-crd-publish-openapi-7363-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  2 18:55:06.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-7363-crds'
Nov  2 18:55:06.709: INFO: stderr: ""
Nov  2 18:55:06.709: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7363-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:10.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1196" for this suite.

• [SLOW TEST:9.618 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":280,"completed":188,"skipped":3175,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:10.500: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1102 18:55:20.960790      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  2 18:55:20.960: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:20.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7603" for this suite.

• [SLOW TEST:10.486 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":280,"completed":189,"skipped":3193,"failed":0}
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:20.986: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4065
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-90f45bcd-a756-4e76-94ec-1366e263a109
STEP: Creating a pod to test consume configMaps
Nov  2 18:55:21.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644" in namespace "configmap-4065" to be "success or failure"
Nov  2 18:55:21.271: INFO: Pod "pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644": Phase="Pending", Reason="", readiness=false. Elapsed: 7.577401ms
Nov  2 18:55:23.278: INFO: Pod "pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015263116s
Nov  2 18:55:25.292: INFO: Pod "pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029234627s
STEP: Saw pod success
Nov  2 18:55:25.292: INFO: Pod "pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644" satisfied condition "success or failure"
Nov  2 18:55:25.300: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:55:25.403: INFO: Waiting for pod pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644 to disappear
Nov  2 18:55:25.420: INFO: Pod pod-configmaps-f35a45de-1af7-4234-a36e-58d5817af644 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:25.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4065" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":190,"skipped":3193,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:25.456: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 18:55:25.763: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95" in namespace "projected-2517" to be "success or failure"
Nov  2 18:55:25.776: INFO: Pod "downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95": Phase="Pending", Reason="", readiness=false. Elapsed: 13.51393ms
Nov  2 18:55:27.785: INFO: Pod "downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022348402s
Nov  2 18:55:29.795: INFO: Pod "downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031935187s
STEP: Saw pod success
Nov  2 18:55:29.795: INFO: Pod "downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95" satisfied condition "success or failure"
Nov  2 18:55:29.802: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95 container client-container: <nil>
STEP: delete the pod
Nov  2 18:55:29.859: INFO: Waiting for pod downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95 to disappear
Nov  2 18:55:29.866: INFO: Pod downwardapi-volume-91a48b1a-7066-47cc-bb81-cae475d8fc95 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:29.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2517" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":191,"skipped":3217,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:29.895: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-3796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:46
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:30.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-3796" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":280,"completed":192,"skipped":3225,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:30.154: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov  2 18:55:30.395: INFO: Waiting up to 5m0s for pod "downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1" in namespace "downward-api-9059" to be "success or failure"
Nov  2 18:55:30.401: INFO: Pod "downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037985ms
Nov  2 18:55:32.409: INFO: Pod "downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014757417s
Nov  2 18:55:34.422: INFO: Pod "downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027095943s
STEP: Saw pod success
Nov  2 18:55:34.422: INFO: Pod "downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1" satisfied condition "success or failure"
Nov  2 18:55:34.429: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1 container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:55:34.517: INFO: Waiting for pod downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1 to disappear
Nov  2 18:55:34.528: INFO: Pod downward-api-807ce191-4d18-46a0-8407-09a39ae0e8b1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:34.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9059" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":280,"completed":193,"skipped":3261,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:34.559: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-cdef00a9-d502-495a-90cb-2c930d43e43f
STEP: Creating a pod to test consume configMaps
Nov  2 18:55:34.816: INFO: Waiting up to 5m0s for pod "pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf" in namespace "configmap-7769" to be "success or failure"
Nov  2 18:55:34.829: INFO: Pod "pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.947652ms
Nov  2 18:55:36.844: INFO: Pod "pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02783466s
Nov  2 18:55:38.852: INFO: Pod "pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035778462s
STEP: Saw pod success
Nov  2 18:55:38.852: INFO: Pod "pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf" satisfied condition "success or failure"
Nov  2 18:55:38.860: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:55:38.917: INFO: Waiting for pod pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf to disappear
Nov  2 18:55:38.923: INFO: Pod pod-configmaps-dcf9945f-9494-4082-a6fd-2aeabc87fccf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:38.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7769" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":194,"skipped":3268,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:38.961: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3052
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  2 18:55:39.290: INFO: Waiting up to 5m0s for pod "pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3" in namespace "emptydir-3052" to be "success or failure"
Nov  2 18:55:39.303: INFO: Pod "pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.081278ms
Nov  2 18:55:41.311: INFO: Pod "pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020680083s
Nov  2 18:55:43.320: INFO: Pod "pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029169832s
STEP: Saw pod success
Nov  2 18:55:43.320: INFO: Pod "pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3" satisfied condition "success or failure"
Nov  2 18:55:43.328: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3 container test-container: <nil>
STEP: delete the pod
Nov  2 18:55:43.426: INFO: Waiting for pod pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3 to disappear
Nov  2 18:55:43.433: INFO: Pod pod-9adfaad7-ed3b-4e87-ba49-d761ca9e14d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:43.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3052" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":195,"skipped":3272,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:43.470: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:178
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:55:43.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3401" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":280,"completed":196,"skipped":3294,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:55:43.820: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9020
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:56:00.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9020" for this suite.

• [SLOW TEST:16.348 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":280,"completed":197,"skipped":3296,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:56:00.169: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov  2 18:56:00.401: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  2 18:56:00.432: INFO: Waiting for terminating namespaces to be deleted...
Nov  2 18:56:00.447: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-brzmg before test
Nov  2 18:56:00.588: INFO: dashboard-metrics-scraper-59bfc65dc9-mx5wv from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.588: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:56:00.588: INFO: node-local-dns-nwqv9 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.588: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:56:00.588: INFO: canal-c64t7 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.588: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:56:00.588: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:56:00.588: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-11-02 09:26:48 +0000 UTC (5 container statuses recorded)
Nov  2 18:56:00.588: INFO: 	Container cinder-csi-plugin ready: true, restart count 2
Nov  2 18:56:00.588: INFO: 	Container csi-attacher ready: true, restart count 0
Nov  2 18:56:00.588: INFO: 	Container csi-provisioner ready: true, restart count 0
Nov  2 18:56:00.588: INFO: 	Container csi-resizer ready: true, restart count 0
Nov  2 18:56:00.588: INFO: 	Container csi-snapshotter ready: true, restart count 0
Nov  2 18:56:00.588: INFO: coredns-57f944bd9f-492kl from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.588: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:56:00.589: INFO: dashboard-metrics-scraper-59bfc65dc9-vv6zf from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 18:56:00.589: INFO: openvpn-client-84ccd8596d-qps5z from kube-system started at 2020-11-02 09:28:26 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  2 18:56:00.589: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  2 18:56:00.589: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:56:00.589: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:56:00.589: INFO: logrotate-vdk6h from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:56:00.589: INFO: user-ssh-keys-agent-wklnz from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:56:00.589: INFO: kube-proxy-gk2s6 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:56:00.589: INFO: csi-cinder-nodeplugin-ubuntu-xqnfj from kube-system started at 2020-11-02 09:26:48 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:56:00.589: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:56:00.589: INFO: coredns-57f944bd9f-h8sb4 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.589: INFO: 	Container coredns ready: true, restart count 0
Nov  2 18:56:00.589: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-dc8qz before test
Nov  2 18:56:00.790: INFO: canal-6x859 from kube-system started at 2020-11-02 09:31:11 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.790: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:56:00.790: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:56:00.790: INFO: user-ssh-keys-agent-99zc9 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.790: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:56:00.790: INFO: sonobuoy-e2e-job-4da6a1ac755345e8 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.790: INFO: 	Container e2e ready: true, restart count 0
Nov  2 18:56:00.790: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:56:00.790: INFO: kube-proxy-4bdvn from kube-system started at 2020-11-02 09:31:11 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.790: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:56:00.790: INFO: node-local-dns-7m96x from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.791: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:56:00.791: INFO: csi-cinder-nodeplugin-ubuntu-rwf9k from kube-system started at 2020-11-02 09:31:41 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.791: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:56:00.791: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:56:00.791: INFO: logrotate-6plw5 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.791: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 18:56:00.791: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-9c9cl from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:56:00.791: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:56:00.791: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-drfqf before test
Nov  2 18:56:00.887: INFO: user-ssh-keys-agent-8898v from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.887: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 18:56:00.887: INFO: sonobuoy from sonobuoy started at 2020-11-02 17:59:56 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.887: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  2 18:56:00.887: INFO: kube-proxy-h49pz from kube-system started at 2020-11-02 09:28:06 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.887: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 18:56:00.888: INFO: node-local-dns-wbdvv from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.888: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 18:56:00.888: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-h8fmt from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.888: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 18:56:00.888: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 18:56:00.888: INFO: canal-l9xkd from kube-system started at 2020-11-02 09:28:06 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.888: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 18:56:00.888: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 18:56:00.888: INFO: csi-cinder-nodeplugin-ubuntu-879qh from kube-system started at 2020-11-02 18:16:57 +0000 UTC (2 container statuses recorded)
Nov  2 18:56:00.888: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 18:56:00.888: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 18:56:00.888: INFO: logrotate-28zzm from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 18:56:00.888: INFO: 	Container logrotate ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: verifying the node has the label node awesome-shannon-698f584c96-brzmg
STEP: verifying the node has the label node awesome-shannon-698f584c96-dc8qz
STEP: verifying the node has the label node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.016: INFO: Pod canal-6x859 requesting resource cpu=250m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.016: INFO: Pod canal-c64t7 requesting resource cpu=250m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.016: INFO: Pod canal-l9xkd requesting resource cpu=250m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.016: INFO: Pod coredns-57f944bd9f-492kl requesting resource cpu=100m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.017: INFO: Pod coredns-57f944bd9f-h8sb4 requesting resource cpu=100m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.017: INFO: Pod csi-cinder-controllerplugin-0 requesting resource cpu=0m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.017: INFO: Pod csi-cinder-nodeplugin-ubuntu-879qh requesting resource cpu=0m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.017: INFO: Pod csi-cinder-nodeplugin-ubuntu-rwf9k requesting resource cpu=0m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.017: INFO: Pod csi-cinder-nodeplugin-ubuntu-xqnfj requesting resource cpu=0m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.017: INFO: Pod kube-proxy-4bdvn requesting resource cpu=75m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.017: INFO: Pod kube-proxy-gk2s6 requesting resource cpu=75m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.018: INFO: Pod kube-proxy-h49pz requesting resource cpu=75m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.018: INFO: Pod logrotate-28zzm requesting resource cpu=75m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.018: INFO: Pod logrotate-6plw5 requesting resource cpu=75m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.018: INFO: Pod logrotate-vdk6h requesting resource cpu=75m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.018: INFO: Pod node-local-dns-7m96x requesting resource cpu=25m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.018: INFO: Pod node-local-dns-nwqv9 requesting resource cpu=25m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.019: INFO: Pod node-local-dns-wbdvv requesting resource cpu=25m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.019: INFO: Pod openvpn-client-84ccd8596d-qps5z requesting resource cpu=30m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.019: INFO: Pod user-ssh-keys-agent-8898v requesting resource cpu=0m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.019: INFO: Pod user-ssh-keys-agent-99zc9 requesting resource cpu=0m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.019: INFO: Pod user-ssh-keys-agent-wklnz requesting resource cpu=0m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.019: INFO: Pod dashboard-metrics-scraper-59bfc65dc9-mx5wv requesting resource cpu=50m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.019: INFO: Pod dashboard-metrics-scraper-59bfc65dc9-vv6zf requesting resource cpu=50m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.020: INFO: Pod sonobuoy requesting resource cpu=0m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.020: INFO: Pod sonobuoy-e2e-job-4da6a1ac755345e8 requesting resource cpu=0m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.020: INFO: Pod sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4 requesting resource cpu=0m on Node awesome-shannon-698f584c96-brzmg
Nov  2 18:56:01.020: INFO: Pod sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-9c9cl requesting resource cpu=0m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.020: INFO: Pod sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-h8fmt requesting resource cpu=0m on Node awesome-shannon-698f584c96-drfqf
STEP: Starting Pods to consume most of the cluster CPU.
Nov  2 18:56:01.021: INFO: Creating a pod which consumes cpu=2362m on Node awesome-shannon-698f584c96-dc8qz
Nov  2 18:56:01.058: INFO: Creating a pod which consumes cpu=2362m on Node awesome-shannon-698f584c96-drfqf
Nov  2 18:56:01.189: INFO: Creating a pod which consumes cpu=2131m on Node awesome-shannon-698f584c96-brzmg
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a.1643c5c96f808d00], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4587/filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a to awesome-shannon-698f584c96-drfqf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a.1643c5c9c2266726], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a.1643c5c9d07e6f8b], Reason = [Created], Message = [Created container filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a.1643c5c9de4c817f], Reason = [Started], Message = [Started container filler-pod-239e2ca9-6fdc-4179-8e39-c138ac860f7a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9.1643c5c9654a7926], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4587/filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9 to awesome-shannon-698f584c96-dc8qz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9.1643c5c9b206ddc2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9.1643c5c9bbc50205], Reason = [Created], Message = [Created container filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9.1643c5c9c8b07cb9], Reason = [Started], Message = [Started container filler-pod-a1f95569-4152-47f4-9db8-6e231014e7b9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a65f9639-3223-48d6-b812-f905352b9a32.1643c5c97104b40a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4587/filler-pod-a65f9639-3223-48d6-b812-f905352b9a32 to awesome-shannon-698f584c96-brzmg]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a65f9639-3223-48d6-b812-f905352b9a32.1643c5c9c0cddb91], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a65f9639-3223-48d6-b812-f905352b9a32.1643c5c9cb088df1], Reason = [Created], Message = [Created container filler-pod-a65f9639-3223-48d6-b812-f905352b9a32]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a65f9639-3223-48d6-b812-f905352b9a32.1643c5c9d7a1c0af], Reason = [Started], Message = [Started container filler-pod-a65f9639-3223-48d6-b812-f905352b9a32]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1643c5ca6326209b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node awesome-shannon-698f584c96-brzmg
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node awesome-shannon-698f584c96-dc8qz
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node awesome-shannon-698f584c96-drfqf
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:56:06.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4587" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:6.323 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":280,"completed":198,"skipped":3303,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:56:06.494: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-2d9117f0-d471-4190-a322-92dfa4dca160 in namespace container-probe-7611
Nov  2 18:56:10.801: INFO: Started pod liveness-2d9117f0-d471-4190-a322-92dfa4dca160 in namespace container-probe-7611
STEP: checking the pod's current state and verifying that restartCount is present
Nov  2 18:56:10.810: INFO: Initial restart count of pod liveness-2d9117f0-d471-4190-a322-92dfa4dca160 is 0
Nov  2 18:56:30.926: INFO: Restart count of pod container-probe-7611/liveness-2d9117f0-d471-4190-a322-92dfa4dca160 is now 1 (20.116165259s elapsed)
Nov  2 18:56:51.031: INFO: Restart count of pod container-probe-7611/liveness-2d9117f0-d471-4190-a322-92dfa4dca160 is now 2 (40.220811824s elapsed)
Nov  2 18:57:09.112: INFO: Restart count of pod container-probe-7611/liveness-2d9117f0-d471-4190-a322-92dfa4dca160 is now 3 (58.301531902s elapsed)
Nov  2 18:57:29.203: INFO: Restart count of pod container-probe-7611/liveness-2d9117f0-d471-4190-a322-92dfa4dca160 is now 4 (1m18.393151933s elapsed)
Nov  2 18:57:49.297: INFO: Restart count of pod container-probe-7611/liveness-2d9117f0-d471-4190-a322-92dfa4dca160 is now 5 (1m38.486944313s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:57:49.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7611" for this suite.

• [SLOW TEST:102.868 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":280,"completed":199,"skipped":3311,"failed":0}
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:57:49.362: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:57:53.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9679" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":200,"skipped":3311,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:57:53.862: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  2 18:57:54.120: INFO: Waiting up to 5m0s for pod "pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c" in namespace "emptydir-3808" to be "success or failure"
Nov  2 18:57:54.133: INFO: Pod "pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.484294ms
Nov  2 18:57:56.144: INFO: Pod "pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024540379s
Nov  2 18:57:58.158: INFO: Pod "pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038421959s
STEP: Saw pod success
Nov  2 18:57:58.158: INFO: Pod "pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c" satisfied condition "success or failure"
Nov  2 18:57:58.169: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c container test-container: <nil>
STEP: delete the pod
Nov  2 18:57:58.391: INFO: Waiting for pod pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c to disappear
Nov  2 18:57:58.400: INFO: Pod pod-9bee35fc-f16d-4d7c-8e42-e58e9eefbc7c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:57:58.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3808" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":201,"skipped":3316,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:57:58.429: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-aba600a1-c580-49b3-a2c2-fd48df16ac22
STEP: Creating a pod to test consume secrets
Nov  2 18:57:58.749: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df" in namespace "projected-3928" to be "success or failure"
Nov  2 18:57:58.758: INFO: Pod "pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df": Phase="Pending", Reason="", readiness=false. Elapsed: 9.570343ms
Nov  2 18:58:00.767: INFO: Pod "pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018819711s
Nov  2 18:58:02.781: INFO: Pod "pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032224067s
STEP: Saw pod success
Nov  2 18:58:02.781: INFO: Pod "pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df" satisfied condition "success or failure"
Nov  2 18:58:02.788: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  2 18:58:02.873: INFO: Waiting for pod pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df to disappear
Nov  2 18:58:02.882: INFO: Pod pod-projected-secrets-fd0dc7f9-6752-4356-89f1-3811f029e2df no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:02.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3928" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":202,"skipped":3379,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:02.907: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Nov  2 18:58:03.140: INFO: Waiting up to 5m0s for pod "downward-api-83cf4086-350e-4eaa-975b-54b3570e8392" in namespace "downward-api-6911" to be "success or failure"
Nov  2 18:58:03.158: INFO: Pod "downward-api-83cf4086-350e-4eaa-975b-54b3570e8392": Phase="Pending", Reason="", readiness=false. Elapsed: 17.40766ms
Nov  2 18:58:05.166: INFO: Pod "downward-api-83cf4086-350e-4eaa-975b-54b3570e8392": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025414522s
Nov  2 18:58:07.181: INFO: Pod "downward-api-83cf4086-350e-4eaa-975b-54b3570e8392": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041128822s
STEP: Saw pod success
Nov  2 18:58:07.181: INFO: Pod "downward-api-83cf4086-350e-4eaa-975b-54b3570e8392" satisfied condition "success or failure"
Nov  2 18:58:07.188: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downward-api-83cf4086-350e-4eaa-975b-54b3570e8392 container dapi-container: <nil>
STEP: delete the pod
Nov  2 18:58:07.246: INFO: Waiting for pod downward-api-83cf4086-350e-4eaa-975b-54b3570e8392 to disappear
Nov  2 18:58:07.253: INFO: Pod downward-api-83cf4086-350e-4eaa-975b-54b3570e8392 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:07.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6911" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":280,"completed":203,"skipped":3380,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:07.286: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  2 18:58:07.554: INFO: Waiting up to 5m0s for pod "pod-929f4705-4304-464c-bceb-5da1ec0c0d02" in namespace "emptydir-3913" to be "success or failure"
Nov  2 18:58:07.563: INFO: Pod "pod-929f4705-4304-464c-bceb-5da1ec0c0d02": Phase="Pending", Reason="", readiness=false. Elapsed: 9.244955ms
Nov  2 18:58:09.572: INFO: Pod "pod-929f4705-4304-464c-bceb-5da1ec0c0d02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018149704s
Nov  2 18:58:11.580: INFO: Pod "pod-929f4705-4304-464c-bceb-5da1ec0c0d02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026463057s
STEP: Saw pod success
Nov  2 18:58:11.581: INFO: Pod "pod-929f4705-4304-464c-bceb-5da1ec0c0d02" satisfied condition "success or failure"
Nov  2 18:58:11.588: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-929f4705-4304-464c-bceb-5da1ec0c0d02 container test-container: <nil>
STEP: delete the pod
Nov  2 18:58:11.635: INFO: Waiting for pod pod-929f4705-4304-464c-bceb-5da1ec0c0d02 to disappear
Nov  2 18:58:11.648: INFO: Pod pod-929f4705-4304-464c-bceb-5da1ec0c0d02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:11.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3913" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":204,"skipped":3390,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:11.694: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9417
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:58:11.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 version'
Nov  2 18:58:12.040: INFO: stderr: ""
Nov  2 18:58:12.040: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.9\", GitCommit:\"4fb7ed12476d57b8437ada90b4f93b17ffaeed99\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:18:16Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.9\", GitCommit:\"4fb7ed12476d57b8437ada90b4f93b17ffaeed99\", GitTreeState:\"clean\", BuildDate:\"2020-07-15T16:10:45Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:12.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9417" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":280,"completed":205,"skipped":3390,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:12.072: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8242
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  2 18:58:12.328: INFO: Waiting up to 5m0s for pod "pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d" in namespace "emptydir-8242" to be "success or failure"
Nov  2 18:58:12.335: INFO: Pod "pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.86631ms
Nov  2 18:58:14.347: INFO: Pod "pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019163995s
Nov  2 18:58:16.356: INFO: Pod "pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028222925s
STEP: Saw pod success
Nov  2 18:58:16.357: INFO: Pod "pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d" satisfied condition "success or failure"
Nov  2 18:58:16.370: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d container test-container: <nil>
STEP: delete the pod
Nov  2 18:58:16.448: INFO: Waiting for pod pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d to disappear
Nov  2 18:58:16.461: INFO: Pod pod-2e83a07f-2ee9-4837-bad7-a6ebd6aead8d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:16.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8242" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":206,"skipped":3425,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:16.489: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-1217689b-fcdf-425a-9ea0-dc1c9adc129c
STEP: Creating a pod to test consume configMaps
Nov  2 18:58:16.745: INFO: Waiting up to 5m0s for pod "pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4" in namespace "configmap-3822" to be "success or failure"
Nov  2 18:58:16.766: INFO: Pod "pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.173245ms
Nov  2 18:58:18.775: INFO: Pod "pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030101586s
Nov  2 18:58:20.783: INFO: Pod "pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037592672s
STEP: Saw pod success
Nov  2 18:58:20.783: INFO: Pod "pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4" satisfied condition "success or failure"
Nov  2 18:58:20.790: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 18:58:20.846: INFO: Waiting for pod pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4 to disappear
Nov  2 18:58:20.855: INFO: Pod pod-configmaps-292c79ba-aff7-4470-9466-81992d13c6e4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:20.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3822" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":207,"skipped":3425,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:20.896: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  2 18:58:21.139: INFO: Waiting up to 5m0s for pod "pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a" in namespace "emptydir-5302" to be "success or failure"
Nov  2 18:58:21.159: INFO: Pod "pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a": Phase="Pending", Reason="", readiness=false. Elapsed: 19.474708ms
Nov  2 18:58:23.168: INFO: Pod "pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028857108s
Nov  2 18:58:25.176: INFO: Pod "pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037058233s
STEP: Saw pod success
Nov  2 18:58:25.176: INFO: Pod "pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a" satisfied condition "success or failure"
Nov  2 18:58:25.184: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a container test-container: <nil>
STEP: delete the pod
Nov  2 18:58:25.240: INFO: Waiting for pod pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a to disappear
Nov  2 18:58:25.250: INFO: Pod pod-2d5c33b7-188a-4265-b5e4-700fe415dd9a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:25.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5302" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":208,"skipped":3440,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:25.280: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2639
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 18:58:26.053: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 18:58:28.078: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940306, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940306, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940306, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940306, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 18:58:31.112: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:58:31.122: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4043-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:32.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2639" for this suite.
STEP: Destroying namespace "webhook-2639-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.434 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":280,"completed":209,"skipped":3440,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:32.714: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9866
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:44.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9866" for this suite.

• [SLOW TEST:11.501 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":280,"completed":210,"skipped":3447,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:44.216: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7679
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:58:44.532: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  2 18:58:48.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-7679 create -f -'
Nov  2 18:58:49.259: INFO: stderr: ""
Nov  2 18:58:49.259: INFO: stdout: "e2e-test-crd-publish-openapi-4853-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  2 18:58:49.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-7679 delete e2e-test-crd-publish-openapi-4853-crds test-cr'
Nov  2 18:58:49.398: INFO: stderr: ""
Nov  2 18:58:49.398: INFO: stdout: "e2e-test-crd-publish-openapi-4853-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov  2 18:58:49.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-7679 apply -f -'
Nov  2 18:58:49.671: INFO: stderr: ""
Nov  2 18:58:49.671: INFO: stdout: "e2e-test-crd-publish-openapi-4853-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  2 18:58:49.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 --namespace=crd-publish-openapi-7679 delete e2e-test-crd-publish-openapi-4853-crds test-cr'
Nov  2 18:58:49.800: INFO: stderr: ""
Nov  2 18:58:49.800: INFO: stdout: "e2e-test-crd-publish-openapi-4853-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov  2 18:58:49.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 explain e2e-test-crd-publish-openapi-4853-crds'
Nov  2 18:58:50.115: INFO: stderr: ""
Nov  2 18:58:50.116: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4853-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:53.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7679" for this suite.

• [SLOW TEST:9.638 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":280,"completed":211,"skipped":3504,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:53.855: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:58:54.077: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  2 18:58:59.091: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  2 18:58:59.091: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov  2 18:58:59.165: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4573 /apis/apps/v1/namespaces/deployment-4573/deployments/test-cleanup-deployment 65462101-09bc-470c-809b-f51f695b32be 170881 1 2020-11-02 18:58:59 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b57488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov  2 18:58:59.190: INFO: New ReplicaSet "test-cleanup-deployment-55ffc6b7b6" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6  deployment-4573 /apis/apps/v1/namespaces/deployment-4573/replicasets/test-cleanup-deployment-55ffc6b7b6 e3a8efdd-4626-4256-9ab1-f13857d6f143 170883 1 2020-11-02 18:58:59 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 65462101-09bc-470c-809b-f51f695b32be 0xc004b57c37 0xc004b57c38}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55ffc6b7b6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b57ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:58:59.190: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  2 18:58:59.191: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-4573 /apis/apps/v1/namespaces/deployment-4573/replicasets/test-cleanup-controller 673bb65d-d645-46d5-89a6-50a9c961609b 170882 1 2020-11-02 18:58:54 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 65462101-09bc-470c-809b-f51f695b32be 0xc004b57b67 0xc004b57b68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004b57bc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  2 18:58:59.198: INFO: Pod "test-cleanup-controller-w9zbp" is available:
&Pod{ObjectMeta:{test-cleanup-controller-w9zbp test-cleanup-controller- deployment-4573 /api/v1/namespaces/deployment-4573/pods/test-cleanup-controller-w9zbp 7efa1e4c-e8af-4c39-a21d-85f7af93cccb 170859 0 2020-11-02 18:58:54 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:172.25.1.193/32] [{apps/v1 ReplicaSet test-cleanup-controller 673bb65d-d645-46d5-89a6-50a9c961609b 0xc004b1c337 0xc004b1c338}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-b9dph,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-b9dph,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-b9dph,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:58:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:58:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:58:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:58:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:172.25.1.193,StartTime:2020-11-02 18:58:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 18:58:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b0fd52d8c3f4ef5dd0ea03093342b6c1205c6092cb1efddc1bfdf141642e9df9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.193,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 18:58:59.198: INFO: Pod "test-cleanup-deployment-55ffc6b7b6-xfzz5" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6-xfzz5 test-cleanup-deployment-55ffc6b7b6- deployment-4573 /api/v1/namespaces/deployment-4573/pods/test-cleanup-deployment-55ffc6b7b6-xfzz5 a22b1182-b5f0-4729-8dd5-8ada45f99b02 170888 0 2020-11-02 18:58:59 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-55ffc6b7b6 e3a8efdd-4626-4256-9ab1-f13857d6f143 0xc004b1c617 0xc004b1c618}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-b9dph,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-b9dph,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-b9dph,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 18:58:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:58:59.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4573" for this suite.

• [SLOW TEST:5.434 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":280,"completed":212,"skipped":3518,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:58:59.289: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2712
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-88cfd2d7-4560-4534-90b4-16ec947be288
STEP: Creating configMap with name cm-test-opt-upd-87c849ce-2071-4588-bf71-8aa837e8f56d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-88cfd2d7-4560-4534-90b4-16ec947be288
STEP: Updating configmap cm-test-opt-upd-87c849ce-2071-4588-bf71-8aa837e8f56d
STEP: Creating configMap with name cm-test-opt-create-8df2949d-1abc-4020-95e3-205fd14f392e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:59:08.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2712" for this suite.

• [SLOW TEST:8.952 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":213,"skipped":3529,"failed":0}
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:59:08.241: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 18:59:08.526: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  2 18:59:08.547: INFO: Number of nodes with available pods: 0
Nov  2 18:59:08.547: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  2 18:59:08.601: INFO: Number of nodes with available pods: 0
Nov  2 18:59:08.601: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:09.610: INFO: Number of nodes with available pods: 0
Nov  2 18:59:09.610: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:10.610: INFO: Number of nodes with available pods: 0
Nov  2 18:59:10.617: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:11.609: INFO: Number of nodes with available pods: 1
Nov  2 18:59:11.609: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  2 18:59:11.668: INFO: Number of nodes with available pods: 0
Nov  2 18:59:11.670: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  2 18:59:11.768: INFO: Number of nodes with available pods: 0
Nov  2 18:59:11.768: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:12.776: INFO: Number of nodes with available pods: 0
Nov  2 18:59:12.776: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:13.775: INFO: Number of nodes with available pods: 0
Nov  2 18:59:13.775: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:14.777: INFO: Number of nodes with available pods: 0
Nov  2 18:59:14.777: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:15.777: INFO: Number of nodes with available pods: 0
Nov  2 18:59:15.777: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:16.775: INFO: Number of nodes with available pods: 0
Nov  2 18:59:16.775: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:17.781: INFO: Number of nodes with available pods: 1
Nov  2 18:59:17.781: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1335, will wait for the garbage collector to delete the pods
Nov  2 18:59:17.872: INFO: Deleting DaemonSet.extensions daemon-set took: 20.104448ms
Nov  2 18:59:17.973: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.370197ms
Nov  2 18:59:22.783: INFO: Number of nodes with available pods: 0
Nov  2 18:59:22.783: INFO: Number of running nodes: 0, number of available pods: 0
Nov  2 18:59:22.797: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1335/daemonsets","resourceVersion":"171144"},"items":null}

Nov  2 18:59:22.805: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1335/pods","resourceVersion":"171144"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:59:22.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1335" for this suite.

• [SLOW TEST:14.648 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":280,"completed":214,"skipped":3529,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:59:22.889: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  2 18:59:23.246: INFO: Number of nodes with available pods: 0
Nov  2 18:59:23.246: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:24.274: INFO: Number of nodes with available pods: 0
Nov  2 18:59:24.274: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:25.272: INFO: Number of nodes with available pods: 0
Nov  2 18:59:25.272: INFO: Node awesome-shannon-698f584c96-brzmg is running more than one daemon pod
Nov  2 18:59:26.278: INFO: Number of nodes with available pods: 3
Nov  2 18:59:26.278: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  2 18:59:26.341: INFO: Number of nodes with available pods: 2
Nov  2 18:59:26.343: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:59:27.361: INFO: Number of nodes with available pods: 2
Nov  2 18:59:27.361: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:59:28.365: INFO: Number of nodes with available pods: 2
Nov  2 18:59:28.365: INFO: Node awesome-shannon-698f584c96-dc8qz is running more than one daemon pod
Nov  2 18:59:29.372: INFO: Number of nodes with available pods: 3
Nov  2 18:59:29.372: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7556, will wait for the garbage collector to delete the pods
Nov  2 18:59:29.485: INFO: Deleting DaemonSet.extensions daemon-set took: 38.143152ms
Nov  2 18:59:29.585: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.225238ms
Nov  2 18:59:40.793: INFO: Number of nodes with available pods: 0
Nov  2 18:59:40.793: INFO: Number of running nodes: 0, number of available pods: 0
Nov  2 18:59:40.800: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7556/daemonsets","resourceVersion":"171335"},"items":null}

Nov  2 18:59:40.806: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7556/pods","resourceVersion":"171335"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 18:59:40.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7556" for this suite.

• [SLOW TEST:17.992 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":280,"completed":215,"skipped":3546,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 18:59:40.882: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-3505
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  2 18:59:41.098: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  2 19:00:03.383: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.197:8080/dial?request=hostname&protocol=udp&host=172.25.0.32&port=8081&tries=1'] Namespace:pod-network-test-3505 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:00:03.383: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:00:03.917: INFO: Waiting for responses: map[]
Nov  2 19:00:03.929: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.197:8080/dial?request=hostname&protocol=udp&host=172.25.2.89&port=8081&tries=1'] Namespace:pod-network-test-3505 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:00:03.929: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:00:04.549: INFO: Waiting for responses: map[]
Nov  2 19:00:04.558: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.197:8080/dial?request=hostname&protocol=udp&host=172.25.1.196&port=8081&tries=1'] Namespace:pod-network-test-3505 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:00:04.558: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:00:05.095: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:00:05.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3505" for this suite.

• [SLOW TEST:24.265 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":216,"skipped":3557,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:00:05.147: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-7178
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:00:05.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-7178" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":280,"completed":217,"skipped":3582,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:00:05.629: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Nov  2 19:00:05.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 create -f - --namespace=kubectl-3279'
Nov  2 19:00:06.247: INFO: stderr: ""
Nov  2 19:00:06.247: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Nov  2 19:00:07.257: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 19:00:07.257: INFO: Found 0 / 1
Nov  2 19:00:08.262: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 19:00:08.262: INFO: Found 0 / 1
Nov  2 19:00:09.257: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 19:00:09.257: INFO: Found 1 / 1
Nov  2 19:00:09.257: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  2 19:00:09.275: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 19:00:09.275: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  2 19:00:09.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 patch pod agnhost-master-58tfj --namespace=kubectl-3279 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  2 19:00:09.419: INFO: stderr: ""
Nov  2 19:00:09.419: INFO: stdout: "pod/agnhost-master-58tfj patched\n"
STEP: checking annotations
Nov  2 19:00:09.432: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  2 19:00:09.432: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:00:09.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3279" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":280,"completed":218,"skipped":3633,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:00:09.518: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-secret-9zkm
STEP: Creating a pod to test atomic-volume-subpath
Nov  2 19:00:09.824: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9zkm" in namespace "subpath-6814" to be "success or failure"
Nov  2 19:00:09.852: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Pending", Reason="", readiness=false. Elapsed: 27.780365ms
Nov  2 19:00:11.898: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073673751s
Nov  2 19:00:13.910: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.085498133s
Nov  2 19:00:15.918: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 6.093572207s
Nov  2 19:00:17.927: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 8.103133821s
Nov  2 19:00:19.935: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 10.110734675s
Nov  2 19:00:21.947: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 12.123190281s
Nov  2 19:00:23.957: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 14.133263042s
Nov  2 19:00:25.965: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 16.141178069s
Nov  2 19:00:27.974: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 18.149464489s
Nov  2 19:00:29.983: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 20.158699176s
Nov  2 19:00:31.992: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Running", Reason="", readiness=true. Elapsed: 22.167581043s
Nov  2 19:00:33.999: INFO: Pod "pod-subpath-test-secret-9zkm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.174960738s
STEP: Saw pod success
Nov  2 19:00:33.999: INFO: Pod "pod-subpath-test-secret-9zkm" satisfied condition "success or failure"
Nov  2 19:00:34.006: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-subpath-test-secret-9zkm container test-container-subpath-secret-9zkm: <nil>
STEP: delete the pod
Nov  2 19:00:34.204: INFO: Waiting for pod pod-subpath-test-secret-9zkm to disappear
Nov  2 19:00:34.225: INFO: Pod pod-subpath-test-secret-9zkm no longer exists
STEP: Deleting pod pod-subpath-test-secret-9zkm
Nov  2 19:00:34.225: INFO: Deleting pod "pod-subpath-test-secret-9zkm" in namespace "subpath-6814"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:00:34.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6814" for this suite.

• [SLOW TEST:24.753 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":280,"completed":219,"skipped":3635,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:00:34.271: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-15435480-d9c8-486a-b7aa-f5347c119d36
STEP: Creating a pod to test consume secrets
Nov  2 19:00:34.518: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7" in namespace "projected-9513" to be "success or failure"
Nov  2 19:00:34.531: INFO: Pod "pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.744898ms
Nov  2 19:00:36.543: INFO: Pod "pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024955583s
Nov  2 19:00:38.562: INFO: Pod "pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043337112s
STEP: Saw pod success
Nov  2 19:00:38.562: INFO: Pod "pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7" satisfied condition "success or failure"
Nov  2 19:00:38.570: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  2 19:00:38.631: INFO: Waiting for pod pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7 to disappear
Nov  2 19:00:38.648: INFO: Pod pod-projected-secrets-9fbdd94a-72e6-48e5-98c0-990bce02bcd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:00:38.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9513" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":220,"skipped":3642,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:00:38.678: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4372.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4372.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4372.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4372.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 19:00:43.161: INFO: DNS probes using dns-test-cc29a1b0-0318-4325-8dd6-17dee37589ed succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4372.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4372.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4372.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4372.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 19:00:47.463: INFO: DNS probes using dns-test-d9fd9733-4d7d-464d-ad30-2130447123bf succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4372.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4372.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4372.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4372.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  2 19:00:51.705: INFO: File wheezy_udp@dns-test-service-3.dns-4372.svc.cluster.local from pod  dns-4372/dns-test-3b1c1b42-4096-49e0-821a-4109bd8146e7 contains '' instead of '10.240.19.9'
Nov  2 19:00:51.794: INFO: Lookups using dns-4372/dns-test-3b1c1b42-4096-49e0-821a-4109bd8146e7 failed for: [wheezy_udp@dns-test-service-3.dns-4372.svc.cluster.local]

Nov  2 19:00:56.910: INFO: DNS probes using dns-test-3b1c1b42-4096-49e0-821a-4109bd8146e7 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:00:57.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4372" for this suite.

• [SLOW TEST:18.390 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":280,"completed":221,"skipped":3682,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:00:57.069: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:00:57.276: INFO: Creating ReplicaSet my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae
Nov  2 19:00:57.295: INFO: Pod name my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae: Found 0 pods out of 1
Nov  2 19:01:02.319: INFO: Pod name my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae: Found 1 pods out of 1
Nov  2 19:01:02.319: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae" is running
Nov  2 19:01:02.328: INFO: Pod "my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae-wc4lt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 19:00:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 19:00:59 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 19:00:59 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-11-02 19:00:57 +0000 UTC Reason: Message:}])
Nov  2 19:01:02.328: INFO: Trying to dial the pod
Nov  2 19:01:07.451: INFO: Controller my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae: Got expected result from replica 1 [my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae-wc4lt]: "my-hostname-basic-d15d410c-25f8-4284-abf8-0d39b2991eae-wc4lt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:07.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3341" for this suite.

• [SLOW TEST:10.412 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":222,"skipped":3692,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:07.485: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-downwardapi-rgqg
STEP: Creating a pod to test atomic-volume-subpath
Nov  2 19:01:07.753: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rgqg" in namespace "subpath-6318" to be "success or failure"
Nov  2 19:01:07.760: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.596262ms
Nov  2 19:01:09.770: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016429297s
Nov  2 19:01:11.778: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 4.024955718s
Nov  2 19:01:13.788: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 6.034802543s
Nov  2 19:01:15.797: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 8.043022419s
Nov  2 19:01:17.806: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 10.052400315s
Nov  2 19:01:19.817: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 12.063352723s
Nov  2 19:01:21.825: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 14.071261299s
Nov  2 19:01:23.833: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 16.079874485s
Nov  2 19:01:25.844: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 18.090483444s
Nov  2 19:01:27.854: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 20.100976503s
Nov  2 19:01:29.862: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Running", Reason="", readiness=true. Elapsed: 22.108414442s
Nov  2 19:01:31.870: INFO: Pod "pod-subpath-test-downwardapi-rgqg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.116496186s
STEP: Saw pod success
Nov  2 19:01:31.870: INFO: Pod "pod-subpath-test-downwardapi-rgqg" satisfied condition "success or failure"
Nov  2 19:01:31.878: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-subpath-test-downwardapi-rgqg container test-container-subpath-downwardapi-rgqg: <nil>
STEP: delete the pod
Nov  2 19:01:32.042: INFO: Waiting for pod pod-subpath-test-downwardapi-rgqg to disappear
Nov  2 19:01:32.052: INFO: Pod pod-subpath-test-downwardapi-rgqg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rgqg
Nov  2 19:01:32.052: INFO: Deleting pod "pod-subpath-test-downwardapi-rgqg" in namespace "subpath-6318"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:32.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6318" for this suite.

• [SLOW TEST:24.614 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":280,"completed":223,"skipped":3715,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:32.100: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Nov  2 19:01:36.990: INFO: Successfully updated pod "annotationupdate032f94d4-4abb-464e-bfd8-2e27b8715776"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:39.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9694" for this suite.

• [SLOW TEST:6.988 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":224,"skipped":3737,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:39.089: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  2 19:01:39.387: INFO: Waiting up to 5m0s for pod "pod-8262c698-dbd4-41c7-93c3-386ef398e3bc" in namespace "emptydir-7120" to be "success or failure"
Nov  2 19:01:39.405: INFO: Pod "pod-8262c698-dbd4-41c7-93c3-386ef398e3bc": Phase="Pending", Reason="", readiness=false. Elapsed: 17.411312ms
Nov  2 19:01:41.413: INFO: Pod "pod-8262c698-dbd4-41c7-93c3-386ef398e3bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025139133s
Nov  2 19:01:43.420: INFO: Pod "pod-8262c698-dbd4-41c7-93c3-386ef398e3bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032505032s
STEP: Saw pod success
Nov  2 19:01:43.420: INFO: Pod "pod-8262c698-dbd4-41c7-93c3-386ef398e3bc" satisfied condition "success or failure"
Nov  2 19:01:43.429: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-8262c698-dbd4-41c7-93c3-386ef398e3bc container test-container: <nil>
STEP: delete the pod
Nov  2 19:01:43.485: INFO: Waiting for pod pod-8262c698-dbd4-41c7-93c3-386ef398e3bc to disappear
Nov  2 19:01:43.493: INFO: Pod pod-8262c698-dbd4-41c7-93c3-386ef398e3bc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:43.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7120" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":225,"skipped":3738,"failed":0}
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:43.516: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override command
Nov  2 19:01:43.759: INFO: Waiting up to 5m0s for pod "client-containers-6e4b3123-af29-4565-9160-2b60cc750174" in namespace "containers-7992" to be "success or failure"
Nov  2 19:01:43.784: INFO: Pod "client-containers-6e4b3123-af29-4565-9160-2b60cc750174": Phase="Pending", Reason="", readiness=false. Elapsed: 25.001787ms
Nov  2 19:01:45.794: INFO: Pod "client-containers-6e4b3123-af29-4565-9160-2b60cc750174": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034955657s
Nov  2 19:01:47.803: INFO: Pod "client-containers-6e4b3123-af29-4565-9160-2b60cc750174": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043936349s
STEP: Saw pod success
Nov  2 19:01:47.803: INFO: Pod "client-containers-6e4b3123-af29-4565-9160-2b60cc750174" satisfied condition "success or failure"
Nov  2 19:01:47.810: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod client-containers-6e4b3123-af29-4565-9160-2b60cc750174 container test-container: <nil>
STEP: delete the pod
Nov  2 19:01:47.857: INFO: Waiting for pod client-containers-6e4b3123-af29-4565-9160-2b60cc750174 to disappear
Nov  2 19:01:47.865: INFO: Pod client-containers-6e4b3123-af29-4565-9160-2b60cc750174 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:47.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7992" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":280,"completed":226,"skipped":3741,"failed":0}
SSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:47.919: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:01:48.168: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-ed4c92d4-ae0f-454b-9988-b2a86f8ab876" in namespace "security-context-test-4924" to be "success or failure"
Nov  2 19:01:48.179: INFO: Pod "busybox-privileged-false-ed4c92d4-ae0f-454b-9988-b2a86f8ab876": Phase="Pending", Reason="", readiness=false. Elapsed: 11.78833ms
Nov  2 19:01:50.187: INFO: Pod "busybox-privileged-false-ed4c92d4-ae0f-454b-9988-b2a86f8ab876": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019148416s
Nov  2 19:01:52.195: INFO: Pod "busybox-privileged-false-ed4c92d4-ae0f-454b-9988-b2a86f8ab876": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027170346s
Nov  2 19:01:52.195: INFO: Pod "busybox-privileged-false-ed4c92d4-ae0f-454b-9988-b2a86f8ab876" satisfied condition "success or failure"
Nov  2 19:01:52.259: INFO: Got logs for pod "busybox-privileged-false-ed4c92d4-ae0f-454b-9988-b2a86f8ab876": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:52.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4924" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":227,"skipped":3744,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:52.291: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name secret-emptykey-test-aeac0254-d49e-4473-b2a4-e32ee2aa147a
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:52.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7637" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":280,"completed":228,"skipped":3758,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:52.579: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4000
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 19:01:52.822: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8" in namespace "downward-api-4000" to be "success or failure"
Nov  2 19:01:52.834: INFO: Pod "downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.255028ms
Nov  2 19:01:54.842: INFO: Pod "downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020162861s
Nov  2 19:01:56.853: INFO: Pod "downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031436272s
STEP: Saw pod success
Nov  2 19:01:56.853: INFO: Pod "downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8" satisfied condition "success or failure"
Nov  2 19:01:56.861: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8 container client-container: <nil>
STEP: delete the pod
Nov  2 19:01:56.932: INFO: Waiting for pod downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8 to disappear
Nov  2 19:01:56.950: INFO: Pod downwardapi-volume-ffe26d68-7197-473c-bd3f-6ceeaef749b8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:01:56.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4000" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":229,"skipped":3776,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:01:57.009: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's args
Nov  2 19:01:57.299: INFO: Waiting up to 5m0s for pod "var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7" in namespace "var-expansion-4581" to be "success or failure"
Nov  2 19:01:57.323: INFO: Pod "var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.105762ms
Nov  2 19:01:59.332: INFO: Pod "var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032539852s
Nov  2 19:02:01.340: INFO: Pod "var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04102331s
STEP: Saw pod success
Nov  2 19:02:01.340: INFO: Pod "var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7" satisfied condition "success or failure"
Nov  2 19:02:01.350: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7 container dapi-container: <nil>
STEP: delete the pod
Nov  2 19:02:01.440: INFO: Waiting for pod var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7 to disappear
Nov  2 19:02:01.451: INFO: Pod var-expansion-92b9bc42-c6d8-4f86-bf8e-54ae6a1ed3c7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:01.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4581" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":280,"completed":230,"skipped":3796,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:01.477: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8486
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov  2 19:02:01.747: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:02.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8486" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":280,"completed":231,"skipped":3802,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:02.819: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
Nov  2 19:02:03.647: INFO: created pod pod-service-account-defaultsa
Nov  2 19:02:03.647: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  2 19:02:03.670: INFO: created pod pod-service-account-mountsa
Nov  2 19:02:03.670: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  2 19:02:03.705: INFO: created pod pod-service-account-nomountsa
Nov  2 19:02:03.705: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  2 19:02:03.725: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  2 19:02:03.726: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  2 19:02:03.779: INFO: created pod pod-service-account-mountsa-mountspec
Nov  2 19:02:03.779: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  2 19:02:03.810: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  2 19:02:03.810: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  2 19:02:03.827: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  2 19:02:03.827: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  2 19:02:03.887: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  2 19:02:03.887: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  2 19:02:03.902: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  2 19:02:03.902: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:03.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9720" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":280,"completed":232,"skipped":3828,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:03.967: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-297e873e-ad4f-41e8-85e1-c5cd55359ad5
STEP: Creating a pod to test consume configMaps
Nov  2 19:02:04.229: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4" in namespace "projected-7414" to be "success or failure"
Nov  2 19:02:04.248: INFO: Pod "pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.511669ms
Nov  2 19:02:06.261: INFO: Pod "pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031917186s
Nov  2 19:02:08.269: INFO: Pod "pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040509908s
STEP: Saw pod success
Nov  2 19:02:08.270: INFO: Pod "pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4" satisfied condition "success or failure"
Nov  2 19:02:08.278: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 19:02:08.367: INFO: Waiting for pod pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4 to disappear
Nov  2 19:02:08.383: INFO: Pod pod-projected-configmaps-006bf80d-a0b4-4a97-940d-c4ab23eac8a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:08.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7414" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":233,"skipped":3849,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:08.410: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Starting the proxy
Nov  2 19:02:08.657: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-142776444 proxy --unix-socket=/tmp/kubectl-proxy-unix777598435/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:08.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4390" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":280,"completed":234,"skipped":3856,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:08.766: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1525
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 19:02:08.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8298'
Nov  2 19:02:09.098: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  2 19:02:09.098: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov  2 19:02:09.129: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-88tmg]
Nov  2 19:02:09.129: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-88tmg" in namespace "kubectl-8298" to be "running and ready"
Nov  2 19:02:09.156: INFO: Pod "e2e-test-httpd-rc-88tmg": Phase="Pending", Reason="", readiness=false. Elapsed: 26.74198ms
Nov  2 19:02:11.165: INFO: Pod "e2e-test-httpd-rc-88tmg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035774192s
Nov  2 19:02:13.174: INFO: Pod "e2e-test-httpd-rc-88tmg": Phase="Running", Reason="", readiness=true. Elapsed: 4.044288272s
Nov  2 19:02:13.174: INFO: Pod "e2e-test-httpd-rc-88tmg" satisfied condition "running and ready"
Nov  2 19:02:13.174: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-88tmg]
Nov  2 19:02:13.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 logs rc/e2e-test-httpd-rc --namespace=kubectl-8298'
Nov  2 19:02:13.379: INFO: stderr: ""
Nov  2 19:02:13.379: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.25.1.215. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.25.1.215. Set the 'ServerName' directive globally to suppress this message\n[Mon Nov 02 19:02:11.246374 2020] [mpm_event:notice] [pid 1:tid 139885254048616] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Nov 02 19:02:11.246424 2020] [core:notice] [pid 1:tid 139885254048616] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
Nov  2 19:02:13.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete rc e2e-test-httpd-rc --namespace=kubectl-8298'
Nov  2 19:02:13.495: INFO: stderr: ""
Nov  2 19:02:13.495: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:13.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8298" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run rc should create an rc from an image  [Conformance]","total":280,"completed":235,"skipped":3874,"failed":0}
S
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:13.556: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-2358, will wait for the garbage collector to delete the pods
Nov  2 19:02:17.908: INFO: Deleting Job.batch foo took: 19.97208ms
Nov  2 19:02:18.008: INFO: Terminating Job.batch foo pods took: 100.299665ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:02:51.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2358" for this suite.

• [SLOW TEST:37.602 seconds]
[sig-apps] Job
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":280,"completed":236,"skipped":3875,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:02:51.159: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8405
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:03:04.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8405" for this suite.

• [SLOW TEST:13.460 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":280,"completed":237,"skipped":3892,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:03:04.620: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:04.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1105" for this suite.

• [SLOW TEST:60.286 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":280,"completed":238,"skipped":3904,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:04.906: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  2 19:04:05.221: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5810 /api/v1/namespaces/watch-5810/configmaps/e2e-watch-test-resource-version 11cab08e-67e6-4185-b421-32ce792f37dd 173625 0 2020-11-02 19:04:05 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  2 19:04:05.221: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5810 /api/v1/namespaces/watch-5810/configmaps/e2e-watch-test-resource-version 11cab08e-67e6-4185-b421-32ce792f37dd 173627 0 2020-11-02 19:04:05 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:05.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5810" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":280,"completed":239,"skipped":3919,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:05.250: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 19:04:06.130: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 19:04:08.179: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940646, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940646, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940646, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940646, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 19:04:11.222: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:22.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9830" for this suite.
STEP: Destroying namespace "webhook-9830-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:17.021 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":280,"completed":240,"skipped":3951,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:22.272: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4415
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  2 19:04:22.572: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4415 /api/v1/namespaces/watch-4415/configmaps/e2e-watch-test-label-changed bde10f0a-4961-4bc2-962d-d57c680215e1 173800 0 2020-11-02 19:04:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  2 19:04:22.572: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4415 /api/v1/namespaces/watch-4415/configmaps/e2e-watch-test-label-changed bde10f0a-4961-4bc2-962d-d57c680215e1 173802 0 2020-11-02 19:04:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  2 19:04:22.573: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4415 /api/v1/namespaces/watch-4415/configmaps/e2e-watch-test-label-changed bde10f0a-4961-4bc2-962d-d57c680215e1 173803 0 2020-11-02 19:04:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  2 19:04:32.693: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4415 /api/v1/namespaces/watch-4415/configmaps/e2e-watch-test-label-changed bde10f0a-4961-4bc2-962d-d57c680215e1 173885 0 2020-11-02 19:04:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  2 19:04:32.694: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4415 /api/v1/namespaces/watch-4415/configmaps/e2e-watch-test-label-changed bde10f0a-4961-4bc2-962d-d57c680215e1 173886 0 2020-11-02 19:04:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  2 19:04:32.694: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4415 /api/v1/namespaces/watch-4415/configmaps/e2e-watch-test-label-changed bde10f0a-4961-4bc2-962d-d57c680215e1 173888 0 2020-11-02 19:04:22 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:32.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4415" for this suite.

• [SLOW TEST:10.449 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":280,"completed":241,"skipped":3958,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:32.721: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3994
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run default
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1489
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  2 19:04:32.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3994'
Nov  2 19:04:33.072: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  2 19:04:33.072: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1495
Nov  2 19:04:35.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 delete deployment e2e-test-httpd-deployment --namespace=kubectl-3994'
Nov  2 19:04:35.221: INFO: stderr: ""
Nov  2 19:04:35.221: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:35.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3994" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run default should create an rc or deployment from an image  [Conformance]","total":280,"completed":242,"skipped":4015,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:35.247: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4568
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting the proxy server
Nov  2 19:04:35.466: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-142776444 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:35.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4568" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":280,"completed":243,"skipped":4018,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:35.574: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2307
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Nov  2 19:04:35.797: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:04:57.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2307" for this suite.

• [SLOW TEST:21.592 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":280,"completed":244,"skipped":4024,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:04:57.167: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7595
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-47f64a1d-acf9-4165-bd2f-b77514afffe9
STEP: Creating a pod to test consume secrets
Nov  2 19:04:57.457: INFO: Waiting up to 5m0s for pod "pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a" in namespace "secrets-7595" to be "success or failure"
Nov  2 19:04:57.474: INFO: Pod "pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.159907ms
Nov  2 19:04:59.486: INFO: Pod "pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028240462s
Nov  2 19:05:01.499: INFO: Pod "pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041656339s
STEP: Saw pod success
Nov  2 19:05:01.499: INFO: Pod "pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a" satisfied condition "success or failure"
Nov  2 19:05:01.510: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a container secret-volume-test: <nil>
STEP: delete the pod
Nov  2 19:05:01.735: INFO: Waiting for pod pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a to disappear
Nov  2 19:05:01.743: INFO: Pod pod-secrets-1674c1b9-1b35-40d3-a568-03b17f5c117a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:01.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7595" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":245,"skipped":4038,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:01.788: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6346
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:05:02.025: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6346" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":280,"completed":246,"skipped":4064,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:03.148: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:19.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1834" for this suite.

• [SLOW TEST:16.579 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":280,"completed":247,"skipped":4083,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:19.730: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  2 19:05:20.040: INFO: Waiting up to 5m0s for pod "pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616" in namespace "emptydir-2152" to be "success or failure"
Nov  2 19:05:20.060: INFO: Pod "pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616": Phase="Pending", Reason="", readiness=false. Elapsed: 19.609058ms
Nov  2 19:05:22.074: INFO: Pod "pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033751979s
Nov  2 19:05:24.081: INFO: Pod "pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041265268s
STEP: Saw pod success
Nov  2 19:05:24.081: INFO: Pod "pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616" satisfied condition "success or failure"
Nov  2 19:05:24.089: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616 container test-container: <nil>
STEP: delete the pod
Nov  2 19:05:24.151: INFO: Waiting for pod pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616 to disappear
Nov  2 19:05:24.160: INFO: Pod pod-8fee2e91-b2a9-44a4-b2af-069bf7aec616 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:24.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2152" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":248,"skipped":4132,"failed":0}
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:24.205: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:05:24.456: INFO: (0) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.608438ms)
Nov  2 19:05:24.504: INFO: (1) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 47.724808ms)
Nov  2 19:05:24.520: INFO: (2) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.735206ms)
Nov  2 19:05:24.532: INFO: (3) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.749789ms)
Nov  2 19:05:24.552: INFO: (4) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.7693ms)
Nov  2 19:05:24.566: INFO: (5) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.755076ms)
Nov  2 19:05:24.580: INFO: (6) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.236118ms)
Nov  2 19:05:24.608: INFO: (7) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 28.03771ms)
Nov  2 19:05:24.623: INFO: (8) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.455695ms)
Nov  2 19:05:24.640: INFO: (9) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.049509ms)
Nov  2 19:05:24.662: INFO: (10) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.014008ms)
Nov  2 19:05:24.675: INFO: (11) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.690434ms)
Nov  2 19:05:24.691: INFO: (12) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.475282ms)
Nov  2 19:05:24.705: INFO: (13) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.549499ms)
Nov  2 19:05:24.718: INFO: (14) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.735083ms)
Nov  2 19:05:24.739: INFO: (15) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.331231ms)
Nov  2 19:05:24.756: INFO: (16) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.620363ms)
Nov  2 19:05:24.768: INFO: (17) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.069792ms)
Nov  2 19:05:24.783: INFO: (18) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.866487ms)
Nov  2 19:05:24.797: INFO: (19) /api/v1/nodes/awesome-shannon-698f584c96-drfqf:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.152167ms)
[AfterEach] version v1
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:24.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8010" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":280,"completed":249,"skipped":4137,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:24.820: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 19:05:25.618: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 19:05:27.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940725, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940725, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940725, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940725, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 19:05:30.688: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:05:30.700: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:31.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5548" for this suite.
STEP: Destroying namespace "webhook-5548-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.407 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":280,"completed":250,"skipped":4137,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:32.229: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-9258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  2 19:05:32.996: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  2 19:05:35.018: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940733, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940733, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940733, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940732, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 19:05:38.063: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:05:38.072: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:39.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9258" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:7.785 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":280,"completed":251,"skipped":4148,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:40.014: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 19:05:40.770: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 19:05:42.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940740, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940740, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940740, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739940740, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 19:05:45.829: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:05:45.838: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-971-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:47.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4291" for this suite.
STEP: Destroying namespace "webhook-4291-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.666 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":280,"completed":252,"skipped":4148,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:47.683: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1037
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 19:05:47.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1" in namespace "projected-1037" to be "success or failure"
Nov  2 19:05:47.928: INFO: Pod "downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.45234ms
Nov  2 19:05:49.937: INFO: Pod "downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019695053s
Nov  2 19:05:51.953: INFO: Pod "downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034980401s
STEP: Saw pod success
Nov  2 19:05:51.953: INFO: Pod "downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1" satisfied condition "success or failure"
Nov  2 19:05:51.966: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1 container client-container: <nil>
STEP: delete the pod
Nov  2 19:05:52.052: INFO: Waiting for pod downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1 to disappear
Nov  2 19:05:52.068: INFO: Pod downwardapi-volume-882556ca-2ffe-4ab4-9be4-d90ddefd53a1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:05:52.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1037" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":253,"skipped":4200,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:05:52.100: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1344
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Nov  2 19:05:52.338: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  2 19:05:52.385: INFO: Waiting for terminating namespaces to be deleted...
Nov  2 19:05:52.393: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-brzmg before test
Nov  2 19:05:52.543: INFO: kube-proxy-gk2s6 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 19:05:52.543: INFO: csi-cinder-nodeplugin-ubuntu-xqnfj from kube-system started at 2020-11-02 09:26:48 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 19:05:52.543: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 19:05:52.543: INFO: coredns-57f944bd9f-h8sb4 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container coredns ready: true, restart count 0
Nov  2 19:05:52.543: INFO: logrotate-vdk6h from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 19:05:52.543: INFO: user-ssh-keys-agent-wklnz from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 19:05:52.543: INFO: dashboard-metrics-scraper-59bfc65dc9-mx5wv from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 19:05:52.543: INFO: node-local-dns-nwqv9 from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 19:05:52.543: INFO: canal-c64t7 from kube-system started at 2020-11-02 09:26:29 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 19:05:52.543: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 19:05:52.543: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-11-02 09:26:48 +0000 UTC (5 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container cinder-csi-plugin ready: true, restart count 2
Nov  2 19:05:52.543: INFO: 	Container csi-attacher ready: true, restart count 0
Nov  2 19:05:52.543: INFO: 	Container csi-provisioner ready: true, restart count 0
Nov  2 19:05:52.543: INFO: 	Container csi-resizer ready: true, restart count 0
Nov  2 19:05:52.543: INFO: 	Container csi-snapshotter ready: true, restart count 0
Nov  2 19:05:52.543: INFO: coredns-57f944bd9f-492kl from kube-system started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.543: INFO: 	Container coredns ready: true, restart count 0
Nov  2 19:05:52.543: INFO: dashboard-metrics-scraper-59bfc65dc9-vv6zf from kubernetes-dashboard started at 2020-11-02 09:28:26 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.544: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  2 19:05:52.544: INFO: openvpn-client-84ccd8596d-qps5z from kube-system started at 2020-11-02 09:28:26 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.544: INFO: 	Container dnat-controller ready: true, restart count 0
Nov  2 19:05:52.544: INFO: 	Container openvpn-client ready: true, restart count 0
Nov  2 19:05:52.544: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-79jk4 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.544: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  2 19:05:52.544: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 19:05:52.544: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-dc8qz before test
Nov  2 19:05:52.756: INFO: logrotate-6plw5 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container logrotate ready: true, restart count 0
Nov  2 19:05:52.756: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-9c9cl from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  2 19:05:52.756: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 19:05:52.756: INFO: kube-proxy-4bdvn from kube-system started at 2020-11-02 09:31:11 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 19:05:52.756: INFO: node-local-dns-7m96x from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 19:05:52.756: INFO: csi-cinder-nodeplugin-ubuntu-rwf9k from kube-system started at 2020-11-02 09:31:41 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 19:05:52.756: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 19:05:52.756: INFO: canal-6x859 from kube-system started at 2020-11-02 09:31:11 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 19:05:52.756: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 19:05:52.756: INFO: user-ssh-keys-agent-99zc9 from kube-system started at 2020-11-02 09:31:41 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 19:05:52.756: INFO: sonobuoy-e2e-job-4da6a1ac755345e8 from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.756: INFO: 	Container e2e ready: true, restart count 0
Nov  2 19:05:52.756: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  2 19:05:52.756: INFO: 
Logging pods the kubelet thinks is on node awesome-shannon-698f584c96-drfqf before test
Nov  2 19:05:52.795: INFO: user-ssh-keys-agent-8898v from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.795: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Nov  2 19:05:52.796: INFO: sonobuoy from sonobuoy started at 2020-11-02 17:59:56 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  2 19:05:52.796: INFO: kube-proxy-h49pz from kube-system started at 2020-11-02 09:28:06 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  2 19:05:52.796: INFO: node-local-dns-wbdvv from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container node-cache ready: true, restart count 0
Nov  2 19:05:52.796: INFO: sonobuoy-systemd-logs-daemon-set-34496b28bafc45da-h8fmt from sonobuoy started at 2020-11-02 18:00:03 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  2 19:05:52.796: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  2 19:05:52.796: INFO: canal-l9xkd from kube-system started at 2020-11-02 09:28:06 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container calico-node ready: true, restart count 0
Nov  2 19:05:52.796: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  2 19:05:52.796: INFO: csi-cinder-nodeplugin-ubuntu-879qh from kube-system started at 2020-11-02 18:16:57 +0000 UTC (2 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Nov  2 19:05:52.796: INFO: 	Container node-driver-registrar ready: true, restart count 0
Nov  2 19:05:52.796: INFO: logrotate-28zzm from kube-system started at 2020-11-02 18:16:57 +0000 UTC (1 container statuses recorded)
Nov  2 19:05:52.796: INFO: 	Container logrotate ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a1b2fde8-2e19-4a20-87fd-14999fedfa69 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-a1b2fde8-2e19-4a20-87fd-14999fedfa69 off the node awesome-shannon-698f584c96-drfqf
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a1b2fde8-2e19-4a20-87fd-14999fedfa69
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:11:01.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1344" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:309.006 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":280,"completed":254,"skipped":4202,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:11:01.109: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-c655e35c-b289-4868-8bef-200db01bc09b in namespace container-probe-6726
Nov  2 19:11:05.357: INFO: Started pod liveness-c655e35c-b289-4868-8bef-200db01bc09b in namespace container-probe-6726
STEP: checking the pod's current state and verifying that restartCount is present
Nov  2 19:11:05.364: INFO: Initial restart count of pod liveness-c655e35c-b289-4868-8bef-200db01bc09b is 0
Nov  2 19:11:23.459: INFO: Restart count of pod container-probe-6726/liveness-c655e35c-b289-4868-8bef-200db01bc09b is now 1 (18.094637675s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:11:23.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6726" for this suite.

• [SLOW TEST:22.420 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":255,"skipped":4260,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:11:23.530: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9315
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-9315
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9315
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9315
Nov  2 19:11:23.797: INFO: Found 0 stateful pods, waiting for 1
Nov  2 19:11:33.807: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  2 19:11:33.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 19:11:35.026: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 19:11:35.026: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 19:11:35.026: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 19:11:35.034: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  2 19:11:45.049: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 19:11:45.049: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 19:11:45.094: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999165s
Nov  2 19:11:46.102: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.9889119s
Nov  2 19:11:47.111: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981426993s
Nov  2 19:11:48.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.972130967s
Nov  2 19:11:49.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.962647025s
Nov  2 19:11:50.140: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.953269224s
Nov  2 19:11:51.147: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.943675474s
Nov  2 19:11:52.157: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.936143071s
Nov  2 19:11:53.167: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.925792362s
Nov  2 19:11:54.175: INFO: Verifying statefulset ss doesn't scale past 1 for another 916.409164ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9315
Nov  2 19:11:55.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:11:55.886: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  2 19:11:55.886: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 19:11:55.886: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 19:11:55.895: INFO: Found 1 stateful pods, waiting for 3
Nov  2 19:12:05.908: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 19:12:05.908: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  2 19:12:05.908: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  2 19:12:05.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 19:12:06.556: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 19:12:06.556: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 19:12:06.556: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 19:12:06.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 19:12:07.215: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 19:12:07.215: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 19:12:07.215: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 19:12:07.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  2 19:12:07.817: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  2 19:12:07.817: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  2 19:12:07.817: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  2 19:12:07.817: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 19:12:07.825: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  2 19:12:17.846: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 19:12:17.846: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 19:12:17.846: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  2 19:12:17.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999448s
Nov  2 19:12:18.910: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988449047s
Nov  2 19:12:19.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977221375s
Nov  2 19:12:20.928: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968473261s
Nov  2 19:12:21.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960116473s
Nov  2 19:12:22.950: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.95130001s
Nov  2 19:12:23.964: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.937327629s
Nov  2 19:12:24.975: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.923228871s
Nov  2 19:12:25.988: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.913063317s
Nov  2 19:12:27.000: INFO: Verifying statefulset ss doesn't scale past 3 for another 899.278726ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9315
Nov  2 19:12:28.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:12:28.633: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  2 19:12:28.633: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 19:12:28.633: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 19:12:28.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:12:29.260: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  2 19:12:29.260: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  2 19:12:29.260: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  2 19:12:29.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:12:29.817: INFO: rc: 1
Nov  2 19:12:29.817: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (676d71f8c4cb954a2337c41c0f78d6c9778c73e1f32aa1781d08f7daf1d09b9d)

error:
exit status 1
Nov  2 19:12:39.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:12:39.923: INFO: rc: 1
Nov  2 19:12:39.923: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:12:49.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:12:50.029: INFO: rc: 1
Nov  2 19:12:50.029: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:13:00.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:13:00.140: INFO: rc: 1
Nov  2 19:13:00.140: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:13:10.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:13:10.245: INFO: rc: 1
Nov  2 19:13:10.245: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:13:20.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:13:20.354: INFO: rc: 1
Nov  2 19:13:20.354: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:13:30.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:13:30.481: INFO: rc: 1
Nov  2 19:13:30.481: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:13:40.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:13:40.605: INFO: rc: 1
Nov  2 19:13:40.606: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:13:50.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:13:50.708: INFO: rc: 1
Nov  2 19:13:50.708: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:14:00.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:14:00.843: INFO: rc: 1
Nov  2 19:14:00.843: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:14:10.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:14:10.947: INFO: rc: 1
Nov  2 19:14:10.947: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:14:20.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:14:21.067: INFO: rc: 1
Nov  2 19:14:21.067: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:14:31.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:14:31.167: INFO: rc: 1
Nov  2 19:14:31.167: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:14:41.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:14:41.276: INFO: rc: 1
Nov  2 19:14:41.276: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:14:51.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:14:51.378: INFO: rc: 1
Nov  2 19:14:51.378: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:15:01.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:15:01.493: INFO: rc: 1
Nov  2 19:15:01.493: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:15:11.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:15:11.600: INFO: rc: 1
Nov  2 19:15:11.600: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:15:21.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:15:21.703: INFO: rc: 1
Nov  2 19:15:21.703: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:15:31.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:15:31.808: INFO: rc: 1
Nov  2 19:15:31.808: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:15:41.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:15:41.932: INFO: rc: 1
Nov  2 19:15:41.933: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:15:51.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:15:52.063: INFO: rc: 1
Nov  2 19:15:52.063: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:16:02.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:16:02.170: INFO: rc: 1
Nov  2 19:16:02.170: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:16:12.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:16:12.300: INFO: rc: 1
Nov  2 19:16:12.300: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:16:22.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:16:22.408: INFO: rc: 1
Nov  2 19:16:22.408: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:16:32.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:16:32.506: INFO: rc: 1
Nov  2 19:16:32.506: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:16:42.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:16:42.611: INFO: rc: 1
Nov  2 19:16:42.611: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:16:52.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:16:52.718: INFO: rc: 1
Nov  2 19:16:52.719: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:17:02.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:17:02.904: INFO: rc: 1
Nov  2 19:17:02.904: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:17:12.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:17:13.025: INFO: rc: 1
Nov  2 19:17:13.025: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:17:23.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:17:23.131: INFO: rc: 1
Nov  2 19:17:23.131: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov  2 19:17:33.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=statefulset-9315 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  2 19:17:33.244: INFO: rc: 1
Nov  2 19:17:33.245: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Nov  2 19:17:33.245: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Nov  2 19:17:33.285: INFO: Deleting all statefulset in ns statefulset-9315
Nov  2 19:17:33.293: INFO: Scaling statefulset ss to 0
Nov  2 19:17:33.323: INFO: Waiting for statefulset status.replicas updated to 0
Nov  2 19:17:33.331: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:17:33.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9315" for this suite.

• [SLOW TEST:369.867 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":280,"completed":256,"skipped":4293,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:17:33.397: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7886
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:17:33.605: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:17:37.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7886" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":280,"completed":257,"skipped":4307,"failed":0}

------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:17:37.959: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 19:17:38.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645" in namespace "projected-6181" to be "success or failure"
Nov  2 19:17:38.230: INFO: Pod "downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645": Phase="Pending", Reason="", readiness=false. Elapsed: 27.053231ms
Nov  2 19:17:40.238: INFO: Pod "downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035571389s
Nov  2 19:17:42.256: INFO: Pod "downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053531569s
STEP: Saw pod success
Nov  2 19:17:42.256: INFO: Pod "downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645" satisfied condition "success or failure"
Nov  2 19:17:42.264: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645 container client-container: <nil>
STEP: delete the pod
Nov  2 19:17:42.309: INFO: Waiting for pod downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645 to disappear
Nov  2 19:17:42.315: INFO: Pod downwardapi-volume-2d344b11-bc46-45b0-acc2-888566e54645 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:17:42.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6181" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":280,"completed":258,"skipped":4307,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:17:42.348: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5906
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5906
I1102 19:17:42.656919      24 runners.go:189] Created replication controller with name: externalname-service, namespace: services-5906, replica count: 2
Nov  2 19:17:45.707: INFO: Creating new exec pod
I1102 19:17:45.707625      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  2 19:17:50.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5906 execpodt64lf -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  2 19:17:51.343: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  2 19:17:51.343: INFO: stdout: ""
Nov  2 19:17:51.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5906 execpodt64lf -- /bin/sh -x -c nc -zv -t -w 2 10.240.21.214 80'
Nov  2 19:17:51.983: INFO: stderr: "+ nc -zv -t -w 2 10.240.21.214 80\nConnection to 10.240.21.214 80 port [tcp/http] succeeded!\n"
Nov  2 19:17:51.983: INFO: stdout: ""
Nov  2 19:17:51.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5906 execpodt64lf -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.8 31126'
Nov  2 19:17:52.597: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.8 31126\nConnection to 192.168.1.8 31126 port [tcp/31126] succeeded!\n"
Nov  2 19:17:52.597: INFO: stdout: ""
Nov  2 19:17:52.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5906 execpodt64lf -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.15 31126'
Nov  2 19:17:53.209: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.15 31126\nConnection to 192.168.1.15 31126 port [tcp/31126] succeeded!\n"
Nov  2 19:17:53.209: INFO: stdout: ""
Nov  2 19:17:53.209: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:17:53.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5906" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:10.937 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":280,"completed":259,"skipped":4327,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:17:53.285: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Nov  2 19:17:53.535: INFO: Created pod &Pod{ObjectMeta:{dns-6128  dns-6128 /api/v1/namespaces/dns-6128/pods/dns-6128 c0d86e6e-0643-4efe-bec1-2d6e58c120ab 178477 0 2020-11-02 19:17:53 +0000 UTC <nil> <nil> map[] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jcvsk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jcvsk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jcvsk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
STEP: Verifying customized DNS suffix list is configured on pod...
Nov  2 19:17:57.562: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6128 PodName:dns-6128 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:17:57.562: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Verifying customized DNS server is configured on pod...
Nov  2 19:17:58.107: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6128 PodName:dns-6128 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:17:58.107: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:17:58.657: INFO: Deleting pod dns-6128...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:17:58.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6128" for this suite.

• [SLOW TEST:5.439 seconds]
[sig-network] DNS
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":280,"completed":260,"skipped":4339,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:17:58.724: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-699
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-cde7b4fd-6e39-47b3-8f84-288dd40c6330
STEP: Creating a pod to test consume configMaps
Nov  2 19:17:59.090: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f" in namespace "projected-699" to be "success or failure"
Nov  2 19:17:59.102: INFO: Pod "pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.475381ms
Nov  2 19:18:01.110: INFO: Pod "pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020038904s
Nov  2 19:18:03.125: INFO: Pod "pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035222557s
STEP: Saw pod success
Nov  2 19:18:03.125: INFO: Pod "pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f" satisfied condition "success or failure"
Nov  2 19:18:03.134: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 19:18:03.195: INFO: Waiting for pod pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f to disappear
Nov  2 19:18:03.212: INFO: Pod pod-projected-configmaps-7d020701-dcaa-46c0-99dd-c2f3c82be87f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:18:03.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-699" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":261,"skipped":4345,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:18:03.245: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-594d39ad-7205-4ba8-9c07-f0b08961cfed
STEP: Creating a pod to test consume configMaps
Nov  2 19:18:03.519: INFO: Waiting up to 5m0s for pod "pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e" in namespace "configmap-113" to be "success or failure"
Nov  2 19:18:03.538: INFO: Pod "pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.613238ms
Nov  2 19:18:05.550: INFO: Pod "pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030971804s
Nov  2 19:18:07.559: INFO: Pod "pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040370677s
STEP: Saw pod success
Nov  2 19:18:07.559: INFO: Pod "pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e" satisfied condition "success or failure"
Nov  2 19:18:07.566: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e container configmap-volume-test: <nil>
STEP: delete the pod
Nov  2 19:18:07.764: INFO: Waiting for pod pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e to disappear
Nov  2 19:18:07.771: INFO: Pod pod-configmaps-8354e767-1c36-4034-8375-ebb83431710e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:18:07.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-113" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":262,"skipped":4352,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:18:07.800: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1943
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov  2 19:18:08.000: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:18:11.731: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:18:26.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1943" for this suite.

• [SLOW TEST:18.544 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":280,"completed":263,"skipped":4358,"failed":0}
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:18:26.344: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  2 19:18:31.238: INFO: Successfully updated pod "pod-update-57c2b2b6-8460-499f-9eca-e29f20239b8e"
STEP: verifying the updated pod is in kubernetes
Nov  2 19:18:31.260: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:18:31.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7299" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":280,"completed":264,"skipped":4362,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:18:31.288: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 19:18:31.562: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa" in namespace "downward-api-5487" to be "success or failure"
Nov  2 19:18:31.579: INFO: Pod "downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa": Phase="Pending", Reason="", readiness=false. Elapsed: 17.02583ms
Nov  2 19:18:33.586: INFO: Pod "downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024134515s
Nov  2 19:18:35.595: INFO: Pod "downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033080646s
STEP: Saw pod success
Nov  2 19:18:35.595: INFO: Pod "downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa" satisfied condition "success or failure"
Nov  2 19:18:35.601: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa container client-container: <nil>
STEP: delete the pod
Nov  2 19:18:35.704: INFO: Waiting for pod downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa to disappear
Nov  2 19:18:35.714: INFO: Pod downwardapi-volume-77cbce84-a996-4783-b2b9-03340cd50ffa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:18:35.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5487" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":265,"skipped":4387,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:18:35.750: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating secret secrets-5314/secret-test-fcd0c699-81d3-4562-9c5a-80732a4a0a4e
STEP: Creating a pod to test consume secrets
Nov  2 19:18:36.049: INFO: Waiting up to 5m0s for pod "pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e" in namespace "secrets-5314" to be "success or failure"
Nov  2 19:18:36.075: INFO: Pod "pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.182703ms
Nov  2 19:18:38.084: INFO: Pod "pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035058237s
Nov  2 19:18:40.092: INFO: Pod "pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043340588s
STEP: Saw pod success
Nov  2 19:18:40.092: INFO: Pod "pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e" satisfied condition "success or failure"
Nov  2 19:18:40.099: INFO: Trying to get logs from node awesome-shannon-698f584c96-dc8qz pod pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e container env-test: <nil>
STEP: delete the pod
Nov  2 19:18:40.215: INFO: Waiting for pod pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e to disappear
Nov  2 19:18:40.226: INFO: Pod pod-configmaps-d8659130-118c-461c-a673-4bc509b6e26e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:18:40.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5314" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":266,"skipped":4409,"failed":0}

------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:18:40.291: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7029
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-7029
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  2 19:18:40.542: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  2 19:19:02.801: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.0.34:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7029 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:19:02.801: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:19:03.344: INFO: Found all expected endpoints: [netserver-0]
Nov  2 19:19:03.356: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.2.106:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7029 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:19:03.356: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:19:03.942: INFO: Found all expected endpoints: [netserver-1]
Nov  2 19:19:03.953: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.1.238:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7029 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  2 19:19:03.953: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:19:04.555: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:19:04.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7029" for this suite.

• [SLOW TEST:24.301 seconds]
[sig-network] Networking
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":267,"skipped":4409,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:19:04.593: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 19:19:05.850: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 19:19:07.870: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941545, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941545, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941545, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941545, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 19:19:10.926: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:19:11.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8785" for this suite.
STEP: Destroying namespace "webhook-8785-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.961 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":280,"completed":268,"skipped":4420,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:19:11.555: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Nov  2 19:19:11.785: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201" in namespace "projected-1045" to be "success or failure"
Nov  2 19:19:11.797: INFO: Pod "downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201": Phase="Pending", Reason="", readiness=false. Elapsed: 11.431298ms
Nov  2 19:19:13.806: INFO: Pod "downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021008434s
Nov  2 19:19:15.816: INFO: Pod "downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031012703s
STEP: Saw pod success
Nov  2 19:19:15.816: INFO: Pod "downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201" satisfied condition "success or failure"
Nov  2 19:19:15.824: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201 container client-container: <nil>
STEP: delete the pod
Nov  2 19:19:15.872: INFO: Waiting for pod downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201 to disappear
Nov  2 19:19:15.879: INFO: Pod downwardapi-volume-8bceb481-c1c2-4b69-bf16-22436771f201 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:19:15.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1045" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":269,"skipped":4443,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:19:15.905: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:19:16.109: INFO: Creating deployment "webserver-deployment"
Nov  2 19:19:16.122: INFO: Waiting for observed generation 1
Nov  2 19:19:18.211: INFO: Waiting for all required pods to come up
Nov  2 19:19:18.232: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  2 19:19:20.287: INFO: Waiting for deployment "webserver-deployment" to complete
Nov  2 19:19:20.315: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov  2 19:19:20.357: INFO: Updating deployment webserver-deployment
Nov  2 19:19:20.357: INFO: Waiting for observed generation 2
Nov  2 19:19:22.383: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  2 19:19:22.391: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  2 19:19:22.398: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  2 19:19:22.417: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  2 19:19:22.417: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  2 19:19:22.424: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  2 19:19:22.438: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov  2 19:19:22.438: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov  2 19:19:22.469: INFO: Updating deployment webserver-deployment
Nov  2 19:19:22.469: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov  2 19:19:22.494: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  2 19:19:22.501: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Nov  2 19:19:22.569: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9785 /apis/apps/v1/namespaces/deployment-9785/deployments/webserver-deployment 8a0c85fd-e6af-4ca9-a72b-d3b51ae67c4b 179567 3 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004531a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-11-02 19:19:20 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-11-02 19:19:22 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov  2 19:19:22.594: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9785 /apis/apps/v1/namespaces/deployment-9785/replicasets/webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 179559 3 2020-11-02 19:19:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 8a0c85fd-e6af-4ca9-a72b-d3b51ae67c4b 0xc0044fa177 0xc0044fa178}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0044fa208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  2 19:19:22.594: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov  2 19:19:22.594: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9785 /apis/apps/v1/namespaces/deployment-9785/replicasets/webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 179557 3 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 8a0c85fd-e6af-4ca9-a72b-d3b51ae67c4b 0xc0044fa037 0xc0044fa038}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0044fa0b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov  2 19:19:22.677: INFO: Pod "webserver-deployment-595b5b9587-97zln" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-97zln webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-97zln 81a5e6d9-df54-40fb-90b1-f02652527652 179448 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.1.241/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fa747 0xc0044fa748}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:172.25.1.241,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://580eb8efe1f5b2cd119401711b5774de7df60425960c5060bf4d9b222252a349,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.241,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.677: INFO: Pod "webserver-deployment-595b5b9587-ds8f6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ds8f6 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-ds8f6 7f32fee0-9a02-4006-8b7f-ce9788a912b7 179618 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fa8f7 0xc0044fa8f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.677: INFO: Pod "webserver-deployment-595b5b9587-fcfh9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fcfh9 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-fcfh9 f7e900d0-40bb-41a4-bd9b-7db9d61b82b1 179431 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.0.35/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044faa20 0xc0044faa21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.35,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b52b2022a7897496d0a357f276f14b5897be38472b131c6ee571a1a8ac0252a8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.0.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-fnw5g" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fnw5g webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-fnw5g e2bb225e-9206-48fc-ab5d-02ac7540bb9e 179463 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.2.111/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fab97 0xc0044fab98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.2.111,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://170ad7894875ff0b8c4cce43c0c2ba3a0cbc6ed7c1b5c0dd66011d4ddacc15b2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-gmrjq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gmrjq webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-gmrjq dfe52813-9179-4cad-a67c-1c2aebe3bfa6 179454 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.1.243/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fad17 0xc0044fad18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:172.25.1.243,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2e2721cff22789ccde001d55e529a18114d40a8b1444c77e96bee751e0515f39,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.243,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-hncn6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hncn6 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-hncn6 c1938dcf-2f93-4ce0-a007-521a2beacb48 179451 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.1.244/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044faee7 0xc0044faee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:172.25.1.244,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1fec32b6befe3046599b1e66cd1fc95c21a89f729638ecc5e7605d51cddee58c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.244,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-hnv6s" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hnv6s webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-hnv6s 8d557e0e-2e33-4cda-b5a3-5c4ab37c95b6 179616 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fb057 0xc0044fb058}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-jt8q9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jt8q9 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-jt8q9 8fd79f9f-fa91-4f6a-b298-6688567e6dbe 179615 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fb200 0xc0044fb201}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-l7hn2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l7hn2 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-l7hn2 027a83c4-4684-46c0-9447-a9168e5f6982 179435 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.0.36/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fb360 0xc0044fb361}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.8,PodIP:172.25.0.36,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1c96690239f851848ac594616e31b79ff00de0613cf9db0965c78a0f0fb1df6d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.0.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.678: INFO: Pod "webserver-deployment-595b5b9587-lsrdc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lsrdc webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-lsrdc f265bc8e-c440-424f-aafc-6b65fc37c57c 179595 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fb5a7 0xc0044fb5a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.679: INFO: Pod "webserver-deployment-595b5b9587-m97z8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-m97z8 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-m97z8 2556952f-7da8-4362-bf29-423364fb33a8 179466 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.2.109/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fb740 0xc0044fb741}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.2.109,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://63dea6523a0bbccc8564f60f091dd032d1af93847b54b05dac2c8dae9bbc197b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.109,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.679: INFO: Pod "webserver-deployment-595b5b9587-pfx9w" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pfx9w webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-pfx9w ac44a901-d043-4b5c-9e2d-76ca6ebb3c4f 179589 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fb937 0xc0044fb938}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.679: INFO: Pod "webserver-deployment-595b5b9587-s6mnj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s6mnj webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-s6mnj ed2846ef-f4ae-4121-926e-037a167dca81 179579 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fba80 0xc0044fba81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.679: INFO: Pod "webserver-deployment-595b5b9587-tpvqt" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tpvqt webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-tpvqt 5fe79eee-b0fe-49b6-91e1-27062a060ed8 179611 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fbbb0 0xc0044fbbb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2020-11-02 19:19:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.680: INFO: Pod "webserver-deployment-595b5b9587-vb5gw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vb5gw webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-vb5gw aa323336-a204-4a6f-86ae-8dfab972fa38 179609 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fbd97 0xc0044fbd98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:,StartTime:2020-11-02 19:19:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.680: INFO: Pod "webserver-deployment-595b5b9587-w4rpj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-w4rpj webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-w4rpj 9dc39186-e865-4c2a-9d88-98f64962bd4d 179617 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044fbfa7 0xc0044fbfa8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.680: INFO: Pod "webserver-deployment-595b5b9587-wpz6n" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wpz6n webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-wpz6n a416f9d6-56ff-43a8-8712-265abd92ef10 179613 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044a2110 0xc0044a2111}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.680: INFO: Pod "webserver-deployment-595b5b9587-x88k7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x88k7 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-x88k7 cd32e1cd-970e-49a7-b888-977b75ec0525 179469 0 2020-11-02 19:19:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.25.2.110/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044a22a0 0xc0044a22a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:172.25.2.110,StartTime:2020-11-02 19:19:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-11-02 19:19:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://efc77780b26b9d447f659cfab9013b8a313aeecea93c30876d440077307e39ae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.680: INFO: Pod "webserver-deployment-595b5b9587-xg765" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xg765 webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-xg765 931166a5-e7ce-4387-a634-0f00e2901336 179590 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044a2487 0xc0044a2488}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.680: INFO: Pod "webserver-deployment-595b5b9587-zx4rk" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zx4rk webserver-deployment-595b5b9587- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-595b5b9587-zx4rk b8ceee47-b37c-4000-a4f3-d28de26137da 179599 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 c434389a-1c9c-4fe0-b910-8fb3070e91c3 0xc0044a2640 0xc0044a2641}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2020-11-02 19:19:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-2gfb4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2gfb4 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-2gfb4 aa2754f3-5da2-4e20-a8bf-56b275adfc6d 179602 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a2807 0xc0044a2808}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-65zhf" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-65zhf webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-65zhf bda10a68-bd60-407d-9724-fd1531be8c69 179607 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a29f0 0xc0044a29f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-6pdh9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6pdh9 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-6pdh9 c5f2cb1f-e6be-486f-9610-a18af76099a4 179545 0 2020-11-02 19:19:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.25.1.245/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a2b90 0xc0044a2b91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:,StartTime:2020-11-02 19:19:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-9gcp7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9gcp7 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-9gcp7 3fe06318-49a3-4f1a-bdf1-2af6f0c6c00d 179548 0 2020-11-02 19:19:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.25.2.112/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a2d57 0xc0044a2d58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2020-11-02 19:19:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-hklqp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hklqp webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-hklqp 9df0f70e-8f8e-4309-be14-7ca83abe4229 179543 0 2020-11-02 19:19:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.25.0.37/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a2f07 0xc0044a2f08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.8,PodIP:,StartTime:2020-11-02 19:19:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-lrvx7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lrvx7 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-lrvx7 f24fe95b-5ddd-43c3-b5a3-6ae0f1f076eb 179552 0 2020-11-02 19:19:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.25.1.246/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a3140 0xc0044a3141}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.15,PodIP:,StartTime:2020-11-02 19:19:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.681: INFO: Pod "webserver-deployment-c7997dcc8-qtn2g" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qtn2g webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-qtn2g 4467d080-183e-45ba-b1ac-d9c890ee03b0 179582 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a3337 0xc0044a3338}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.682: INFO: Pod "webserver-deployment-c7997dcc8-qxkjd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qxkjd webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-qxkjd 8ba7e612-8ebd-430d-9a10-2b8cd96bb6ed 179587 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a3560 0xc0044a3561}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.682: INFO: Pod "webserver-deployment-c7997dcc8-rm48l" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rm48l webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-rm48l 0948bcd1-b3b5-45c2-af5b-c58094d57f5e 179598 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a36e0 0xc0044a36e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-brzmg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.682: INFO: Pod "webserver-deployment-c7997dcc8-tsqz8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tsqz8 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-tsqz8 def6a34d-eb0b-4bcf-8340-10e7ec59b45a 179606 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a3860 0xc0044a3861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.682: INFO: Pod "webserver-deployment-c7997dcc8-vmbqz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vmbqz webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-vmbqz 0714d0b1-97bd-45c7-90cf-e37271f8e930 179624 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a39a0 0xc0044a39a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.682: INFO: Pod "webserver-deployment-c7997dcc8-xlsv9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xlsv9 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-xlsv9 b2034d42-ca28-47c0-973e-4e70f6f3a786 179578 0 2020-11-02 19:19:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a3b20 0xc0044a3b21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-drfqf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  2 19:19:22.682: INFO: Pod "webserver-deployment-c7997dcc8-z2j77" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-z2j77 webserver-deployment-c7997dcc8- deployment-9785 /api/v1/namespaces/deployment-9785/pods/webserver-deployment-c7997dcc8-z2j77 97661e65-1825-4fa5-8712-018d9d94e469 179554 0 2020-11-02 19:19:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.25.2.113/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 5ce42113-136d-49fc-be9c-11207606011d 0xc0044a3c50 0xc0044a3c51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssp58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssp58,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssp58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:awesome-shannon-698f584c96-dc8qz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-11-02 19:19:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.11,PodIP:,StartTime:2020-11-02 19:19:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:19:22.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9785" for this suite.

• [SLOW TEST:6.854 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":280,"completed":270,"skipped":4453,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:19:22.760: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5158
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service nodeport-test with type=NodePort in namespace services-5158
STEP: creating replication controller nodeport-test in namespace services-5158
I1102 19:19:23.234636      24 runners.go:189] Created replication controller with name: nodeport-test, namespace: services-5158, replica count: 2
I1102 19:19:26.284976      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1102 19:19:29.285165      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  2 19:19:29.285: INFO: Creating new exec pod
Nov  2 19:19:34.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5158 execpod8fqgj -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov  2 19:19:35.018: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov  2 19:19:35.018: INFO: stdout: ""
Nov  2 19:19:35.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5158 execpod8fqgj -- /bin/sh -x -c nc -zv -t -w 2 10.240.17.32 80'
Nov  2 19:19:35.653: INFO: stderr: "+ nc -zv -t -w 2 10.240.17.32 80\nConnection to 10.240.17.32 80 port [tcp/http] succeeded!\n"
Nov  2 19:19:35.653: INFO: stdout: ""
Nov  2 19:19:35.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5158 execpod8fqgj -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.8 31572'
Nov  2 19:19:36.188: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.8 31572\nConnection to 192.168.1.8 31572 port [tcp/31572] succeeded!\n"
Nov  2 19:19:36.188: INFO: stdout: ""
Nov  2 19:19:36.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-5158 execpod8fqgj -- /bin/sh -x -c nc -zv -t -w 2 192.168.1.11 31572'
Nov  2 19:19:36.827: INFO: stderr: "+ nc -zv -t -w 2 192.168.1.11 31572\nConnection to 192.168.1.11 31572 port [tcp/31572] succeeded!\n"
Nov  2 19:19:36.827: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:19:36.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5158" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:14.100 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":280,"completed":271,"skipped":4463,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:19:36.861: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-9118
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:163
Nov  2 19:19:37.088: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  2 19:20:37.146: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:20:37.166: INFO: Starting informer...
STEP: Starting pod...
Nov  2 19:20:37.403: INFO: Pod is running on awesome-shannon-698f584c96-drfqf. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov  2 19:20:37.435: INFO: Pod wasn't evicted. Proceeding
Nov  2 19:20:37.435: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov  2 19:21:52.517: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:21:52.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9118" for this suite.

• [SLOW TEST:135.680 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":280,"completed":272,"skipped":4476,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:21:52.543: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7491
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov  2 19:21:57.879: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:21:58.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7491" for this suite.

• [SLOW TEST:5.546 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":280,"completed":273,"skipped":4477,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:21:58.089: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9749
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Nov  2 19:21:58.344: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5f9cda60-5cea-422e-be50-c5e536b52e5f" in namespace "security-context-test-9749" to be "success or failure"
Nov  2 19:21:58.353: INFO: Pod "busybox-user-65534-5f9cda60-5cea-422e-be50-c5e536b52e5f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.678781ms
Nov  2 19:22:00.368: INFO: Pod "busybox-user-65534-5f9cda60-5cea-422e-be50-c5e536b52e5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024408598s
Nov  2 19:22:02.376: INFO: Pod "busybox-user-65534-5f9cda60-5cea-422e-be50-c5e536b52e5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031627495s
Nov  2 19:22:02.376: INFO: Pod "busybox-user-65534-5f9cda60-5cea-422e-be50-c5e536b52e5f" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:22:02.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9749" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":274,"skipped":4491,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:22:02.402: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6418
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6418
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6418
STEP: creating replication controller externalsvc in namespace services-6418
I1102 19:22:02.720306      24 runners.go:189] Created replication controller with name: externalsvc, namespace: services-6418, replica count: 2
I1102 19:22:05.770699      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov  2 19:22:05.816: INFO: Creating new exec pod
Nov  2 19:22:09.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-142776444 exec --namespace=services-6418 execpodrbb42 -- /bin/sh -x -c nslookup clusterip-service'
Nov  2 19:22:11.173: INFO: stderr: "+ nslookup clusterip-service\n"
Nov  2 19:22:11.173: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nclusterip-service.services-6418.svc.cluster.local\tcanonical name = externalsvc.services-6418.svc.cluster.local.\nName:\texternalsvc.services-6418.svc.cluster.local\nAddress: 10.240.23.186\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6418, will wait for the garbage collector to delete the pods
Nov  2 19:22:11.260: INFO: Deleting ReplicationController externalsvc took: 28.04211ms
Nov  2 19:22:11.766: INFO: Terminating ReplicationController externalsvc pods took: 505.7781ms
Nov  2 19:22:27.005: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:22:27.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6418" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:24.670 seconds]
[sig-network] Services
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":280,"completed":275,"skipped":4516,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:22:27.073: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2870
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1102 19:23:07.410883      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  2 19:23:07.410: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:23:07.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2870" for this suite.

• [SLOW TEST:40.364 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":280,"completed":276,"skipped":4528,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:23:07.437: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  2 19:23:07.681: INFO: Waiting up to 5m0s for pod "pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3" in namespace "emptydir-2240" to be "success or failure"
Nov  2 19:23:07.696: INFO: Pod "pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.352237ms
Nov  2 19:23:09.710: INFO: Pod "pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029427009s
Nov  2 19:23:11.720: INFO: Pod "pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038934112s
STEP: Saw pod success
Nov  2 19:23:11.720: INFO: Pod "pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3" satisfied condition "success or failure"
Nov  2 19:23:11.727: INFO: Trying to get logs from node awesome-shannon-698f584c96-drfqf pod pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3 container test-container: <nil>
STEP: delete the pod
Nov  2 19:23:11.881: INFO: Waiting for pod pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3 to disappear
Nov  2 19:23:11.887: INFO: Pod pod-3a22ccae-5807-4c3d-8c0d-07dfa72e04a3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:23:11.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2240" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":277,"skipped":4538,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:23:11.909: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7278
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  2 19:23:12.804: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  2 19:23:14.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941792, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941792, loc:(*time.Location)(0x7925260)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941792, loc:(*time.Location)(0x7925260)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63739941792, loc:(*time.Location)(0x7925260)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  2 19:23:17.875: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:23:18.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7278" for this suite.
STEP: Destroying namespace "webhook-7278-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.099 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":280,"completed":278,"skipped":4538,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:23:19.008: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  2 19:23:25.325: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1102 19:23:25.325143      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  2 19:23:25.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9815" for this suite.

• [SLOW TEST:6.353 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":280,"completed":279,"skipped":4553,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  2 19:23:25.360: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4830
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov  2 19:23:25.604: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
Nov  2 19:23:29.479: INFO: >>> kubeConfig: /tmp/kubeconfig-142776444
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  2 19:23:44.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4830" for this suite.

• [SLOW TEST:18.699 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.9-rc.0.37+d1c2f63bd4fc89/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":280,"completed":280,"skipped":4556,"failed":0}
SSSSSSSNov  2 19:23:44.060: INFO: Running AfterSuite actions on all nodes
Nov  2 19:23:44.060: INFO: Running AfterSuite actions on node 1
Nov  2 19:23:44.060: INFO: Skipping dumping logs from cluster
{"msg":"Test Suite completed","total":280,"completed":280,"skipped":4563,"failed":0}

Ran 280 of 4843 Specs in 4996.029 seconds
SUCCESS! -- 280 Passed | 0 Failed | 0 Pending | 4563 Skipped
PASS

Ginkgo ran 1 suite in 1h23m17.682898377s
Test Suite Passed
