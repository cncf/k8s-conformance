I0115 14:39:42.632946      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-889858361
I0115 14:39:42.633058      18 e2e.go:224] Starting e2e run "64f35b4a-18d3-11e9-9d2c-c274f07984f4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547563182 - Will randomize all specs
Will run 201 of 1946 specs

Jan 15 14:39:42.730: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:39:42.732: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 15 14:39:42.746: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 15 14:39:42.772: INFO: The status of Pod calico-complete-upgrade-v331-68hdc is Succeeded, skipping waiting
Jan 15 14:39:42.772: INFO: 34 / 35 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 15 14:39:42.772: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
Jan 15 14:39:42.772: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 15 14:39:42.780: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jan 15 14:39:42.780: INFO: e2e test version: v1.13.0
Jan 15 14:39:42.780: INFO: kube-apiserver version: v1.11.6
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:39:42.780: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename daemonsets
Jan 15 14:39:42.821: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 14:39:42.842: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 14:39:42.853: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:42.853: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:42.853: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:42.856: INFO: Number of nodes with available pods: 0
Jan 15 14:39:42.856: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:39:43.861: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:43.861: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:43.861: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:43.864: INFO: Number of nodes with available pods: 0
Jan 15 14:39:43.864: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:39:44.862: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:44.862: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:44.862: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:44.865: INFO: Number of nodes with available pods: 0
Jan 15 14:39:44.865: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:39:45.860: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:45.860: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:45.860: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:45.863: INFO: Number of nodes with available pods: 3
Jan 15 14:39:45.863: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 15 14:39:45.887: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:45.887: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:45.887: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:45.890: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:45.890: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:45.890: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:46.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:46.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:46.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:46.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:46.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:46.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:47.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:47.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:47.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:47.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:47.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:47.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:48.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:48.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:48.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:48.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:48.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:48.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:49.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:49.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:49.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:49.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:49.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:49.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:50.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:50.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:50.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:50.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:50.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:50.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:51.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:51.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:51.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:51.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:51.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:51.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:52.902: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:52.902: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:52.902: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:52.906: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:52.906: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:52.906: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:53.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:53.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:53.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:53.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:53.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:53.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:54.896: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:54.896: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:54.896: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:54.909: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:54.909: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:54.909: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:55.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:55.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:55.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:55.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:55.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:55.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:56.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:56.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:56.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:56.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:56.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:56.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:57.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:57.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:57.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:57.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:57.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:57.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:58.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:58.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:58.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:58.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:58.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:58.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:59.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:59.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:59.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:39:59.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:59.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:39:59.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:00.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:00.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:00.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:00.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:00.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:00.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:01.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:01.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:01.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:01.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:01.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:01.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:02.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:02.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:02.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:02.897: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:02.897: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:02.897: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:03.900: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:03.900: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:03.900: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:03.903: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:03.903: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:03.903: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:04.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:04.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:04.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:04.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:04.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:04.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:05.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:05.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:05.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:05.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:05.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:05.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:06.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:06.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:06.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:06.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:06.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:06.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:07.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:07.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:07.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:07.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:07.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:07.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:08.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:08.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:08.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:08.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:08.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:08.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:09.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:09.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:09.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:09.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:09.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:09.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:10.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:10.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:10.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:10.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:10.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:10.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:11.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:11.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:11.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:11.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:11.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:11.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:12.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:12.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:12.895: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:12.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:12.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:12.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:13.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:13.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:13.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:13.897: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:13.897: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:13.897: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:14.900: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:14.900: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:14.900: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:14.903: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:14.903: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:14.903: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:15.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:15.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:15.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:15.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:15.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:15.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:16.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:16.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:16.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:16.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:16.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:16.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:17.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:17.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:17.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:17.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:17.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:17.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:18.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:18.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:18.894: INFO: Wrong image for pod: daemon-set-pn5c4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:18.894: INFO: Pod daemon-set-pn5c4 is not available
Jan 15 14:40:18.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:18.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:18.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:19.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:19.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:19.895: INFO: Pod daemon-set-qvq46 is not available
Jan 15 14:40:19.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:19.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:19.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:20.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:20.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:20.895: INFO: Pod daemon-set-qvq46 is not available
Jan 15 14:40:20.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:20.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:20.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:21.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:21.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:21.894: INFO: Pod daemon-set-qvq46 is not available
Jan 15 14:40:21.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:21.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:21.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:22.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:22.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:22.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:22.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:22.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:23.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:23.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:23.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:23.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:23.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:24.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:24.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:24.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:24.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:24.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:25.900: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:25.900: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:25.904: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:25.904: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:25.904: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:26.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:26.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:26.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:26.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:26.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:27.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:27.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:27.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:27.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:27.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:28.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:28.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:28.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:28.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:28.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:29.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:29.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:29.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:29.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:29.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:30.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:30.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:30.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:30.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:30.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:31.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:31.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:31.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:31.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:31.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:32.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:32.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:32.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:32.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:32.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:33.896: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:33.896: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:33.901: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:33.901: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:33.901: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:34.896: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:34.896: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:34.901: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:34.901: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:34.901: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:35.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:35.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:35.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:35.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:35.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:36.902: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:36.902: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:36.906: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:36.906: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:36.906: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:37.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:37.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:37.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:37.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:37.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:38.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:38.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:38.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:38.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:38.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:39.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:39.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:39.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:39.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:39.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:40.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:40.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:40.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:40.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:40.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:41.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:41.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:41.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:41.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:41.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:42.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:42.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:42.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:42.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:42.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:43.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:43.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:43.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:43.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:43.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:44.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:44.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:44.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:44.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:44.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:45.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:45.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:45.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:45.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:45.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:46.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:46.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:46.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:46.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:46.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:47.900: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:47.900: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:47.903: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:47.903: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:47.903: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:48.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:48.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:48.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:48.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:48.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:49.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:49.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:49.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:49.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:49.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:50.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:50.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:50.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:50.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:50.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:51.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:51.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:51.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:51.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:51.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:52.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:52.895: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:52.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:52.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:52.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:53.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:53.894: INFO: Wrong image for pod: daemon-set-hx8rp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:53.894: INFO: Pod daemon-set-hx8rp is not available
Jan 15 14:40:53.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:53.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:53.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:54.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:54.894: INFO: Pod daemon-set-kznrl is not available
Jan 15 14:40:54.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:54.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:54.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:55.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:55.895: INFO: Pod daemon-set-kznrl is not available
Jan 15 14:40:55.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:55.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:55.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:56.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:56.895: INFO: Pod daemon-set-kznrl is not available
Jan 15 14:40:56.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:56.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:56.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:57.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:57.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:57.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:57.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:58.900: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:58.904: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:58.904: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:58.904: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:59.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:40:59.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:59.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:40:59.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:00.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:00.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:00.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:00.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:01.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:01.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:01.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:01.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:02.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:02.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:02.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:02.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:03.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:03.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:03.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:03.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:04.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:04.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:04.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:04.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:05.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:05.897: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:05.897: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:05.897: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:06.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:06.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:06.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:06.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:07.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:07.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:07.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:07.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:08.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:08.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:08.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:08.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:09.901: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:09.906: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:09.906: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:09.906: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:10.896: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:10.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:10.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:10.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:11.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:11.901: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:11.901: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:11.901: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:12.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:12.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:12.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:12.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:13.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:13.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:13.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:13.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:14.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:14.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:14.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:14.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:15.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:15.897: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:15.897: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:15.897: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:16.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:16.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:16.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:16.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:17.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:17.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:17.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:17.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:18.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:18.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:18.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:18.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:19.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:19.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:19.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:19.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:20.901: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:20.906: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:20.906: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:20.906: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:21.896: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:21.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:21.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:21.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:22.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:22.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:22.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:22.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:23.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:23.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:23.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:23.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:24.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:24.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:24.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:24.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:25.894: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:25.898: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:25.898: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:25.898: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:26.896: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:26.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:26.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:26.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:27.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:27.900: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:27.900: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:27.900: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:28.895: INFO: Wrong image for pod: daemon-set-7dh2h. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 14:41:28.895: INFO: Pod daemon-set-7dh2h is not available
Jan 15 14:41:28.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:28.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:28.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:29.895: INFO: Pod daemon-set-p2sgj is not available
Jan 15 14:41:29.899: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:29.899: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:29.899: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 15 14:41:29.903: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:29.903: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:29.903: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:29.907: INFO: Number of nodes with available pods: 2
Jan 15 14:41:29.907: INFO: Node ip-172-24-87-161.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:41:30.919: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:30.919: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:30.919: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:30.922: INFO: Number of nodes with available pods: 2
Jan 15 14:41:30.922: INFO: Node ip-172-24-87-161.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:41:31.912: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:31.912: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:31.912: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:31.915: INFO: Number of nodes with available pods: 2
Jan 15 14:41:31.915: INFO: Node ip-172-24-87-161.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:41:32.912: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:32.912: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:32.912: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:41:32.916: INFO: Number of nodes with available pods: 3
Jan 15 14:41:32.916: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-gvqqh, will wait for the garbage collector to delete the pods
Jan 15 14:41:32.997: INFO: Deleting DaemonSet.extensions daemon-set took: 9.713659ms
Jan 15 14:41:33.097: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.362239ms
Jan 15 14:41:47.208: INFO: Number of nodes with available pods: 0
Jan 15 14:41:47.208: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 14:41:47.211: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gvqqh/daemonsets","resourceVersion":"190276"},"items":null}

Jan 15 14:41:47.214: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gvqqh/pods","resourceVersion":"190276"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:41:47.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gvqqh" for this suite.
Jan 15 14:41:53.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:41:53.330: INFO: namespace: e2e-tests-daemonsets-gvqqh, resource: bindings, ignored listing per whitelist
Jan 15 14:41:53.338: INFO: namespace e2e-tests-daemonsets-gvqqh deletion completed in 6.105308024s

 [SLOW TEST:130.558 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:41:53.338: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b31e649e-18d3-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 14:41:53.392: INFO: Waiting up to 5m0s for pod "pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-bxdps" to be "success or failure"
Jan 15 14:41:53.396: INFO: Pod "pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619093ms
Jan 15 14:41:55.400: INFO: Pod "pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.007040943s
Jan 15 14:41:57.408: INFO: Pod "pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015642424s
STEP: Saw pod success
Jan 15 14:41:57.408: INFO: Pod "pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:41:57.411: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 14:41:57.443: INFO: Waiting for pod pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:41:57.446: INFO: Pod pod-secrets-b31f7203-18d3-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:41:57.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bxdps" for this suite.
Jan 15 14:42:03.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:42:03.552: INFO: namespace: e2e-tests-secrets-bxdps, resource: bindings, ignored listing per whitelist
Jan 15 14:42:03.552: INFO: namespace e2e-tests-secrets-bxdps deletion completed in 6.102008801s

 [SLOW TEST:10.214 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:42:03.552: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-b934e61c-18d3-11e9-9d2c-c274f07984f4
STEP: Creating secret with name secret-projected-all-test-volume-b934e5f8-18d3-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 15 14:42:03.611: INFO: Waiting up to 5m0s for pod "projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-9wpz5" to be "success or failure"
Jan 15 14:42:03.614: INFO: Pod "projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.000696ms
Jan 15 14:42:05.618: INFO: Pod "projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007350794s
STEP: Saw pod success
Jan 15 14:42:05.618: INFO: Pod "projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:42:05.621: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 15 14:42:05.654: INFO: Waiting for pod projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:42:05.658: INFO: Pod projected-volume-b934e5bd-18d3-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:42:05.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9wpz5" for this suite.
Jan 15 14:42:11.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:42:11.768: INFO: namespace: e2e-tests-projected-9wpz5, resource: bindings, ignored listing per whitelist
Jan 15 14:42:11.773: INFO: namespace e2e-tests-projected-9wpz5 deletion completed in 6.111598148s

 [SLOW TEST:8.221 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:42:11.774: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-t5zz
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 14:42:11.832: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-t5zz" in namespace "e2e-tests-subpath-pfbbr" to be "success or failure"
Jan 15 14:42:11.836: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.906575ms
Jan 15 14:42:13.839: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00722029s
Jan 15 14:42:15.842: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 4.010299073s
Jan 15 14:42:17.853: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 6.020880557s
Jan 15 14:42:19.856: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 8.023968192s
Jan 15 14:42:21.860: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 10.027892753s
Jan 15 14:42:23.864: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 12.03185691s
Jan 15 14:42:25.867: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 14.035076693s
Jan 15 14:42:27.876: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 16.043979908s
Jan 15 14:42:29.880: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 18.047833383s
Jan 15 14:42:31.884: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 20.052170219s
Jan 15 14:42:33.889: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Running", Reason="", readiness=false. Elapsed: 22.056643427s
Jan 15 14:42:35.892: INFO: Pod "pod-subpath-test-projected-t5zz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.06043348s
STEP: Saw pod success
Jan 15 14:42:35.892: INFO: Pod "pod-subpath-test-projected-t5zz" satisfied condition "success or failure"
Jan 15 14:42:35.895: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-subpath-test-projected-t5zz container test-container-subpath-projected-t5zz: <nil>
STEP: delete the pod
Jan 15 14:42:35.930: INFO: Waiting for pod pod-subpath-test-projected-t5zz to disappear
Jan 15 14:42:35.933: INFO: Pod pod-subpath-test-projected-t5zz no longer exists
STEP: Deleting pod pod-subpath-test-projected-t5zz
Jan 15 14:42:35.933: INFO: Deleting pod "pod-subpath-test-projected-t5zz" in namespace "e2e-tests-subpath-pfbbr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:42:35.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-pfbbr" for this suite.
Jan 15 14:42:41.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:42:42.048: INFO: namespace: e2e-tests-subpath-pfbbr, resource: bindings, ignored listing per whitelist
Jan 15 14:42:42.051: INFO: namespace e2e-tests-subpath-pfbbr deletion completed in 6.110267578s

 [SLOW TEST:30.277 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:42:42.051: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 14:42:42.094: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:42:46.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-542gq" for this suite.
Jan 15 14:43:30.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:43:30.212: INFO: namespace: e2e-tests-pods-542gq, resource: bindings, ignored listing per whitelist
Jan 15 14:43:30.291: INFO: namespace e2e-tests-pods-542gq deletion completed in 44.104416088s

 [SLOW TEST:48.240 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:43:30.291: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 14:43:30.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-c4r5w'
Jan 15 14:43:30.568: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 14:43:30.568: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 15 14:43:30.576: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-p5k8g]
Jan 15 14:43:30.576: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-p5k8g" in namespace "e2e-tests-kubectl-c4r5w" to be "running and ready"
Jan 15 14:43:30.580: INFO: Pod "e2e-test-nginx-rc-p5k8g": Phase="Pending", Reason="", readiness=false. Elapsed: 3.237235ms
Jan 15 14:43:32.584: INFO: Pod "e2e-test-nginx-rc-p5k8g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007711434s
Jan 15 14:43:34.593: INFO: Pod "e2e-test-nginx-rc-p5k8g": Phase="Running", Reason="", readiness=true. Elapsed: 4.016358508s
Jan 15 14:43:34.593: INFO: Pod "e2e-test-nginx-rc-p5k8g" satisfied condition "running and ready"
Jan 15 14:43:34.593: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-p5k8g]
Jan 15 14:43:34.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-c4r5w'
Jan 15 14:43:34.683: INFO: stderr: ""
Jan 15 14:43:34.683: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jan 15 14:43:34.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-c4r5w'
Jan 15 14:43:34.747: INFO: stderr: ""
Jan 15 14:43:34.747: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:43:34.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c4r5w" for this suite.
Jan 15 14:43:40.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:43:40.833: INFO: namespace: e2e-tests-kubectl-c4r5w, resource: bindings, ignored listing per whitelist
Jan 15 14:43:40.862: INFO: namespace e2e-tests-kubectl-c4r5w deletion completed in 6.110493381s

 [SLOW TEST:10.571 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:43:40.862: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6wlp5
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-6wlp5
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-6wlp5
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-6wlp5
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-6wlp5
Jan 15 14:43:46.940: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6wlp5, name: ss-0, uid: f6b0c2b4-18d3-11e9-8532-0a00a28bbe76, status phase: Pending. Waiting for statefulset controller to delete.
Jan 15 14:43:47.338: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6wlp5, name: ss-0, uid: f6b0c2b4-18d3-11e9-8532-0a00a28bbe76, status phase: Failed. Waiting for statefulset controller to delete.
Jan 15 14:43:47.344: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6wlp5, name: ss-0, uid: f6b0c2b4-18d3-11e9-8532-0a00a28bbe76, status phase: Failed. Waiting for statefulset controller to delete.
Jan 15 14:43:47.346: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-6wlp5
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-6wlp5
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-6wlp5 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 14:43:51.370: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6wlp5
Jan 15 14:43:51.373: INFO: Scaling statefulset ss to 0
Jan 15 14:44:01.395: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 14:44:01.398: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:44:01.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6wlp5" for this suite.
Jan 15 14:44:07.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:44:07.515: INFO: namespace: e2e-tests-statefulset-6wlp5, resource: bindings, ignored listing per whitelist
Jan 15 14:44:07.524: INFO: namespace e2e-tests-statefulset-6wlp5 deletion completed in 6.107718001s

 [SLOW TEST:26.661 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:44:07.524: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hjbxp
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 15 14:44:07.581: INFO: Found 0 stateful pods, waiting for 3
Jan 15 14:44:17.592: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 14:44:17.592: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 14:44:17.592: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 14:44:17.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-hjbxp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 14:44:17.737: INFO: stderr: ""
Jan 15 14:44:17.737: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 14:44:17.737: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 15 14:44:27.776: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 15 14:44:37.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-hjbxp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 14:44:37.928: INFO: stderr: ""
Jan 15 14:44:37.928: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 14:44:37.928: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 14:44:57.956: INFO: Waiting for StatefulSet e2e-tests-statefulset-hjbxp/ss2 to complete update
STEP: Rolling back to a previous revision
Jan 15 14:45:07.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-hjbxp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 14:45:08.103: INFO: stderr: ""
Jan 15 14:45:08.103: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 14:45:08.103: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 14:45:18.139: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 15 14:45:28.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-hjbxp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 14:45:28.289: INFO: stderr: ""
Jan 15 14:45:28.289: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 14:45:28.289: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 14:45:38.317: INFO: Waiting for StatefulSet e2e-tests-statefulset-hjbxp/ss2 to complete update
Jan 15 14:45:38.317: INFO: Waiting for Pod e2e-tests-statefulset-hjbxp/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 15 14:45:38.317: INFO: Waiting for Pod e2e-tests-statefulset-hjbxp/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 15 14:45:38.317: INFO: Waiting for Pod e2e-tests-statefulset-hjbxp/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 15 14:45:48.328: INFO: Waiting for StatefulSet e2e-tests-statefulset-hjbxp/ss2 to complete update
Jan 15 14:45:48.328: INFO: Waiting for Pod e2e-tests-statefulset-hjbxp/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 15 14:45:58.324: INFO: Waiting for StatefulSet e2e-tests-statefulset-hjbxp/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 14:46:08.329: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hjbxp
Jan 15 14:46:08.332: INFO: Scaling statefulset ss2 to 0
Jan 15 14:46:18.354: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 14:46:18.357: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:46:18.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hjbxp" for this suite.
Jan 15 14:46:24.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:46:24.441: INFO: namespace: e2e-tests-statefulset-hjbxp, resource: bindings, ignored listing per whitelist
Jan 15 14:46:24.476: INFO: namespace e2e-tests-statefulset-hjbxp deletion completed in 6.098113377s

 [SLOW TEST:136.952 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:46:24.476: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 14:46:24.525: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-bbgj2" to be "success or failure"
Jan 15 14:46:24.528: INFO: Pod "downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.57694ms
Jan 15 14:46:26.532: INFO: Pod "downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007736576s
STEP: Saw pod success
Jan 15 14:46:26.533: INFO: Pod "downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:46:26.536: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 14:46:26.557: INFO: Waiting for pod downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:46:26.560: INFO: Pod downwardapi-volume-54ba91d9-18d4-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:46:26.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bbgj2" for this suite.
Jan 15 14:46:32.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:46:32.641: INFO: namespace: e2e-tests-projected-bbgj2, resource: bindings, ignored listing per whitelist
Jan 15 14:46:32.673: INFO: namespace e2e-tests-projected-bbgj2 deletion completed in 6.108604774s

 [SLOW TEST:8.197 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:46:32.673: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Jan 15 14:46:43.896: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:47:00.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-6tr82" for this suite.
Jan 15 14:47:06.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:47:06.876: INFO: namespace: e2e-tests-namespaces-6tr82, resource: bindings, ignored listing per whitelist
Jan 15 14:47:06.931: INFO: namespace e2e-tests-namespaces-6tr82 deletion completed in 6.118876401s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7p6vv" for this suite.
Jan 15 14:47:06.934: INFO: Namespace e2e-tests-nsdeletetest-7p6vv was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-plrvw" for this suite.
Jan 15 14:47:12.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:47:12.954: INFO: namespace: e2e-tests-nsdeletetest-plrvw, resource: bindings, ignored listing per whitelist
Jan 15 14:47:13.034: INFO: namespace e2e-tests-nsdeletetest-plrvw deletion completed in 6.099486892s

 [SLOW TEST:40.361 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:47:13.034: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hwhwz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 14:47:13.078: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 14:47:33.164: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.100.156.214 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hwhwz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 14:47:33.164: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:47:34.233: INFO: Found all expected endpoints: [netserver-0]
Jan 15 14:47:34.236: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.107.48.20 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hwhwz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 14:47:34.236: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:47:35.299: INFO: Found all expected endpoints: [netserver-1]
Jan 15 14:47:35.303: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.115.205.144 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hwhwz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 14:47:35.303: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:47:36.365: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:47:36.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hwhwz" for this suite.
Jan 15 14:47:58.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:47:58.463: INFO: namespace: e2e-tests-pod-network-test-hwhwz, resource: bindings, ignored listing per whitelist
Jan 15 14:47:58.468: INFO: namespace e2e-tests-pod-network-test-hwhwz deletion completed in 22.098013197s

 [SLOW TEST:45.434 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:47:58.468: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 14:47:58.509: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 15 14:47:58.519: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 15 14:48:03.523: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 14:48:03.523: INFO: Creating deployment "test-rolling-update-deployment"
Jan 15 14:48:03.527: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 15 14:48:03.533: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 15 14:48:05.548: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 15 14:48:05.551: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 14:48:05.560: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-fbrt9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fbrt9/deployments/test-rolling-update-deployment,UID:8fbdfc4a-18d4-11e9-a8cf-02ce79272a22,ResourceVersion:191736,Generation:1,CreationTimestamp:2019-01-15 14:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-15 14:48:03 +0000 UTC 2019-01-15 14:48:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-15 14:48:05 +0000 UTC 2019-01-15 14:48:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79779c8f77" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 15 14:48:05.563: INFO: New ReplicaSet "test-rolling-update-deployment-79779c8f77" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79779c8f77,GenerateName:,Namespace:e2e-tests-deployment-fbrt9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fbrt9/replicasets/test-rolling-update-deployment-79779c8f77,UID:8fbffdd7-18d4-11e9-8532-0a00a28bbe76,ResourceVersion:191727,Generation:1,CreationTimestamp:2019-01-15 14:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 3533574933,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8fbdfc4a-18d4-11e9-a8cf-02ce79272a22 0xc000a1dce7 0xc000a1dce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 3533574933,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 3533574933,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 14:48:05.563: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 15 14:48:05.563: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-fbrt9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fbrt9/replicasets/test-rolling-update-controller,UID:8cc0ece8-18d4-11e9-a8cf-02ce79272a22,ResourceVersion:191735,Generation:2,CreationTimestamp:2019-01-15 14:47:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8fbdfc4a-18d4-11e9-a8cf-02ce79272a22 0xc000a1dbd7 0xc000a1dbd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 14:48:05.566: INFO: Pod "test-rolling-update-deployment-79779c8f77-l2lqx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79779c8f77-l2lqx,GenerateName:test-rolling-update-deployment-79779c8f77-,Namespace:e2e-tests-deployment-fbrt9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fbrt9/pods/test-rolling-update-deployment-79779c8f77-l2lqx,UID:8fc09476-18d4-11e9-8532-0a00a28bbe76,ResourceVersion:191726,Generation:0,CreationTimestamp:2019-01-15 14:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 3533574933,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79779c8f77 8fbffdd7-18d4-11e9-8532-0a00a28bbe76 0xc00107b847 0xc00107b848}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hk45v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hk45v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hk45v true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00107b8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00107ba60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:48:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:48:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:48:03 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:100.100.156.216,StartTime:2019-01-15 14:48:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-15 14:48:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1b819e71b994b416b6820cb9504b7140e9437846972ee95abd91929cc911fc05}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:48:05.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fbrt9" for this suite.
Jan 15 14:48:11.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:48:11.614: INFO: namespace: e2e-tests-deployment-fbrt9, resource: bindings, ignored listing per whitelist
Jan 15 14:48:11.678: INFO: namespace e2e-tests-deployment-fbrt9 deletion completed in 6.107684822s

 [SLOW TEST:13.209 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:48:11.678: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-mgqpf.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-mgqpf.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-mgqpf.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-mgqpf.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-mgqpf.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-mgqpf.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 14:48:23.812: INFO: DNS probes using e2e-tests-dns-mgqpf/dns-test-94a0b5c6-18d4-11e9-9d2c-c274f07984f4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:48:23.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-mgqpf" for this suite.
Jan 15 14:48:29.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:48:29.926: INFO: namespace: e2e-tests-dns-mgqpf, resource: bindings, ignored listing per whitelist
Jan 15 14:48:29.941: INFO: namespace e2e-tests-dns-mgqpf deletion completed in 6.112916526s

 [SLOW TEST:18.263 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:48:29.941: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 14:48:29.987: INFO: Creating deployment "test-recreate-deployment"
Jan 15 14:48:29.994: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 15 14:48:30.002: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan 15 14:48:32.009: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 15 14:48:32.011: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 15 14:48:32.018: INFO: Updating deployment test-recreate-deployment
Jan 15 14:48:32.018: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 14:48:32.062: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-r4xn6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r4xn6/deployments/test-recreate-deployment,UID:9f841e0b-18d4-11e9-a8cf-02ce79272a22,ResourceVersion:191871,Generation:2,CreationTimestamp:2019-01-15 14:48:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-15 14:48:32 +0000 UTC 2019-01-15 14:48:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-15 14:48:32 +0000 UTC 2019-01-15 14:48:29 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7c94d58dbd" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 15 14:48:32.066: INFO: New ReplicaSet "test-recreate-deployment-7c94d58dbd" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7c94d58dbd,GenerateName:,Namespace:e2e-tests-deployment-r4xn6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r4xn6/replicasets/test-recreate-deployment-7c94d58dbd,UID:a0bcef28-18d4-11e9-8532-0a00a28bbe76,ResourceVersion:191869,Generation:1,CreationTimestamp:2019-01-15 14:48:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 3750814868,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9f841e0b-18d4-11e9-a8cf-02ce79272a22 0xc001d1c537 0xc001d1c538}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 3750814868,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 3750814868,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 14:48:32.066: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 15 14:48:32.066: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-685f8785bf,GenerateName:,Namespace:e2e-tests-deployment-r4xn6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r4xn6/replicasets/test-recreate-deployment-685f8785bf,UID:9f84f55a-18d4-11e9-8532-0a00a28bbe76,ResourceVersion:191863,Generation:2,CreationTimestamp:2019-01-15 14:48:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 2419434169,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 9f841e0b-18d4-11e9-a8cf-02ce79272a22 0xc001d1c477 0xc001d1c478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 2419434169,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 2419434169,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 14:48:32.069: INFO: Pod "test-recreate-deployment-7c94d58dbd-79h6b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7c94d58dbd-79h6b,GenerateName:test-recreate-deployment-7c94d58dbd-,Namespace:e2e-tests-deployment-r4xn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r4xn6/pods/test-recreate-deployment-7c94d58dbd-79h6b,UID:a0bd90b3-18d4-11e9-8532-0a00a28bbe76,ResourceVersion:191872,Generation:0,CreationTimestamp:2019-01-15 14:48:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 3750814868,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7c94d58dbd a0bcef28-18d4-11e9-8532-0a00a28bbe76 0xc001d1ce57 0xc001d1ce58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwf4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwf4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwf4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d1cee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d1cf00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:48:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:48:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:48:32 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:,StartTime:2019-01-15 14:48:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:48:32.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-r4xn6" for this suite.
Jan 15 14:48:38.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:48:38.146: INFO: namespace: e2e-tests-deployment-r4xn6, resource: bindings, ignored listing per whitelist
Jan 15 14:48:38.185: INFO: namespace e2e-tests-deployment-r4xn6 deletion completed in 6.112492157s

 [SLOW TEST:8.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:48:38.185: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 15 14:48:38.742: INFO: Waiting up to 5m0s for pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b" in namespace "e2e-tests-svcaccounts-fcbbq" to be "success or failure"
Jan 15 14:48:38.747: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.955452ms
Jan 15 14:48:40.751: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009057864s
STEP: Saw pod success
Jan 15 14:48:40.751: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b" satisfied condition "success or failure"
Jan 15 14:48:40.755: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b container token-test: <nil>
STEP: delete the pod
Jan 15 14:48:40.778: INFO: Waiting for pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b to disappear
Jan 15 14:48:40.781: INFO: Pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-kkv6b no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 15 14:48:40.786: INFO: Waiting up to 5m0s for pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv" in namespace "e2e-tests-svcaccounts-fcbbq" to be "success or failure"
Jan 15 14:48:40.790: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv": Phase="Pending", Reason="", readiness=false. Elapsed: 3.972871ms
Jan 15 14:48:42.794: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007696616s
STEP: Saw pod success
Jan 15 14:48:42.794: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv" satisfied condition "success or failure"
Jan 15 14:48:42.798: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv container root-ca-test: <nil>
STEP: delete the pod
Jan 15 14:48:42.825: INFO: Waiting for pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv to disappear
Jan 15 14:48:42.828: INFO: Pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-7wsxv no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 15 14:48:42.833: INFO: Waiting up to 5m0s for pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw" in namespace "e2e-tests-svcaccounts-fcbbq" to be "success or failure"
Jan 15 14:48:42.838: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.755928ms
Jan 15 14:48:44.842: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008585399s
Jan 15 14:48:46.851: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017558869s
STEP: Saw pod success
Jan 15 14:48:46.851: INFO: Pod "pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw" satisfied condition "success or failure"
Jan 15 14:48:46.853: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw container namespace-test: <nil>
STEP: delete the pod
Jan 15 14:48:46.875: INFO: Waiting for pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw to disappear
Jan 15 14:48:46.878: INFO: Pod pod-service-account-a4ba57bb-18d4-11e9-9d2c-c274f07984f4-zr4cw no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:48:46.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fcbbq" for this suite.
Jan 15 14:48:52.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:48:52.955: INFO: namespace: e2e-tests-svcaccounts-fcbbq, resource: bindings, ignored listing per whitelist
Jan 15 14:48:52.995: INFO: namespace e2e-tests-svcaccounts-fcbbq deletion completed in 6.112603052s

 [SLOW TEST:14.809 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:48:52.995: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ad42713d-18d4-11e9-9d2c-c274f07984f4
STEP: Creating configMap with name cm-test-opt-upd-ad42717f-18d4-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ad42713d-18d4-11e9-9d2c-c274f07984f4
STEP: Updating configmap cm-test-opt-upd-ad42717f-18d4-11e9-9d2c-c274f07984f4
STEP: Creating configMap with name cm-test-opt-create-ad42719a-18d4-11e9-9d2c-c274f07984f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:50:11.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j2jdf" for this suite.
Jan 15 14:50:33.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:50:33.592: INFO: namespace: e2e-tests-projected-j2jdf, resource: bindings, ignored listing per whitelist
Jan 15 14:50:33.664: INFO: namespace e2e-tests-projected-j2jdf deletion completed in 22.09975527s

 [SLOW TEST:100.669 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:50:33.664: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:50:40.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-h2hbj" for this suite.
Jan 15 14:51:02.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:51:02.818: INFO: namespace: e2e-tests-replication-controller-h2hbj, resource: bindings, ignored listing per whitelist
Jan 15 14:51:02.846: INFO: namespace e2e-tests-replication-controller-h2hbj deletion completed in 22.102527046s

 [SLOW TEST:29.182 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:51:02.846: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 15 14:51:02.897: INFO: Waiting up to 5m0s for pod "pod-faa6c478-18d4-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-z2xq5" to be "success or failure"
Jan 15 14:51:02.901: INFO: Pod "pod-faa6c478-18d4-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.333845ms
Jan 15 14:51:04.904: INFO: Pod "pod-faa6c478-18d4-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006749993s
STEP: Saw pod success
Jan 15 14:51:04.904: INFO: Pod "pod-faa6c478-18d4-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:51:04.907: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-faa6c478-18d4-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 14:51:04.929: INFO: Waiting for pod pod-faa6c478-18d4-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:51:04.932: INFO: Pod pod-faa6c478-18d4-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:51:04.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z2xq5" for this suite.
Jan 15 14:51:10.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:51:11.031: INFO: namespace: e2e-tests-emptydir-z2xq5, resource: bindings, ignored listing per whitelist
Jan 15 14:51:11.034: INFO: namespace e2e-tests-emptydir-z2xq5 deletion completed in 6.098195371s

 [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:51:11.034: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ff87acfd-18d4-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 14:51:11.085: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-qqcqj" to be "success or failure"
Jan 15 14:51:11.089: INFO: Pod "pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.432194ms
Jan 15 14:51:13.100: INFO: Pod "pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014866542s
STEP: Saw pod success
Jan 15 14:51:13.100: INFO: Pod "pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:51:13.103: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 14:51:13.127: INFO: Waiting for pod pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:51:13.130: INFO: Pod pod-projected-configmaps-ff889dc1-18d4-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:51:13.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qqcqj" for this suite.
Jan 15 14:51:19.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:51:19.169: INFO: namespace: e2e-tests-projected-qqcqj, resource: bindings, ignored listing per whitelist
Jan 15 14:51:19.236: INFO: namespace e2e-tests-projected-qqcqj deletion completed in 6.101259855s

 [SLOW TEST:8.201 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:51:19.236: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jgcmj
Jan 15 14:51:23.299: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jgcmj
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 14:51:23.302: INFO: Initial restart count of pod liveness-http is 0
Jan 15 14:51:41.347: INFO: Restart count of pod e2e-tests-container-probe-jgcmj/liveness-http is now 1 (18.044909046s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:51:41.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jgcmj" for this suite.
Jan 15 14:51:47.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:51:47.440: INFO: namespace: e2e-tests-container-probe-jgcmj, resource: bindings, ignored listing per whitelist
Jan 15 14:51:47.459: INFO: namespace e2e-tests-container-probe-jgcmj deletion completed in 6.096622888s

 [SLOW TEST:28.223 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:51:47.459: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 14:51:47.530: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:47.530: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:47.530: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:47.535: INFO: Number of nodes with available pods: 0
Jan 15 14:51:47.535: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:51:48.539: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:48.539: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:48.539: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:48.542: INFO: Number of nodes with available pods: 0
Jan 15 14:51:48.542: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:51:49.539: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:49.539: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:49.539: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:49.542: INFO: Number of nodes with available pods: 3
Jan 15 14:51:49.542: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 15 14:51:49.556: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:49.556: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:49.556: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:49.559: INFO: Number of nodes with available pods: 2
Jan 15 14:51:49.559: INFO: Node ip-172-24-62-130.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:51:50.563: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:50.563: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:50.564: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:50.567: INFO: Number of nodes with available pods: 2
Jan 15 14:51:50.567: INFO: Node ip-172-24-62-130.us-east-2.compute.internal is running more than one daemon pod
Jan 15 14:51:51.564: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:51.564: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:51.564: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 14:51:51.567: INFO: Number of nodes with available pods: 3
Jan 15 14:51:51.567: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-sxxdx, will wait for the garbage collector to delete the pods
Jan 15 14:51:51.637: INFO: Deleting DaemonSet.extensions daemon-set took: 9.763057ms
Jan 15 14:51:51.737: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.297797ms
Jan 15 14:52:37.846: INFO: Number of nodes with available pods: 0
Jan 15 14:52:37.846: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 14:52:37.848: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sxxdx/daemonsets","resourceVersion":"192677"},"items":null}

Jan 15 14:52:37.851: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sxxdx/pods","resourceVersion":"192677"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:52:37.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sxxdx" for this suite.
Jan 15 14:52:43.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:52:43.891: INFO: namespace: e2e-tests-daemonsets-sxxdx, resource: bindings, ignored listing per whitelist
Jan 15 14:52:43.964: INFO: namespace e2e-tests-daemonsets-sxxdx deletion completed in 6.098026924s

 [SLOW TEST:56.505 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:52:43.964: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4zxzd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 14:52:44.004: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 14:53:04.079: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.100.156.222:8080/dial?request=hostName&protocol=http&host=100.107.48.27&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4zxzd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 14:53:04.079: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:53:04.153: INFO: Waiting for endpoints: map[]
Jan 15 14:53:04.156: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.100.156.222:8080/dial?request=hostName&protocol=http&host=100.100.156.221&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4zxzd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 14:53:04.157: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:53:04.224: INFO: Waiting for endpoints: map[]
Jan 15 14:53:04.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.100.156.222:8080/dial?request=hostName&protocol=http&host=100.115.205.151&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4zxzd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 14:53:04.227: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 14:53:04.296: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:53:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4zxzd" for this suite.
Jan 15 14:53:26.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:53:26.340: INFO: namespace: e2e-tests-pod-network-test-4zxzd, resource: bindings, ignored listing per whitelist
Jan 15 14:53:26.397: INFO: namespace e2e-tests-pod-network-test-4zxzd deletion completed in 22.097071046s

 [SLOW TEST:42.433 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:53:26.397: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:53:30.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-sxwdx" for this suite.
Jan 15 14:53:36.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:53:36.510: INFO: namespace: e2e-tests-kubelet-test-sxwdx, resource: bindings, ignored listing per whitelist
Jan 15 14:53:36.559: INFO: namespace e2e-tests-kubelet-test-sxwdx deletion completed in 6.094055087s

 [SLOW TEST:10.162 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:53:36.559: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 15 14:53:36.610: INFO: Waiting up to 5m0s for pod "pod-56456662-18d5-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-k54b7" to be "success or failure"
Jan 15 14:53:36.613: INFO: Pod "pod-56456662-18d5-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.6631ms
Jan 15 14:53:38.617: INFO: Pod "pod-56456662-18d5-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007248077s
STEP: Saw pod success
Jan 15 14:53:38.617: INFO: Pod "pod-56456662-18d5-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:53:38.620: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-56456662-18d5-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 14:53:38.642: INFO: Waiting for pod pod-56456662-18d5-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:53:38.645: INFO: Pod pod-56456662-18d5-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:53:38.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k54b7" for this suite.
Jan 15 14:53:44.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:53:44.688: INFO: namespace: e2e-tests-emptydir-k54b7, resource: bindings, ignored listing per whitelist
Jan 15 14:53:44.745: INFO: namespace e2e-tests-emptydir-k54b7 deletion completed in 6.095228461s

 [SLOW TEST:8.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:53:44.745: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-wdv7
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 14:53:44.802: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wdv7" in namespace "e2e-tests-subpath-cnjz7" to be "success or failure"
Jan 15 14:53:44.807: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.715042ms
Jan 15 14:53:46.810: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008204686s
Jan 15 14:53:48.814: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 4.011828437s
Jan 15 14:53:50.823: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 6.021101614s
Jan 15 14:53:52.826: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 8.024481174s
Jan 15 14:53:54.830: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 10.028320975s
Jan 15 14:53:56.834: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 12.031927128s
Jan 15 14:53:58.837: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 14.03545306s
Jan 15 14:54:00.846: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 16.044550473s
Jan 15 14:54:02.850: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 18.04794477s
Jan 15 14:54:04.853: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 20.051315458s
Jan 15 14:54:06.857: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Running", Reason="", readiness=false. Elapsed: 22.054675605s
Jan 15 14:54:08.860: INFO: Pod "pod-subpath-test-downwardapi-wdv7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05849108s
STEP: Saw pod success
Jan 15 14:54:08.860: INFO: Pod "pod-subpath-test-downwardapi-wdv7" satisfied condition "success or failure"
Jan 15 14:54:08.863: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-subpath-test-downwardapi-wdv7 container test-container-subpath-downwardapi-wdv7: <nil>
STEP: delete the pod
Jan 15 14:54:08.885: INFO: Waiting for pod pod-subpath-test-downwardapi-wdv7 to disappear
Jan 15 14:54:08.888: INFO: Pod pod-subpath-test-downwardapi-wdv7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wdv7
Jan 15 14:54:08.888: INFO: Deleting pod "pod-subpath-test-downwardapi-wdv7" in namespace "e2e-tests-subpath-cnjz7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:54:08.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cnjz7" for this suite.
Jan 15 14:54:14.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:54:14.927: INFO: namespace: e2e-tests-subpath-cnjz7, resource: bindings, ignored listing per whitelist
Jan 15 14:54:14.990: INFO: namespace e2e-tests-subpath-cnjz7 deletion completed in 6.094880969s

 [SLOW TEST:30.245 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:54:14.990: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6d2d9aef-18d5-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 14:54:15.073: INFO: Waiting up to 5m0s for pod "pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-95qhb" to be "success or failure"
Jan 15 14:54:15.077: INFO: Pod "pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.439282ms
Jan 15 14:54:17.080: INFO: Pod "pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00691393s
STEP: Saw pod success
Jan 15 14:54:17.080: INFO: Pod "pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 14:54:17.083: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 14:54:17.103: INFO: Waiting for pod pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4 to disappear
Jan 15 14:54:17.106: INFO: Pod pod-secrets-6d330c4e-18d5-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:54:17.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-95qhb" for this suite.
Jan 15 14:54:23.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:54:23.152: INFO: namespace: e2e-tests-secrets-95qhb, resource: bindings, ignored listing per whitelist
Jan 15 14:54:23.204: INFO: namespace e2e-tests-secrets-95qhb deletion completed in 6.095261877s
STEP: Destroying namespace "e2e-tests-secret-namespace-r76qs" for this suite.
Jan 15 14:54:29.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:54:29.230: INFO: namespace: e2e-tests-secret-namespace-r76qs, resource: bindings, ignored listing per whitelist
Jan 15 14:54:29.301: INFO: namespace e2e-tests-secret-namespace-r76qs deletion completed in 6.09695778s

 [SLOW TEST:14.311 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:54:29.301: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 15 14:54:29.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:29.627: INFO: stderr: ""
Jan 15 14:54:29.627: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 14:54:29.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:29.691: INFO: stderr: ""
Jan 15 14:54:29.691: INFO: stdout: "update-demo-nautilus-wv4g7 update-demo-nautilus-ww7vj "
Jan 15 14:54:29.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-wv4g7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:29.750: INFO: stderr: ""
Jan 15 14:54:29.750: INFO: stdout: ""
Jan 15 14:54:29.750: INFO: update-demo-nautilus-wv4g7 is created but not running
Jan 15 14:54:34.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:34.815: INFO: stderr: ""
Jan 15 14:54:34.815: INFO: stdout: "update-demo-nautilus-wv4g7 update-demo-nautilus-ww7vj "
Jan 15 14:54:34.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-wv4g7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:34.875: INFO: stderr: ""
Jan 15 14:54:34.875: INFO: stdout: "true"
Jan 15 14:54:34.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-wv4g7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:34.931: INFO: stderr: ""
Jan 15 14:54:34.931: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:54:34.931: INFO: validating pod update-demo-nautilus-wv4g7
Jan 15 14:54:34.937: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:54:34.937: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:54:34.937: INFO: update-demo-nautilus-wv4g7 is verified up and running
Jan 15 14:54:34.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-ww7vj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:34.995: INFO: stderr: ""
Jan 15 14:54:34.995: INFO: stdout: "true"
Jan 15 14:54:34.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-ww7vj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:35.056: INFO: stderr: ""
Jan 15 14:54:35.056: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:54:35.056: INFO: validating pod update-demo-nautilus-ww7vj
Jan 15 14:54:35.060: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:54:35.060: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:54:35.060: INFO: update-demo-nautilus-ww7vj is verified up and running
STEP: rolling-update to new replication controller
Jan 15 14:54:35.061: INFO: scanned /root for discovery docs: <nil>
Jan 15 14:54:35.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:57.344: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 15 14:54:57.344: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 14:54:57.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:54:57.407: INFO: stderr: ""
Jan 15 14:54:57.407: INFO: stdout: "update-demo-kitten-77b5s update-demo-kitten-hp4sd update-demo-nautilus-ww7vj "
STEP: Replicas for name=update-demo: expected=2 actual=3
Jan 15 14:55:02.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:55:02.477: INFO: stderr: ""
Jan 15 14:55:02.477: INFO: stdout: "update-demo-kitten-77b5s update-demo-kitten-hp4sd "
Jan 15 14:55:02.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-kitten-77b5s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:55:02.538: INFO: stderr: ""
Jan 15 14:55:02.538: INFO: stdout: "true"
Jan 15 14:55:02.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-kitten-77b5s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:55:02.598: INFO: stderr: ""
Jan 15 14:55:02.598: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 15 14:55:02.598: INFO: validating pod update-demo-kitten-77b5s
Jan 15 14:55:02.603: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 15 14:55:02.603: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 15 14:55:02.603: INFO: update-demo-kitten-77b5s is verified up and running
Jan 15 14:55:02.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-kitten-hp4sd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:55:02.659: INFO: stderr: ""
Jan 15 14:55:02.659: INFO: stdout: "true"
Jan 15 14:55:02.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-kitten-hp4sd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ncwpl'
Jan 15 14:55:02.718: INFO: stderr: ""
Jan 15 14:55:02.718: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 15 14:55:02.718: INFO: validating pod update-demo-kitten-hp4sd
Jan 15 14:55:02.724: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 15 14:55:02.724: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 15 14:55:02.724: INFO: update-demo-kitten-hp4sd is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:55:02.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ncwpl" for this suite.
Jan 15 14:55:24.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:55:24.753: INFO: namespace: e2e-tests-kubectl-ncwpl, resource: bindings, ignored listing per whitelist
Jan 15 14:55:24.828: INFO: namespace e2e-tests-kubectl-ncwpl deletion completed in 22.100776425s

 [SLOW TEST:55.527 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:55:24.828: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 15 14:55:24.896: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-smcnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-smcnj/configmaps/e2e-watch-test-resource-version,UID:96cde4ec-18d5-11e9-a8cf-02ce79272a22,ResourceVersion:193334,Generation:0,CreationTimestamp:2019-01-15 14:55:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 14:55:24.896: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-smcnj,SelfLink:/api/v1/namespaces/e2e-tests-watch-smcnj/configmaps/e2e-watch-test-resource-version,UID:96cde4ec-18d5-11e9-a8cf-02ce79272a22,ResourceVersion:193335,Generation:0,CreationTimestamp:2019-01-15 14:55:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:55:24.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-smcnj" for this suite.
Jan 15 14:55:30.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:55:30.952: INFO: namespace: e2e-tests-watch-smcnj, resource: bindings, ignored listing per whitelist
Jan 15 14:55:30.998: INFO: namespace e2e-tests-watch-smcnj deletion completed in 6.098393698s

 [SLOW TEST:6.170 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:55:30.998: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 15 14:55:31.036: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 14:55:31.043: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 14:55:31.046: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-119-14.us-east-2.compute.internal before test
Jan 15 14:55:31.052: INFO: kube-proxy-ip-172-24-119-14.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 14:55:31.052: INFO: nginx-ingress-controller-78bb4d5664-7mjzf from ingress-nginx started at 2019-01-14 14:09:14 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 15 14:55:31.052: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-6snp6 from platform started at 2019-01-14 14:25:28 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: false, restart count 0
Jan 15 14:55:31.052: INFO: 	Container filebeat ready: false, restart count 0
Jan 15 14:55:31.052: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-g9xsw from platform started at 2019-01-14 14:53:45 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 14:55:31.052: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.052: INFO: calico-node-46lhq from kube-system started at 2019-01-14 13:47:01 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 14:55:31.052: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 14:55:31.052: INFO: default-http-backend-846b65fb5f-pmll5 from ingress-nginx started at 2019-01-14 14:09:14 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container default-http-backend ready: true, restart count 0
Jan 15 14:55:31.052: INFO: tiller-deploy-64ddd985c9-fjhs4 from kube-system started at 2019-01-14 14:10:18 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container tiller ready: true, restart count 0
Jan 15 14:55:31.052: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-7s94d from platform started at 2019-01-14 14:34:46 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 14:55:31.052: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.052: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-vh7zc from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.052: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: false, restart count 245
Jan 15 14:55:31.052: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.052: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-62-130.us-east-2.compute.internal before test
Jan 15 14:55:31.058: INFO: kube-proxy-ip-172-24-62-130.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 14:55:31.058: INFO: kube-dns-6b4f4b544c-l248h from kube-system started at 2019-01-14 13:47:21 +0000 UTC (3 container statuses recorded)
Jan 15 14:55:31.058: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 14:55:31.058: INFO: dev-pf-conf-svc-platform-conf-svc-958fddc8f-sl6vl from platform started at 2019-01-14 14:23:07 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.058: INFO: 	Container dev-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.058: INFO: stg-pf-sign-svc-platform-signup-svc-74fb49b447-rqr8g from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.058: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container stg-pf-sign-svc-platform-signup-svc ready: false, restart count 247
Jan 15 14:55:31.058: INFO: calico-node-ftx9x from kube-system started at 2019-01-14 13:46:59 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.058: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 14:55:31.058: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-bfcxr from platform started at 2019-01-14 14:37:34 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.058: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.058: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-nvgqq from platform started at 2019-01-14 14:55:41 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.058: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.058: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-87-161.us-east-2.compute.internal before test
Jan 15 14:55:31.065: INFO: kube-proxy-ip-172-24-87-161.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 14:55:31.065: INFO: calico-node-b7djp from kube-system started at 2019-01-14 13:46:58 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 14:55:31.065: INFO: heapster-66b886659c-lndvb from kube-system started at 2019-01-14 14:07:19 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container heapster ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 15 14:55:31.065: INFO: platform-utils-svc-7fbd5dd74c-zzz5q from platform started at 2019-01-14 14:17:49 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container platform-utils-svc ready: true, restart count 0
Jan 15 14:55:31.065: INFO: calico-complete-upgrade-v331-68hdc from kube-system started at 2019-01-14 13:47:19 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container migrate-completion ready: false, restart count 0
Jan 15 14:55:31.065: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-15 14:39:28 +0000 UTC (3 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container cleanup ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container forwarder ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 14:55:31.065: INFO: kube-dns-6b4f4b544c-xw7bn from kube-system started at 2019-01-14 13:47:19 +0000 UTC (3 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 14:55:31.065: INFO: kube-dns-autoscaler-6b658bd4d5-6bgxt from kube-system started at 2019-01-14 13:47:19 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 14:55:31.065: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-bckvj from platform started at 2019-01-14 14:53:45 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.065: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-88r5r from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: true, restart count 246
Jan 15 14:55:31.065: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.065: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-9jpmd from platform started at 2019-01-14 14:25:28 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 14:55:31.065: INFO: dev-pf-sign-ui-platform-signup-ui-57985cd7f8-gw4km from platform started at 2019-01-14 14:49:12 +0000 UTC (1 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container platform-signup-ui ready: false, restart count 0
Jan 15 14:55:31.065: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-kb4xz from platform started at 2019-01-14 14:55:05 +0000 UTC (2 container statuses recorded)
Jan 15 14:55:31.065: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 14:55:31.065: INFO: 	Container filebeat ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9ce7924c-18d5-11e9-9d2c-c274f07984f4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9ce7924c-18d5-11e9-9d2c-c274f07984f4 off the node ip-172-24-62-130.us-east-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9ce7924c-18d5-11e9-9d2c-c274f07984f4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:55:37.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qt8nt" for this suite.
Jan 15 14:55:45.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:55:45.225: INFO: namespace: e2e-tests-sched-pred-qt8nt, resource: bindings, ignored listing per whitelist
Jan 15 14:55:45.243: INFO: namespace e2e-tests-sched-pred-qt8nt deletion completed in 8.101190667s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

 [SLOW TEST:14.246 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:55:45.244: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 14:55:45.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 version --client'
Jan 15 14:55:45.327: INFO: stderr: ""
Jan 15 14:55:45.327: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 15 14:55:45.328: INFO: Not supported for server versions before "1.13.0"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:55:45.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hvn7v" for this suite.
Jan 15 14:55:51.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:55:51.426: INFO: namespace: e2e-tests-kubectl-hvn7v, resource: bindings, ignored listing per whitelist
Jan 15 14:55:51.429: INFO: namespace e2e-tests-kubectl-hvn7v deletion completed in 6.096245597s

S [SKIPPING] [6.185 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Jan 15 14:55:45.328: Not supported for server versions before "1.13.0"

    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:55:51.429: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7ptq9 in namespace e2e-tests-proxy-vrpl7
I0115 14:55:51.485496      18 runners.go:184] Created replication controller with name: proxy-service-7ptq9, namespace: e2e-tests-proxy-vrpl7, replica count: 1
I0115 14:55:52.536152      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 14:55:53.536499      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 14:55:54.536771      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:55:55.536977      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:55:56.537249      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:55:57.537457      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:55:58.537690      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:55:59.537913      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:56:00.538190      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:56:01.538409      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:56:02.538645      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 14:56:03.538850      18 runners.go:184] proxy-service-7ptq9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 15 14:56:03.560: INFO: setup took 12.093325744s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 9.064366ms)
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 9.512901ms)
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 9.478067ms)
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 9.44885ms)
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 9.530176ms)
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 9.473272ms)
Jan 15 14:56:03.570: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 9.601771ms)
Jan 15 14:56:03.572: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 11.229636ms)
Jan 15 14:56:03.572: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 11.260715ms)
Jan 15 14:56:03.572: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 11.276929ms)
Jan 15 14:56:03.572: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 11.339958ms)
Jan 15 14:56:03.575: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 14.646765ms)
Jan 15 14:56:03.576: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 15.300303ms)
Jan 15 14:56:03.579: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 18.049415ms)
Jan 15 14:56:03.581: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 20.388531ms)
Jan 15 14:56:03.581: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 20.736606ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.500551ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.596625ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.712064ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.705565ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 7.243628ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 7.211344ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 7.157316ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 7.164963ms)
Jan 15 14:56:03.588: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 7.168427ms)
Jan 15 14:56:03.589: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 7.202131ms)
Jan 15 14:56:03.589: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 7.924388ms)
Jan 15 14:56:03.591: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 9.807101ms)
Jan 15 14:56:03.591: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.793521ms)
Jan 15 14:56:03.591: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.704735ms)
Jan 15 14:56:03.591: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.691479ms)
Jan 15 14:56:03.591: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.811408ms)
Jan 15 14:56:03.595: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 3.919226ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 5.881806ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.077675ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.179382ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.169008ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.292591ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.207976ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.085161ms)
Jan 15 14:56:03.597: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.128263ms)
Jan 15 14:56:03.599: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 7.247321ms)
Jan 15 14:56:03.600: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 8.909216ms)
Jan 15 14:56:03.600: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 8.847136ms)
Jan 15 14:56:03.600: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 8.920121ms)
Jan 15 14:56:03.600: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.053627ms)
Jan 15 14:56:03.600: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.113631ms)
Jan 15 14:56:03.600: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.072262ms)
Jan 15 14:56:03.605: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 4.135378ms)
Jan 15 14:56:03.606: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 5.866598ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.092ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.155728ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.176165ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.192182ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.369532ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.353139ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.473003ms)
Jan 15 14:56:03.607: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.60264ms)
Jan 15 14:56:03.609: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 8.166813ms)
Jan 15 14:56:03.611: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 10.330529ms)
Jan 15 14:56:03.611: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 10.276267ms)
Jan 15 14:56:03.611: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 10.290324ms)
Jan 15 14:56:03.611: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 10.419701ms)
Jan 15 14:56:03.611: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 10.363709ms)
Jan 15 14:56:03.615: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 3.860482ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 5.847037ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 5.813626ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.954774ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.962855ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 5.863323ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.107891ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.970714ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.925084ms)
Jan 15 14:56:03.617: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 5.953514ms)
Jan 15 14:56:03.619: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 7.751496ms)
Jan 15 14:56:03.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.723977ms)
Jan 15 14:56:03.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.652979ms)
Jan 15 14:56:03.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.661353ms)
Jan 15 14:56:03.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 9.721799ms)
Jan 15 14:56:03.621: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.889981ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.891447ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.819544ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.045702ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.060632ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.094306ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.223872ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.285294ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.350628ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.357222ms)
Jan 15 14:56:03.627: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.367067ms)
Jan 15 14:56:03.628: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 7.446493ms)
Jan 15 14:56:03.630: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.271844ms)
Jan 15 14:56:03.630: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.210559ms)
Jan 15 14:56:03.630: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.199377ms)
Jan 15 14:56:03.630: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.311903ms)
Jan 15 14:56:03.630: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.29256ms)
Jan 15 14:56:03.635: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 4.848496ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.260524ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.288239ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.389137ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.298883ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.368356ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.28741ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.221421ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.39872ms)
Jan 15 14:56:03.637: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.346826ms)
Jan 15 14:56:03.638: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 7.903366ms)
Jan 15 14:56:03.639: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 8.21622ms)
Jan 15 14:56:03.640: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.764329ms)
Jan 15 14:56:03.640: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.82305ms)
Jan 15 14:56:03.640: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.795254ms)
Jan 15 14:56:03.640: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 9.894435ms)
Jan 15 14:56:03.645: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 4.408922ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.158562ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.164509ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.274577ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.821036ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.648831ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.931665ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.925236ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.834598ms)
Jan 15 14:56:03.647: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.940009ms)
Jan 15 14:56:03.649: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 8.697677ms)
Jan 15 14:56:03.651: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 10.60681ms)
Jan 15 14:56:03.651: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 10.575789ms)
Jan 15 14:56:03.651: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 10.63685ms)
Jan 15 14:56:03.651: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 10.783123ms)
Jan 15 14:56:03.651: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 10.747623ms)
Jan 15 14:56:03.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 4.158278ms)
Jan 15 14:56:03.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.003379ms)
Jan 15 14:56:03.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.063688ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.144559ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.117468ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.153543ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.307771ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.149338ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.218127ms)
Jan 15 14:56:03.658: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.299929ms)
Jan 15 14:56:03.659: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 7.912512ms)
Jan 15 14:56:03.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.797318ms)
Jan 15 14:56:03.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.911989ms)
Jan 15 14:56:03.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.890479ms)
Jan 15 14:56:03.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 9.86653ms)
Jan 15 14:56:03.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.863118ms)
Jan 15 14:56:03.667: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.749882ms)
Jan 15 14:56:03.667: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.782584ms)
Jan 15 14:56:03.667: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 5.938847ms)
Jan 15 14:56:03.667: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 5.999432ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.108309ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.271919ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.201455ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.173535ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.237507ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.312622ms)
Jan 15 14:56:03.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 7.157011ms)
Jan 15 14:56:03.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 8.854018ms)
Jan 15 14:56:03.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 8.811442ms)
Jan 15 14:56:03.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 8.944569ms)
Jan 15 14:56:03.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 9.000956ms)
Jan 15 14:56:03.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.036648ms)
Jan 15 14:56:03.676: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 5.650775ms)
Jan 15 14:56:03.676: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.651619ms)
Jan 15 14:56:03.676: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 5.856603ms)
Jan 15 14:56:03.677: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 5.954742ms)
Jan 15 14:56:03.677: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.112707ms)
Jan 15 14:56:03.677: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.21743ms)
Jan 15 14:56:03.678: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 7.682368ms)
Jan 15 14:56:03.678: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 7.711125ms)
Jan 15 14:56:03.678: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 7.758373ms)
Jan 15 14:56:03.678: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 7.900129ms)
Jan 15 14:56:03.678: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 7.76121ms)
Jan 15 14:56:03.680: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.34876ms)
Jan 15 14:56:03.680: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.432751ms)
Jan 15 14:56:03.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 11.211363ms)
Jan 15 14:56:03.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 11.233897ms)
Jan 15 14:56:03.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 11.184907ms)
Jan 15 14:56:03.687: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 4.860324ms)
Jan 15 14:56:03.688: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.016606ms)
Jan 15 14:56:03.688: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.618696ms)
Jan 15 14:56:03.689: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.57286ms)
Jan 15 14:56:03.689: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.603721ms)
Jan 15 14:56:03.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 7.918232ms)
Jan 15 14:56:03.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 8.064596ms)
Jan 15 14:56:03.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 7.965154ms)
Jan 15 14:56:03.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 8.004619ms)
Jan 15 14:56:03.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 8.217586ms)
Jan 15 14:56:03.692: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.703501ms)
Jan 15 14:56:03.692: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.98719ms)
Jan 15 14:56:03.692: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.998592ms)
Jan 15 14:56:03.693: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 11.369505ms)
Jan 15 14:56:03.693: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 11.588056ms)
Jan 15 14:56:03.694: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 11.667492ms)
Jan 15 14:56:03.699: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 5.338136ms)
Jan 15 14:56:03.700: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 5.951651ms)
Jan 15 14:56:03.700: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.194547ms)
Jan 15 14:56:03.700: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.273361ms)
Jan 15 14:56:03.700: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.372665ms)
Jan 15 14:56:03.700: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.43173ms)
Jan 15 14:56:03.700: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.374992ms)
Jan 15 14:56:03.702: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 8.043439ms)
Jan 15 14:56:03.702: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 8.052296ms)
Jan 15 14:56:03.702: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 8.103223ms)
Jan 15 14:56:03.704: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.82812ms)
Jan 15 14:56:03.704: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.788368ms)
Jan 15 14:56:03.704: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.872616ms)
Jan 15 14:56:03.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 11.435161ms)
Jan 15 14:56:03.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 11.467763ms)
Jan 15 14:56:03.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 11.580803ms)
Jan 15 14:56:03.709: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 3.903381ms)
Jan 15 14:56:03.711: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 5.759409ms)
Jan 15 14:56:03.711: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.909785ms)
Jan 15 14:56:03.711: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 5.967082ms)
Jan 15 14:56:03.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.104302ms)
Jan 15 14:56:03.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.158722ms)
Jan 15 14:56:03.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.163466ms)
Jan 15 14:56:03.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.209973ms)
Jan 15 14:56:03.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.272319ms)
Jan 15 14:56:03.712: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.173111ms)
Jan 15 14:56:03.713: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 8.024156ms)
Jan 15 14:56:03.715: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 10.121925ms)
Jan 15 14:56:03.715: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 10.08111ms)
Jan 15 14:56:03.716: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 10.151544ms)
Jan 15 14:56:03.716: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 10.143649ms)
Jan 15 14:56:03.716: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 10.158942ms)
Jan 15 14:56:03.720: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 4.01275ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.052964ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.19688ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.153269ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.215208ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.291186ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.232754ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.290164ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.381849ms)
Jan 15 14:56:03.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.394792ms)
Jan 15 14:56:03.724: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 8.254235ms)
Jan 15 14:56:03.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 10.237307ms)
Jan 15 14:56:03.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 10.43059ms)
Jan 15 14:56:03.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 10.339776ms)
Jan 15 14:56:03.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 10.463343ms)
Jan 15 14:56:03.726: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 10.602707ms)
Jan 15 14:56:03.731: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 4.207703ms)
Jan 15 14:56:03.732: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.185881ms)
Jan 15 14:56:03.732: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.11621ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.195584ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.601237ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.709848ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.691881ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.648716ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.7115ms)
Jan 15 14:56:03.733: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.645247ms)
Jan 15 14:56:03.735: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 8.276903ms)
Jan 15 14:56:03.736: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.872985ms)
Jan 15 14:56:03.736: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.924932ms)
Jan 15 14:56:03.736: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 10.06083ms)
Jan 15 14:56:03.736: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 10.044913ms)
Jan 15 14:56:03.736: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 10.096767ms)
Jan 15 14:56:03.741: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 4.116964ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.84764ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.922394ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 5.917939ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 5.971673ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 5.950815ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.023633ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 5.992299ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.068401ms)
Jan 15 14:56:03.743: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.049921ms)
Jan 15 14:56:03.744: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 7.891462ms)
Jan 15 14:56:03.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.5739ms)
Jan 15 14:56:03.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.66464ms)
Jan 15 14:56:03.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.683499ms)
Jan 15 14:56:03.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.743011ms)
Jan 15 14:56:03.746: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.84024ms)
Jan 15 14:56:03.752: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.000607ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 5.943803ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.11964ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.182459ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.766272ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.733894ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.680557ms)
Jan 15 14:56:03.753: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 6.698733ms)
Jan 15 14:56:03.754: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 7.924403ms)
Jan 15 14:56:03.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 8.050802ms)
Jan 15 14:56:03.755: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 8.09195ms)
Jan 15 14:56:03.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 9.398524ms)
Jan 15 14:56:03.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.189055ms)
Jan 15 14:56:03.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.431841ms)
Jan 15 14:56:03.756: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.546949ms)
Jan 15 14:56:03.758: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 11.149898ms)
Jan 15 14:56:03.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.383938ms)
Jan 15 14:56:03.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.348502ms)
Jan 15 14:56:03.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.564257ms)
Jan 15 14:56:03.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.506389ms)
Jan 15 14:56:03.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.52277ms)
Jan 15 14:56:03.764: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.568591ms)
Jan 15 14:56:03.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 7.964866ms)
Jan 15 14:56:03.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 7.918603ms)
Jan 15 14:56:03.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 8.06606ms)
Jan 15 14:56:03.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 7.930453ms)
Jan 15 14:56:03.766: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 7.957831ms)
Jan 15 14:56:03.767: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 9.63919ms)
Jan 15 14:56:03.767: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.58714ms)
Jan 15 14:56:03.769: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 11.361267ms)
Jan 15 14:56:03.769: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 11.470745ms)
Jan 15 14:56:03.769: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 11.579953ms)
Jan 15 14:56:03.775: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:443/proxy/... (200; 5.972396ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.252907ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.296997ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:462/proxy/: tls qux (200; 6.410769ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:162/proxy/: bar (200; 6.316205ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:160/proxy/: foo (200; 6.27401ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/https:proxy-service-7ptq9-szn5b:460/proxy/: tls baz (200; 6.345153ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/http:proxy-service-7ptq9-szn5b:1080/proxy/... (200; 6.304513ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b:1080/proxy/rewri... (200; 6.355924ms)
Jan 15 14:56:03.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vrpl7/pods/proxy-service-7ptq9-szn5b/proxy/rewriteme"... (200; 6.439081ms)
Jan 15 14:56:03.777: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname2/proxy/: bar (200; 7.744906ms)
Jan 15 14:56:03.777: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname1/proxy/: tls baz (200; 7.857138ms)
Jan 15 14:56:03.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname2/proxy/: bar (200; 9.710002ms)
Jan 15 14:56:03.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/proxy-service-7ptq9:portname1/proxy/: foo (200; 9.730081ms)
Jan 15 14:56:03.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/https:proxy-service-7ptq9:tlsportname2/proxy/: tls qux (200; 9.8627ms)
Jan 15 14:56:03.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vrpl7/services/http:proxy-service-7ptq9:portname1/proxy/: foo (200; 9.803931ms)
STEP: deleting ReplicationController proxy-service-7ptq9 in namespace e2e-tests-proxy-vrpl7, will wait for the garbage collector to delete the pods
Jan 15 14:56:03.840: INFO: Deleting ReplicationController proxy-service-7ptq9 took: 8.067122ms
Jan 15 14:56:03.941: INFO: Terminating ReplicationController proxy-service-7ptq9 pods took: 100.301807ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:56:09.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vrpl7" for this suite.
Jan 15 14:56:15.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:56:15.737: INFO: namespace: e2e-tests-proxy-vrpl7, resource: bindings, ignored listing per whitelist
Jan 15 14:56:15.742: INFO: namespace e2e-tests-proxy-vrpl7 deletion completed in 6.096807958s

 [SLOW TEST:24.313 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:56:15.742: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 15 14:56:15.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:15.904: INFO: stderr: ""
Jan 15 14:56:15.904: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 14:56:15.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:15.971: INFO: stderr: ""
Jan 15 14:56:15.971: INFO: stdout: "update-demo-nautilus-f9nrb update-demo-nautilus-j7c4b "
Jan 15 14:56:15.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:16.030: INFO: stderr: ""
Jan 15 14:56:16.030: INFO: stdout: ""
Jan 15 14:56:16.030: INFO: update-demo-nautilus-f9nrb is created but not running
Jan 15 14:56:21.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:21.092: INFO: stderr: ""
Jan 15 14:56:21.092: INFO: stdout: "update-demo-nautilus-f9nrb update-demo-nautilus-j7c4b "
Jan 15 14:56:21.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:21.151: INFO: stderr: ""
Jan 15 14:56:21.152: INFO: stdout: "true"
Jan 15 14:56:21.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:21.210: INFO: stderr: ""
Jan 15 14:56:21.210: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:56:21.210: INFO: validating pod update-demo-nautilus-f9nrb
Jan 15 14:56:21.216: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:56:21.216: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:56:21.216: INFO: update-demo-nautilus-f9nrb is verified up and running
Jan 15 14:56:21.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-j7c4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:21.278: INFO: stderr: ""
Jan 15 14:56:21.278: INFO: stdout: "true"
Jan 15 14:56:21.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-j7c4b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:21.336: INFO: stderr: ""
Jan 15 14:56:21.336: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:56:21.336: INFO: validating pod update-demo-nautilus-j7c4b
Jan 15 14:56:21.341: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:56:21.341: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:56:21.341: INFO: update-demo-nautilus-j7c4b is verified up and running
STEP: scaling down the replication controller
Jan 15 14:56:21.342: INFO: scanned /root for discovery docs: <nil>
Jan 15 14:56:21.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:22.423: INFO: stderr: ""
Jan 15 14:56:22.423: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 14:56:22.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:22.482: INFO: stderr: ""
Jan 15 14:56:22.482: INFO: stdout: "update-demo-nautilus-f9nrb update-demo-nautilus-j7c4b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 15 14:56:27.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:27.543: INFO: stderr: ""
Jan 15 14:56:27.543: INFO: stdout: "update-demo-nautilus-f9nrb update-demo-nautilus-j7c4b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 15 14:56:32.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:32.606: INFO: stderr: ""
Jan 15 14:56:32.606: INFO: stdout: "update-demo-nautilus-f9nrb "
Jan 15 14:56:32.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:32.664: INFO: stderr: ""
Jan 15 14:56:32.664: INFO: stdout: "true"
Jan 15 14:56:32.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:32.725: INFO: stderr: ""
Jan 15 14:56:32.725: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:56:32.725: INFO: validating pod update-demo-nautilus-f9nrb
Jan 15 14:56:32.735: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:56:32.735: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:56:32.735: INFO: update-demo-nautilus-f9nrb is verified up and running
STEP: scaling up the replication controller
Jan 15 14:56:32.736: INFO: scanned /root for discovery docs: <nil>
Jan 15 14:56:32.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:33.819: INFO: stderr: ""
Jan 15 14:56:33.819: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 14:56:33.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:33.881: INFO: stderr: ""
Jan 15 14:56:33.881: INFO: stdout: "update-demo-nautilus-f9nrb update-demo-nautilus-l94bn "
Jan 15 14:56:33.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:33.937: INFO: stderr: ""
Jan 15 14:56:33.937: INFO: stdout: "true"
Jan 15 14:56:33.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:33.996: INFO: stderr: ""
Jan 15 14:56:33.996: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:56:33.996: INFO: validating pod update-demo-nautilus-f9nrb
Jan 15 14:56:34.001: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:56:34.001: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:56:34.001: INFO: update-demo-nautilus-f9nrb is verified up and running
Jan 15 14:56:34.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-l94bn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:34.060: INFO: stderr: ""
Jan 15 14:56:34.060: INFO: stdout: ""
Jan 15 14:56:34.060: INFO: update-demo-nautilus-l94bn is created but not running
Jan 15 14:56:39.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.119: INFO: stderr: ""
Jan 15 14:56:39.120: INFO: stdout: "update-demo-nautilus-f9nrb update-demo-nautilus-l94bn "
Jan 15 14:56:39.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.178: INFO: stderr: ""
Jan 15 14:56:39.178: INFO: stdout: "true"
Jan 15 14:56:39.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-f9nrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.236: INFO: stderr: ""
Jan 15 14:56:39.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:56:39.236: INFO: validating pod update-demo-nautilus-f9nrb
Jan 15 14:56:39.240: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:56:39.240: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:56:39.240: INFO: update-demo-nautilus-f9nrb is verified up and running
Jan 15 14:56:39.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-l94bn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.296: INFO: stderr: ""
Jan 15 14:56:39.296: INFO: stdout: "true"
Jan 15 14:56:39.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-l94bn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.354: INFO: stderr: ""
Jan 15 14:56:39.354: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 14:56:39.354: INFO: validating pod update-demo-nautilus-l94bn
Jan 15 14:56:39.361: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 14:56:39.361: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 14:56:39.361: INFO: update-demo-nautilus-l94bn is verified up and running
STEP: using delete to clean up resources
Jan 15 14:56:39.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.422: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 14:56:39.422: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 15 14:56:39.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-gbz4j'
Jan 15 14:56:39.484: INFO: stderr: "No resources found.\n"
Jan 15 14:56:39.484: INFO: stdout: ""
Jan 15 14:56:39.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -l name=update-demo --namespace=e2e-tests-kubectl-gbz4j -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 14:56:39.545: INFO: stderr: ""
Jan 15 14:56:39.545: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:56:39.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gbz4j" for this suite.
Jan 15 14:57:01.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:57:01.604: INFO: namespace: e2e-tests-kubectl-gbz4j, resource: bindings, ignored listing per whitelist
Jan 15 14:57:01.643: INFO: namespace e2e-tests-kubectl-gbz4j deletion completed in 22.093818539s

 [SLOW TEST:45.901 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:57:01.643: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 15 14:57:01.698: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m4rhw,SelfLink:/api/v1/namespaces/e2e-tests-watch-m4rhw/configmaps/e2e-watch-test-watch-closed,UID:d082eea9-18d5-11e9-a8cf-02ce79272a22,ResourceVersion:193713,Generation:0,CreationTimestamp:2019-01-15 14:57:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 14:57:01.698: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m4rhw,SelfLink:/api/v1/namespaces/e2e-tests-watch-m4rhw/configmaps/e2e-watch-test-watch-closed,UID:d082eea9-18d5-11e9-a8cf-02ce79272a22,ResourceVersion:193714,Generation:0,CreationTimestamp:2019-01-15 14:57:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 15 14:57:01.713: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m4rhw,SelfLink:/api/v1/namespaces/e2e-tests-watch-m4rhw/configmaps/e2e-watch-test-watch-closed,UID:d082eea9-18d5-11e9-a8cf-02ce79272a22,ResourceVersion:193715,Generation:0,CreationTimestamp:2019-01-15 14:57:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 14:57:01.713: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-m4rhw,SelfLink:/api/v1/namespaces/e2e-tests-watch-m4rhw/configmaps/e2e-watch-test-watch-closed,UID:d082eea9-18d5-11e9-a8cf-02ce79272a22,ResourceVersion:193716,Generation:0,CreationTimestamp:2019-01-15 14:57:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:57:01.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-m4rhw" for this suite.
Jan 15 14:57:07.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:57:07.803: INFO: namespace: e2e-tests-watch-m4rhw, resource: bindings, ignored listing per whitelist
Jan 15 14:57:07.813: INFO: namespace e2e-tests-watch-m4rhw deletion completed in 6.09690773s

 [SLOW TEST:6.171 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:57:07.814: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-hwcmg
Jan 15 14:57:09.866: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-hwcmg
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 14:57:09.871: INFO: Initial restart count of pod liveness-exec is 0
Jan 15 14:58:00.000: INFO: Restart count of pod e2e-tests-container-probe-hwcmg/liveness-exec is now 1 (50.128855057s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:58:00.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hwcmg" for this suite.
Jan 15 14:58:06.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:58:06.046: INFO: namespace: e2e-tests-container-probe-hwcmg, resource: bindings, ignored listing per whitelist
Jan 15 14:58:06.126: INFO: namespace e2e-tests-container-probe-hwcmg deletion completed in 6.11048563s

 [SLOW TEST:58.312 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:58:06.126: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:58:12.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5cpmg" for this suite.
Jan 15 14:58:18.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:58:18.323: INFO: namespace: e2e-tests-namespaces-5cpmg, resource: bindings, ignored listing per whitelist
Jan 15 14:58:18.339: INFO: namespace e2e-tests-namespaces-5cpmg deletion completed in 6.098355544s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7ff8k" for this suite.
Jan 15 14:58:18.342: INFO: Namespace e2e-tests-nsdeletetest-7ff8k was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-sn7jn" for this suite.
Jan 15 14:58:24.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:58:24.362: INFO: namespace: e2e-tests-nsdeletetest-sn7jn, resource: bindings, ignored listing per whitelist
Jan 15 14:58:24.445: INFO: namespace e2e-tests-nsdeletetest-sn7jn deletion completed in 6.103235397s

 [SLOW TEST:18.319 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:58:24.445: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 14:58:24.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-lhcht'
Jan 15 14:58:24.553: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 14:58:24.553: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 15 14:58:24.557: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan 15 14:58:24.560: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 15 14:58:24.563: INFO: scanned /root for discovery docs: <nil>
Jan 15 14:58:24.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-lhcht'
Jan 15 14:58:40.308: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 15 14:58:40.308: INFO: stdout: "Created e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25\nScaling up e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 15 14:58:40.308: INFO: stdout: "Created e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25\nScaling up e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 15 14:58:40.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lhcht'
Jan 15 14:58:40.378: INFO: stderr: ""
Jan 15 14:58:40.378: INFO: stdout: "e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25-qv6lr "
Jan 15 14:58:40.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25-qv6lr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lhcht'
Jan 15 14:58:40.443: INFO: stderr: ""
Jan 15 14:58:40.443: INFO: stdout: "true"
Jan 15 14:58:40.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25-qv6lr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lhcht'
Jan 15 14:58:40.505: INFO: stderr: ""
Jan 15 14:58:40.505: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan 15 14:58:40.505: INFO: e2e-test-nginx-rc-91243c9a982fbbbef1639ed8bc95fe25-qv6lr is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jan 15 14:58:40.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lhcht'
Jan 15 14:58:40.571: INFO: stderr: ""
Jan 15 14:58:40.571: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:58:40.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lhcht" for this suite.
Jan 15 14:58:46.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:58:46.681: INFO: namespace: e2e-tests-kubectl-lhcht, resource: bindings, ignored listing per whitelist
Jan 15 14:58:46.687: INFO: namespace e2e-tests-kubectl-lhcht deletion completed in 6.111737211s

 [SLOW TEST:22.242 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:58:46.687: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 14:58:46.741: INFO: (0) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.578099ms)
Jan 15 14:58:46.746: INFO: (1) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.491764ms)
Jan 15 14:58:46.750: INFO: (2) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.215018ms)
Jan 15 14:58:46.755: INFO: (3) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.525966ms)
Jan 15 14:58:46.759: INFO: (4) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.481959ms)
Jan 15 14:58:46.764: INFO: (5) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.333484ms)
Jan 15 14:58:46.768: INFO: (6) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.579951ms)
Jan 15 14:58:46.773: INFO: (7) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.444907ms)
Jan 15 14:58:46.777: INFO: (8) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.321066ms)
Jan 15 14:58:46.781: INFO: (9) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.161443ms)
Jan 15 14:58:46.785: INFO: (10) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.205104ms)
Jan 15 14:58:46.790: INFO: (11) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.311976ms)
Jan 15 14:58:46.794: INFO: (12) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.2229ms)
Jan 15 14:58:46.799: INFO: (13) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.562799ms)
Jan 15 14:58:46.803: INFO: (14) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.559372ms)
Jan 15 14:58:46.808: INFO: (15) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.549626ms)
Jan 15 14:58:46.812: INFO: (16) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.778904ms)
Jan 15 14:58:46.817: INFO: (17) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.541344ms)
Jan 15 14:58:46.821: INFO: (18) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.169603ms)
Jan 15 14:58:46.826: INFO: (19) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.247318ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:58:46.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-r6nsz" for this suite.
Jan 15 14:58:52.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:58:52.923: INFO: namespace: e2e-tests-proxy-r6nsz, resource: bindings, ignored listing per whitelist
Jan 15 14:58:52.923: INFO: namespace e2e-tests-proxy-r6nsz deletion completed in 6.094132149s

 [SLOW TEST:6.236 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:58:52.923: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-l4zsr;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-l4zsr;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-l4zsr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 91.113.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.113.91_udp@PTR;check="$$(dig +tcp +noall +answer +search 91.113.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.113.91_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-l4zsr;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-l4zsr;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-l4zsr.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-l4zsr.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-l4zsr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 91.113.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.113.91_udp@PTR;check="$$(dig +tcp +noall +answer +search 91.113.65.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.65.113.91_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 14:59:03.005: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.009: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.012: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-l4zsr from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.016: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-l4zsr from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.020: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-l4zsr.svc from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.024: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-l4zsr.svc from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.028: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.031: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.057: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.061: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.064: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-l4zsr from pod e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4: the server could not find the requested resource (get pods dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4)
Jan 15 14:59:03.106: INFO: Lookups using e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-l4zsr wheezy_tcp@dns-test-service.e2e-tests-dns-l4zsr wheezy_udp@dns-test-service.e2e-tests-dns-l4zsr.svc wheezy_tcp@dns-test-service.e2e-tests-dns-l4zsr.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-l4zsr.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-l4zsr]

Jan 15 14:59:08.221: INFO: DNS probes using e2e-tests-dns-l4zsr/dns-test-12d90fda-18d6-11e9-9d2c-c274f07984f4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:59:08.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-l4zsr" for this suite.
Jan 15 14:59:14.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:59:14.323: INFO: namespace: e2e-tests-dns-l4zsr, resource: bindings, ignored listing per whitelist
Jan 15 14:59:14.388: INFO: namespace e2e-tests-dns-l4zsr deletion completed in 6.108977227s

 [SLOW TEST:21.465 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:59:14.388: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-1fa2fd07-18d6-11e9-9d2c-c274f07984f4
STEP: Creating configMap with name cm-test-opt-upd-1fa2fd56-18d6-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1fa2fd07-18d6-11e9-9d2c-c274f07984f4
STEP: Updating configmap cm-test-opt-upd-1fa2fd56-18d6-11e9-9d2c-c274f07984f4
STEP: Creating configMap with name cm-test-opt-create-1fa2fd90-18d6-11e9-9d2c-c274f07984f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:59:18.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cpcxq" for this suite.
Jan 15 14:59:40.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 14:59:40.587: INFO: namespace: e2e-tests-configmap-cpcxq, resource: bindings, ignored listing per whitelist
Jan 15 14:59:40.640: INFO: namespace e2e-tests-configmap-cpcxq deletion completed in 22.096911084s

 [SLOW TEST:26.252 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 14:59:40.641: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2f48670f-18d6-11e9-9d2c-c274f07984f4
STEP: Creating secret with name s-test-opt-upd-2f486748-18d6-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2f48670f-18d6-11e9-9d2c-c274f07984f4
STEP: Updating secret s-test-opt-upd-2f486748-18d6-11e9-9d2c-c274f07984f4
STEP: Creating secret with name s-test-opt-create-2f486761-18d6-11e9-9d2c-c274f07984f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 14:59:46.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7hp8x" for this suite.
Jan 15 15:00:08.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:00:08.918: INFO: namespace: e2e-tests-secrets-7hp8x, resource: bindings, ignored listing per whitelist
Jan 15 15:00:08.929: INFO: namespace e2e-tests-secrets-7hp8x deletion completed in 22.109889547s

 [SLOW TEST:28.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:00:08.930: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 15:00:11.514: INFO: Successfully updated pod "labelsupdate40250d9e-18d6-11e9-9d2c-c274f07984f4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:00:15.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wxn7f" for this suite.
Jan 15 15:00:37.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:00:37.585: INFO: namespace: e2e-tests-projected-wxn7f, resource: bindings, ignored listing per whitelist
Jan 15 15:00:37.655: INFO: namespace e2e-tests-projected-wxn7f deletion completed in 22.108463579s

 [SLOW TEST:28.726 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:00:37.655: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 15 15:00:37.717: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7w7pl,SelfLink:/api/v1/namespaces/e2e-tests-watch-7w7pl/configmaps/e2e-watch-test-label-changed,UID:5143ea25-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:194460,Generation:0,CreationTimestamp:2019-01-15 15:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 15:00:37.717: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7w7pl,SelfLink:/api/v1/namespaces/e2e-tests-watch-7w7pl/configmaps/e2e-watch-test-label-changed,UID:5143ea25-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:194461,Generation:0,CreationTimestamp:2019-01-15 15:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 15 15:00:37.717: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7w7pl,SelfLink:/api/v1/namespaces/e2e-tests-watch-7w7pl/configmaps/e2e-watch-test-label-changed,UID:5143ea25-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:194462,Generation:0,CreationTimestamp:2019-01-15 15:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 15 15:00:47.752: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7w7pl,SelfLink:/api/v1/namespaces/e2e-tests-watch-7w7pl/configmaps/e2e-watch-test-label-changed,UID:5143ea25-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:194485,Generation:0,CreationTimestamp:2019-01-15 15:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 15:00:47.752: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7w7pl,SelfLink:/api/v1/namespaces/e2e-tests-watch-7w7pl/configmaps/e2e-watch-test-label-changed,UID:5143ea25-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:194486,Generation:0,CreationTimestamp:2019-01-15 15:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 15 15:00:47.752: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7w7pl,SelfLink:/api/v1/namespaces/e2e-tests-watch-7w7pl/configmaps/e2e-watch-test-label-changed,UID:5143ea25-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:194487,Generation:0,CreationTimestamp:2019-01-15 15:00:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:00:47.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7w7pl" for this suite.
Jan 15 15:00:53.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:00:53.797: INFO: namespace: e2e-tests-watch-7w7pl, resource: bindings, ignored listing per whitelist
Jan 15 15:00:53.862: INFO: namespace e2e-tests-watch-7w7pl deletion completed in 6.106914483s

 [SLOW TEST:16.207 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:00:53.863: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 15:00:53.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9lhjw'
Jan 15 15:00:53.977: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 15:00:53.977: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jan 15 15:00:55.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9lhjw'
Jan 15 15:00:56.063: INFO: stderr: ""
Jan 15 15:00:56.063: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:00:56.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9lhjw" for this suite.
Jan 15 15:01:14.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:01:14.116: INFO: namespace: e2e-tests-kubectl-9lhjw, resource: bindings, ignored listing per whitelist
Jan 15 15:01:14.178: INFO: namespace e2e-tests-kubectl-9lhjw deletion completed in 18.110447988s

 [SLOW TEST:20.315 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:01:14.178: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 15 15:01:20.276: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:20.279: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:22.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:22.283: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:24.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:24.283: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:26.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:26.284: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:28.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:28.284: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:30.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:30.289: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:32.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:32.283: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:34.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:34.283: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:36.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:36.283: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 15:01:38.280: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 15:01:38.284: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:01:38.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-whz7k" for this suite.
Jan 15 15:02:00.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:02:00.382: INFO: namespace: e2e-tests-container-lifecycle-hook-whz7k, resource: bindings, ignored listing per whitelist
Jan 15 15:02:00.384: INFO: namespace e2e-tests-container-lifecycle-hook-whz7k deletion completed in 22.096565301s

 [SLOW TEST:46.206 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:02:00.384: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 15:02:02.968: INFO: Successfully updated pod "labelsupdate8292f640-18d6-11e9-9d2c-c274f07984f4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:02:04.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5fvdf" for this suite.
Jan 15 15:02:27.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:02:27.088: INFO: namespace: e2e-tests-downward-api-5fvdf, resource: bindings, ignored listing per whitelist
Jan 15 15:02:27.092: INFO: namespace e2e-tests-downward-api-5fvdf deletion completed in 22.100583966s

 [SLOW TEST:26.707 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:02:27.092: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-8dlv
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 15:02:27.149: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8dlv" in namespace "e2e-tests-subpath-lrdkm" to be "success or failure"
Jan 15 15:02:27.153: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Pending", Reason="", readiness=false. Elapsed: 3.751095ms
Jan 15 15:02:29.157: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007689971s
Jan 15 15:02:31.161: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 4.011434901s
Jan 15 15:02:33.165: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 6.015251091s
Jan 15 15:02:35.175: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 8.025269671s
Jan 15 15:02:37.179: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 10.029164963s
Jan 15 15:02:39.183: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 12.033344908s
Jan 15 15:02:41.186: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 14.037006209s
Jan 15 15:02:43.191: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 16.041217879s
Jan 15 15:02:45.200: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 18.050650895s
Jan 15 15:02:47.204: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 20.054476135s
Jan 15 15:02:49.208: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Running", Reason="", readiness=false. Elapsed: 22.058497419s
Jan 15 15:02:51.211: INFO: Pod "pod-subpath-test-configmap-8dlv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061585754s
STEP: Saw pod success
Jan 15 15:02:51.211: INFO: Pod "pod-subpath-test-configmap-8dlv" satisfied condition "success or failure"
Jan 15 15:02:51.214: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-subpath-test-configmap-8dlv container test-container-subpath-configmap-8dlv: <nil>
STEP: delete the pod
Jan 15 15:02:51.234: INFO: Waiting for pod pod-subpath-test-configmap-8dlv to disappear
Jan 15 15:02:51.237: INFO: Pod pod-subpath-test-configmap-8dlv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8dlv
Jan 15 15:02:51.237: INFO: Deleting pod "pod-subpath-test-configmap-8dlv" in namespace "e2e-tests-subpath-lrdkm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:02:51.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lrdkm" for this suite.
Jan 15 15:02:57.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:02:57.294: INFO: namespace: e2e-tests-subpath-lrdkm, resource: bindings, ignored listing per whitelist
Jan 15 15:02:57.341: INFO: namespace e2e-tests-subpath-lrdkm deletion completed in 6.097446573s

 [SLOW TEST:30.249 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:02:57.341: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 15 15:02:57.393: INFO: Waiting up to 5m0s for pod "pod-a4864e32-18d6-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-jbvt9" to be "success or failure"
Jan 15 15:02:57.397: INFO: Pod "pod-a4864e32-18d6-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.511026ms
Jan 15 15:02:59.400: INFO: Pod "pod-a4864e32-18d6-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006532947s
STEP: Saw pod success
Jan 15 15:02:59.400: INFO: Pod "pod-a4864e32-18d6-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:02:59.403: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-a4864e32-18d6-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:02:59.423: INFO: Waiting for pod pod-a4864e32-18d6-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:02:59.426: INFO: Pod pod-a4864e32-18d6-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:02:59.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jbvt9" for this suite.
Jan 15 15:03:05.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:03:05.479: INFO: namespace: e2e-tests-emptydir-jbvt9, resource: bindings, ignored listing per whitelist
Jan 15 15:03:05.541: INFO: namespace e2e-tests-emptydir-jbvt9 deletion completed in 6.111335002s

 [SLOW TEST:8.199 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:03:05.541: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 15 15:03:05.589: INFO: Waiting up to 5m0s for pod "pod-a968cc31-18d6-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-6825s" to be "success or failure"
Jan 15 15:03:05.593: INFO: Pod "pod-a968cc31-18d6-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.550464ms
Jan 15 15:03:07.596: INFO: Pod "pod-a968cc31-18d6-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007724322s
STEP: Saw pod success
Jan 15 15:03:07.596: INFO: Pod "pod-a968cc31-18d6-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:03:07.599: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-a968cc31-18d6-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:03:07.620: INFO: Waiting for pod pod-a968cc31-18d6-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:03:07.623: INFO: Pod pod-a968cc31-18d6-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:03:07.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6825s" for this suite.
Jan 15 15:03:13.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:03:13.725: INFO: namespace: e2e-tests-emptydir-6825s, resource: bindings, ignored listing per whitelist
Jan 15 15:03:13.731: INFO: namespace e2e-tests-emptydir-6825s deletion completed in 6.103397587s

 [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:03:13.731: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ae4b387b-18d6-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:03:13.788: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-jbpxw" to be "success or failure"
Jan 15 15:03:13.792: INFO: Pod "pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677365ms
Jan 15 15:03:15.802: INFO: Pod "pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014017923s
STEP: Saw pod success
Jan 15 15:03:15.802: INFO: Pod "pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:03:15.805: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:03:15.828: INFO: Waiting for pod pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:03:15.831: INFO: Pod pod-projected-secrets-ae4c370e-18d6-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:03:15.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jbpxw" for this suite.
Jan 15 15:03:21.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:03:21.876: INFO: namespace: e2e-tests-projected-jbpxw, resource: bindings, ignored listing per whitelist
Jan 15 15:03:21.950: INFO: namespace e2e-tests-projected-jbpxw deletion completed in 6.112790747s

 [SLOW TEST:8.219 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:03:21.950: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:03:22.000: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-qfdmg" to be "success or failure"
Jan 15 15:03:22.004: INFO: Pod "downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019469ms
Jan 15 15:03:24.008: INFO: Pod "downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007873799s
STEP: Saw pod success
Jan 15 15:03:24.008: INFO: Pod "downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:03:24.013: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:03:24.035: INFO: Waiting for pod downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:03:24.038: INFO: Pod downwardapi-volume-b330e6fb-18d6-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:03:24.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qfdmg" for this suite.
Jan 15 15:03:30.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:03:30.142: INFO: namespace: e2e-tests-projected-qfdmg, resource: bindings, ignored listing per whitelist
Jan 15 15:03:30.153: INFO: namespace e2e-tests-projected-qfdmg deletion completed in 6.111228052s

 [SLOW TEST:8.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:03:30.153: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:03:30.206: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 15 15:03:35.210: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 15:03:35.210: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 15 15:03:37.220: INFO: Creating deployment "test-rollover-deployment"
Jan 15 15:03:37.229: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 15 15:03:39.235: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 15 15:03:39.241: INFO: Ensure that both replica sets have 1 created replica
Jan 15 15:03:39.247: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 15 15:03:39.254: INFO: Updating deployment test-rollover-deployment
Jan 15 15:03:39.254: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 15 15:03:41.263: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 15 15:03:41.270: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 15 15:03:41.277: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 15:03:41.277: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161420, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-c4bdf8748\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 15:03:43.285: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 15:03:43.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161420, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-c4bdf8748\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 15:03:45.285: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 15:03:45.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161420, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-c4bdf8748\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 15:03:47.289: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 15:03:47.289: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161420, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-c4bdf8748\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 15:03:49.284: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 15:03:49.284: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161420, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683161417, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-c4bdf8748\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 15:03:51.284: INFO: 
Jan 15 15:03:51.284: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 15:03:51.292: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-g8lhn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8lhn/deployments/test-rollover-deployment,UID:bc44e388-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:195185,Generation:2,CreationTimestamp:2019-01-15 15:03:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-15 15:03:37 +0000 UTC 2019-01-15 15:03:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-15 15:03:50 +0000 UTC 2019-01-15 15:03:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-c4bdf8748" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 15 15:03:51.295: INFO: New ReplicaSet "test-rollover-deployment-c4bdf8748" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-c4bdf8748,GenerateName:,Namespace:e2e-tests-deployment-g8lhn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8lhn/replicasets/test-rollover-deployment-c4bdf8748,UID:bd7b0280-18d6-11e9-8532-0a00a28bbe76,ResourceVersion:195177,Generation:2,CreationTimestamp:2019-01-15 15:03:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 706894304,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bc44e388-18d6-11e9-a8cf-02ce79272a22 0xc000d8edc0 0xc000d8edc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 706894304,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 706894304,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 15:03:51.296: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 15 15:03:51.296: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-g8lhn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8lhn/replicasets/test-rollover-controller,UID:b81503a7-18d6-11e9-a8cf-02ce79272a22,ResourceVersion:195184,Generation:2,CreationTimestamp:2019-01-15 15:03:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bc44e388-18d6-11e9-a8cf-02ce79272a22 0xc000d8ed07 0xc000d8ed08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 15:03:51.296: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-f98c95c97,GenerateName:,Namespace:e2e-tests-deployment-g8lhn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-g8lhn/replicasets/test-rollover-deployment-f98c95c97,UID:bc46de23-18d6-11e9-8532-0a00a28bbe76,ResourceVersion:195139,Generation:2,CreationTimestamp:2019-01-15 15:03:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 954751753,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bc44e388-18d6-11e9-a8cf-02ce79272a22 0xc000d8ee80 0xc000d8ee81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 954751753,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 954751753,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 15:03:51.299: INFO: Pod "test-rollover-deployment-c4bdf8748-qfdnc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-c4bdf8748-qfdnc,GenerateName:test-rollover-deployment-c4bdf8748-,Namespace:e2e-tests-deployment-g8lhn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-g8lhn/pods/test-rollover-deployment-c4bdf8748-qfdnc,UID:bd7dc696-18d6-11e9-8532-0a00a28bbe76,ResourceVersion:195154,Generation:0,CreationTimestamp:2019-01-15 15:03:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 706894304,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-c4bdf8748 bd7b0280-18d6-11e9-8532-0a00a28bbe76 0xc000d8fa90 0xc000d8fa91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8wsfd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8wsfd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8wsfd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d8fb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d8fb30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:03:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:03:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:03:39 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:100.100.156.232,StartTime:2019-01-15 15:03:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-15 15:03:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://47192309968e6b53d5592e5adc016658a07e3236138fac0a17c6855180351864}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:03:51.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-g8lhn" for this suite.
Jan 15 15:03:57.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:03:57.409: INFO: namespace: e2e-tests-deployment-g8lhn, resource: bindings, ignored listing per whitelist
Jan 15 15:03:57.411: INFO: namespace e2e-tests-deployment-g8lhn deletion completed in 6.10929822s

 [SLOW TEST:27.259 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:03:57.412: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 15:03:57.481: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:57.481: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:57.481: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:57.485: INFO: Number of nodes with available pods: 0
Jan 15 15:03:57.485: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:03:58.489: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:58.489: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:58.489: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:58.492: INFO: Number of nodes with available pods: 0
Jan 15 15:03:58.493: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:03:59.490: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:59.490: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:59.490: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:59.493: INFO: Number of nodes with available pods: 3
Jan 15 15:03:59.493: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 15 15:03:59.511: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:59.511: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:59.511: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:03:59.514: INFO: Number of nodes with available pods: 2
Jan 15 15:03:59.514: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:00.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:00.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:00.518: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:00.521: INFO: Number of nodes with available pods: 2
Jan 15 15:04:00.521: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:01.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:01.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:01.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:01.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:01.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:02.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:02.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:02.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:02.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:02.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:03.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:03.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:03.518: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:03.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:03.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:04.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:04.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:04.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:04.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:04.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:05.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:05.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:05.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:05.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:05.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:06.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:06.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:06.518: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:06.521: INFO: Number of nodes with available pods: 2
Jan 15 15:04:06.521: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:07.525: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:07.526: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:07.526: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:07.529: INFO: Number of nodes with available pods: 2
Jan 15 15:04:07.529: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:08.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:08.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:08.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:08.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:08.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:09.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:09.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:09.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:09.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:09.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:10.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:10.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:10.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:10.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:10.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:11.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:11.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:11.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:11.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:11.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:12.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:12.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:12.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:12.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:12.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:13.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:13.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:13.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:13.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:13.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:14.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:14.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:14.518: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:14.521: INFO: Number of nodes with available pods: 2
Jan 15 15:04:14.521: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:15.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:15.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:15.520: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:15.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:15.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:16.520: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:16.520: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:16.520: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:16.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:16.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:17.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:17.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:17.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:17.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:17.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:18.526: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:18.526: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:18.526: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:18.530: INFO: Number of nodes with available pods: 2
Jan 15 15:04:18.530: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:19.520: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:19.520: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:19.520: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:19.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:19.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:20.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:20.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:20.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:20.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:20.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:21.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:21.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:21.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:21.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:21.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:22.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:22.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:22.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:22.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:22.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:23.520: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:23.520: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:23.520: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:23.524: INFO: Number of nodes with available pods: 2
Jan 15 15:04:23.524: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:24.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:24.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:24.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:24.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:24.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:25.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:25.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:25.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:25.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:25.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:26.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:26.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:26.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:26.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:26.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:27.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:27.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:27.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:27.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:27.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:28.519: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:28.519: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:28.520: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:28.523: INFO: Number of nodes with available pods: 2
Jan 15 15:04:28.523: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:29.526: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:29.526: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:29.526: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:29.530: INFO: Number of nodes with available pods: 2
Jan 15 15:04:29.530: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:30.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:30.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:30.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:30.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:30.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:31.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:31.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:31.519: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:31.522: INFO: Number of nodes with available pods: 2
Jan 15 15:04:31.522: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:32.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:32.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:32.518: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:32.521: INFO: Number of nodes with available pods: 2
Jan 15 15:04:32.521: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:04:33.518: INFO: DaemonSet pods can't tolerate node ip-172-24-124-80.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:33.518: INFO: DaemonSet pods can't tolerate node ip-172-24-45-174.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:33.518: INFO: DaemonSet pods can't tolerate node ip-172-24-82-195.us-east-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jan 15 15:04:33.521: INFO: Number of nodes with available pods: 3
Jan 15 15:04:33.522: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-mwpnj, will wait for the garbage collector to delete the pods
Jan 15 15:04:33.586: INFO: Deleting DaemonSet.extensions daemon-set took: 8.366371ms
Jan 15 15:04:33.686: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.279041ms
Jan 15 15:05:09.696: INFO: Number of nodes with available pods: 0
Jan 15 15:05:09.696: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 15:05:09.699: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mwpnj/daemonsets","resourceVersion":"195433"},"items":null}

Jan 15 15:05:09.702: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mwpnj/pods","resourceVersion":"195433"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:05:09.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mwpnj" for this suite.
Jan 15 15:05:15.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:05:15.783: INFO: namespace: e2e-tests-daemonsets-mwpnj, resource: bindings, ignored listing per whitelist
Jan 15 15:05:15.818: INFO: namespace e2e-tests-daemonsets-mwpnj deletion completed in 6.098150108s

 [SLOW TEST:78.406 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:05:15.818: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 15 15:05:19.904: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:19.904: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:19.978: INFO: Exec stderr: ""
Jan 15 15:05:19.978: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:19.978: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.041: INFO: Exec stderr: ""
Jan 15 15:05:20.041: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.042: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.104: INFO: Exec stderr: ""
Jan 15 15:05:20.104: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.104: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.183: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 15 15:05:20.183: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.183: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.247: INFO: Exec stderr: ""
Jan 15 15:05:20.247: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.247: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.318: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 15 15:05:20.318: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.318: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.385: INFO: Exec stderr: ""
Jan 15 15:05:20.385: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.385: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.453: INFO: Exec stderr: ""
Jan 15 15:05:20.453: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.453: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.520: INFO: Exec stderr: ""
Jan 15 15:05:20.520: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gskwf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:05:20.520: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:05:20.588: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:05:20.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-gskwf" for this suite.
Jan 15 15:06:10.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:06:10.662: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-gskwf, resource: bindings, ignored listing per whitelist
Jan 15 15:06:10.692: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-gskwf deletion completed in 50.099950013s

 [SLOW TEST:54.875 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:06:10.692: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-f22zw
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-f22zw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-f22zw
Jan 15 15:06:10.747: INFO: Found 0 stateful pods, waiting for 1
Jan 15 15:06:20.756: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 15 15:06:20.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 15:06:20.883: INFO: stderr: ""
Jan 15 15:06:20.883: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 15:06:20.883: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 15:06:20.887: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 15 15:06:30.897: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 15:06:30.897: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 15:06:30.914: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999196s
Jan 15 15:06:31.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995079836s
Jan 15 15:06:32.922: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990699377s
Jan 15 15:06:33.927: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986835374s
Jan 15 15:06:34.931: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982321141s
Jan 15 15:06:35.935: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977827691s
Jan 15 15:06:36.940: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973561415s
Jan 15 15:06:37.944: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.968953717s
Jan 15 15:06:38.948: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964974546s
Jan 15 15:06:39.952: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.830612ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-f22zw
Jan 15 15:06:40.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 15:06:41.101: INFO: stderr: ""
Jan 15 15:06:41.101: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 15:06:41.101: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 15:06:41.105: INFO: Found 1 stateful pods, waiting for 3
Jan 15 15:06:51.115: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 15:06:51.115: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 15:06:51.115: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 15 15:06:51.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 15:06:51.261: INFO: stderr: ""
Jan 15 15:06:51.261: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 15:06:51.261: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 15:06:51.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 15:06:51.395: INFO: stderr: ""
Jan 15 15:06:51.395: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 15:06:51.395: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 15:06:51.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 15:06:51.519: INFO: stderr: ""
Jan 15 15:06:51.519: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 15:06:51.519: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 15:06:51.519: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 15:06:51.522: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 15 15:07:01.535: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 15:07:01.535: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 15:07:01.535: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 15:07:01.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999174s
Jan 15 15:07:02.550: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995088298s
Jan 15 15:07:03.554: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991421205s
Jan 15 15:07:04.558: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987603649s
Jan 15 15:07:05.561: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983905463s
Jan 15 15:07:06.566: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979975402s
Jan 15 15:07:07.570: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975810021s
Jan 15 15:07:08.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971378596s
Jan 15 15:07:09.578: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967860703s
Jan 15 15:07:10.583: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.156904ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-f22zw
Jan 15 15:07:11.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 15:07:11.727: INFO: stderr: ""
Jan 15 15:07:11.727: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 15:07:11.727: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 15:07:11.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 15:07:11.859: INFO: stderr: ""
Jan 15 15:07:11.859: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 15:07:11.859: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 15:07:11.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-f22zw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 15:07:11.988: INFO: stderr: ""
Jan 15 15:07:11.988: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 15:07:11.988: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 15:07:11.988: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 15:07:32.003: INFO: Deleting all statefulset in ns e2e-tests-statefulset-f22zw
Jan 15 15:07:32.006: INFO: Scaling statefulset ss to 0
Jan 15 15:07:32.023: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 15:07:32.026: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:07:32.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-f22zw" for this suite.
Jan 15 15:07:38.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:07:38.102: INFO: namespace: e2e-tests-statefulset-f22zw, resource: bindings, ignored listing per whitelist
Jan 15 15:07:38.157: INFO: namespace e2e-tests-statefulset-f22zw deletion completed in 6.110640423s

 [SLOW TEST:87.465 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:07:38.157: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:07:38.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-qx5l7" to be "success or failure"
Jan 15 15:07:38.214: INFO: Pod "downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.790827ms
Jan 15 15:07:40.217: INFO: Pod "downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008391489s
STEP: Saw pod success
Jan 15 15:07:40.217: INFO: Pod "downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:07:40.220: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:07:40.241: INFO: Waiting for pod downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:07:40.244: INFO: Pod downwardapi-volume-4be763f8-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:07:40.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qx5l7" for this suite.
Jan 15 15:07:46.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:07:46.297: INFO: namespace: e2e-tests-projected-qx5l7, resource: bindings, ignored listing per whitelist
Jan 15 15:07:46.350: INFO: namespace e2e-tests-projected-qx5l7 deletion completed in 6.103302323s

 [SLOW TEST:8.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:07:46.350: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 15 15:07:46.398: INFO: Waiting up to 5m0s for pod "pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-5xmz2" to be "success or failure"
Jan 15 15:07:46.403: INFO: Pod "pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934558ms
Jan 15 15:07:48.406: INFO: Pod "pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008165912s
Jan 15 15:07:50.410: INFO: Pod "pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011920417s
STEP: Saw pod success
Jan 15 15:07:50.410: INFO: Pod "pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:07:50.413: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:07:50.432: INFO: Waiting for pod pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:07:50.435: INFO: Pod pod-50c8ea4a-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:07:50.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5xmz2" for this suite.
Jan 15 15:07:56.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:07:56.511: INFO: namespace: e2e-tests-emptydir-5xmz2, resource: bindings, ignored listing per whitelist
Jan 15 15:07:56.538: INFO: namespace e2e-tests-emptydir-5xmz2 deletion completed in 6.099037624s

 [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:07:56.538: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-56dbbdca-18d7-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:07:56.591: INFO: Waiting up to 5m0s for pod "pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-qq679" to be "success or failure"
Jan 15 15:07:56.595: INFO: Pod "pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.392516ms
Jan 15 15:07:58.598: INFO: Pod "pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006915137s
STEP: Saw pod success
Jan 15 15:07:58.598: INFO: Pod "pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:07:58.601: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4 container secret-env-test: <nil>
STEP: delete the pod
Jan 15 15:07:58.621: INFO: Waiting for pod pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:07:58.624: INFO: Pod pod-secrets-56dcb465-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:07:58.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qq679" for this suite.
Jan 15 15:08:04.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:08:04.668: INFO: namespace: e2e-tests-secrets-qq679, resource: bindings, ignored listing per whitelist
Jan 15 15:08:04.724: INFO: namespace e2e-tests-secrets-qq679 deletion completed in 6.096848737s

 [SLOW TEST:8.187 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:08:04.725: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 15 15:08:04.771: INFO: Waiting up to 5m0s for pod "client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-containers-b9x7f" to be "success or failure"
Jan 15 15:08:04.775: INFO: Pod "client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.611678ms
Jan 15 15:08:06.778: INFO: Pod "client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006757393s
Jan 15 15:08:08.782: INFO: Pod "client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010431309s
STEP: Saw pod success
Jan 15 15:08:08.782: INFO: Pod "client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:08:08.785: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:08:08.809: INFO: Waiting for pod client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:08:08.812: INFO: Pod client-containers-5bbc677e-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:08:08.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-b9x7f" for this suite.
Jan 15 15:08:14.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:08:14.914: INFO: namespace: e2e-tests-containers-b9x7f, resource: bindings, ignored listing per whitelist
Jan 15 15:08:14.926: INFO: namespace e2e-tests-containers-b9x7f deletion completed in 6.109449876s

 [SLOW TEST:10.201 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:08:14.926: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 15:08:14.978: INFO: Waiting up to 5m0s for pod "downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-b97rh" to be "success or failure"
Jan 15 15:08:14.983: INFO: Pod "downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.516877ms
Jan 15 15:08:16.987: INFO: Pod "downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008439492s
STEP: Saw pod success
Jan 15 15:08:16.987: INFO: Pod "downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:08:16.990: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 15:08:17.014: INFO: Waiting for pod downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:08:17.017: INFO: Pod downward-api-61d1d319-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:08:17.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b97rh" for this suite.
Jan 15 15:08:23.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:08:23.126: INFO: namespace: e2e-tests-downward-api-b97rh, resource: bindings, ignored listing per whitelist
Jan 15 15:08:23.143: INFO: namespace e2e-tests-downward-api-b97rh deletion completed in 6.12173852s

 [SLOW TEST:8.217 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:08:23.144: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:08:47.204: INFO: Container started at 2019-01-15 15:08:24 +0000 UTC, pod became ready at 2019-01-15 15:08:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:08:47.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vsf8m" for this suite.
Jan 15 15:09:09.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:09:09.314: INFO: namespace: e2e-tests-container-probe-vsf8m, resource: bindings, ignored listing per whitelist
Jan 15 15:09:09.317: INFO: namespace e2e-tests-container-probe-vsf8m deletion completed in 22.109030511s

 [SLOW TEST:46.173 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:09:09.317: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:09:09.371: INFO: Waiting up to 5m0s for pod "downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-lwtwb" to be "success or failure"
Jan 15 15:09:09.375: INFO: Pod "downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007519ms
Jan 15 15:09:11.379: INFO: Pod "downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007784393s
STEP: Saw pod success
Jan 15 15:09:11.379: INFO: Pod "downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:09:11.382: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:09:11.406: INFO: Waiting for pod downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:09:11.409: INFO: Pod downwardapi-volume-823d68e7-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:09:11.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lwtwb" for this suite.
Jan 15 15:09:17.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:09:17.518: INFO: namespace: e2e-tests-downward-api-lwtwb, resource: bindings, ignored listing per whitelist
Jan 15 15:09:17.530: INFO: namespace e2e-tests-downward-api-lwtwb deletion completed in 6.116769417s

 [SLOW TEST:8.213 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:09:17.530: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tpw9c
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 15:09:17.569: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 15:09:39.658: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.115.205.168:8080/dial?request=hostName&protocol=udp&host=100.115.205.167&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tpw9c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:09:39.658: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:09:39.724: INFO: Waiting for endpoints: map[]
Jan 15 15:09:39.727: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.115.205.168:8080/dial?request=hostName&protocol=udp&host=100.107.48.47&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tpw9c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:09:39.727: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:09:39.794: INFO: Waiting for endpoints: map[]
Jan 15 15:09:39.797: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.115.205.168:8080/dial?request=hostName&protocol=udp&host=100.100.156.238&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-tpw9c PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:09:39.797: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:09:39.864: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:09:39.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tpw9c" for this suite.
Jan 15 15:10:01.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:10:01.911: INFO: namespace: e2e-tests-pod-network-test-tpw9c, resource: bindings, ignored listing per whitelist
Jan 15 15:10:01.963: INFO: namespace e2e-tests-pod-network-test-tpw9c deletion completed in 22.094828408s

 [SLOW TEST:44.433 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:10:01.963: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 15 15:10:02.526: INFO: created pod pod-service-account-defaultsa
Jan 15 15:10:02.526: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 15 15:10:02.532: INFO: created pod pod-service-account-mountsa
Jan 15 15:10:02.532: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 15 15:10:02.536: INFO: created pod pod-service-account-nomountsa
Jan 15 15:10:02.536: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 15 15:10:02.542: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 15 15:10:02.542: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 15 15:10:02.547: INFO: created pod pod-service-account-mountsa-mountspec
Jan 15 15:10:02.547: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 15 15:10:02.552: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 15 15:10:02.552: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 15 15:10:02.559: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 15 15:10:02.559: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 15 15:10:02.565: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 15 15:10:02.565: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 15 15:10:02.569: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 15 15:10:02.569: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:10:02.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-zhmvc" for this suite.
Jan 15 15:10:08.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:10:08.675: INFO: namespace: e2e-tests-svcaccounts-zhmvc, resource: bindings, ignored listing per whitelist
Jan 15 15:10:08.675: INFO: namespace e2e-tests-svcaccounts-zhmvc deletion completed in 6.099595366s

 [SLOW TEST:6.712 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:10:08.675: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 15:10:08.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-wc9kw'
Jan 15 15:10:08.910: INFO: stderr: ""
Jan 15 15:10:08.910: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jan 15 15:10:08.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wc9kw'
Jan 15 15:10:17.179: INFO: stderr: ""
Jan 15 15:10:17.179: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:10:17.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wc9kw" for this suite.
Jan 15 15:10:23.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:10:23.246: INFO: namespace: e2e-tests-kubectl-wc9kw, resource: bindings, ignored listing per whitelist
Jan 15 15:10:23.294: INFO: namespace e2e-tests-kubectl-wc9kw deletion completed in 6.103410865s

 [SLOW TEST:14.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:10:23.294: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-qr84
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 15:10:23.354: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-qr84" in namespace "e2e-tests-subpath-cs7th" to be "success or failure"
Jan 15 15:10:23.358: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Pending", Reason="", readiness=false. Elapsed: 3.010823ms
Jan 15 15:10:25.361: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 2.006077117s
Jan 15 15:10:27.371: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 4.016562529s
Jan 15 15:10:29.375: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 6.020045797s
Jan 15 15:10:31.379: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 8.024155003s
Jan 15 15:10:33.383: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 10.028364158s
Jan 15 15:10:35.387: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 12.032434516s
Jan 15 15:10:37.398: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 14.043419194s
Jan 15 15:10:39.402: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 16.047879606s
Jan 15 15:10:41.407: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 18.052383684s
Jan 15 15:10:43.411: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Running", Reason="", readiness=false. Elapsed: 20.056848695s
Jan 15 15:10:45.415: INFO: Pod "pod-subpath-test-secret-qr84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.060123201s
STEP: Saw pod success
Jan 15 15:10:45.415: INFO: Pod "pod-subpath-test-secret-qr84" satisfied condition "success or failure"
Jan 15 15:10:45.417: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-subpath-test-secret-qr84 container test-container-subpath-secret-qr84: <nil>
STEP: delete the pod
Jan 15 15:10:45.440: INFO: Waiting for pod pod-subpath-test-secret-qr84 to disappear
Jan 15 15:10:45.443: INFO: Pod pod-subpath-test-secret-qr84 no longer exists
STEP: Deleting pod pod-subpath-test-secret-qr84
Jan 15 15:10:45.443: INFO: Deleting pod "pod-subpath-test-secret-qr84" in namespace "e2e-tests-subpath-cs7th"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:10:45.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cs7th" for this suite.
Jan 15 15:10:51.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:10:51.474: INFO: namespace: e2e-tests-subpath-cs7th, resource: bindings, ignored listing per whitelist
Jan 15 15:10:51.544: INFO: namespace e2e-tests-subpath-cs7th deletion completed in 6.094662547s

 [SLOW TEST:28.250 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:10:51.544: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 15 15:10:51.595: INFO: Waiting up to 5m0s for pod "pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-jkhxr" to be "success or failure"
Jan 15 15:10:51.601: INFO: Pod "pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.057685ms
Jan 15 15:10:53.605: INFO: Pod "pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010087049s
Jan 15 15:10:55.609: INFO: Pod "pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013838321s
STEP: Saw pod success
Jan 15 15:10:55.609: INFO: Pod "pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:10:55.612: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:10:55.635: INFO: Waiting for pod pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:10:55.638: INFO: Pod pod-bf2bb102-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:10:55.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jkhxr" for this suite.
Jan 15 15:11:01.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:11:01.709: INFO: namespace: e2e-tests-emptydir-jkhxr, resource: bindings, ignored listing per whitelist
Jan 15 15:11:01.737: INFO: namespace e2e-tests-emptydir-jkhxr deletion completed in 6.096237895s

 [SLOW TEST:10.193 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:11:01.738: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 15 15:11:01.787: INFO: Waiting up to 5m0s for pod "pod-c53ef250-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-g977s" to be "success or failure"
Jan 15 15:11:01.792: INFO: Pod "pod-c53ef250-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.511566ms
Jan 15 15:11:03.795: INFO: Pod "pod-c53ef250-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008113677s
STEP: Saw pod success
Jan 15 15:11:03.795: INFO: Pod "pod-c53ef250-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:11:03.798: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-c53ef250-18d7-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:11:03.822: INFO: Waiting for pod pod-c53ef250-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:11:03.824: INFO: Pod pod-c53ef250-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:11:03.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g977s" for this suite.
Jan 15 15:11:09.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:11:09.938: INFO: namespace: e2e-tests-emptydir-g977s, resource: bindings, ignored listing per whitelist
Jan 15 15:11:09.938: INFO: namespace e2e-tests-emptydir-g977s deletion completed in 6.109697258s

 [SLOW TEST:8.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:11:09.938: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:11:09.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-bvm4l" to be "success or failure"
Jan 15 15:11:09.996: INFO: Pod "downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.334525ms
Jan 15 15:11:12.000: INFO: Pod "downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008695907s
STEP: Saw pod success
Jan 15 15:11:12.000: INFO: Pod "downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:11:12.003: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:11:12.025: INFO: Waiting for pod downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:11:12.028: INFO: Pod downwardapi-volume-ca2298a2-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:11:12.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bvm4l" for this suite.
Jan 15 15:11:18.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:11:18.089: INFO: namespace: e2e-tests-downward-api-bvm4l, resource: bindings, ignored listing per whitelist
Jan 15 15:11:18.138: INFO: namespace e2e-tests-downward-api-bvm4l deletion completed in 6.10544432s

 [SLOW TEST:8.200 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:11:18.138: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-mkvzn
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-mkvzn
STEP: Deleting pre-stop pod
Jan 15 15:11:29.234: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:11:29.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-mkvzn" for this suite.
Jan 15 15:12:09.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:12:09.346: INFO: namespace: e2e-tests-prestop-mkvzn, resource: bindings, ignored listing per whitelist
Jan 15 15:12:09.357: INFO: namespace e2e-tests-prestop-mkvzn deletion completed in 40.112223528s

 [SLOW TEST:51.219 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:12:09.358: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ed8d8d54-18d7-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:12:09.417: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-txnm4" to be "success or failure"
Jan 15 15:12:09.421: INFO: Pod "pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.870424ms
Jan 15 15:12:11.425: INFO: Pod "pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008149049s
STEP: Saw pod success
Jan 15 15:12:11.425: INFO: Pod "pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:12:11.428: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:12:11.451: INFO: Waiting for pod pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:12:11.455: INFO: Pod pod-projected-configmaps-ed8ea755-18d7-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:12:11.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-txnm4" for this suite.
Jan 15 15:12:17.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:12:17.526: INFO: namespace: e2e-tests-projected-txnm4, resource: bindings, ignored listing per whitelist
Jan 15 15:12:17.571: INFO: namespace e2e-tests-projected-txnm4 deletion completed in 6.112560006s

 [SLOW TEST:8.214 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:12:17.571: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 15 15:12:17.622: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197088,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 15:12:17.622: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197088,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 15 15:12:27.636: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197113,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 15 15:12:27.636: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197113,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 15 15:12:37.652: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197135,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 15:12:37.652: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197135,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 15 15:12:47.666: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197156,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 15:12:47.666: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-a,UID:f272d6cb-18d7-11e9-a8cf-02ce79272a22,ResourceVersion:197156,Generation:0,CreationTimestamp:2019-01-15 15:12:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 15 15:12:57.679: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-b,UID:0a530246-18d8-11e9-a8cf-02ce79272a22,ResourceVersion:197177,Generation:0,CreationTimestamp:2019-01-15 15:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 15:12:57.679: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-b,UID:0a530246-18d8-11e9-a8cf-02ce79272a22,ResourceVersion:197177,Generation:0,CreationTimestamp:2019-01-15 15:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 15 15:13:07.693: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-b,UID:0a530246-18d8-11e9-a8cf-02ce79272a22,ResourceVersion:197199,Generation:0,CreationTimestamp:2019-01-15 15:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 15:13:07.693: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-kcxss,SelfLink:/api/v1/namespaces/e2e-tests-watch-kcxss/configmaps/e2e-watch-test-configmap-b,UID:0a530246-18d8-11e9-a8cf-02ce79272a22,ResourceVersion:197199,Generation:0,CreationTimestamp:2019-01-15 15:12:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:13:17.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kcxss" for this suite.
Jan 15 15:13:23.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:13:23.735: INFO: namespace: e2e-tests-watch-kcxss, resource: bindings, ignored listing per whitelist
Jan 15 15:13:23.798: INFO: namespace e2e-tests-watch-kcxss deletion completed in 6.095477009s

 [SLOW TEST:66.227 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:13:23.798: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:14:23.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cpxsq" for this suite.
Jan 15 15:14:45.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:14:45.923: INFO: namespace: e2e-tests-container-probe-cpxsq, resource: bindings, ignored listing per whitelist
Jan 15 15:14:45.960: INFO: namespace e2e-tests-container-probe-cpxsq deletion completed in 22.103936153s

 [SLOW TEST:82.162 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:14:45.960: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4ae4dcc2-18d8-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:14:46.017: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-vxvkm" to be "success or failure"
Jan 15 15:14:46.021: INFO: Pod "pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01053ms
Jan 15 15:14:48.024: INFO: Pod "pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007784906s
STEP: Saw pod success
Jan 15 15:14:48.024: INFO: Pod "pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:14:48.028: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:14:48.051: INFO: Waiting for pod pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:14:48.054: INFO: Pod pod-configmaps-4ae5f28b-18d8-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:14:48.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vxvkm" for this suite.
Jan 15 15:14:54.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:14:54.095: INFO: namespace: e2e-tests-configmap-vxvkm, resource: bindings, ignored listing per whitelist
Jan 15 15:14:54.168: INFO: namespace e2e-tests-configmap-vxvkm deletion completed in 6.109662663s

 [SLOW TEST:8.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:14:54.168: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:14:56.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-4b8vs" for this suite.
Jan 15 15:15:40.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:15:40.309: INFO: namespace: e2e-tests-kubelet-test-4b8vs, resource: bindings, ignored listing per whitelist
Jan 15 15:15:40.341: INFO: namespace e2e-tests-kubelet-test-4b8vs deletion completed in 44.097698423s

 [SLOW TEST:46.172 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:15:40.341: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:15:40.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-gc5kv" to be "success or failure"
Jan 15 15:15:40.395: INFO: Pod "downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307225ms
Jan 15 15:15:42.398: INFO: Pod "downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007874863s
STEP: Saw pod success
Jan 15 15:15:42.398: INFO: Pod "downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:15:42.401: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:15:42.422: INFO: Waiting for pod downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:15:42.425: INFO: Pod downwardapi-volume-6b4e4640-18d8-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:15:42.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gc5kv" for this suite.
Jan 15 15:15:48.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:15:48.471: INFO: namespace: e2e-tests-projected-gc5kv, resource: bindings, ignored listing per whitelist
Jan 15 15:15:48.533: INFO: namespace e2e-tests-projected-gc5kv deletion completed in 6.104788709s

 [SLOW TEST:8.192 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:15:48.533: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-70302fc6-18d8-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:15:48.585: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-zfbxr" to be "success or failure"
Jan 15 15:15:48.589: INFO: Pod "pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.614255ms
Jan 15 15:15:50.593: INFO: Pod "pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008629053s
STEP: Saw pod success
Jan 15 15:15:50.593: INFO: Pod "pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:15:50.597: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:15:50.618: INFO: Waiting for pod pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:15:50.621: INFO: Pod pod-projected-secrets-70313249-18d8-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:15:50.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zfbxr" for this suite.
Jan 15 15:15:56.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:15:56.712: INFO: namespace: e2e-tests-projected-zfbxr, resource: bindings, ignored listing per whitelist
Jan 15 15:15:56.723: INFO: namespace e2e-tests-projected-zfbxr deletion completed in 6.097540447s

 [SLOW TEST:8.190 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:15:56.723: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:15:56.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-jck8z" to be "success or failure"
Jan 15 15:15:56.777: INFO: Pod "downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.441879ms
Jan 15 15:15:58.788: INFO: Pod "downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014241062s
STEP: Saw pod success
Jan 15 15:15:58.788: INFO: Pod "downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:15:58.791: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:15:58.813: INFO: Waiting for pod downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:15:58.816: INFO: Pod downwardapi-volume-75124539-18d8-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:15:58.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jck8z" for this suite.
Jan 15 15:16:04.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:16:04.926: INFO: namespace: e2e-tests-downward-api-jck8z, resource: bindings, ignored listing per whitelist
Jan 15 15:16:04.932: INFO: namespace e2e-tests-downward-api-jck8z deletion completed in 6.111345642s

 [SLOW TEST:8.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:16:04.932: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lmfp4/configmap-test-79f70734-18d8-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:16:04.988: INFO: Waiting up to 5m0s for pod "pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-lmfp4" to be "success or failure"
Jan 15 15:16:04.992: INFO: Pod "pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.783296ms
Jan 15 15:16:06.996: INFO: Pod "pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007908944s
STEP: Saw pod success
Jan 15 15:16:06.996: INFO: Pod "pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:16:07.000: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4 container env-test: <nil>
STEP: delete the pod
Jan 15 15:16:07.024: INFO: Waiting for pod pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:16:07.027: INFO: Pod pod-configmaps-79f80f61-18d8-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:16:07.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lmfp4" for this suite.
Jan 15 15:16:13.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:16:13.124: INFO: namespace: e2e-tests-configmap-lmfp4, resource: bindings, ignored listing per whitelist
Jan 15 15:16:13.140: INFO: namespace e2e-tests-configmap-lmfp4 deletion completed in 6.109113573s

 [SLOW TEST:8.208 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:16:13.140: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 15:16:13.182: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:16:18.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8tvxh" for this suite.
Jan 15 15:16:40.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:16:40.268: INFO: namespace: e2e-tests-init-container-8tvxh, resource: bindings, ignored listing per whitelist
Jan 15 15:16:40.280: INFO: namespace e2e-tests-init-container-8tvxh deletion completed in 22.101958695s

 [SLOW TEST:27.140 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:16:40.280: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-r9ff2
I0115 15:16:40.331277      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-r9ff2, replica count: 1
I0115 15:16:41.381935      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 15 15:16:41.496: INFO: Created: latency-svc-krdzh
Jan 15 15:16:41.502: INFO: Got endpoints: latency-svc-krdzh [20.744275ms]
Jan 15 15:16:41.518: INFO: Created: latency-svc-hv6vm
Jan 15 15:16:41.524: INFO: Got endpoints: latency-svc-hv6vm [21.156013ms]
Jan 15 15:16:41.528: INFO: Created: latency-svc-wngmz
Jan 15 15:16:41.534: INFO: Got endpoints: latency-svc-wngmz [31.359579ms]
Jan 15 15:16:41.539: INFO: Created: latency-svc-dp8c4
Jan 15 15:16:41.543: INFO: Got endpoints: latency-svc-dp8c4 [39.62394ms]
Jan 15 15:16:41.550: INFO: Created: latency-svc-fglk6
Jan 15 15:16:41.552: INFO: Got endpoints: latency-svc-fglk6 [17.954765ms]
Jan 15 15:16:41.560: INFO: Created: latency-svc-b4l9n
Jan 15 15:16:41.562: INFO: Got endpoints: latency-svc-b4l9n [59.551909ms]
Jan 15 15:16:41.572: INFO: Created: latency-svc-sx6t7
Jan 15 15:16:41.575: INFO: Got endpoints: latency-svc-sx6t7 [71.762137ms]
Jan 15 15:16:41.582: INFO: Created: latency-svc-scrwh
Jan 15 15:16:41.585: INFO: Got endpoints: latency-svc-scrwh [82.192802ms]
Jan 15 15:16:41.593: INFO: Created: latency-svc-c6b88
Jan 15 15:16:41.600: INFO: Got endpoints: latency-svc-c6b88 [97.019887ms]
Jan 15 15:16:41.603: INFO: Created: latency-svc-w7l62
Jan 15 15:16:41.605: INFO: Got endpoints: latency-svc-w7l62 [102.777125ms]
Jan 15 15:16:41.613: INFO: Created: latency-svc-kmfgw
Jan 15 15:16:41.617: INFO: Got endpoints: latency-svc-kmfgw [113.868399ms]
Jan 15 15:16:41.624: INFO: Created: latency-svc-vzxgf
Jan 15 15:16:41.626: INFO: Got endpoints: latency-svc-vzxgf [123.510649ms]
Jan 15 15:16:41.635: INFO: Created: latency-svc-lgdcv
Jan 15 15:16:41.638: INFO: Got endpoints: latency-svc-lgdcv [134.85895ms]
Jan 15 15:16:41.646: INFO: Created: latency-svc-vxhbc
Jan 15 15:16:41.651: INFO: Got endpoints: latency-svc-vxhbc [147.517ms]
Jan 15 15:16:41.655: INFO: Created: latency-svc-lk8js
Jan 15 15:16:41.658: INFO: Got endpoints: latency-svc-lk8js [155.26878ms]
Jan 15 15:16:41.666: INFO: Created: latency-svc-hzbxx
Jan 15 15:16:41.668: INFO: Got endpoints: latency-svc-hzbxx [164.94148ms]
Jan 15 15:16:41.676: INFO: Created: latency-svc-l6pkc
Jan 15 15:16:41.680: INFO: Got endpoints: latency-svc-l6pkc [177.187563ms]
Jan 15 15:16:41.685: INFO: Created: latency-svc-82xdb
Jan 15 15:16:41.688: INFO: Got endpoints: latency-svc-82xdb [163.926918ms]
Jan 15 15:16:41.694: INFO: Created: latency-svc-q98sm
Jan 15 15:16:41.705: INFO: Got endpoints: latency-svc-q98sm [162.801437ms]
Jan 15 15:16:41.709: INFO: Created: latency-svc-ws8l6
Jan 15 15:16:41.714: INFO: Got endpoints: latency-svc-ws8l6 [162.220654ms]
Jan 15 15:16:41.719: INFO: Created: latency-svc-h4hcl
Jan 15 15:16:41.724: INFO: Got endpoints: latency-svc-h4hcl [161.527204ms]
Jan 15 15:16:41.729: INFO: Created: latency-svc-2wlps
Jan 15 15:16:41.735: INFO: Got endpoints: latency-svc-2wlps [159.970722ms]
Jan 15 15:16:41.738: INFO: Created: latency-svc-f7hzl
Jan 15 15:16:41.743: INFO: Got endpoints: latency-svc-f7hzl [158.03979ms]
Jan 15 15:16:41.747: INFO: Created: latency-svc-mjdwd
Jan 15 15:16:41.752: INFO: Got endpoints: latency-svc-mjdwd [152.362389ms]
Jan 15 15:16:41.756: INFO: Created: latency-svc-ddvpr
Jan 15 15:16:41.762: INFO: Got endpoints: latency-svc-ddvpr [156.142518ms]
Jan 15 15:16:41.766: INFO: Created: latency-svc-q5qtk
Jan 15 15:16:41.772: INFO: Got endpoints: latency-svc-q5qtk [154.787575ms]
Jan 15 15:16:41.776: INFO: Created: latency-svc-p5bsz
Jan 15 15:16:41.781: INFO: Got endpoints: latency-svc-p5bsz [154.204155ms]
Jan 15 15:16:41.784: INFO: Created: latency-svc-74pzp
Jan 15 15:16:41.789: INFO: Got endpoints: latency-svc-74pzp [151.24267ms]
Jan 15 15:16:41.794: INFO: Created: latency-svc-vt8q2
Jan 15 15:16:41.796: INFO: Got endpoints: latency-svc-vt8q2 [145.589645ms]
Jan 15 15:16:41.804: INFO: Created: latency-svc-6vdx8
Jan 15 15:16:41.812: INFO: Got endpoints: latency-svc-6vdx8 [153.594429ms]
Jan 15 15:16:41.815: INFO: Created: latency-svc-4fdm2
Jan 15 15:16:41.820: INFO: Got endpoints: latency-svc-4fdm2 [152.343842ms]
Jan 15 15:16:41.824: INFO: Created: latency-svc-pbw8v
Jan 15 15:16:41.829: INFO: Got endpoints: latency-svc-pbw8v [148.739802ms]
Jan 15 15:16:41.833: INFO: Created: latency-svc-4xllf
Jan 15 15:16:41.836: INFO: Got endpoints: latency-svc-4xllf [148.270054ms]
Jan 15 15:16:41.847: INFO: Created: latency-svc-hcks9
Jan 15 15:16:41.852: INFO: Got endpoints: latency-svc-hcks9 [147.072702ms]
Jan 15 15:16:41.857: INFO: Created: latency-svc-nc89z
Jan 15 15:16:41.859: INFO: Got endpoints: latency-svc-nc89z [145.086623ms]
Jan 15 15:16:41.866: INFO: Created: latency-svc-52f75
Jan 15 15:16:41.871: INFO: Got endpoints: latency-svc-52f75 [146.795548ms]
Jan 15 15:16:41.875: INFO: Created: latency-svc-mrwg7
Jan 15 15:16:41.880: INFO: Got endpoints: latency-svc-mrwg7 [145.527357ms]
Jan 15 15:16:41.885: INFO: Created: latency-svc-88pp6
Jan 15 15:16:41.894: INFO: Created: latency-svc-ncmhv
Jan 15 15:16:41.901: INFO: Got endpoints: latency-svc-88pp6 [157.847628ms]
Jan 15 15:16:41.904: INFO: Created: latency-svc-26mj7
Jan 15 15:16:41.918: INFO: Created: latency-svc-xqg7h
Jan 15 15:16:41.928: INFO: Created: latency-svc-6fw2z
Jan 15 15:16:41.936: INFO: Created: latency-svc-msfzf
Jan 15 15:16:41.945: INFO: Created: latency-svc-k6v95
Jan 15 15:16:41.952: INFO: Got endpoints: latency-svc-ncmhv [199.461147ms]
Jan 15 15:16:41.955: INFO: Created: latency-svc-6c5xc
Jan 15 15:16:41.964: INFO: Created: latency-svc-86p9c
Jan 15 15:16:41.974: INFO: Created: latency-svc-vkqmz
Jan 15 15:16:41.985: INFO: Created: latency-svc-scnn4
Jan 15 15:16:41.994: INFO: Created: latency-svc-7xczq
Jan 15 15:16:42.002: INFO: Got endpoints: latency-svc-26mj7 [240.213859ms]
Jan 15 15:16:42.004: INFO: Created: latency-svc-m2897
Jan 15 15:16:42.014: INFO: Created: latency-svc-5xr9s
Jan 15 15:16:42.027: INFO: Created: latency-svc-bpg47
Jan 15 15:16:42.036: INFO: Created: latency-svc-j4vj4
Jan 15 15:16:42.048: INFO: Created: latency-svc-fm772
Jan 15 15:16:42.052: INFO: Got endpoints: latency-svc-xqg7h [280.447851ms]
Jan 15 15:16:42.057: INFO: Created: latency-svc-2c4vx
Jan 15 15:16:42.067: INFO: Created: latency-svc-99xmx
Jan 15 15:16:42.099: INFO: Got endpoints: latency-svc-6fw2z [318.376089ms]
Jan 15 15:16:42.112: INFO: Created: latency-svc-bl792
Jan 15 15:16:42.149: INFO: Got endpoints: latency-svc-msfzf [359.858622ms]
Jan 15 15:16:42.162: INFO: Created: latency-svc-2n88q
Jan 15 15:16:42.199: INFO: Got endpoints: latency-svc-k6v95 [402.872261ms]
Jan 15 15:16:42.217: INFO: Created: latency-svc-bhccs
Jan 15 15:16:42.249: INFO: Got endpoints: latency-svc-6c5xc [437.040666ms]
Jan 15 15:16:42.262: INFO: Created: latency-svc-hkdv9
Jan 15 15:16:42.299: INFO: Got endpoints: latency-svc-86p9c [478.764573ms]
Jan 15 15:16:42.312: INFO: Created: latency-svc-np4nk
Jan 15 15:16:42.350: INFO: Got endpoints: latency-svc-vkqmz [520.734041ms]
Jan 15 15:16:42.362: INFO: Created: latency-svc-58pmp
Jan 15 15:16:42.399: INFO: Got endpoints: latency-svc-scnn4 [563.319411ms]
Jan 15 15:16:42.412: INFO: Created: latency-svc-n2sfj
Jan 15 15:16:42.449: INFO: Got endpoints: latency-svc-7xczq [596.841939ms]
Jan 15 15:16:42.462: INFO: Created: latency-svc-wj2j7
Jan 15 15:16:42.500: INFO: Got endpoints: latency-svc-m2897 [640.168935ms]
Jan 15 15:16:42.512: INFO: Created: latency-svc-hvh82
Jan 15 15:16:42.549: INFO: Got endpoints: latency-svc-5xr9s [678.556019ms]
Jan 15 15:16:42.562: INFO: Created: latency-svc-rw8w9
Jan 15 15:16:42.599: INFO: Got endpoints: latency-svc-bpg47 [719.200178ms]
Jan 15 15:16:42.612: INFO: Created: latency-svc-9b5xq
Jan 15 15:16:42.649: INFO: Got endpoints: latency-svc-j4vj4 [747.718275ms]
Jan 15 15:16:42.662: INFO: Created: latency-svc-w884c
Jan 15 15:16:42.699: INFO: Got endpoints: latency-svc-fm772 [747.649288ms]
Jan 15 15:16:42.712: INFO: Created: latency-svc-bg5d9
Jan 15 15:16:42.750: INFO: Got endpoints: latency-svc-2c4vx [748.162491ms]
Jan 15 15:16:42.763: INFO: Created: latency-svc-859ct
Jan 15 15:16:42.800: INFO: Got endpoints: latency-svc-99xmx [747.434863ms]
Jan 15 15:16:42.813: INFO: Created: latency-svc-g8gxq
Jan 15 15:16:42.849: INFO: Got endpoints: latency-svc-bl792 [750.23248ms]
Jan 15 15:16:42.864: INFO: Created: latency-svc-kbjpk
Jan 15 15:16:42.899: INFO: Got endpoints: latency-svc-2n88q [750.154499ms]
Jan 15 15:16:42.912: INFO: Created: latency-svc-6jjj2
Jan 15 15:16:42.949: INFO: Got endpoints: latency-svc-bhccs [749.808474ms]
Jan 15 15:16:42.962: INFO: Created: latency-svc-jrnpj
Jan 15 15:16:43.000: INFO: Got endpoints: latency-svc-hkdv9 [750.681269ms]
Jan 15 15:16:43.013: INFO: Created: latency-svc-28m2p
Jan 15 15:16:43.049: INFO: Got endpoints: latency-svc-np4nk [750.023427ms]
Jan 15 15:16:43.065: INFO: Created: latency-svc-tsk2g
Jan 15 15:16:43.099: INFO: Got endpoints: latency-svc-58pmp [749.126221ms]
Jan 15 15:16:43.111: INFO: Created: latency-svc-wjxqt
Jan 15 15:16:43.149: INFO: Got endpoints: latency-svc-n2sfj [749.73504ms]
Jan 15 15:16:43.166: INFO: Created: latency-svc-q8jtc
Jan 15 15:16:43.199: INFO: Got endpoints: latency-svc-wj2j7 [749.933151ms]
Jan 15 15:16:43.212: INFO: Created: latency-svc-t7572
Jan 15 15:16:43.249: INFO: Got endpoints: latency-svc-hvh82 [749.467408ms]
Jan 15 15:16:43.262: INFO: Created: latency-svc-kfdj8
Jan 15 15:16:43.299: INFO: Got endpoints: latency-svc-rw8w9 [749.518581ms]
Jan 15 15:16:43.311: INFO: Created: latency-svc-5htwx
Jan 15 15:16:43.349: INFO: Got endpoints: latency-svc-9b5xq [749.349818ms]
Jan 15 15:16:43.361: INFO: Created: latency-svc-x6mxc
Jan 15 15:16:43.399: INFO: Got endpoints: latency-svc-w884c [749.823271ms]
Jan 15 15:16:43.411: INFO: Created: latency-svc-gzrrh
Jan 15 15:16:43.448: INFO: Got endpoints: latency-svc-bg5d9 [748.937113ms]
Jan 15 15:16:43.461: INFO: Created: latency-svc-z6b9s
Jan 15 15:16:43.499: INFO: Got endpoints: latency-svc-859ct [748.645879ms]
Jan 15 15:16:43.511: INFO: Created: latency-svc-xhdlt
Jan 15 15:16:43.549: INFO: Got endpoints: latency-svc-g8gxq [749.182235ms]
Jan 15 15:16:43.562: INFO: Created: latency-svc-fbbw5
Jan 15 15:16:43.599: INFO: Got endpoints: latency-svc-kbjpk [749.491885ms]
Jan 15 15:16:43.611: INFO: Created: latency-svc-ww896
Jan 15 15:16:43.649: INFO: Got endpoints: latency-svc-6jjj2 [749.624923ms]
Jan 15 15:16:43.661: INFO: Created: latency-svc-twhrl
Jan 15 15:16:43.699: INFO: Got endpoints: latency-svc-jrnpj [749.958405ms]
Jan 15 15:16:43.711: INFO: Created: latency-svc-rtnb9
Jan 15 15:16:43.749: INFO: Got endpoints: latency-svc-28m2p [749.69085ms]
Jan 15 15:16:43.762: INFO: Created: latency-svc-mb6ql
Jan 15 15:16:43.799: INFO: Got endpoints: latency-svc-tsk2g [749.531019ms]
Jan 15 15:16:43.811: INFO: Created: latency-svc-w5zc4
Jan 15 15:16:43.848: INFO: Got endpoints: latency-svc-wjxqt [749.556094ms]
Jan 15 15:16:43.862: INFO: Created: latency-svc-7cjnh
Jan 15 15:16:43.899: INFO: Got endpoints: latency-svc-q8jtc [749.79719ms]
Jan 15 15:16:43.912: INFO: Created: latency-svc-xzq9m
Jan 15 15:16:43.949: INFO: Got endpoints: latency-svc-t7572 [749.669865ms]
Jan 15 15:16:43.961: INFO: Created: latency-svc-mtzdb
Jan 15 15:16:43.999: INFO: Got endpoints: latency-svc-kfdj8 [749.362457ms]
Jan 15 15:16:44.012: INFO: Created: latency-svc-frmts
Jan 15 15:16:44.049: INFO: Got endpoints: latency-svc-5htwx [750.033223ms]
Jan 15 15:16:44.062: INFO: Created: latency-svc-lmwgv
Jan 15 15:16:44.099: INFO: Got endpoints: latency-svc-x6mxc [750.478905ms]
Jan 15 15:16:44.112: INFO: Created: latency-svc-6n5ln
Jan 15 15:16:44.149: INFO: Got endpoints: latency-svc-gzrrh [750.312504ms]
Jan 15 15:16:44.169: INFO: Created: latency-svc-4kd5k
Jan 15 15:16:44.202: INFO: Got endpoints: latency-svc-z6b9s [753.90994ms]
Jan 15 15:16:44.215: INFO: Created: latency-svc-s2wwc
Jan 15 15:16:44.249: INFO: Got endpoints: latency-svc-xhdlt [750.372784ms]
Jan 15 15:16:44.262: INFO: Created: latency-svc-nb59m
Jan 15 15:16:44.299: INFO: Got endpoints: latency-svc-fbbw5 [749.826421ms]
Jan 15 15:16:44.311: INFO: Created: latency-svc-5c89k
Jan 15 15:16:44.349: INFO: Got endpoints: latency-svc-ww896 [750.248181ms]
Jan 15 15:16:44.362: INFO: Created: latency-svc-wmbzr
Jan 15 15:16:44.399: INFO: Got endpoints: latency-svc-twhrl [750.032199ms]
Jan 15 15:16:44.414: INFO: Created: latency-svc-ngbxt
Jan 15 15:16:44.449: INFO: Got endpoints: latency-svc-rtnb9 [749.834302ms]
Jan 15 15:16:44.461: INFO: Created: latency-svc-4xk6z
Jan 15 15:16:44.499: INFO: Got endpoints: latency-svc-mb6ql [749.647964ms]
Jan 15 15:16:44.513: INFO: Created: latency-svc-c6b6c
Jan 15 15:16:44.549: INFO: Got endpoints: latency-svc-w5zc4 [749.853621ms]
Jan 15 15:16:44.562: INFO: Created: latency-svc-vp4cw
Jan 15 15:16:44.599: INFO: Got endpoints: latency-svc-7cjnh [750.54502ms]
Jan 15 15:16:44.612: INFO: Created: latency-svc-qxxrw
Jan 15 15:16:44.649: INFO: Got endpoints: latency-svc-xzq9m [750.107357ms]
Jan 15 15:16:44.663: INFO: Created: latency-svc-2t7dg
Jan 15 15:16:44.699: INFO: Got endpoints: latency-svc-mtzdb [749.701884ms]
Jan 15 15:16:44.712: INFO: Created: latency-svc-5w7fz
Jan 15 15:16:44.749: INFO: Got endpoints: latency-svc-frmts [750.309284ms]
Jan 15 15:16:44.763: INFO: Created: latency-svc-wcv2n
Jan 15 15:16:44.799: INFO: Got endpoints: latency-svc-lmwgv [750.412696ms]
Jan 15 15:16:44.814: INFO: Created: latency-svc-wtc7r
Jan 15 15:16:44.849: INFO: Got endpoints: latency-svc-6n5ln [749.556718ms]
Jan 15 15:16:44.862: INFO: Created: latency-svc-9bnzx
Jan 15 15:16:44.899: INFO: Got endpoints: latency-svc-4kd5k [750.271006ms]
Jan 15 15:16:44.912: INFO: Created: latency-svc-mx652
Jan 15 15:16:44.949: INFO: Got endpoints: latency-svc-s2wwc [746.611798ms]
Jan 15 15:16:44.962: INFO: Created: latency-svc-q6ltx
Jan 15 15:16:45.000: INFO: Got endpoints: latency-svc-nb59m [750.24445ms]
Jan 15 15:16:45.012: INFO: Created: latency-svc-mqb5n
Jan 15 15:16:45.049: INFO: Got endpoints: latency-svc-5c89k [749.974298ms]
Jan 15 15:16:45.061: INFO: Created: latency-svc-gv2md
Jan 15 15:16:45.099: INFO: Got endpoints: latency-svc-wmbzr [750.292997ms]
Jan 15 15:16:45.112: INFO: Created: latency-svc-kmqw6
Jan 15 15:16:45.149: INFO: Got endpoints: latency-svc-ngbxt [749.96864ms]
Jan 15 15:16:45.161: INFO: Created: latency-svc-htgmc
Jan 15 15:16:45.199: INFO: Got endpoints: latency-svc-4xk6z [750.133985ms]
Jan 15 15:16:45.211: INFO: Created: latency-svc-6q2x8
Jan 15 15:16:45.249: INFO: Got endpoints: latency-svc-c6b6c [750.104456ms]
Jan 15 15:16:45.261: INFO: Created: latency-svc-4g6xn
Jan 15 15:16:45.299: INFO: Got endpoints: latency-svc-vp4cw [750.775076ms]
Jan 15 15:16:45.312: INFO: Created: latency-svc-xbmkc
Jan 15 15:16:45.349: INFO: Got endpoints: latency-svc-qxxrw [749.55097ms]
Jan 15 15:16:45.361: INFO: Created: latency-svc-bdvbs
Jan 15 15:16:45.399: INFO: Got endpoints: latency-svc-2t7dg [749.869335ms]
Jan 15 15:16:45.411: INFO: Created: latency-svc-tm7kq
Jan 15 15:16:45.449: INFO: Got endpoints: latency-svc-5w7fz [750.394174ms]
Jan 15 15:16:45.461: INFO: Created: latency-svc-phxq7
Jan 15 15:16:45.499: INFO: Got endpoints: latency-svc-wcv2n [750.346486ms]
Jan 15 15:16:45.514: INFO: Created: latency-svc-chhlp
Jan 15 15:16:45.554: INFO: Got endpoints: latency-svc-wtc7r [754.113291ms]
Jan 15 15:16:45.567: INFO: Created: latency-svc-9q9ld
Jan 15 15:16:45.599: INFO: Got endpoints: latency-svc-9bnzx [749.762708ms]
Jan 15 15:16:45.611: INFO: Created: latency-svc-pm5dh
Jan 15 15:16:45.649: INFO: Got endpoints: latency-svc-mx652 [749.363589ms]
Jan 15 15:16:45.661: INFO: Created: latency-svc-d5zlc
Jan 15 15:16:45.699: INFO: Got endpoints: latency-svc-q6ltx [749.852064ms]
Jan 15 15:16:45.711: INFO: Created: latency-svc-zkzgt
Jan 15 15:16:45.749: INFO: Got endpoints: latency-svc-mqb5n [749.888574ms]
Jan 15 15:16:45.764: INFO: Created: latency-svc-mtd6f
Jan 15 15:16:45.798: INFO: Got endpoints: latency-svc-gv2md [749.434535ms]
Jan 15 15:16:45.811: INFO: Created: latency-svc-mpssj
Jan 15 15:16:45.849: INFO: Got endpoints: latency-svc-kmqw6 [749.418336ms]
Jan 15 15:16:45.865: INFO: Created: latency-svc-bdh7m
Jan 15 15:16:45.899: INFO: Got endpoints: latency-svc-htgmc [750.294989ms]
Jan 15 15:16:45.912: INFO: Created: latency-svc-cclgs
Jan 15 15:16:45.949: INFO: Got endpoints: latency-svc-6q2x8 [749.501333ms]
Jan 15 15:16:45.962: INFO: Created: latency-svc-v22vg
Jan 15 15:16:45.999: INFO: Got endpoints: latency-svc-4g6xn [749.711028ms]
Jan 15 15:16:46.011: INFO: Created: latency-svc-slwzq
Jan 15 15:16:46.049: INFO: Got endpoints: latency-svc-xbmkc [749.461559ms]
Jan 15 15:16:46.061: INFO: Created: latency-svc-ghb95
Jan 15 15:16:46.099: INFO: Got endpoints: latency-svc-bdvbs [750.191551ms]
Jan 15 15:16:46.111: INFO: Created: latency-svc-8z8ps
Jan 15 15:16:46.149: INFO: Got endpoints: latency-svc-tm7kq [750.373537ms]
Jan 15 15:16:46.162: INFO: Created: latency-svc-5p6sz
Jan 15 15:16:46.199: INFO: Got endpoints: latency-svc-phxq7 [749.704913ms]
Jan 15 15:16:46.211: INFO: Created: latency-svc-2g8fv
Jan 15 15:16:46.249: INFO: Got endpoints: latency-svc-chhlp [749.764ms]
Jan 15 15:16:46.263: INFO: Created: latency-svc-9xc2f
Jan 15 15:16:46.298: INFO: Got endpoints: latency-svc-9q9ld [744.706117ms]
Jan 15 15:16:46.311: INFO: Created: latency-svc-tsbm8
Jan 15 15:16:46.349: INFO: Got endpoints: latency-svc-pm5dh [750.154825ms]
Jan 15 15:16:46.362: INFO: Created: latency-svc-jmvwf
Jan 15 15:16:46.399: INFO: Got endpoints: latency-svc-d5zlc [750.32656ms]
Jan 15 15:16:46.412: INFO: Created: latency-svc-zgwhz
Jan 15 15:16:46.449: INFO: Got endpoints: latency-svc-zkzgt [749.875015ms]
Jan 15 15:16:46.461: INFO: Created: latency-svc-8twsb
Jan 15 15:16:46.499: INFO: Got endpoints: latency-svc-mtd6f [749.734971ms]
Jan 15 15:16:46.511: INFO: Created: latency-svc-45qj2
Jan 15 15:16:46.549: INFO: Got endpoints: latency-svc-mpssj [751.048568ms]
Jan 15 15:16:46.562: INFO: Created: latency-svc-shkt6
Jan 15 15:16:46.599: INFO: Got endpoints: latency-svc-bdh7m [749.870623ms]
Jan 15 15:16:46.611: INFO: Created: latency-svc-4pkls
Jan 15 15:16:46.649: INFO: Got endpoints: latency-svc-cclgs [749.872579ms]
Jan 15 15:16:46.662: INFO: Created: latency-svc-bzb87
Jan 15 15:16:46.699: INFO: Got endpoints: latency-svc-v22vg [750.567942ms]
Jan 15 15:16:46.711: INFO: Created: latency-svc-jp52t
Jan 15 15:16:46.749: INFO: Got endpoints: latency-svc-slwzq [750.42431ms]
Jan 15 15:16:46.763: INFO: Created: latency-svc-9jq7w
Jan 15 15:16:46.799: INFO: Got endpoints: latency-svc-ghb95 [750.271552ms]
Jan 15 15:16:46.812: INFO: Created: latency-svc-hnqdq
Jan 15 15:16:46.849: INFO: Got endpoints: latency-svc-8z8ps [749.865167ms]
Jan 15 15:16:46.861: INFO: Created: latency-svc-vzrm8
Jan 15 15:16:46.901: INFO: Got endpoints: latency-svc-5p6sz [751.776318ms]
Jan 15 15:16:46.915: INFO: Created: latency-svc-bpdxq
Jan 15 15:16:46.949: INFO: Got endpoints: latency-svc-2g8fv [750.456442ms]
Jan 15 15:16:46.963: INFO: Created: latency-svc-tgtnq
Jan 15 15:16:46.999: INFO: Got endpoints: latency-svc-9xc2f [750.237292ms]
Jan 15 15:16:47.014: INFO: Created: latency-svc-5mgrp
Jan 15 15:16:47.049: INFO: Got endpoints: latency-svc-tsbm8 [750.513692ms]
Jan 15 15:16:47.062: INFO: Created: latency-svc-gj5h7
Jan 15 15:16:47.099: INFO: Got endpoints: latency-svc-jmvwf [750.01357ms]
Jan 15 15:16:47.111: INFO: Created: latency-svc-xbvm7
Jan 15 15:16:47.149: INFO: Got endpoints: latency-svc-zgwhz [750.001859ms]
Jan 15 15:16:47.162: INFO: Created: latency-svc-d4tf8
Jan 15 15:16:47.199: INFO: Got endpoints: latency-svc-8twsb [750.071051ms]
Jan 15 15:16:47.215: INFO: Created: latency-svc-lh8gr
Jan 15 15:16:47.249: INFO: Got endpoints: latency-svc-45qj2 [749.57491ms]
Jan 15 15:16:47.262: INFO: Created: latency-svc-zx25b
Jan 15 15:16:47.299: INFO: Got endpoints: latency-svc-shkt6 [750.170254ms]
Jan 15 15:16:47.315: INFO: Created: latency-svc-wb7zv
Jan 15 15:16:47.351: INFO: Got endpoints: latency-svc-4pkls [751.845246ms]
Jan 15 15:16:47.364: INFO: Created: latency-svc-rkstb
Jan 15 15:16:47.399: INFO: Got endpoints: latency-svc-bzb87 [749.68717ms]
Jan 15 15:16:47.411: INFO: Created: latency-svc-2fjlq
Jan 15 15:16:47.449: INFO: Got endpoints: latency-svc-jp52t [749.847627ms]
Jan 15 15:16:47.463: INFO: Created: latency-svc-mt7jd
Jan 15 15:16:47.500: INFO: Got endpoints: latency-svc-9jq7w [750.363184ms]
Jan 15 15:16:47.513: INFO: Created: latency-svc-q4fhl
Jan 15 15:16:47.549: INFO: Got endpoints: latency-svc-hnqdq [749.639553ms]
Jan 15 15:16:47.562: INFO: Created: latency-svc-srkf9
Jan 15 15:16:47.599: INFO: Got endpoints: latency-svc-vzrm8 [750.134947ms]
Jan 15 15:16:47.613: INFO: Created: latency-svc-shxmh
Jan 15 15:16:47.650: INFO: Got endpoints: latency-svc-bpdxq [748.366334ms]
Jan 15 15:16:47.662: INFO: Created: latency-svc-db9jz
Jan 15 15:16:47.699: INFO: Got endpoints: latency-svc-tgtnq [750.037981ms]
Jan 15 15:16:47.713: INFO: Created: latency-svc-vvgk7
Jan 15 15:16:47.749: INFO: Got endpoints: latency-svc-5mgrp [749.895014ms]
Jan 15 15:16:47.762: INFO: Created: latency-svc-8m4kq
Jan 15 15:16:47.799: INFO: Got endpoints: latency-svc-gj5h7 [749.849401ms]
Jan 15 15:16:47.812: INFO: Created: latency-svc-m8b55
Jan 15 15:16:47.849: INFO: Got endpoints: latency-svc-xbvm7 [750.181817ms]
Jan 15 15:16:47.862: INFO: Created: latency-svc-9bznc
Jan 15 15:16:47.899: INFO: Got endpoints: latency-svc-d4tf8 [750.152781ms]
Jan 15 15:16:47.913: INFO: Created: latency-svc-xkqsr
Jan 15 15:16:47.949: INFO: Got endpoints: latency-svc-lh8gr [750.163842ms]
Jan 15 15:16:47.962: INFO: Created: latency-svc-zp4b5
Jan 15 15:16:47.999: INFO: Got endpoints: latency-svc-zx25b [749.885109ms]
Jan 15 15:16:48.012: INFO: Created: latency-svc-thtcl
Jan 15 15:16:48.049: INFO: Got endpoints: latency-svc-wb7zv [749.595951ms]
Jan 15 15:16:48.063: INFO: Created: latency-svc-6xt95
Jan 15 15:16:48.099: INFO: Got endpoints: latency-svc-rkstb [748.652235ms]
Jan 15 15:16:48.112: INFO: Created: latency-svc-lpq2r
Jan 15 15:16:48.149: INFO: Got endpoints: latency-svc-2fjlq [749.73996ms]
Jan 15 15:16:48.161: INFO: Created: latency-svc-klsmf
Jan 15 15:16:48.200: INFO: Got endpoints: latency-svc-mt7jd [750.471245ms]
Jan 15 15:16:48.212: INFO: Created: latency-svc-pkpmq
Jan 15 15:16:48.249: INFO: Got endpoints: latency-svc-q4fhl [749.420525ms]
Jan 15 15:16:48.262: INFO: Created: latency-svc-k6j7j
Jan 15 15:16:48.299: INFO: Got endpoints: latency-svc-srkf9 [749.803665ms]
Jan 15 15:16:48.312: INFO: Created: latency-svc-v8g7d
Jan 15 15:16:48.353: INFO: Got endpoints: latency-svc-shxmh [754.126356ms]
Jan 15 15:16:48.366: INFO: Created: latency-svc-bmlp4
Jan 15 15:16:48.399: INFO: Got endpoints: latency-svc-db9jz [749.145095ms]
Jan 15 15:16:48.411: INFO: Created: latency-svc-kbzzv
Jan 15 15:16:48.449: INFO: Got endpoints: latency-svc-vvgk7 [749.659183ms]
Jan 15 15:16:48.463: INFO: Created: latency-svc-h5jn7
Jan 15 15:16:48.500: INFO: Got endpoints: latency-svc-8m4kq [750.332373ms]
Jan 15 15:16:48.513: INFO: Created: latency-svc-lg996
Jan 15 15:16:48.549: INFO: Got endpoints: latency-svc-m8b55 [750.467238ms]
Jan 15 15:16:48.564: INFO: Created: latency-svc-g5mgp
Jan 15 15:16:48.599: INFO: Got endpoints: latency-svc-9bznc [749.95847ms]
Jan 15 15:16:48.611: INFO: Created: latency-svc-zxvxr
Jan 15 15:16:48.651: INFO: Got endpoints: latency-svc-xkqsr [751.350865ms]
Jan 15 15:16:48.665: INFO: Created: latency-svc-7pxsd
Jan 15 15:16:48.699: INFO: Got endpoints: latency-svc-zp4b5 [749.921222ms]
Jan 15 15:16:48.712: INFO: Created: latency-svc-bnksv
Jan 15 15:16:48.749: INFO: Got endpoints: latency-svc-thtcl [750.018834ms]
Jan 15 15:16:48.762: INFO: Created: latency-svc-5ls7d
Jan 15 15:16:48.800: INFO: Got endpoints: latency-svc-6xt95 [750.896507ms]
Jan 15 15:16:48.813: INFO: Created: latency-svc-rcbtq
Jan 15 15:16:48.849: INFO: Got endpoints: latency-svc-lpq2r [749.45524ms]
Jan 15 15:16:48.864: INFO: Created: latency-svc-4skfb
Jan 15 15:16:48.899: INFO: Got endpoints: latency-svc-klsmf [750.528509ms]
Jan 15 15:16:48.912: INFO: Created: latency-svc-qtbf2
Jan 15 15:16:48.949: INFO: Got endpoints: latency-svc-pkpmq [749.559301ms]
Jan 15 15:16:48.964: INFO: Created: latency-svc-b5qhc
Jan 15 15:16:48.999: INFO: Got endpoints: latency-svc-k6j7j [749.79319ms]
Jan 15 15:16:49.013: INFO: Created: latency-svc-w7gcn
Jan 15 15:16:49.049: INFO: Got endpoints: latency-svc-v8g7d [750.423936ms]
Jan 15 15:16:49.063: INFO: Created: latency-svc-b952k
Jan 15 15:16:49.099: INFO: Got endpoints: latency-svc-bmlp4 [745.764424ms]
Jan 15 15:16:49.112: INFO: Created: latency-svc-9vbtb
Jan 15 15:16:49.149: INFO: Got endpoints: latency-svc-kbzzv [750.619808ms]
Jan 15 15:16:49.164: INFO: Created: latency-svc-sc4hs
Jan 15 15:16:49.199: INFO: Got endpoints: latency-svc-h5jn7 [749.961638ms]
Jan 15 15:16:49.212: INFO: Created: latency-svc-jp47v
Jan 15 15:16:49.249: INFO: Got endpoints: latency-svc-lg996 [749.208165ms]
Jan 15 15:16:49.262: INFO: Created: latency-svc-tfm8l
Jan 15 15:16:49.300: INFO: Got endpoints: latency-svc-g5mgp [750.641607ms]
Jan 15 15:16:49.313: INFO: Created: latency-svc-zqsbk
Jan 15 15:16:49.349: INFO: Got endpoints: latency-svc-zxvxr [750.363419ms]
Jan 15 15:16:49.399: INFO: Got endpoints: latency-svc-7pxsd [748.442996ms]
Jan 15 15:16:49.449: INFO: Got endpoints: latency-svc-bnksv [749.670932ms]
Jan 15 15:16:49.500: INFO: Got endpoints: latency-svc-5ls7d [750.717498ms]
Jan 15 15:16:49.549: INFO: Got endpoints: latency-svc-rcbtq [749.008032ms]
Jan 15 15:16:49.601: INFO: Got endpoints: latency-svc-4skfb [751.711903ms]
Jan 15 15:16:49.649: INFO: Got endpoints: latency-svc-qtbf2 [749.68218ms]
Jan 15 15:16:49.699: INFO: Got endpoints: latency-svc-b5qhc [750.058142ms]
Jan 15 15:16:49.749: INFO: Got endpoints: latency-svc-w7gcn [750.046521ms]
Jan 15 15:16:49.800: INFO: Got endpoints: latency-svc-b952k [750.978691ms]
Jan 15 15:16:49.849: INFO: Got endpoints: latency-svc-9vbtb [749.980902ms]
Jan 15 15:16:49.899: INFO: Got endpoints: latency-svc-sc4hs [749.607897ms]
Jan 15 15:16:49.950: INFO: Got endpoints: latency-svc-jp47v [751.283445ms]
Jan 15 15:16:49.999: INFO: Got endpoints: latency-svc-tfm8l [750.208841ms]
Jan 15 15:16:50.050: INFO: Got endpoints: latency-svc-zqsbk [749.628647ms]
Jan 15 15:16:50.050: INFO: Latencies: [17.954765ms 21.156013ms 31.359579ms 39.62394ms 59.551909ms 71.762137ms 82.192802ms 97.019887ms 102.777125ms 113.868399ms 123.510649ms 134.85895ms 145.086623ms 145.527357ms 145.589645ms 146.795548ms 147.072702ms 147.517ms 148.270054ms 148.739802ms 151.24267ms 152.343842ms 152.362389ms 153.594429ms 154.204155ms 154.787575ms 155.26878ms 156.142518ms 157.847628ms 158.03979ms 159.970722ms 161.527204ms 162.220654ms 162.801437ms 163.926918ms 164.94148ms 177.187563ms 199.461147ms 240.213859ms 280.447851ms 318.376089ms 359.858622ms 402.872261ms 437.040666ms 478.764573ms 520.734041ms 563.319411ms 596.841939ms 640.168935ms 678.556019ms 719.200178ms 744.706117ms 745.764424ms 746.611798ms 747.434863ms 747.649288ms 747.718275ms 748.162491ms 748.366334ms 748.442996ms 748.645879ms 748.652235ms 748.937113ms 749.008032ms 749.126221ms 749.145095ms 749.182235ms 749.208165ms 749.349818ms 749.362457ms 749.363589ms 749.418336ms 749.420525ms 749.434535ms 749.45524ms 749.461559ms 749.467408ms 749.491885ms 749.501333ms 749.518581ms 749.531019ms 749.55097ms 749.556094ms 749.556718ms 749.559301ms 749.57491ms 749.595951ms 749.607897ms 749.624923ms 749.628647ms 749.639553ms 749.647964ms 749.659183ms 749.669865ms 749.670932ms 749.68218ms 749.68717ms 749.69085ms 749.701884ms 749.704913ms 749.711028ms 749.734971ms 749.73504ms 749.73996ms 749.762708ms 749.764ms 749.79319ms 749.79719ms 749.803665ms 749.808474ms 749.823271ms 749.826421ms 749.834302ms 749.847627ms 749.849401ms 749.852064ms 749.853621ms 749.865167ms 749.869335ms 749.870623ms 749.872579ms 749.875015ms 749.885109ms 749.888574ms 749.895014ms 749.921222ms 749.933151ms 749.958405ms 749.95847ms 749.961638ms 749.96864ms 749.974298ms 749.980902ms 750.001859ms 750.01357ms 750.018834ms 750.023427ms 750.032199ms 750.033223ms 750.037981ms 750.046521ms 750.058142ms 750.071051ms 750.104456ms 750.107357ms 750.133985ms 750.134947ms 750.152781ms 750.154499ms 750.154825ms 750.163842ms 750.170254ms 750.181817ms 750.191551ms 750.208841ms 750.23248ms 750.237292ms 750.24445ms 750.248181ms 750.271006ms 750.271552ms 750.292997ms 750.294989ms 750.309284ms 750.312504ms 750.32656ms 750.332373ms 750.346486ms 750.363184ms 750.363419ms 750.372784ms 750.373537ms 750.394174ms 750.412696ms 750.423936ms 750.42431ms 750.456442ms 750.467238ms 750.471245ms 750.478905ms 750.513692ms 750.528509ms 750.54502ms 750.567942ms 750.619808ms 750.641607ms 750.681269ms 750.717498ms 750.775076ms 750.896507ms 750.978691ms 751.048568ms 751.283445ms 751.350865ms 751.711903ms 751.776318ms 751.845246ms 753.90994ms 754.113291ms 754.126356ms]
Jan 15 15:16:50.050: INFO: 50 %ile: 749.711028ms
Jan 15 15:16:50.050: INFO: 90 %ile: 750.513692ms
Jan 15 15:16:50.050: INFO: 99 %ile: 754.113291ms
Jan 15 15:16:50.050: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:16:50.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-r9ff2" for this suite.
Jan 15 15:17:00.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:17:00.132: INFO: namespace: e2e-tests-svc-latency-r9ff2, resource: bindings, ignored listing per whitelist
Jan 15 15:17:00.155: INFO: namespace e2e-tests-svc-latency-r9ff2 deletion completed in 10.101282977s

 [SLOW TEST:19.875 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:17:00.155: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 15 15:17:00.197: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 15 15:17:00.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:00.323: INFO: stderr: ""
Jan 15 15:17:00.323: INFO: stdout: "service/redis-slave created\n"
Jan 15 15:17:00.323: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 15 15:17:00.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:00.457: INFO: stderr: ""
Jan 15 15:17:00.457: INFO: stdout: "service/redis-master created\n"
Jan 15 15:17:00.457: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 15 15:17:00.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:00.603: INFO: stderr: ""
Jan 15 15:17:00.603: INFO: stdout: "service/frontend created\n"
Jan 15 15:17:00.603: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 15 15:17:00.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:00.725: INFO: stderr: ""
Jan 15 15:17:00.725: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 15 15:17:00.725: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 15 15:17:00.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:00.851: INFO: stderr: ""
Jan 15 15:17:00.851: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 15 15:17:00.851: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 15 15:17:00.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:00.976: INFO: stderr: ""
Jan 15 15:17:00.976: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 15 15:17:00.976: INFO: Waiting for all frontend pods to be Running.
Jan 15 15:17:16.027: INFO: Waiting for frontend to serve content.
Jan 15 15:17:21.055: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jan 15 15:17:26.076: INFO: Trying to add a new entry to the guestbook.
Jan 15 15:17:26.093: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 15 15:17:26.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:26.187: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:17:26.187: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 15:17:26.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:26.265: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:17:26.265: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 15:17:26.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:26.348: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:17:26.348: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 15:17:26.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:26.413: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:17:26.413: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 15:17:26.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:26.483: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:17:26.483: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 15:17:26.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-phj26'
Jan 15 15:17:26.548: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:17:26.548: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:17:26.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-phj26" for this suite.
Jan 15 15:18:04.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:18:04.572: INFO: namespace: e2e-tests-kubectl-phj26, resource: bindings, ignored listing per whitelist
Jan 15 15:18:04.649: INFO: namespace e2e-tests-kubectl-phj26 deletion completed in 38.09764678s

 [SLOW TEST:64.494 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:18:04.649: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c15223e4-18d8-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:18:04.704: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-sm66h" to be "success or failure"
Jan 15 15:18:04.707: INFO: Pod "pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.253756ms
Jan 15 15:18:06.711: INFO: Pod "pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006975828s
STEP: Saw pod success
Jan 15 15:18:06.711: INFO: Pod "pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:18:06.714: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:18:06.739: INFO: Waiting for pod pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:18:06.742: INFO: Pod pod-projected-configmaps-c15334a5-18d8-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:18:06.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sm66h" for this suite.
Jan 15 15:18:12.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:18:12.775: INFO: namespace: e2e-tests-projected-sm66h, resource: bindings, ignored listing per whitelist
Jan 15 15:18:12.844: INFO: namespace e2e-tests-projected-sm66h deletion completed in 6.097132025s

 [SLOW TEST:8.194 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:18:12.844: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jan 15 15:18:13.095: INFO: Pod name wrapped-volume-race-c65270f8-18d8-11e9-9d2c-c274f07984f4: Found 0 pods out of 5
Jan 15 15:18:18.102: INFO: Pod name wrapped-volume-race-c65270f8-18d8-11e9-9d2c-c274f07984f4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c65270f8-18d8-11e9-9d2c-c274f07984f4 in namespace e2e-tests-emptydir-wrapper-94452, will wait for the garbage collector to delete the pods
Jan 15 15:20:04.188: INFO: Deleting ReplicationController wrapped-volume-race-c65270f8-18d8-11e9-9d2c-c274f07984f4 took: 9.877307ms
Jan 15 15:20:04.289: INFO: Terminating ReplicationController wrapped-volume-race-c65270f8-18d8-11e9-9d2c-c274f07984f4 pods took: 100.21699ms
STEP: Creating RC which spawns configmap-volume pods
Jan 15 15:20:50.114: INFO: Pod name wrapped-volume-race-23e81d6a-18d9-11e9-9d2c-c274f07984f4: Found 0 pods out of 5
Jan 15 15:20:55.121: INFO: Pod name wrapped-volume-race-23e81d6a-18d9-11e9-9d2c-c274f07984f4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-23e81d6a-18d9-11e9-9d2c-c274f07984f4 in namespace e2e-tests-emptydir-wrapper-94452, will wait for the garbage collector to delete the pods
Jan 15 15:22:43.211: INFO: Deleting ReplicationController wrapped-volume-race-23e81d6a-18d9-11e9-9d2c-c274f07984f4 took: 10.105305ms
Jan 15 15:22:43.311: INFO: Terminating ReplicationController wrapped-volume-race-23e81d6a-18d9-11e9-9d2c-c274f07984f4 pods took: 100.263646ms
STEP: Creating RC which spawns configmap-volume pods
Jan 15 15:23:29.633: INFO: Pod name wrapped-volume-race-82fd592c-18d9-11e9-9d2c-c274f07984f4: Found 0 pods out of 5
Jan 15 15:23:34.640: INFO: Pod name wrapped-volume-race-82fd592c-18d9-11e9-9d2c-c274f07984f4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-82fd592c-18d9-11e9-9d2c-c274f07984f4 in namespace e2e-tests-emptydir-wrapper-94452, will wait for the garbage collector to delete the pods
Jan 15 15:25:22.726: INFO: Deleting ReplicationController wrapped-volume-race-82fd592c-18d9-11e9-9d2c-c274f07984f4 took: 10.45025ms
Jan 15 15:25:22.826: INFO: Terminating ReplicationController wrapped-volume-race-82fd592c-18d9-11e9-9d2c-c274f07984f4 pods took: 100.276983ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:26:10.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-94452" for this suite.
Jan 15 15:26:16.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:26:16.193: INFO: namespace: e2e-tests-emptydir-wrapper-94452, resource: bindings, ignored listing per whitelist
Jan 15 15:26:16.217: INFO: namespace e2e-tests-emptydir-wrapper-94452 deletion completed in 6.0961976s

 [SLOW TEST:483.373 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:26:16.217: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-e6517ff7-18d9-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:26:16.271: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-ksprl" to be "success or failure"
Jan 15 15:26:16.275: INFO: Pod "pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.75454ms
Jan 15 15:26:18.278: INFO: Pod "pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007155585s
STEP: Saw pod success
Jan 15 15:26:18.278: INFO: Pod "pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:26:18.281: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:26:18.302: INFO: Waiting for pod pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:26:18.305: INFO: Pod pod-projected-secrets-e65289db-18d9-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:26:18.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ksprl" for this suite.
Jan 15 15:26:24.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:26:24.338: INFO: namespace: e2e-tests-projected-ksprl, resource: bindings, ignored listing per whitelist
Jan 15 15:26:24.402: INFO: namespace e2e-tests-projected-ksprl deletion completed in 6.093827683s

 [SLOW TEST:8.185 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:26:24.402: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 15 15:26:24.449: INFO: Waiting up to 5m0s for pod "var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-var-expansion-5p6df" to be "success or failure"
Jan 15 15:26:24.453: INFO: Pod "var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.571847ms
Jan 15 15:26:26.456: INFO: Pod "var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007090876s
STEP: Saw pod success
Jan 15 15:26:26.456: INFO: Pod "var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:26:26.459: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 15:26:26.478: INFO: Waiting for pod var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:26:26.481: INFO: Pod var-expansion-eb31f1ca-18d9-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:26:26.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-5p6df" for this suite.
Jan 15 15:26:32.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:26:32.566: INFO: namespace: e2e-tests-var-expansion-5p6df, resource: bindings, ignored listing per whitelist
Jan 15 15:26:32.586: INFO: namespace e2e-tests-var-expansion-5p6df deletion completed in 6.100912256s

 [SLOW TEST:8.184 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:26:32.586: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f013488e-18d9-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:26:32.641: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-9zd8f" to be "success or failure"
Jan 15 15:26:32.645: INFO: Pod "pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.335903ms
Jan 15 15:26:34.649: INFO: Pod "pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007657754s
STEP: Saw pod success
Jan 15 15:26:34.649: INFO: Pod "pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:26:34.652: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:26:34.673: INFO: Waiting for pod pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:26:34.676: INFO: Pod pod-projected-secrets-f0144908-18d9-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:26:34.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zd8f" for this suite.
Jan 15 15:26:40.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:26:40.727: INFO: namespace: e2e-tests-projected-9zd8f, resource: bindings, ignored listing per whitelist
Jan 15 15:26:40.783: INFO: namespace e2e-tests-projected-9zd8f deletion completed in 6.103291511s

 [SLOW TEST:8.197 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:26:40.783: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:26:40.820: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:26:42.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c8qp8" for this suite.
Jan 15 15:27:20.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:27:20.901: INFO: namespace: e2e-tests-pods-c8qp8, resource: bindings, ignored listing per whitelist
Jan 15 15:27:20.960: INFO: namespace e2e-tests-pods-c8qp8 deletion completed in 38.09663655s

 [SLOW TEST:40.177 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:27:20.960: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mdktt
Jan 15 15:27:25.023: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mdktt
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 15:27:25.026: INFO: Initial restart count of pod liveness-http is 0
Jan 15 15:27:43.065: INFO: Restart count of pod e2e-tests-container-probe-mdktt/liveness-http is now 1 (18.039025783s elapsed)
Jan 15 15:28:03.110: INFO: Restart count of pod e2e-tests-container-probe-mdktt/liveness-http is now 2 (38.08468831s elapsed)
Jan 15 15:28:23.157: INFO: Restart count of pod e2e-tests-container-probe-mdktt/liveness-http is now 3 (58.13103989s elapsed)
Jan 15 15:28:43.202: INFO: Restart count of pod e2e-tests-container-probe-mdktt/liveness-http is now 4 (1m18.176746415s elapsed)
Jan 15 15:29:53.375: INFO: Restart count of pod e2e-tests-container-probe-mdktt/liveness-http is now 5 (2m28.348896606s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:29:53.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mdktt" for this suite.
Jan 15 15:29:59.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:29:59.445: INFO: namespace: e2e-tests-container-probe-mdktt, resource: bindings, ignored listing per whitelist
Jan 15 15:29:59.502: INFO: namespace e2e-tests-container-probe-mdktt deletion completed in 6.109105611s

 [SLOW TEST:158.542 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:29:59.502: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-pnhf
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 15:29:59.568: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pnhf" in namespace "e2e-tests-subpath-tj59f" to be "success or failure"
Jan 15 15:29:59.571: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.670272ms
Jan 15 15:30:01.575: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007220616s
Jan 15 15:30:03.579: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 4.01120044s
Jan 15 15:30:05.588: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 6.020188814s
Jan 15 15:30:07.592: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 8.023797575s
Jan 15 15:30:09.595: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 10.027605238s
Jan 15 15:30:11.599: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 12.031415975s
Jan 15 15:30:13.603: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 14.035188016s
Jan 15 15:30:15.614: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 16.046164482s
Jan 15 15:30:17.619: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 18.051399446s
Jan 15 15:30:19.623: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 20.055483717s
Jan 15 15:30:21.627: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Running", Reason="", readiness=false. Elapsed: 22.058989313s
Jan 15 15:30:23.630: INFO: Pod "pod-subpath-test-configmap-pnhf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.062678079s
STEP: Saw pod success
Jan 15 15:30:23.630: INFO: Pod "pod-subpath-test-configmap-pnhf" satisfied condition "success or failure"
Jan 15 15:30:23.634: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-subpath-test-configmap-pnhf container test-container-subpath-configmap-pnhf: <nil>
STEP: delete the pod
Jan 15 15:30:23.657: INFO: Waiting for pod pod-subpath-test-configmap-pnhf to disappear
Jan 15 15:30:23.660: INFO: Pod pod-subpath-test-configmap-pnhf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pnhf
Jan 15 15:30:23.660: INFO: Deleting pod "pod-subpath-test-configmap-pnhf" in namespace "e2e-tests-subpath-tj59f"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:30:23.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tj59f" for this suite.
Jan 15 15:30:29.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:30:29.753: INFO: namespace: e2e-tests-subpath-tj59f, resource: bindings, ignored listing per whitelist
Jan 15 15:30:29.763: INFO: namespace e2e-tests-subpath-tj59f deletion completed in 6.096569094s

 [SLOW TEST:30.261 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:30:29.763: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:30:29.804: INFO: Creating deployment "nginx-deployment"
Jan 15 15:30:29.811: INFO: Waiting for observed generation 1
Jan 15 15:30:31.817: INFO: Waiting for all required pods to come up
Jan 15 15:30:31.821: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 15 15:30:33.830: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 15 15:30:33.837: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 15 15:30:33.846: INFO: Updating deployment nginx-deployment
Jan 15 15:30:33.846: INFO: Waiting for observed generation 2
Jan 15 15:30:35.861: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 15 15:30:35.864: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 15 15:30:35.867: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 15 15:30:35.877: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 15 15:30:35.877: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 15 15:30:35.881: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 15 15:30:35.888: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 15 15:30:35.888: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 15 15:30:35.895: INFO: Updating deployment nginx-deployment
Jan 15 15:30:35.895: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 15 15:30:35.904: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 15 15:30:37.918: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 15:30:37.924: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k4tsw/deployments/nginx-deployment,UID:7d71b13b-18da-11e9-a8cf-02ce79272a22,ResourceVersion:201840,Generation:3,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-01-15 15:30:35 +0000 UTC 2019-01-15 15:30:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-15 15:30:35 +0000 UTC 2019-01-15 15:30:29 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-658cb79bc5" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 15 15:30:37.927: INFO: New ReplicaSet "nginx-deployment-658cb79bc5" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5,GenerateName:,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k4tsw/replicasets/nginx-deployment-658cb79bc5,UID:7fda204c-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201835,Generation:3,CreationTimestamp:2019-01-15 15:30:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 7d71b13b-18da-11e9-a8cf-02ce79272a22 0xc001381f97 0xc001381f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 2147635671,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 15:30:37.927: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 15 15:30:37.927: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956,GenerateName:,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k4tsw/replicasets/nginx-deployment-6554478956,UID:7d72dbd4-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201838,Generation:3,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 7d71b13b-18da-11e9-a8cf-02ce79272a22 0xc001381ed7 0xc001381ed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 2110034512,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-2ngq8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-2ngq8,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-2ngq8,UID:7d75986f-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201714,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc001c7fb17 0xc001c7fb18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c7fb80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c7fba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:100.100.156.255,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://86d55ac6972cbf3c789e5d8ab35b6f36a177d0606fbe4e154daf0bf3f07d4e7b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-2r6kj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-2r6kj,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-2r6kj,UID:81157322-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201842,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc001c7fc67 0xc001c7fc68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c7fdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c7fdd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-525q7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-525q7,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-525q7,UID:7d75982e-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201708,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc001c7fe87 0xc001c7fe88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c7fef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c7ff10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:100.100.156.197,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://46d68c5b87d7e97f849950effa3c921259382a0ccc2a3d7a59b290b36d0af369}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-5mh2t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-5mh2t,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-5mh2t,UID:81139340-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201827,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc001c7fff7 0xc001c7fff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025260a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-8h8kn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-8h8kn,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-8h8kn,UID:811577d2-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201845,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526157 0xc002526158}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025261c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025261e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-c572n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-c572n,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-c572n,UID:8115797a-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201824,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526447 0xc002526448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025264b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025264d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-dbnpp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-dbnpp,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-dbnpp,UID:7d759360-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201689,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526540 0xc002526541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:100.115.205.185,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://6517c0cc04e06512feea79530ce45e1db584c84f6eb7a1112ae08e7588252e17}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-jvzsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-jvzsx,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-jvzsx,UID:81155679-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201841,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526747 0xc002526748}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025267b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025267d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-kqm8c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-kqm8c,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-kqm8c,UID:7d758ec9-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201702,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526887 0xc002526888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:100.107.48.21,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cd5d78de499e446936a9f0cc2ed5bb2829a0775631269b2438acfb9f4b918413}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.932: INFO: Pod "nginx-deployment-6554478956-ncjch" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-ncjch,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-ncjch,UID:7d74480a-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201719,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc0025269e7 0xc0025269e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:100.100.156.254,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://db0221c5cc58ea18b13d431b0a2f493ff7f9a1faf9c2221ef1749659cc646178}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-nz99b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-nz99b,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-nz99b,UID:7d768369-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201705,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526b37 0xc002526b38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:100.107.48.22,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://eafabed90cae9a01a02a39ff45c52c614a69852fb7e6a20f08f18fb24e98d75b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-ppjxd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-ppjxd,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-ppjxd,UID:81144268-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201846,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526c87 0xc002526c88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-qjkzh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-qjkzh,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-qjkzh,UID:8116e757-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201826,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526dc7 0xc002526dc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-qk4ch" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-qk4ch,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-qk4ch,UID:8116f8fa-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201830,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526ec0 0xc002526ec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002526f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002526f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-qzmsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-qzmsx,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-qzmsx,UID:8116fc2e-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201877,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002526fb0 0xc002526fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-r57v6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-r57v6,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-r57v6,UID:8116f717-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201851,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc0025270e7 0xc0025270e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-rd6hs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-rd6hs,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-rd6hs,UID:7d74e438-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201693,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002527227 0xc002527228}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025272b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:100.115.205.183,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://28e4b905418d814700a9d3efa108831f819a1d59627b6469b959dec1b0e8584e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-t68mp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-t68mp,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-t68mp,UID:811435a7-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201839,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002527387 0xc002527388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025273f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-xldb9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-xldb9,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-xldb9,UID:7d767c35-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201686,Generation:0,CreationTimestamp:2019-01-15 15:30:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc0025274c7 0xc0025274c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:29 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:100.115.205.184,StartTime:2019-01-15 15:30:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:30:30 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://568df97f3cd5be26bb4367c73fc1e142804acc00ee95a07b77af0e9a6e9c2b18}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-6554478956-xm7s6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6554478956-xm7s6,GenerateName:nginx-deployment-6554478956-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-6554478956-xm7s6,UID:8116eaa2-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201825,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2110034512,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6554478956 7d72dbd4-18da-11e9-8532-0a00a28bbe76 0xc002527647 0xc002527648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025276c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025276e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.933: INFO: Pod "nginx-deployment-658cb79bc5-2hb27" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-2hb27,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-2hb27,UID:7fdfb0f0-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201782,Generation:0,CreationTimestamp:2019-01-15 15:30:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc002527750 0xc002527751}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025277c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025277e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:,StartTime:2019-01-15 15:30:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-7qh7w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-7qh7w,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-7qh7w,UID:7fdef850-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201799,Generation:0,CreationTimestamp:2019-01-15 15:30:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc0025278c0 0xc0025278c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:100.115.205.187,StartTime:2019-01-15 15:30:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-9bcb9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-9bcb9,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-9bcb9,UID:8115bfac-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201844,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc002527a60 0xc002527a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-b2jl5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-b2jl5,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-b2jl5,UID:7fdb5c46-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201777,Generation:0,CreationTimestamp:2019-01-15 15:30:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc002527da0 0xc002527da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002527e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002527e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:,StartTime:2019-01-15 15:30:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-b7hq9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-b7hq9,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-b7hq9,UID:81141c6c-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201843,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224c2c0 0xc00224c2c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224c470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224c490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-dctpw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-dctpw,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-dctpw,UID:7fdaabba-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201773,Generation:0,CreationTimestamp:2019-01-15 15:30:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224c5d0 0xc00224c5d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224c640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224ca60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:100.115.205.186,StartTime:2019-01-15 15:30:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-jtb7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-jtb7n,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-jtb7n,UID:8115b209-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201852,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224cdf0 0xc00224cdf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224ce60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224ce80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-k44bw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-k44bw,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-k44bw,UID:8115c0ad-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201879,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224d000 0xc00224d001}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-knjld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-knjld,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-knjld,UID:81173de2-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201833,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224d1f0 0xc00224d1f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-ll5r6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-ll5r6,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-ll5r6,UID:8115c2a6-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201823,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224d370 0xc00224d371}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d3e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-p4jlk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-p4jlk,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-p4jlk,UID:8114cc21-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201854,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224d470 0xc00224d471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-87-161.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.87.161,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-s7hlx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-s7hlx,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-s7hlx,UID:8114c313-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201837,Generation:0,CreationTimestamp:2019-01-15 15:30:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224d640 0xc00224d641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d6b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d6d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:35 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:,StartTime:2019-01-15 15:30:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 15:30:37.934: INFO: Pod "nginx-deployment-658cb79bc5-zlznz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-658cb79bc5-zlznz,GenerateName:nginx-deployment-658cb79bc5-,Namespace:e2e-tests-deployment-k4tsw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k4tsw/pods/nginx-deployment-658cb79bc5-zlznz,UID:7fdb53d6-18da-11e9-8532-0a00a28bbe76,ResourceVersion:201781,Generation:0,CreationTimestamp:2019-01-15 15:30:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 2147635671,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-658cb79bc5 7fda204c-18da-11e9-8532-0a00a28bbe76 0xc00224d840 0xc00224d841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t6m9n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t6m9n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t6m9n true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:30:33 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:,StartTime:2019-01-15 15:30:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:30:37.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-k4tsw" for this suite.
Jan 15 15:30:43.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:30:44.001: INFO: namespace: e2e-tests-deployment-k4tsw, resource: bindings, ignored listing per whitelist
Jan 15 15:30:44.033: INFO: namespace e2e-tests-deployment-k4tsw deletion completed in 6.094649202s

 [SLOW TEST:14.269 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:30:44.033: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 15 15:30:52.116: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:30:52.119: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:30:54.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:30:54.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:30:56.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:30:56.130: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:30:58.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:30:58.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:00.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:00.123: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:02.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:02.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:04.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:04.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:06.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:06.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:08.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:08.129: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:10.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:10.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:12.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:12.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:14.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:14.122: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:16.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:16.123: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 15:31:18.119: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 15:31:18.123: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:31:18.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-46ksc" for this suite.
Jan 15 15:31:40.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:31:40.205: INFO: namespace: e2e-tests-container-lifecycle-hook-46ksc, resource: bindings, ignored listing per whitelist
Jan 15 15:31:40.260: INFO: namespace e2e-tests-container-lifecycle-hook-46ksc deletion completed in 22.117278247s

 [SLOW TEST:56.227 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:31:40.260: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a776d2f7-18da-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:31:40.317: INFO: Waiting up to 5m0s for pod "pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-2t65m" to be "success or failure"
Jan 15 15:31:40.321: INFO: Pod "pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.591087ms
Jan 15 15:31:42.325: INFO: Pod "pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008739124s
STEP: Saw pod success
Jan 15 15:31:42.326: INFO: Pod "pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:31:42.329: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:31:42.351: INFO: Waiting for pod pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:31:42.356: INFO: Pod pod-configmaps-a777d664-18da-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:31:42.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2t65m" for this suite.
Jan 15 15:31:48.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:31:48.402: INFO: namespace: e2e-tests-configmap-2t65m, resource: bindings, ignored listing per whitelist
Jan 15 15:31:48.458: INFO: namespace e2e-tests-configmap-2t65m deletion completed in 6.098030293s

 [SLOW TEST:8.198 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:31:48.458: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-ac58e44c-18da-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:31:48.509: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-v8lqs" to be "success or failure"
Jan 15 15:31:48.513: INFO: Pod "pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043214ms
Jan 15 15:31:50.522: INFO: Pod "pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013208422s
STEP: Saw pod success
Jan 15 15:31:50.522: INFO: Pod "pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:31:50.525: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:31:50.546: INFO: Waiting for pod pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:31:50.548: INFO: Pod pod-projected-secrets-ac59ec76-18da-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:31:50.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v8lqs" for this suite.
Jan 15 15:31:56.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:31:56.640: INFO: namespace: e2e-tests-projected-v8lqs, resource: bindings, ignored listing per whitelist
Jan 15 15:31:56.648: INFO: namespace e2e-tests-projected-v8lqs deletion completed in 6.095923829s

 [SLOW TEST:8.190 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:31:56.648: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 15 15:31:56.699: INFO: Waiting up to 5m0s for pod "pod-b13b457b-18da-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-ghgn8" to be "success or failure"
Jan 15 15:31:56.703: INFO: Pod "pod-b13b457b-18da-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.64007ms
Jan 15 15:31:58.707: INFO: Pod "pod-b13b457b-18da-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007550304s
STEP: Saw pod success
Jan 15 15:31:58.707: INFO: Pod "pod-b13b457b-18da-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:31:58.710: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-b13b457b-18da-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:31:58.734: INFO: Waiting for pod pod-b13b457b-18da-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:31:58.737: INFO: Pod pod-b13b457b-18da-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:31:58.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ghgn8" for this suite.
Jan 15 15:32:04.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:32:04.786: INFO: namespace: e2e-tests-emptydir-ghgn8, resource: bindings, ignored listing per whitelist
Jan 15 15:32:04.849: INFO: namespace e2e-tests-emptydir-ghgn8 deletion completed in 6.107169759s

 [SLOW TEST:8.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:32:04.849: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:32:04.900: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 15 15:32:09.903: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 15:32:09.903: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 15:32:09.920: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-hk56q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hk56q/deployments/test-cleanup-deployment,UID:b91c2559-18da-11e9-a8cf-02ce79272a22,ResourceVersion:202488,Generation:1,CreationTimestamp:2019-01-15 15:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 15 15:32:09.924: INFO: New ReplicaSet "test-cleanup-deployment-d69d8ff79" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-d69d8ff79,GenerateName:,Namespace:e2e-tests-deployment-hk56q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hk56q/replicasets/test-cleanup-deployment-d69d8ff79,UID:b91ddb50-18da-11e9-8532-0a00a28bbe76,ResourceVersion:202490,Generation:1,CreationTimestamp:2019-01-15 15:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 825849935,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b91c2559-18da-11e9-a8cf-02ce79272a22 0xc001e6fbb0 0xc001e6fbb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 825849935,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 825849935,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 15:32:09.924: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 15 15:32:09.925: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-hk56q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hk56q/replicasets/test-cleanup-controller,UID:b61e8f89-18da-11e9-a8cf-02ce79272a22,ResourceVersion:202489,Generation:1,CreationTimestamp:2019-01-15 15:32:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b91c2559-18da-11e9-a8cf-02ce79272a22 0xc001e6faf7 0xc001e6faf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 15:32:09.931: INFO: Pod "test-cleanup-controller-dqtql" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-dqtql,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-hk56q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hk56q/pods/test-cleanup-controller-dqtql,UID:b6201e53-18da-11e9-8532-0a00a28bbe76,ResourceVersion:202475,Generation:0,CreationTimestamp:2019-01-15 15:32:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller b61e8f89-18da-11e9-a8cf-02ce79272a22 0xc001404dd7 0xc001404dd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-p2fnf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p2fnf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p2fnf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-62-130.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001404e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001404e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:32:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:32:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:32:04 +0000 UTC  }],Message:,Reason:,HostIP:172.24.62.130,PodIP:100.115.205.138,StartTime:2019-01-15 15:32:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 15:32:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cd37dee4c211661d770a2283c30a3b26314c937fc62bc924b5a2cad9e4f1a720}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:32:09.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hk56q" for this suite.
Jan 15 15:32:15.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:32:16.001: INFO: namespace: e2e-tests-deployment-hk56q, resource: bindings, ignored listing per whitelist
Jan 15 15:32:16.047: INFO: namespace e2e-tests-deployment-hk56q deletion completed in 6.111151576s

 [SLOW TEST:11.198 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:32:16.047: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-bccb9e39-18da-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:32:16.105: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-6fvmh" to be "success or failure"
Jan 15 15:32:16.109: INFO: Pod "pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110201ms
Jan 15 15:32:18.113: INFO: Pod "pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007945886s
STEP: Saw pod success
Jan 15 15:32:18.113: INFO: Pod "pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:32:18.116: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:32:18.137: INFO: Waiting for pod pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:32:18.139: INFO: Pod pod-projected-configmaps-bcccc150-18da-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:32:18.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fvmh" for this suite.
Jan 15 15:32:24.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:32:24.229: INFO: namespace: e2e-tests-projected-6fvmh, resource: bindings, ignored listing per whitelist
Jan 15 15:32:24.240: INFO: namespace e2e-tests-projected-6fvmh deletion completed in 6.096881311s

 [SLOW TEST:8.193 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:32:24.240: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 15 15:32:26.301: INFO: Pod pod-hostip-c1ad0919-18da-11e9-9d2c-c274f07984f4 has hostIP: 172.24.62.130
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:32:26.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-55gq4" for this suite.
Jan 15 15:32:48.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:32:48.353: INFO: namespace: e2e-tests-pods-55gq4, resource: bindings, ignored listing per whitelist
Jan 15 15:32:48.420: INFO: namespace e2e-tests-pods-55gq4 deletion completed in 22.114599829s

 [SLOW TEST:24.180 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:32:48.420: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 15 15:32:48.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:48.745: INFO: stderr: ""
Jan 15 15:32:48.745: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 15:32:48.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:48.806: INFO: stderr: ""
Jan 15 15:32:48.806: INFO: stdout: "update-demo-nautilus-g9mhm update-demo-nautilus-r6g2s "
Jan 15 15:32:48.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-g9mhm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:48.861: INFO: stderr: ""
Jan 15 15:32:48.861: INFO: stdout: ""
Jan 15 15:32:48.861: INFO: update-demo-nautilus-g9mhm is created but not running
Jan 15 15:32:53.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:53.925: INFO: stderr: ""
Jan 15 15:32:53.925: INFO: stdout: "update-demo-nautilus-g9mhm update-demo-nautilus-r6g2s "
Jan 15 15:32:53.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-g9mhm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:53.980: INFO: stderr: ""
Jan 15 15:32:53.980: INFO: stdout: "true"
Jan 15 15:32:53.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-g9mhm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:54.037: INFO: stderr: ""
Jan 15 15:32:54.037: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 15:32:54.037: INFO: validating pod update-demo-nautilus-g9mhm
Jan 15 15:32:54.044: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 15:32:54.044: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 15:32:54.044: INFO: update-demo-nautilus-g9mhm is verified up and running
Jan 15 15:32:54.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-r6g2s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:54.104: INFO: stderr: ""
Jan 15 15:32:54.104: INFO: stdout: "true"
Jan 15 15:32:54.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods update-demo-nautilus-r6g2s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:54.162: INFO: stderr: ""
Jan 15 15:32:54.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 15:32:54.162: INFO: validating pod update-demo-nautilus-r6g2s
Jan 15 15:32:54.166: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 15:32:54.166: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 15:32:54.166: INFO: update-demo-nautilus-r6g2s is verified up and running
STEP: using delete to clean up resources
Jan 15 15:32:54.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:54.228: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:32:54.228: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 15 15:32:54.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-5vqr5'
Jan 15 15:32:54.290: INFO: stderr: "No resources found.\n"
Jan 15 15:32:54.290: INFO: stdout: ""
Jan 15 15:32:54.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -l name=update-demo --namespace=e2e-tests-kubectl-5vqr5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 15:32:54.357: INFO: stderr: ""
Jan 15 15:32:54.357: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:32:54.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5vqr5" for this suite.
Jan 15 15:33:00.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:33:00.435: INFO: namespace: e2e-tests-kubectl-5vqr5, resource: bindings, ignored listing per whitelist
Jan 15 15:33:00.456: INFO: namespace e2e-tests-kubectl-5vqr5 deletion completed in 6.094927148s

 [SLOW TEST:12.036 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:33:00.456: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0115 15:33:31.040925      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 15:33:31.040: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:33:31.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zk8mc" for this suite.
Jan 15 15:33:37.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:33:37.063: INFO: namespace: e2e-tests-gc-zk8mc, resource: bindings, ignored listing per whitelist
Jan 15 15:33:37.141: INFO: namespace e2e-tests-gc-zk8mc deletion completed in 6.096678952s

 [SLOW TEST:36.685 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:33:37.141: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 15 15:33:37.182: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-889858361 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:33:37.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8j5f7" for this suite.
Jan 15 15:33:43.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:33:43.260: INFO: namespace: e2e-tests-kubectl-8j5f7, resource: bindings, ignored listing per whitelist
Jan 15 15:33:43.348: INFO: namespace e2e-tests-kubectl-8j5f7 deletion completed in 6.109850302s

 [SLOW TEST:6.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:33:43.348: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jan 15 15:33:50.421: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:33:51.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-vrhhz" for this suite.
Jan 15 15:34:13.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:34:13.499: INFO: namespace: e2e-tests-replicaset-vrhhz, resource: bindings, ignored listing per whitelist
Jan 15 15:34:13.552: INFO: namespace e2e-tests-replicaset-vrhhz deletion completed in 22.106654796s

 [SLOW TEST:30.203 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:34:13.552: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 15 15:34:17.644: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 15:34:17.648: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 15:34:19.648: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 15:34:19.652: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 15:34:21.648: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 15:34:21.651: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:34:21.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9wv8q" for this suite.
Jan 15 15:34:43.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:34:43.676: INFO: namespace: e2e-tests-container-lifecycle-hook-9wv8q, resource: bindings, ignored listing per whitelist
Jan 15 15:34:43.753: INFO: namespace e2e-tests-container-lifecycle-hook-9wv8q deletion completed in 22.097718778s

 [SLOW TEST:30.201 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:34:43.753: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 15:34:43.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-smzmk'
Jan 15 15:34:43.863: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 15:34:43.863: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jan 15 15:34:43.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-smzmk'
Jan 15 15:34:43.934: INFO: stderr: ""
Jan 15 15:34:43.934: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:34:43.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-smzmk" for this suite.
Jan 15 15:34:49.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:34:50.013: INFO: namespace: e2e-tests-kubectl-smzmk, resource: bindings, ignored listing per whitelist
Jan 15 15:34:50.034: INFO: namespace e2e-tests-kubectl-smzmk deletion completed in 6.09585096s

 [SLOW TEST:6.282 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:34:50.034: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-k6lgg/configmap-test-18933f83-18db-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:34:50.086: INFO: Waiting up to 5m0s for pod "pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-k6lgg" to be "success or failure"
Jan 15 15:34:50.089: INFO: Pod "pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109065ms
Jan 15 15:34:52.093: INFO: Pod "pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006899617s
STEP: Saw pod success
Jan 15 15:34:52.093: INFO: Pod "pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:34:52.096: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4 container env-test: <nil>
STEP: delete the pod
Jan 15 15:34:52.119: INFO: Waiting for pod pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:34:52.122: INFO: Pod pod-configmaps-18944718-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:34:52.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k6lgg" for this suite.
Jan 15 15:34:58.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:34:58.226: INFO: namespace: e2e-tests-configmap-k6lgg, resource: bindings, ignored listing per whitelist
Jan 15 15:34:58.228: INFO: namespace e2e-tests-configmap-k6lgg deletion completed in 6.101830238s

 [SLOW TEST:8.194 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:34:58.229: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 15 15:34:58.271: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-889858361 proxy --unix-socket=/tmp/kubectl-proxy-unix850278724/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:34:58.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cb645" for this suite.
Jan 15 15:35:04.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:35:04.407: INFO: namespace: e2e-tests-kubectl-cb645, resource: bindings, ignored listing per whitelist
Jan 15 15:35:04.418: INFO: namespace e2e-tests-kubectl-cb645 deletion completed in 6.098775603s

 [SLOW TEST:6.189 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:35:04.418: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 15 15:35:06.992: INFO: Successfully updated pod "pod-update-activedeadlineseconds-21261ca9-18db-11e9-9d2c-c274f07984f4"
Jan 15 15:35:06.992: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-21261ca9-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-pods-5dhq8" to be "terminated due to deadline exceeded"
Jan 15 15:35:06.995: INFO: Pod "pod-update-activedeadlineseconds-21261ca9-18db-11e9-9d2c-c274f07984f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.853199ms
Jan 15 15:35:08.999: INFO: Pod "pod-update-activedeadlineseconds-21261ca9-18db-11e9-9d2c-c274f07984f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006289615s
Jan 15 15:35:11.002: INFO: Pod "pod-update-activedeadlineseconds-21261ca9-18db-11e9-9d2c-c274f07984f4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009838995s
Jan 15 15:35:11.002: INFO: Pod "pod-update-activedeadlineseconds-21261ca9-18db-11e9-9d2c-c274f07984f4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:35:11.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5dhq8" for this suite.
Jan 15 15:35:17.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:35:17.103: INFO: namespace: e2e-tests-pods-5dhq8, resource: bindings, ignored listing per whitelist
Jan 15 15:35:17.111: INFO: namespace e2e-tests-pods-5dhq8 deletion completed in 6.104589609s

 [SLOW TEST:12.693 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:35:17.111: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:35:41.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-gsr9k" for this suite.
Jan 15 15:35:47.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:35:47.461: INFO: namespace: e2e-tests-container-runtime-gsr9k, resource: bindings, ignored listing per whitelist
Jan 15 15:35:47.482: INFO: namespace e2e-tests-container-runtime-gsr9k deletion completed in 6.117821686s

 [SLOW TEST:30.372 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:35:47.483: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:35:49.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vhh9w" for this suite.
Jan 15 15:36:39.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:36:39.633: INFO: namespace: e2e-tests-kubelet-test-vhh9w, resource: bindings, ignored listing per whitelist
Jan 15 15:36:39.660: INFO: namespace e2e-tests-kubelet-test-vhh9w deletion completed in 50.10006841s

 [SLOW TEST:52.177 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:36:39.660: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 15 15:36:39.711: INFO: Waiting up to 5m0s for pod "pod-59eb79ab-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-chgq4" to be "success or failure"
Jan 15 15:36:39.715: INFO: Pod "pod-59eb79ab-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.553496ms
Jan 15 15:36:41.719: INFO: Pod "pod-59eb79ab-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007073372s
STEP: Saw pod success
Jan 15 15:36:41.719: INFO: Pod "pod-59eb79ab-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:36:41.721: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-59eb79ab-18db-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:36:41.742: INFO: Waiting for pod pod-59eb79ab-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:36:41.744: INFO: Pod pod-59eb79ab-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:36:41.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-chgq4" for this suite.
Jan 15 15:36:47.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:36:47.811: INFO: namespace: e2e-tests-emptydir-chgq4, resource: bindings, ignored listing per whitelist
Jan 15 15:36:47.857: INFO: namespace e2e-tests-emptydir-chgq4 deletion completed in 6.107869671s

 [SLOW TEST:8.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:36:47.857: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 15 15:36:47.907: INFO: Waiting up to 5m0s for pod "client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-containers-jl4vs" to be "success or failure"
Jan 15 15:36:47.910: INFO: Pod "client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.009372ms
Jan 15 15:36:49.914: INFO: Pod "client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006476267s
STEP: Saw pod success
Jan 15 15:36:49.914: INFO: Pod "client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:36:49.917: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:36:49.938: INFO: Waiting for pod client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:36:49.940: INFO: Pod client-containers-5ecdf26f-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:36:49.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jl4vs" for this suite.
Jan 15 15:36:55.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:36:55.982: INFO: namespace: e2e-tests-containers-jl4vs, resource: bindings, ignored listing per whitelist
Jan 15 15:36:56.054: INFO: namespace e2e-tests-containers-jl4vs deletion completed in 6.110275314s

 [SLOW TEST:8.197 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:36:56.054: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:36:56.124: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"63b3fa33-18db-11e9-a8cf-02ce79272a22", Controller:(*bool)(0xc0026d57b2), BlockOwnerDeletion:(*bool)(0xc0026d57b3)}}
Jan 15 15:36:56.129: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"63b240d7-18db-11e9-a8cf-02ce79272a22", Controller:(*bool)(0xc002919a0a), BlockOwnerDeletion:(*bool)(0xc002919a0b)}}
Jan 15 15:36:56.134: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"63b3577d-18db-11e9-a8cf-02ce79272a22", Controller:(*bool)(0xc0027d2362), BlockOwnerDeletion:(*bool)(0xc0027d2363)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:01.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h78t6" for this suite.
Jan 15 15:37:07.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:37:07.229: INFO: namespace: e2e-tests-gc-h78t6, resource: bindings, ignored listing per whitelist
Jan 15 15:37:07.247: INFO: namespace e2e-tests-gc-h78t6 deletion completed in 6.098261444s

 [SLOW TEST:11.193 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:37:07.248: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:37:07.296: INFO: (0) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.449031ms)
Jan 15 15:37:07.300: INFO: (1) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.171877ms)
Jan 15 15:37:07.304: INFO: (2) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.194499ms)
Jan 15 15:37:07.309: INFO: (3) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.543374ms)
Jan 15 15:37:07.313: INFO: (4) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.097288ms)
Jan 15 15:37:07.318: INFO: (5) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.464182ms)
Jan 15 15:37:07.323: INFO: (6) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.233476ms)
Jan 15 15:37:07.327: INFO: (7) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.202363ms)
Jan 15 15:37:07.331: INFO: (8) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.12142ms)
Jan 15 15:37:07.335: INFO: (9) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.166733ms)
Jan 15 15:37:07.339: INFO: (10) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.038482ms)
Jan 15 15:37:07.344: INFO: (11) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.439953ms)
Jan 15 15:37:07.348: INFO: (12) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.134811ms)
Jan 15 15:37:07.352: INFO: (13) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.07725ms)
Jan 15 15:37:07.356: INFO: (14) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.094294ms)
Jan 15 15:37:07.361: INFO: (15) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.423142ms)
Jan 15 15:37:07.365: INFO: (16) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.09229ms)
Jan 15 15:37:07.369: INFO: (17) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.324002ms)
Jan 15 15:37:07.374: INFO: (18) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.522067ms)
Jan 15 15:37:07.379: INFO: (19) /api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.012741ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:07.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-qlfss" for this suite.
Jan 15 15:37:13.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:37:13.475: INFO: namespace: e2e-tests-proxy-qlfss, resource: bindings, ignored listing per whitelist
Jan 15 15:37:13.489: INFO: namespace e2e-tests-proxy-qlfss deletion completed in 6.106991416s

 [SLOW TEST:6.241 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:37:13.489: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0115 15:37:19.568194      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 15:37:19.568: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:19.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cpsk9" for this suite.
Jan 15 15:37:25.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:37:25.630: INFO: namespace: e2e-tests-gc-cpsk9, resource: bindings, ignored listing per whitelist
Jan 15 15:37:25.680: INFO: namespace e2e-tests-gc-cpsk9 deletion completed in 6.108482405s

 [SLOW TEST:12.191 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:37:25.680: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:37:25.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 version'
Jan 15 15:37:25.778: INFO: stderr: ""
Jan 15 15:37:25.778: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.6\", GitCommit:\"b1d75deca493a24a2f87eb1efde1a569e52fc8d9\", GitTreeState:\"clean\", BuildDate:\"2018-12-16T04:30:10Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:25.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g6lwq" for this suite.
Jan 15 15:37:31.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:37:31.861: INFO: namespace: e2e-tests-kubectl-g6lwq, resource: bindings, ignored listing per whitelist
Jan 15 15:37:31.877: INFO: namespace e2e-tests-kubectl-g6lwq deletion completed in 6.095378812s

 [SLOW TEST:6.197 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:37:31.877: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 15 15:37:31.924: INFO: Waiting up to 5m0s for pod "var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-var-expansion-8kv4d" to be "success or failure"
Jan 15 15:37:31.928: INFO: Pod "var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.304378ms
Jan 15 15:37:33.931: INFO: Pod "var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007706518s
STEP: Saw pod success
Jan 15 15:37:33.931: INFO: Pod "var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:37:33.934: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 15:37:33.955: INFO: Waiting for pod var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:37:33.958: INFO: Pod var-expansion-790a8470-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:33.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-8kv4d" for this suite.
Jan 15 15:37:39.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:37:39.992: INFO: namespace: e2e-tests-var-expansion-8kv4d, resource: bindings, ignored listing per whitelist
Jan 15 15:37:40.065: INFO: namespace e2e-tests-var-expansion-8kv4d deletion completed in 6.103796328s

 [SLOW TEST:8.188 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:37:40.065: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 15:37:40.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pwqxh'
Jan 15 15:37:40.183: INFO: stderr: ""
Jan 15 15:37:40.183: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 15 15:37:45.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pwqxh -o json'
Jan 15 15:37:45.301: INFO: stderr: ""
Jan 15 15:37:45.301: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-15T15:37:40Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-pwqxh\",\n        \"resourceVersion\": \"203935\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-pwqxh/pods/e2e-test-nginx-pod\",\n        \"uid\": \"7df6161b-18db-11e9-9f92-067e9883fa18\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xdc95\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-172-24-87-161.us-east-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xdc95\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xdc95\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T15:37:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T15:37:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T15:37:40Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://32ec64f7f3dbd070b7f51bd675ce282f5d83eeccc36d003ba4ec6145d3857979\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-15T15:37:41Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.24.87.161\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.100.156.223\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-15T15:37:40Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 15 15:37:45.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 replace -f - --namespace=e2e-tests-kubectl-pwqxh'
Jan 15 15:37:45.430: INFO: stderr: ""
Jan 15 15:37:45.430: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jan 15 15:37:45.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pwqxh'
Jan 15 15:37:47.269: INFO: stderr: ""
Jan 15 15:37:47.269: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:47.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pwqxh" for this suite.
Jan 15 15:37:53.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:37:53.357: INFO: namespace: e2e-tests-kubectl-pwqxh, resource: bindings, ignored listing per whitelist
Jan 15 15:37:53.386: INFO: namespace e2e-tests-kubectl-pwqxh deletion completed in 6.111535492s

 [SLOW TEST:13.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:37:53.386: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-85ddb803-18db-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:37:53.446: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-7smwz" to be "success or failure"
Jan 15 15:37:53.450: INFO: Pod "pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.8266ms
Jan 15 15:37:55.453: INFO: Pod "pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006926967s
STEP: Saw pod success
Jan 15 15:37:55.453: INFO: Pod "pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:37:55.456: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:37:55.476: INFO: Waiting for pod pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:37:55.478: INFO: Pod pod-projected-configmaps-85decd42-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:37:55.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7smwz" for this suite.
Jan 15 15:38:01.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:38:01.578: INFO: namespace: e2e-tests-projected-7smwz, resource: bindings, ignored listing per whitelist
Jan 15 15:38:01.584: INFO: namespace e2e-tests-projected-7smwz deletion completed in 6.10250586s

 [SLOW TEST:8.198 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:38:01.584: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 15:38:04.165: INFO: Successfully updated pod "annotationupdate8abf9289-18db-11e9-9d2c-c274f07984f4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:38:06.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7zwhf" for this suite.
Jan 15 15:38:28.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:38:28.265: INFO: namespace: e2e-tests-downward-api-7zwhf, resource: bindings, ignored listing per whitelist
Jan 15 15:38:28.289: INFO: namespace e2e-tests-downward-api-7zwhf deletion completed in 22.100016875s

 [SLOW TEST:26.704 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:38:28.289: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 15 15:38:28.328: INFO: namespace e2e-tests-kubectl-zp2vq
Jan 15 15:38:28.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-zp2vq'
Jan 15 15:38:28.456: INFO: stderr: ""
Jan 15 15:38:28.456: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 15:38:29.459: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 15:38:29.459: INFO: Found 0 / 1
Jan 15 15:38:30.460: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 15:38:30.460: INFO: Found 1 / 1
Jan 15 15:38:30.460: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 15:38:30.462: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 15:38:30.462: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 15:38:30.462: INFO: wait on redis-master startup in e2e-tests-kubectl-zp2vq 
Jan 15 15:38:30.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 logs redis-master-xdh44 redis-master --namespace=e2e-tests-kubectl-zp2vq'
Jan 15 15:38:30.530: INFO: stderr: ""
Jan 15 15:38:30.530: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 15:38:29.263 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 15:38:29.263 # Server started, Redis version 3.2.12\n1:M 15 Jan 15:38:29.263 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 15:38:29.263 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 15 15:38:30.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-zp2vq'
Jan 15 15:38:30.607: INFO: stderr: ""
Jan 15 15:38:30.607: INFO: stdout: "service/rm2 exposed\n"
Jan 15 15:38:30.612: INFO: Service rm2 in namespace e2e-tests-kubectl-zp2vq found.
STEP: exposing service
Jan 15 15:38:32.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-zp2vq'
Jan 15 15:38:32.693: INFO: stderr: ""
Jan 15 15:38:32.693: INFO: stdout: "service/rm3 exposed\n"
Jan 15 15:38:32.696: INFO: Service rm3 in namespace e2e-tests-kubectl-zp2vq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:38:34.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zp2vq" for this suite.
Jan 15 15:38:56.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:38:56.795: INFO: namespace: e2e-tests-kubectl-zp2vq, resource: bindings, ignored listing per whitelist
Jan 15 15:38:56.813: INFO: namespace e2e-tests-kubectl-zp2vq deletion completed in 22.101773429s

 [SLOW TEST:28.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:38:56.813: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:38:58.892: INFO: Waiting up to 5m0s for pod "client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-pods-pmk84" to be "success or failure"
Jan 15 15:38:58.895: INFO: Pod "client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.349682ms
Jan 15 15:39:00.899: INFO: Pod "client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007020511s
STEP: Saw pod success
Jan 15 15:39:00.899: INFO: Pod "client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:39:00.902: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4 container env3cont: <nil>
STEP: delete the pod
Jan 15 15:39:00.923: INFO: Waiting for pod client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:39:00.926: INFO: Pod client-envvars-ace18853-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:39:00.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pmk84" for this suite.
Jan 15 15:39:50.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:39:51.020: INFO: namespace: e2e-tests-pods-pmk84, resource: bindings, ignored listing per whitelist
Jan 15 15:39:51.028: INFO: namespace e2e-tests-pods-pmk84 deletion completed in 50.098391433s

 [SLOW TEST:54.215 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:39:51.028: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:39:51.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xxvm6" for this suite.
Jan 15 15:40:13.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:40:13.191: INFO: namespace: e2e-tests-pods-xxvm6, resource: bindings, ignored listing per whitelist
Jan 15 15:40:13.194: INFO: namespace e2e-tests-pods-xxvm6 deletion completed in 22.109440969s

 [SLOW TEST:22.167 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:40:13.194: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:40:13.258: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jan 15 15:40:13.265: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bzvqb/daemonsets","resourceVersion":"204443"},"items":null}

Jan 15 15:40:13.267: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bzvqb/pods","resourceVersion":"204443"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:40:13.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bzvqb" for this suite.
Jan 15 15:40:19.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:40:19.376: INFO: namespace: e2e-tests-daemonsets-bzvqb, resource: bindings, ignored listing per whitelist
Jan 15 15:40:19.392: INFO: namespace e2e-tests-daemonsets-bzvqb deletion completed in 6.10969598s

S [SKIPPING] [6.198 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 15 15:40:13.258: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:40:19.393: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-dce485ad-18db-11e9-9d2c-c274f07984f4
STEP: Creating secret with name s-test-opt-upd-dce485f9-18db-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dce485ad-18db-11e9-9d2c-c274f07984f4
STEP: Updating secret s-test-opt-upd-dce485f9-18db-11e9-9d2c-c274f07984f4
STEP: Creating secret with name s-test-opt-create-dce48612-18db-11e9-9d2c-c274f07984f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:40:23.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fwnqb" for this suite.
Jan 15 15:40:45.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:40:45.600: INFO: namespace: e2e-tests-projected-fwnqb, resource: bindings, ignored listing per whitelist
Jan 15 15:40:45.645: INFO: namespace e2e-tests-projected-fwnqb deletion completed in 22.096928156s

 [SLOW TEST:26.252 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:40:45.645: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 15:40:45.685: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:40:49.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7l8ns" for this suite.
Jan 15 15:40:55.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:40:55.299: INFO: namespace: e2e-tests-init-container-7l8ns, resource: bindings, ignored listing per whitelist
Jan 15 15:40:55.379: INFO: namespace e2e-tests-init-container-7l8ns deletion completed in 6.09657533s

 [SLOW TEST:9.735 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:40:55.380: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0115 15:41:05.489105      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 15:41:05.489: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:05.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bswc9" for this suite.
Jan 15 15:41:11.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:41:11.587: INFO: namespace: e2e-tests-gc-bswc9, resource: bindings, ignored listing per whitelist
Jan 15 15:41:11.598: INFO: namespace e2e-tests-gc-bswc9 deletion completed in 6.104735096s

 [SLOW TEST:16.218 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:41:11.598: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fc01b7c3-18db-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:41:11.652: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-qsvtf" to be "success or failure"
Jan 15 15:41:11.655: INFO: Pod "pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.994112ms
Jan 15 15:41:13.658: INFO: Pod "pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006010466s
STEP: Saw pod success
Jan 15 15:41:13.658: INFO: Pod "pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:41:13.661: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:41:13.682: INFO: Waiting for pod pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:41:13.685: INFO: Pod pod-projected-configmaps-fc02c68e-18db-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:13.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qsvtf" for this suite.
Jan 15 15:41:19.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:41:19.777: INFO: namespace: e2e-tests-projected-qsvtf, resource: bindings, ignored listing per whitelist
Jan 15 15:41:19.791: INFO: namespace e2e-tests-projected-qsvtf deletion completed in 6.102467811s

 [SLOW TEST:8.193 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:41:19.792: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:41:19.843: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-sbdgb" to be "success or failure"
Jan 15 15:41:19.846: INFO: Pod "downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.121115ms
Jan 15 15:41:21.856: INFO: Pod "downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013397648s
STEP: Saw pod success
Jan 15 15:41:21.856: INFO: Pod "downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:41:21.859: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:41:21.886: INFO: Waiting for pod downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:41:21.889: INFO: Pod downwardapi-volume-00e3ac57-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:21.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sbdgb" for this suite.
Jan 15 15:41:27.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:41:27.978: INFO: namespace: e2e-tests-projected-sbdgb, resource: bindings, ignored listing per whitelist
Jan 15 15:41:27.992: INFO: namespace e2e-tests-projected-sbdgb deletion completed in 6.098792486s

 [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:41:27.992: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:41:28.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-v752k" to be "success or failure"
Jan 15 15:41:28.045: INFO: Pod "downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.687811ms
Jan 15 15:41:30.049: INFO: Pod "downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007566584s
STEP: Saw pod success
Jan 15 15:41:30.049: INFO: Pod "downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:41:30.053: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:41:30.077: INFO: Waiting for pod downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:41:30.080: INFO: Pod downwardapi-volume-05c738d1-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:30.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v752k" for this suite.
Jan 15 15:41:36.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:41:36.110: INFO: namespace: e2e-tests-downward-api-v752k, resource: bindings, ignored listing per whitelist
Jan 15 15:41:36.189: INFO: namespace e2e-tests-downward-api-v752k deletion completed in 6.104654354s

 [SLOW TEST:8.197 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:41:36.189: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 15:41:36.240: INFO: Waiting up to 5m0s for pod "downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-ktws9" to be "success or failure"
Jan 15 15:41:36.244: INFO: Pod "downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.001178ms
Jan 15 15:41:38.248: INFO: Pod "downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008599973s
STEP: Saw pod success
Jan 15 15:41:38.248: INFO: Pod "downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:41:38.252: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 15:41:38.275: INFO: Waiting for pod downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:41:38.278: INFO: Pod downward-api-0aaa071b-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:38.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ktws9" for this suite.
Jan 15 15:41:44.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:41:44.375: INFO: namespace: e2e-tests-downward-api-ktws9, resource: bindings, ignored listing per whitelist
Jan 15 15:41:44.380: INFO: namespace e2e-tests-downward-api-ktws9 deletion completed in 6.097914345s

 [SLOW TEST:8.190 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:41:44.380: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:41:44.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-2h8vz" to be "success or failure"
Jan 15 15:41:44.434: INFO: Pod "downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.299821ms
Jan 15 15:41:46.438: INFO: Pod "downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007700055s
STEP: Saw pod success
Jan 15 15:41:46.438: INFO: Pod "downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:41:46.441: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:41:46.461: INFO: Waiting for pod downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:41:46.464: INFO: Pod downwardapi-volume-0f8be2c5-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:46.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2h8vz" for this suite.
Jan 15 15:41:52.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:41:52.525: INFO: namespace: e2e-tests-downward-api-2h8vz, resource: bindings, ignored listing per whitelist
Jan 15 15:41:52.569: INFO: namespace e2e-tests-downward-api-2h8vz deletion completed in 6.10209733s

 [SLOW TEST:8.189 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:41:52.569: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-146ce982-18dc-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:41:52.620: INFO: Waiting up to 5m0s for pod "pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-44cwt" to be "success or failure"
Jan 15 15:41:52.624: INFO: Pod "pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.396813ms
Jan 15 15:41:54.628: INFO: Pod "pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007581957s
STEP: Saw pod success
Jan 15 15:41:54.628: INFO: Pod "pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:41:54.631: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:41:54.655: INFO: Waiting for pod pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:41:54.658: INFO: Pod pod-secrets-146e00a9-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:41:54.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-44cwt" for this suite.
Jan 15 15:42:00.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:42:00.733: INFO: namespace: e2e-tests-secrets-44cwt, resource: bindings, ignored listing per whitelist
Jan 15 15:42:00.775: INFO: namespace e2e-tests-secrets-44cwt deletion completed in 6.112347417s

 [SLOW TEST:8.206 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:42:00.776: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4
Jan 15 15:42:00.832: INFO: Pod name my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4: Found 0 pods out of 1
Jan 15 15:42:05.843: INFO: Pod name my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4: Found 1 pods out of 1
Jan 15 15:42:05.843: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4" are running
Jan 15 15:42:05.846: INFO: Pod "my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4-pw7f6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-15 15:42:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-15 15:42:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-15 15:42:00 +0000 UTC Reason: Message:}])
Jan 15 15:42:05.846: INFO: Trying to dial the pod
Jan 15 15:42:10.858: INFO: Controller my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4: Got expected result from replica 1 [my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4-pw7f6]: "my-hostname-basic-19528321-18dc-11e9-9d2c-c274f07984f4-pw7f6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:42:10.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-n42dp" for this suite.
Jan 15 15:42:16.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:42:16.914: INFO: namespace: e2e-tests-replication-controller-n42dp, resource: bindings, ignored listing per whitelist
Jan 15 15:42:16.964: INFO: namespace e2e-tests-replication-controller-n42dp deletion completed in 6.101634434s

 [SLOW TEST:16.188 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:42:16.964: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 15 15:42:17.005: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 15:42:17.012: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 15:42:17.015: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-119-14.us-east-2.compute.internal before test
Jan 15 15:42:17.021: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-vh7zc from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: false, restart count 253
Jan 15 15:42:17.021: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.021: INFO: tiller-deploy-64ddd985c9-fjhs4 from kube-system started at 2019-01-14 14:10:18 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container tiller ready: true, restart count 0
Jan 15 15:42:17.021: INFO: nginx-ingress-controller-78bb4d5664-7mjzf from ingress-nginx started at 2019-01-14 14:09:14 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 15 15:42:17.021: INFO: default-http-backend-846b65fb5f-pmll5 from ingress-nginx started at 2019-01-14 14:09:14 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container default-http-backend ready: true, restart count 0
Jan 15 15:42:17.021: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-7s94d from platform started at 2019-01-14 14:34:46 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 15:42:17.021: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.021: INFO: calico-node-46lhq from kube-system started at 2019-01-14 13:47:01 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 15:42:17.021: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 15:42:17.021: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-6snp6 from platform started at 2019-01-14 14:25:28 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: false, restart count 0
Jan 15 15:42:17.021: INFO: 	Container filebeat ready: false, restart count 0
Jan 15 15:42:17.021: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-g9xsw from platform started at 2019-01-14 14:53:45 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.021: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 15:42:17.021: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.021: INFO: kube-proxy-ip-172-24-119-14.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 15:42:17.021: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-62-130.us-east-2.compute.internal before test
Jan 15 15:42:17.027: INFO: calico-node-ftx9x from kube-system started at 2019-01-14 13:46:59 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.027: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 15:42:17.027: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-nvgqq from platform started at 2019-01-14 14:55:41 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.027: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.027: INFO: kube-proxy-ip-172-24-62-130.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 15:42:17.027: INFO: stg-pf-sign-svc-platform-signup-svc-74fb49b447-rqr8g from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.027: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container stg-pf-sign-svc-platform-signup-svc ready: true, restart count 255
Jan 15 15:42:17.027: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-bfcxr from platform started at 2019-01-14 14:37:34 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.027: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.027: INFO: kube-dns-6b4f4b544c-l248h from kube-system started at 2019-01-14 13:47:21 +0000 UTC (3 container statuses recorded)
Jan 15 15:42:17.027: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 15:42:17.027: INFO: dev-pf-conf-svc-platform-conf-svc-958fddc8f-sl6vl from platform started at 2019-01-14 14:23:07 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.027: INFO: 	Container dev-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.027: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-87-161.us-east-2.compute.internal before test
Jan 15 15:42:17.034: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-bckvj from platform started at 2019-01-14 14:53:45 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.034: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-88r5r from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: false, restart count 253
Jan 15 15:42:17.034: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.034: INFO: kube-dns-6b4f4b544c-xw7bn from kube-system started at 2019-01-14 13:47:19 +0000 UTC (3 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 15:42:17.034: INFO: kube-dns-autoscaler-6b658bd4d5-6bgxt from kube-system started at 2019-01-14 13:47:19 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 15:42:17.034: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-kb4xz from platform started at 2019-01-14 14:55:05 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.034: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-9jpmd from platform started at 2019-01-14 14:25:28 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:42:17.034: INFO: dev-pf-sign-ui-platform-signup-ui-57985cd7f8-gw4km from platform started at 2019-01-14 14:49:12 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container platform-signup-ui ready: false, restart count 0
Jan 15 15:42:17.034: INFO: heapster-66b886659c-lndvb from kube-system started at 2019-01-14 14:07:19 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container heapster ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 15 15:42:17.034: INFO: platform-utils-svc-7fbd5dd74c-zzz5q from platform started at 2019-01-14 14:17:49 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container platform-utils-svc ready: true, restart count 0
Jan 15 15:42:17.034: INFO: kube-proxy-ip-172-24-87-161.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 15:42:17.034: INFO: calico-node-b7djp from kube-system started at 2019-01-14 13:46:58 +0000 UTC (2 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 15:42:17.034: INFO: calico-complete-upgrade-v331-68hdc from kube-system started at 2019-01-14 13:47:19 +0000 UTC (1 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container migrate-completion ready: false, restart count 0
Jan 15 15:42:17.034: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-15 14:39:28 +0000 UTC (3 container statuses recorded)
Jan 15 15:42:17.034: INFO: 	Container cleanup ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container forwarder ready: true, restart count 0
Jan 15 15:42:17.034: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-172-24-119-14.us-east-2.compute.internal
STEP: verifying the node has the label node ip-172-24-62-130.us-east-2.compute.internal
STEP: verifying the node has the label node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod default-http-backend-846b65fb5f-pmll5 requesting resource cpu=10m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod nginx-ingress-controller-78bb4d5664-7mjzf requesting resource cpu=0m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod calico-node-46lhq requesting resource cpu=20m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod calico-node-b7djp requesting resource cpu=20m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod calico-node-ftx9x requesting resource cpu=20m on Node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod heapster-66b886659c-lndvb requesting resource cpu=134m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod kube-dns-6b4f4b544c-l248h requesting resource cpu=260m on Node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod kube-dns-6b4f4b544c-xw7bn requesting resource cpu=260m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod kube-dns-autoscaler-6b658bd4d5-6bgxt requesting resource cpu=20m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod kube-proxy-ip-172-24-119-14.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod kube-proxy-ip-172-24-62-130.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod kube-proxy-ip-172-24-87-161.us-east-2.compute.internal requesting resource cpu=100m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod tiller-deploy-64ddd985c9-fjhs4 requesting resource cpu=0m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-dss-lc-svc-dss-lc-service-5455ccdc6f-bckvj requesting resource cpu=250m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-dss-lc-svc-dss-lc-service-5455ccdc6f-g9xsw requesting resource cpu=250m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-act-svc-platform-activity-svc-5b8f476bf8-88r5r requesting resource cpu=250m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-act-svc-platform-activity-svc-5b8f476bf8-vh7zc requesting resource cpu=250m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-audit-svc-platform-audit-svc-86674fb5c6-7s94d requesting resource cpu=250m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-audit-svc-platform-audit-svc-86674fb5c6-nvgqq requesting resource cpu=250m on Node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-bfcxr requesting resource cpu=250m on Node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-kb4xz requesting resource cpu=250m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-conf-svc-platform-conf-svc-958fddc8f-sl6vl requesting resource cpu=250m on Node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-6snp6 requesting resource cpu=250m on Node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-9jpmd requesting resource cpu=250m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod dev-pf-sign-ui-platform-signup-ui-57985cd7f8-gw4km requesting resource cpu=250m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod platform-utils-svc-7fbd5dd74c-zzz5q requesting resource cpu=0m on Node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 15:42:17.079: INFO: Pod stg-pf-sign-svc-platform-signup-svc-74fb49b447-rqr8g requesting resource cpu=250m on Node ip-172-24-62-130.us-east-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23032648-18dc-11e9-9d2c-c274f07984f4.157a0fee0f6599d6], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2tg4m/filler-pod-23032648-18dc-11e9-9d2c-c274f07984f4 to ip-172-24-119-14.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23032648-18dc-11e9-9d2c-c274f07984f4.157a0fee382ae70c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23032648-18dc-11e9-9d2c-c274f07984f4.157a0fee3d25e4b1], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23032648-18dc-11e9-9d2c-c274f07984f4.157a0fee469afedb], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2304aa35-18dc-11e9-9d2c-c274f07984f4.157a0fee0fb17f12], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2tg4m/filler-pod-2304aa35-18dc-11e9-9d2c-c274f07984f4 to ip-172-24-62-130.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2304aa35-18dc-11e9-9d2c-c274f07984f4.157a0fee38ec7697], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2304aa35-18dc-11e9-9d2c-c274f07984f4.157a0fee3b513739], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2304aa35-18dc-11e9-9d2c-c274f07984f4.157a0fee4187109e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23055c5f-18dc-11e9-9d2c-c274f07984f4.157a0fee0fe44e5f], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2tg4m/filler-pod-23055c5f-18dc-11e9-9d2c-c274f07984f4 to ip-172-24-87-161.us-east-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23055c5f-18dc-11e9-9d2c-c274f07984f4.157a0fee3e6df2f9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23055c5f-18dc-11e9-9d2c-c274f07984f4.157a0fee4218e0d3], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-23055c5f-18dc-11e9-9d2c-c274f07984f4.157a0fee48bbfc7e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157a0fee8844971d], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node ip-172-24-62-130.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-24-87-161.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-24-119-14.us-east-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:42:20.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2tg4m" for this suite.
Jan 15 15:42:26.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:42:26.252: INFO: namespace: e2e-tests-sched-pred-2tg4m, resource: bindings, ignored listing per whitelist
Jan 15 15:42:26.258: INFO: namespace e2e-tests-sched-pred-2tg4m deletion completed in 6.095137823s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

 [SLOW TEST:9.294 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:42:26.258: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:42:26.304: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-xhtk5" to be "success or failure"
Jan 15 15:42:26.308: INFO: Pod "downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.875333ms
Jan 15 15:42:28.317: INFO: Pod "downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013318033s
STEP: Saw pod success
Jan 15 15:42:28.318: INFO: Pod "downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:42:28.320: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:42:28.341: INFO: Waiting for pod downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:42:28.344: INFO: Pod downwardapi-volume-28815a0d-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:42:28.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xhtk5" for this suite.
Jan 15 15:42:34.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:42:34.439: INFO: namespace: e2e-tests-projected-xhtk5, resource: bindings, ignored listing per whitelist
Jan 15 15:42:34.456: INFO: namespace e2e-tests-projected-xhtk5 deletion completed in 6.108675848s

 [SLOW TEST:8.198 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:42:34.456: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vdzl8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 15:42:34.500: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 15:42:54.576: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.107.48.59:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vdzl8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:42:54.576: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:42:54.650: INFO: Found all expected endpoints: [netserver-0]
Jan 15 15:42:54.653: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.115.205.158:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vdzl8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:42:54.653: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:42:54.727: INFO: Found all expected endpoints: [netserver-1]
Jan 15 15:42:54.730: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.100.156.233:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vdzl8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 15:42:54.730: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
Jan 15 15:42:54.792: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:42:54.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vdzl8" for this suite.
Jan 15 15:43:16.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:43:16.828: INFO: namespace: e2e-tests-pod-network-test-vdzl8, resource: bindings, ignored listing per whitelist
Jan 15 15:43:16.894: INFO: namespace e2e-tests-pod-network-test-vdzl8 deletion completed in 22.097594886s

 [SLOW TEST:42.437 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:43:16.894: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:43:16.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5hqxz" for this suite.
Jan 15 15:43:22.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:43:22.979: INFO: namespace: e2e-tests-services-5hqxz, resource: bindings, ignored listing per whitelist
Jan 15 15:43:23.047: INFO: namespace e2e-tests-services-5hqxz deletion completed in 6.10682446s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

 [SLOW TEST:6.153 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:43:23.047: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:43:23.096: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-n7gmx" to be "success or failure"
Jan 15 15:43:23.100: INFO: Pod "downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.946448ms
Jan 15 15:43:25.103: INFO: Pod "downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007507768s
STEP: Saw pod success
Jan 15 15:43:25.103: INFO: Pod "downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:43:25.106: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:43:25.126: INFO: Waiting for pod downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:43:25.129: INFO: Pod downwardapi-volume-4a5b1064-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:43:25.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n7gmx" for this suite.
Jan 15 15:43:31.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:43:31.196: INFO: namespace: e2e-tests-downward-api-n7gmx, resource: bindings, ignored listing per whitelist
Jan 15 15:43:31.231: INFO: namespace e2e-tests-downward-api-n7gmx deletion completed in 6.097870745s

 [SLOW TEST:8.183 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:43:31.231: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 15:43:33.817: INFO: Successfully updated pod "annotationupdate4f3bf846-18dc-11e9-9d2c-c274f07984f4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:43:37.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tv4jb" for this suite.
Jan 15 15:43:59.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:43:59.897: INFO: namespace: e2e-tests-projected-tv4jb, resource: bindings, ignored listing per whitelist
Jan 15 15:43:59.953: INFO: namespace e2e-tests-projected-tv4jb deletion completed in 22.10226916s

 [SLOW TEST:28.723 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:43:59.953: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0115 15:44:40.037908      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 15:44:40.037: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:44:40.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mhd9z" for this suite.
Jan 15 15:44:46.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:44:46.115: INFO: namespace: e2e-tests-gc-mhd9z, resource: bindings, ignored listing per whitelist
Jan 15 15:44:46.135: INFO: namespace e2e-tests-gc-mhd9z deletion completed in 6.094404937s

 [SLOW TEST:46.182 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:44:46.135: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 15 15:44:46.188: INFO: Waiting up to 5m0s for pod "client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-containers-hr5pv" to be "success or failure"
Jan 15 15:44:46.193: INFO: Pod "client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.931723ms
Jan 15 15:44:48.197: INFO: Pod "client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00854449s
Jan 15 15:44:50.205: INFO: Pod "client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017068149s
STEP: Saw pod success
Jan 15 15:44:50.205: INFO: Pod "client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:44:50.208: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:44:50.229: INFO: Waiting for pod client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:44:50.232: INFO: Pod client-containers-7be1f7c8-18dc-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:44:50.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hr5pv" for this suite.
Jan 15 15:44:56.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:44:56.330: INFO: namespace: e2e-tests-containers-hr5pv, resource: bindings, ignored listing per whitelist
Jan 15 15:44:56.333: INFO: namespace e2e-tests-containers-hr5pv deletion completed in 6.098016876s

 [SLOW TEST:10.198 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:44:56.333: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-sx478
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sx478 to expose endpoints map[]
Jan 15 15:44:56.391: INFO: Get endpoints failed (2.891985ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 15 15:44:57.394: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sx478 exposes endpoints map[] (1.006328683s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-sx478
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sx478 to expose endpoints map[pod1:[100]]
Jan 15 15:44:59.420: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sx478 exposes endpoints map[pod1:[100]] (2.019115341s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-sx478
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sx478 to expose endpoints map[pod1:[100] pod2:[101]]
Jan 15 15:45:01.456: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sx478 exposes endpoints map[pod1:[100] pod2:[101]] (2.031466394s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-sx478
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sx478 to expose endpoints map[pod2:[101]]
Jan 15 15:45:02.476: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sx478 exposes endpoints map[pod2:[101]] (1.013846702s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-sx478
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sx478 to expose endpoints map[]
Jan 15 15:45:03.489: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sx478 exposes endpoints map[] (1.00650351s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:45:03.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-sx478" for this suite.
Jan 15 15:45:09.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:45:09.574: INFO: namespace: e2e-tests-services-sx478, resource: bindings, ignored listing per whitelist
Jan 15 15:45:09.615: INFO: namespace e2e-tests-services-sx478 deletion completed in 6.101059699s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

 [SLOW TEST:13.281 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:45:09.615: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-xfnf9
Jan 15 15:45:11.678: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-xfnf9
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 15:45:11.681: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:49:12.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xfnf9" for this suite.
Jan 15 15:49:18.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:49:18.305: INFO: namespace: e2e-tests-container-probe-xfnf9, resource: bindings, ignored listing per whitelist
Jan 15 15:49:18.350: INFO: namespace e2e-tests-container-probe-xfnf9 deletion completed in 6.098965168s

 [SLOW TEST:248.736 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:49:18.351: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:49:18.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-g22dp" to be "success or failure"
Jan 15 15:49:18.406: INFO: Pod "downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.394891ms
Jan 15 15:49:20.410: INFO: Pod "downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007831156s
STEP: Saw pod success
Jan 15 15:49:20.410: INFO: Pod "downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:49:20.413: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:49:20.434: INFO: Waiting for pod downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:49:20.436: INFO: Pod downwardapi-volume-1e2251ab-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:49:20.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g22dp" for this suite.
Jan 15 15:49:26.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:49:26.465: INFO: namespace: e2e-tests-projected-g22dp, resource: bindings, ignored listing per whitelist
Jan 15 15:49:26.536: INFO: namespace e2e-tests-projected-g22dp deletion completed in 6.095666093s

 [SLOW TEST:8.185 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:49:26.536: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 15 15:49:26.583: INFO: Waiting up to 5m0s for pod "pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-knkv7" to be "success or failure"
Jan 15 15:49:26.588: INFO: Pod "pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.556918ms
Jan 15 15:49:28.591: INFO: Pod "pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008071657s
STEP: Saw pod success
Jan 15 15:49:28.591: INFO: Pod "pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:49:28.594: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:49:28.614: INFO: Waiting for pod pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:49:28.618: INFO: Pod pod-2302dd3b-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:49:28.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-knkv7" for this suite.
Jan 15 15:49:34.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:49:34.708: INFO: namespace: e2e-tests-emptydir-knkv7, resource: bindings, ignored listing per whitelist
Jan 15 15:49:34.716: INFO: namespace e2e-tests-emptydir-knkv7 deletion completed in 6.095002406s

 [SLOW TEST:8.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:49:34.716: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 15:49:34.767: INFO: Waiting up to 5m0s for pod "downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-5dbhm" to be "success or failure"
Jan 15 15:49:34.770: INFO: Pod "downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.699174ms
Jan 15 15:49:36.774: INFO: Pod "downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007143881s
STEP: Saw pod success
Jan 15 15:49:36.774: INFO: Pod "downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:49:36.777: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 15:49:36.798: INFO: Waiting for pod downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:49:36.800: INFO: Pod downward-api-27e3834b-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:49:36.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5dbhm" for this suite.
Jan 15 15:49:42.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:49:42.862: INFO: namespace: e2e-tests-downward-api-5dbhm, resource: bindings, ignored listing per whitelist
Jan 15 15:49:42.905: INFO: namespace e2e-tests-downward-api-5dbhm deletion completed in 6.100957891s

 [SLOW TEST:8.189 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:49:42.905: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jan 15 15:49:42.942: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 15:49:42.948: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 15:49:42.951: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-119-14.us-east-2.compute.internal before test
Jan 15 15:49:42.957: INFO: nginx-ingress-controller-78bb4d5664-7mjzf from ingress-nginx started at 2019-01-14 14:09:14 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 15 15:49:42.957: INFO: default-http-backend-846b65fb5f-pmll5 from ingress-nginx started at 2019-01-14 14:09:14 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container default-http-backend ready: true, restart count 0
Jan 15 15:49:42.957: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-7s94d from platform started at 2019-01-14 14:34:46 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 15:49:42.957: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.957: INFO: calico-node-46lhq from kube-system started at 2019-01-14 13:47:01 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 15:49:42.957: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 15:49:42.957: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-6snp6 from platform started at 2019-01-14 14:25:28 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: false, restart count 0
Jan 15 15:49:42.957: INFO: 	Container filebeat ready: false, restart count 0
Jan 15 15:49:42.957: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-g9xsw from platform started at 2019-01-14 14:53:45 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 15:49:42.957: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.957: INFO: kube-proxy-ip-172-24-119-14.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 15:49:42.957: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-vh7zc from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: false, restart count 254
Jan 15 15:49:42.957: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.957: INFO: tiller-deploy-64ddd985c9-fjhs4 from kube-system started at 2019-01-14 14:10:18 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.957: INFO: 	Container tiller ready: true, restart count 0
Jan 15 15:49:42.957: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-62-130.us-east-2.compute.internal before test
Jan 15 15:49:42.963: INFO: kube-proxy-ip-172-24-62-130.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 15:49:42.963: INFO: stg-pf-sign-svc-platform-signup-svc-74fb49b447-rqr8g from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.963: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container stg-pf-sign-svc-platform-signup-svc ready: false, restart count 256
Jan 15 15:49:42.963: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-bfcxr from platform started at 2019-01-14 14:37:34 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.963: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.963: INFO: kube-dns-6b4f4b544c-l248h from kube-system started at 2019-01-14 13:47:21 +0000 UTC (3 container statuses recorded)
Jan 15 15:49:42.963: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 15:49:42.963: INFO: dev-pf-conf-svc-platform-conf-svc-958fddc8f-sl6vl from platform started at 2019-01-14 14:23:07 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.963: INFO: 	Container dev-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.963: INFO: calico-node-ftx9x from kube-system started at 2019-01-14 13:46:59 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.963: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 15:49:42.963: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-nvgqq from platform started at 2019-01-14 14:55:41 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.963: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.963: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-87-161.us-east-2.compute.internal before test
Jan 15 15:49:42.969: INFO: kube-proxy-ip-172-24-87-161.us-east-2.compute.internal from kube-system started at <nil> (0 container statuses recorded)
Jan 15 15:49:42.969: INFO: calico-node-b7djp from kube-system started at 2019-01-14 13:46:58 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 15:49:42.970: INFO: heapster-66b886659c-lndvb from kube-system started at 2019-01-14 14:07:19 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container heapster ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container heapster-nanny ready: true, restart count 0
Jan 15 15:49:42.970: INFO: platform-utils-svc-7fbd5dd74c-zzz5q from platform started at 2019-01-14 14:17:49 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container platform-utils-svc ready: true, restart count 0
Jan 15 15:49:42.970: INFO: calico-complete-upgrade-v331-68hdc from kube-system started at 2019-01-14 13:47:19 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container migrate-completion ready: false, restart count 0
Jan 15 15:49:42.970: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-15 14:39:28 +0000 UTC (3 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container cleanup ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container forwarder ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 15:49:42.970: INFO: kube-dns-6b4f4b544c-xw7bn from kube-system started at 2019-01-14 13:47:19 +0000 UTC (3 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 15:49:42.970: INFO: kube-dns-autoscaler-6b658bd4d5-6bgxt from kube-system started at 2019-01-14 13:47:19 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 15:49:42.970: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-bckvj from platform started at 2019-01-14 14:53:45 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.970: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-88r5r from platform started at 2019-01-14 14:49:12 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: true, restart count 255
Jan 15 15:49:42.970: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.970: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-9jpmd from platform started at 2019-01-14 14:25:28 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 15:49:42.970: INFO: dev-pf-sign-ui-platform-signup-ui-57985cd7f8-gw4km from platform started at 2019-01-14 14:49:12 +0000 UTC (1 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container platform-signup-ui ready: false, restart count 0
Jan 15 15:49:42.970: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-kb4xz from platform started at 2019-01-14 14:55:05 +0000 UTC (2 container statuses recorded)
Jan 15 15:49:42.970: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 15:49:42.970: INFO: 	Container filebeat ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157a1055e10afb93], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:49:43.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9z9lr" for this suite.
Jan 15 15:49:50.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:49:50.061: INFO: namespace: e2e-tests-sched-pred-9z9lr, resource: bindings, ignored listing per whitelist
Jan 15 15:49:50.095: INFO: namespace e2e-tests-sched-pred-9z9lr deletion completed in 6.097327566s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

 [SLOW TEST:7.190 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:49:50.096: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:49:52.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-lspl2" for this suite.
Jan 15 15:49:58.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:49:58.292: INFO: namespace: e2e-tests-emptydir-wrapper-lspl2, resource: bindings, ignored listing per whitelist
Jan 15 15:49:58.292: INFO: namespace e2e-tests-emptydir-wrapper-lspl2 deletion completed in 6.093923124s

 [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:49:58.292: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:49:58.348: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 15 15:49:58.359: INFO: Number of nodes with available pods: 0
Jan 15 15:49:58.359: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 15 15:49:58.375: INFO: Number of nodes with available pods: 0
Jan 15 15:49:58.375: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:49:59.379: INFO: Number of nodes with available pods: 0
Jan 15 15:49:59.379: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:00.379: INFO: Number of nodes with available pods: 1
Jan 15 15:50:00.379: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 15 15:50:00.393: INFO: Number of nodes with available pods: 1
Jan 15 15:50:00.393: INFO: Number of running nodes: 0, number of available pods: 1
Jan 15 15:50:01.397: INFO: Number of nodes with available pods: 0
Jan 15 15:50:01.397: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 15 15:50:01.405: INFO: Number of nodes with available pods: 0
Jan 15 15:50:01.405: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:02.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:02.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:03.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:03.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:04.415: INFO: Number of nodes with available pods: 0
Jan 15 15:50:04.415: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:05.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:05.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:06.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:06.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:07.408: INFO: Number of nodes with available pods: 0
Jan 15 15:50:07.408: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:08.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:08.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:09.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:09.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:10.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:10.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:11.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:11.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:12.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:12.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:13.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:13.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:14.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:14.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:15.415: INFO: Number of nodes with available pods: 0
Jan 15 15:50:15.415: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:16.410: INFO: Number of nodes with available pods: 0
Jan 15 15:50:16.410: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:17.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:17.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:18.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:18.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:19.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:19.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:20.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:20.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:21.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:21.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:22.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:22.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:23.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:23.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:24.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:24.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:25.410: INFO: Number of nodes with available pods: 0
Jan 15 15:50:25.410: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:26.417: INFO: Number of nodes with available pods: 0
Jan 15 15:50:26.417: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:27.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:27.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:28.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:28.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:29.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:29.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:30.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:30.410: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:31.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:31.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:32.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:32.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:33.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:33.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:34.409: INFO: Number of nodes with available pods: 0
Jan 15 15:50:34.409: INFO: Node ip-172-24-119-14.us-east-2.compute.internal is running more than one daemon pod
Jan 15 15:50:35.409: INFO: Number of nodes with available pods: 1
Jan 15 15:50:35.409: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-gn4hp, will wait for the garbage collector to delete the pods
Jan 15 15:50:35.476: INFO: Deleting DaemonSet.extensions daemon-set took: 8.391247ms
Jan 15 15:50:35.576: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.19477ms
Jan 15 15:51:19.686: INFO: Number of nodes with available pods: 0
Jan 15 15:51:19.686: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 15:51:19.690: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gn4hp/daemonsets","resourceVersion":"206907"},"items":null}

Jan 15 15:51:19.693: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gn4hp/pods","resourceVersion":"206907"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:51:19.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gn4hp" for this suite.
Jan 15 15:51:25.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:51:25.756: INFO: namespace: e2e-tests-daemonsets-gn4hp, resource: bindings, ignored listing per whitelist
Jan 15 15:51:25.827: INFO: namespace e2e-tests-daemonsets-gn4hp deletion completed in 6.10979467s

 [SLOW TEST:87.535 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:51:25.827: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-6a1e469a-18dd-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:51:25.886: INFO: Waiting up to 5m0s for pod "pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-rzb8j" to be "success or failure"
Jan 15 15:51:25.890: INFO: Pod "pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.779216ms
Jan 15 15:51:27.893: INFO: Pod "pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006951678s
STEP: Saw pod success
Jan 15 15:51:27.893: INFO: Pod "pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:51:27.895: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:51:27.919: INFO: Waiting for pod pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:51:27.922: INFO: Pod pod-configmaps-6a1f5d7c-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:51:27.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rzb8j" for this suite.
Jan 15 15:51:33.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:51:33.972: INFO: namespace: e2e-tests-configmap-rzb8j, resource: bindings, ignored listing per whitelist
Jan 15 15:51:34.032: INFO: namespace e2e-tests-configmap-rzb8j deletion completed in 6.106805235s

 [SLOW TEST:8.205 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:51:34.033: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6f01c4e1-18dd-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:51:34.088: INFO: Waiting up to 5m0s for pod "pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-qdhjl" to be "success or failure"
Jan 15 15:51:34.093: INFO: Pod "pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.149218ms
Jan 15 15:51:36.096: INFO: Pod "pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007974098s
STEP: Saw pod success
Jan 15 15:51:36.096: INFO: Pod "pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:51:36.099: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:51:36.123: INFO: Waiting for pod pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:51:36.126: INFO: Pod pod-secrets-6f02e72b-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:51:36.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qdhjl" for this suite.
Jan 15 15:51:42.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:51:42.165: INFO: namespace: e2e-tests-secrets-qdhjl, resource: bindings, ignored listing per whitelist
Jan 15 15:51:42.227: INFO: namespace e2e-tests-secrets-qdhjl deletion completed in 6.096219723s

 [SLOW TEST:8.194 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:51:42.227: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 15 15:51:42.277: INFO: Waiting up to 5m0s for pod "client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-containers-7q4h2" to be "success or failure"
Jan 15 15:51:42.280: INFO: Pod "client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.362912ms
Jan 15 15:51:44.284: INFO: Pod "client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006946597s
STEP: Saw pod success
Jan 15 15:51:44.284: INFO: Pod "client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:51:44.286: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:51:44.307: INFO: Waiting for pod client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:51:44.310: INFO: Pod client-containers-73e40a99-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:51:44.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7q4h2" for this suite.
Jan 15 15:51:50.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:51:50.366: INFO: namespace: e2e-tests-containers-7q4h2, resource: bindings, ignored listing per whitelist
Jan 15 15:51:50.430: INFO: namespace e2e-tests-containers-7q4h2 deletion completed in 6.116124731s

 [SLOW TEST:8.203 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:51:50.430: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:51:50.483: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-xk5dr" to be "success or failure"
Jan 15 15:51:50.488: INFO: Pod "downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.143817ms
Jan 15 15:51:52.492: INFO: Pod "downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008335248s
STEP: Saw pod success
Jan 15 15:51:52.492: INFO: Pod "downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:51:52.495: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:51:52.517: INFO: Waiting for pod downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:51:52.520: INFO: Pod downwardapi-volume-78c83249-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:51:52.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xk5dr" for this suite.
Jan 15 15:51:58.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:51:58.630: INFO: namespace: e2e-tests-projected-xk5dr, resource: bindings, ignored listing per whitelist
Jan 15 15:51:58.635: INFO: namespace e2e-tests-projected-xk5dr deletion completed in 6.111321054s

 [SLOW TEST:8.205 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:51:58.636: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7dac5bfc-18dd-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 15:51:58.694: INFO: Waiting up to 5m0s for pod "pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-474lq" to be "success or failure"
Jan 15 15:51:58.698: INFO: Pod "pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850701ms
Jan 15 15:52:00.709: INFO: Pod "pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014620403s
STEP: Saw pod success
Jan 15 15:52:00.709: INFO: Pod "pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:52:00.712: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 15:52:00.733: INFO: Waiting for pod pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:52:00.736: INFO: Pod pod-configmaps-7dad7bfa-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:52:00.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-474lq" for this suite.
Jan 15 15:52:06.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:52:06.830: INFO: namespace: e2e-tests-configmap-474lq, resource: bindings, ignored listing per whitelist
Jan 15 15:52:06.838: INFO: namespace e2e-tests-configmap-474lq deletion completed in 6.097721025s

 [SLOW TEST:8.202 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:52:06.838: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 15:52:06.885: INFO: Waiting up to 5m0s for pod "downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-l77vq" to be "success or failure"
Jan 15 15:52:06.889: INFO: Pod "downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.902308ms
Jan 15 15:52:08.892: INFO: Pod "downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007151306s
STEP: Saw pod success
Jan 15 15:52:08.892: INFO: Pod "downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:52:08.895: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 15:52:08.916: INFO: Waiting for pod downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:52:08.919: INFO: Pod downward-api-828f0481-18dd-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:52:08.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l77vq" for this suite.
Jan 15 15:52:14.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:52:14.998: INFO: namespace: e2e-tests-downward-api-l77vq, resource: bindings, ignored listing per whitelist
Jan 15 15:52:15.034: INFO: namespace e2e-tests-downward-api-l77vq deletion completed in 6.110909625s

 [SLOW TEST:8.196 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:52:15.034: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 15 15:52:15.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 api-versions'
Jan 15 15:52:15.147: INFO: stderr: ""
Jan 15 15:52:15.147: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:52:15.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5b4nh" for this suite.
Jan 15 15:52:21.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:52:21.206: INFO: namespace: e2e-tests-kubectl-5b4nh, resource: bindings, ignored listing per whitelist
Jan 15 15:52:21.266: INFO: namespace e2e-tests-kubectl-5b4nh deletion completed in 6.114879447s

 [SLOW TEST:6.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:52:21.266: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jan 15 15:52:21.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-fwpl9'
Jan 15 15:52:21.571: INFO: stderr: ""
Jan 15 15:52:21.571: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 15 15:52:22.576: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 15:52:22.576: INFO: Found 0 / 1
Jan 15 15:52:23.576: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 15:52:23.576: INFO: Found 1 / 1
Jan 15 15:52:23.576: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 15:52:23.579: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 15:52:23.579: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 15 15:52:23.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 logs redis-master-fg6gg redis-master --namespace=e2e-tests-kubectl-fwpl9'
Jan 15 15:52:23.671: INFO: stderr: ""
Jan 15 15:52:23.671: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 15:52:22.382 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 15:52:22.382 # Server started, Redis version 3.2.12\n1:M 15 Jan 15:52:22.382 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 15:52:22.382 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 15 15:52:23.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 log redis-master-fg6gg redis-master --namespace=e2e-tests-kubectl-fwpl9 --tail=1'
Jan 15 15:52:23.743: INFO: stderr: ""
Jan 15 15:52:23.743: INFO: stdout: "1:M 15 Jan 15:52:22.382 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 15 15:52:23.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 log redis-master-fg6gg redis-master --namespace=e2e-tests-kubectl-fwpl9 --limit-bytes=1'
Jan 15 15:52:23.814: INFO: stderr: ""
Jan 15 15:52:23.814: INFO: stdout: " "
STEP: exposing timestamps
Jan 15 15:52:23.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 log redis-master-fg6gg redis-master --namespace=e2e-tests-kubectl-fwpl9 --tail=1 --timestamps'
Jan 15 15:52:23.881: INFO: stderr: ""
Jan 15 15:52:23.881: INFO: stdout: "2019-01-15T15:52:22.382836746Z 1:M 15 Jan 15:52:22.382 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 15 15:52:26.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 log redis-master-fg6gg redis-master --namespace=e2e-tests-kubectl-fwpl9 --since=1s'
Jan 15 15:52:26.456: INFO: stderr: ""
Jan 15 15:52:26.457: INFO: stdout: ""
Jan 15 15:52:26.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 log redis-master-fg6gg redis-master --namespace=e2e-tests-kubectl-fwpl9 --since=24h'
Jan 15 15:52:26.525: INFO: stderr: ""
Jan 15 15:52:26.525: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 15:52:22.382 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 15:52:22.382 # Server started, Redis version 3.2.12\n1:M 15 Jan 15:52:22.382 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 15:52:22.382 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jan 15 15:52:26.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwpl9'
Jan 15 15:52:26.590: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:52:26.590: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 15 15:52:26.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-fwpl9'
Jan 15 15:52:26.658: INFO: stderr: "No resources found.\n"
Jan 15 15:52:26.658: INFO: stdout: ""
Jan 15 15:52:26.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -l name=nginx --namespace=e2e-tests-kubectl-fwpl9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 15:52:26.715: INFO: stderr: ""
Jan 15 15:52:26.715: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:52:26.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fwpl9" for this suite.
Jan 15 15:52:32.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:52:32.795: INFO: namespace: e2e-tests-kubectl-fwpl9, resource: bindings, ignored listing per whitelist
Jan 15 15:52:32.833: INFO: namespace e2e-tests-kubectl-fwpl9 deletion completed in 6.114928738s

 [SLOW TEST:11.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:52:32.833: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xkj9s
Jan 15 15:52:34.894: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xkj9s
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 15:52:34.898: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:56:35.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xkj9s" for this suite.
Jan 15 15:56:41.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:56:41.491: INFO: namespace: e2e-tests-container-probe-xkj9s, resource: bindings, ignored listing per whitelist
Jan 15 15:56:41.568: INFO: namespace e2e-tests-container-probe-xkj9s deletion completed in 6.10042001s

 [SLOW TEST:248.735 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:56:41.569: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 15:56:41.610: INFO: Creating ReplicaSet my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4
Jan 15 15:56:41.620: INFO: Pod name my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4: Found 0 pods out of 1
Jan 15 15:56:46.631: INFO: Pod name my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4: Found 1 pods out of 1
Jan 15 15:56:46.631: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4" is running
Jan 15 15:56:46.634: INFO: Pod "my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4-4jc5g" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-15 15:56:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-15 15:56:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-15 15:56:41 +0000 UTC Reason: Message:}])
Jan 15 15:56:46.634: INFO: Trying to dial the pod
Jan 15 15:56:51.646: INFO: Controller my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4: Got expected result from replica 1 [my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4-4jc5g]: "my-hostname-basic-26501fb3-18de-11e9-9d2c-c274f07984f4-4jc5g", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:56:51.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-hv75w" for this suite.
Jan 15 15:56:57.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:56:57.722: INFO: namespace: e2e-tests-replicaset-hv75w, resource: bindings, ignored listing per whitelist
Jan 15 15:56:57.768: INFO: namespace e2e-tests-replicaset-hv75w deletion completed in 6.118619391s

 [SLOW TEST:16.199 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:56:57.768: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0115 15:56:58.859044      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 15:56:58.859: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:56:58.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-drs7k" for this suite.
Jan 15 15:57:04.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:57:04.878: INFO: namespace: e2e-tests-gc-drs7k, resource: bindings, ignored listing per whitelist
Jan 15 15:57:04.957: INFO: namespace e2e-tests-gc-drs7k deletion completed in 6.094751979s

 [SLOW TEST:7.189 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:57:04.957: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-j9xk7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-j9xk7 to expose endpoints map[]
Jan 15 15:57:05.015: INFO: Get endpoints failed (2.759655ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 15 15:57:06.018: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-j9xk7 exposes endpoints map[] (1.006319966s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-j9xk7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-j9xk7 to expose endpoints map[pod1:[80]]
Jan 15 15:57:08.055: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-j9xk7 exposes endpoints map[pod1:[80]] (2.028082743s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-j9xk7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-j9xk7 to expose endpoints map[pod1:[80] pod2:[80]]
Jan 15 15:57:10.087: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-j9xk7 exposes endpoints map[pod1:[80] pod2:[80]] (2.027887448s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-j9xk7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-j9xk7 to expose endpoints map[pod2:[80]]
Jan 15 15:57:10.101: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-j9xk7 exposes endpoints map[pod2:[80]] (6.997277ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-j9xk7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-j9xk7 to expose endpoints map[]
Jan 15 15:57:11.117: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-j9xk7 exposes endpoints map[] (1.007621784s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:57:11.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-j9xk7" for this suite.
Jan 15 15:57:33.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:57:33.224: INFO: namespace: e2e-tests-services-j9xk7, resource: bindings, ignored listing per whitelist
Jan 15 15:57:33.240: INFO: namespace e2e-tests-services-j9xk7 deletion completed in 22.095199824s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

 [SLOW TEST:28.283 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:57:33.240: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-451c737d-18de-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:57:33.294: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-jj8wh" to be "success or failure"
Jan 15 15:57:33.298: INFO: Pod "pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.939573ms
Jan 15 15:57:35.302: INFO: Pod "pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00774872s
STEP: Saw pod success
Jan 15 15:57:35.302: INFO: Pod "pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:57:35.305: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:57:35.329: INFO: Waiting for pod pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:57:35.332: INFO: Pod pod-projected-secrets-451d6d68-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:57:35.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jj8wh" for this suite.
Jan 15 15:57:41.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:57:41.455: INFO: namespace: e2e-tests-projected-jj8wh, resource: bindings, ignored listing per whitelist
Jan 15 15:57:41.455: INFO: namespace e2e-tests-projected-jj8wh deletion completed in 6.118201938s

 [SLOW TEST:8.215 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:57:41.455: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 15 15:57:41.508: INFO: Waiting up to 5m0s for pod "pod-4a020cd3-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-kvk9p" to be "success or failure"
Jan 15 15:57:41.511: INFO: Pod "pod-4a020cd3-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.382465ms
Jan 15 15:57:43.516: INFO: Pod "pod-4a020cd3-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007993966s
STEP: Saw pod success
Jan 15 15:57:43.516: INFO: Pod "pod-4a020cd3-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:57:43.519: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-4a020cd3-18de-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:57:43.542: INFO: Waiting for pod pod-4a020cd3-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:57:43.545: INFO: Pod pod-4a020cd3-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:57:43.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kvk9p" for this suite.
Jan 15 15:57:49.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:57:49.573: INFO: namespace: e2e-tests-emptydir-kvk9p, resource: bindings, ignored listing per whitelist
Jan 15 15:57:49.663: INFO: namespace e2e-tests-emptydir-kvk9p deletion completed in 6.112960817s

 [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:57:49.663: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 15 15:57:49.722: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-vjpqw" to be "success or failure"
Jan 15 15:57:49.726: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.283135ms
Jan 15 15:57:51.737: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01479938s
STEP: Saw pod success
Jan 15 15:57:51.737: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 15 15:57:51.740: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 15 15:57:51.763: INFO: Waiting for pod pod-host-path-test to disappear
Jan 15 15:57:51.766: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:57:51.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-vjpqw" for this suite.
Jan 15 15:57:57.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:57:57.871: INFO: namespace: e2e-tests-hostpath-vjpqw, resource: bindings, ignored listing per whitelist
Jan 15 15:57:57.877: INFO: namespace e2e-tests-hostpath-vjpqw deletion completed in 6.106659993s

 [SLOW TEST:8.214 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:57:57.877: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jan 15 15:57:57.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:57:58.050: INFO: stderr: ""
Jan 15 15:57:58.050: INFO: stdout: "pod/pause created\n"
Jan 15 15:57:58.050: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 15 15:57:58.050: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-s77s8" to be "running and ready"
Jan 15 15:57:58.053: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.932431ms
Jan 15 15:58:00.056: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.006445681s
Jan 15 15:58:00.056: INFO: Pod "pause" satisfied condition "running and ready"
Jan 15 15:58:00.056: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 15 15:58:00.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:58:00.132: INFO: stderr: ""
Jan 15 15:58:00.132: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 15 15:58:00.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pod pause -L testing-label --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:58:00.193: INFO: stderr: ""
Jan 15 15:58:00.193: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 15 15:58:00.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 label pods pause testing-label- --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:58:00.257: INFO: stderr: ""
Jan 15 15:58:00.257: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 15 15:58:00.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pod pause -L testing-label --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:58:00.315: INFO: stderr: ""
Jan 15 15:58:00.315: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jan 15 15:58:00.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:58:00.382: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 15:58:00.382: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 15 15:58:00.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-s77s8'
Jan 15 15:58:00.444: INFO: stderr: "No resources found.\n"
Jan 15 15:58:00.444: INFO: stdout: ""
Jan 15 15:58:00.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 get pods -l name=pause --namespace=e2e-tests-kubectl-s77s8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 15:58:00.503: INFO: stderr: ""
Jan 15 15:58:00.503: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:58:00.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s77s8" for this suite.
Jan 15 15:58:06.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:58:06.592: INFO: namespace: e2e-tests-kubectl-s77s8, resource: bindings, ignored listing per whitelist
Jan 15 15:58:06.600: INFO: namespace e2e-tests-kubectl-s77s8 deletion completed in 6.093945412s

 [SLOW TEST:8.723 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:58:06.600: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-58ff46e2-18de-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-58ff46e2-18de-11e9-9d2c-c274f07984f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:58:10.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qlkqp" for this suite.
Jan 15 15:58:32.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:58:32.746: INFO: namespace: e2e-tests-configmap-qlkqp, resource: bindings, ignored listing per whitelist
Jan 15 15:58:32.808: INFO: namespace e2e-tests-configmap-qlkqp deletion completed in 22.109030734s

 [SLOW TEST:26.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:58:32.808: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 15 15:58:36.908: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:36.912: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:38.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:38.917: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:40.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:40.916: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:42.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:42.916: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:44.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:44.923: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:46.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:46.916: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:48.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:48.916: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 15:58:50.913: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 15:58:50.916: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:58:50.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zhvct" for this suite.
Jan 15 15:59:12.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:59:13.018: INFO: namespace: e2e-tests-container-lifecycle-hook-zhvct, resource: bindings, ignored listing per whitelist
Jan 15 15:59:13.049: INFO: namespace e2e-tests-container-lifecycle-hook-zhvct deletion completed in 22.119872222s

 [SLOW TEST:40.241 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:59:13.049: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-z2d92/secret-test-809a846c-18de-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:59:13.106: INFO: Waiting up to 5m0s for pod "pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-z2d92" to be "success or failure"
Jan 15 15:59:13.110: INFO: Pod "pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.381259ms
Jan 15 15:59:15.114: INFO: Pod "pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007082214s
STEP: Saw pod success
Jan 15 15:59:15.114: INFO: Pod "pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:59:15.116: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4 container env-test: <nil>
STEP: delete the pod
Jan 15 15:59:15.138: INFO: Waiting for pod pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:59:15.141: INFO: Pod pod-configmaps-809ba81f-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:59:15.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-z2d92" for this suite.
Jan 15 15:59:21.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:59:21.220: INFO: namespace: e2e-tests-secrets-z2d92, resource: bindings, ignored listing per whitelist
Jan 15 15:59:21.242: INFO: namespace e2e-tests-secrets-z2d92 deletion completed in 6.09668627s

 [SLOW TEST:8.193 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:59:21.242: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:59:21.291: INFO: Waiting up to 5m0s for pod "downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-fm76v" to be "success or failure"
Jan 15 15:59:21.296: INFO: Pod "downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.496398ms
Jan 15 15:59:23.301: INFO: Pod "downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009923183s
STEP: Saw pod success
Jan 15 15:59:23.301: INFO: Pod "downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:59:23.304: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:59:23.326: INFO: Waiting for pod downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:59:23.329: INFO: Pod downwardapi-volume-857c00e8-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:59:23.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fm76v" for this suite.
Jan 15 15:59:29.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:59:29.433: INFO: namespace: e2e-tests-projected-fm76v, resource: bindings, ignored listing per whitelist
Jan 15 15:59:29.442: INFO: namespace e2e-tests-projected-fm76v deletion completed in 6.108845203s

 [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:59:29.442: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 15:59:29.500: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-t94vj" to be "success or failure"
Jan 15 15:59:29.504: INFO: Pod "downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.120612ms
Jan 15 15:59:31.508: INFO: Pod "downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00799864s
STEP: Saw pod success
Jan 15 15:59:31.508: INFO: Pod "downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:59:31.511: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 15:59:31.533: INFO: Waiting for pod downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:59:31.536: INFO: Pod downwardapi-volume-8a608499-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:59:31.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t94vj" for this suite.
Jan 15 15:59:37.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:59:37.630: INFO: namespace: e2e-tests-downward-api-t94vj, resource: bindings, ignored listing per whitelist
Jan 15 15:59:37.659: INFO: namespace e2e-tests-downward-api-t94vj deletion completed in 6.119259954s

 [SLOW TEST:8.217 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:59:37.659: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-8f4550ab-18de-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:59:37.713: INFO: Waiting up to 5m0s for pod "pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-wxn5n" to be "success or failure"
Jan 15 15:59:37.718: INFO: Pod "pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.585928ms
Jan 15 15:59:39.722: INFO: Pod "pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008937997s
STEP: Saw pod success
Jan 15 15:59:39.722: INFO: Pod "pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:59:39.726: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:59:39.749: INFO: Waiting for pod pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:59:39.752: INFO: Pod pod-secrets-8f46532d-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:59:39.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wxn5n" for this suite.
Jan 15 15:59:45.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:59:45.852: INFO: namespace: e2e-tests-secrets-wxn5n, resource: bindings, ignored listing per whitelist
Jan 15 15:59:45.855: INFO: namespace e2e-tests-secrets-wxn5n deletion completed in 6.098057976s

 [SLOW TEST:8.196 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:59:45.855: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 15 15:59:45.908: INFO: Waiting up to 5m0s for pod "pod-9428531f-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-v7f9k" to be "success or failure"
Jan 15 15:59:45.912: INFO: Pod "pod-9428531f-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.932374ms
Jan 15 15:59:47.922: INFO: Pod "pod-9428531f-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013536279s
STEP: Saw pod success
Jan 15 15:59:47.922: INFO: Pod "pod-9428531f-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:59:47.924: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-9428531f-18de-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 15:59:47.944: INFO: Waiting for pod pod-9428531f-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:59:47.947: INFO: Pod pod-9428531f-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:59:47.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v7f9k" for this suite.
Jan 15 15:59:53.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 15:59:53.994: INFO: namespace: e2e-tests-emptydir-v7f9k, resource: bindings, ignored listing per whitelist
Jan 15 15:59:54.047: INFO: namespace e2e-tests-emptydir-v7f9k deletion completed in 6.097414424s

 [SLOW TEST:8.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 15:59:54.048: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-9909646d-18de-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 15:59:54.098: INFO: Waiting up to 5m0s for pod "pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-w58xx" to be "success or failure"
Jan 15 15:59:54.102: INFO: Pod "pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.647872ms
Jan 15 15:59:56.105: INFO: Pod "pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006609343s
STEP: Saw pod success
Jan 15 15:59:56.105: INFO: Pod "pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 15:59:56.107: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 15:59:56.129: INFO: Waiting for pod pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4 to disappear
Jan 15 15:59:56.132: INFO: Pod pod-secrets-990a68aa-18de-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 15:59:56.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w58xx" for this suite.
Jan 15 16:00:02.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:00:02.152: INFO: namespace: e2e-tests-secrets-w58xx, resource: bindings, ignored listing per whitelist
Jan 15 16:00:02.230: INFO: namespace e2e-tests-secrets-w58xx deletion completed in 6.093848518s

 [SLOW TEST:8.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:00:02.231: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mmkv8
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 15 16:00:02.285: INFO: Found 0 stateful pods, waiting for 3
Jan 15 16:00:12.295: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 16:00:12.295: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 16:00:12.295: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 15 16:00:12.322: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 15 16:00:22.359: INFO: Updating stateful set ss2
Jan 15 16:00:22.365: INFO: Waiting for Pod e2e-tests-statefulset-mmkv8/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 15 16:00:32.413: INFO: Found 2 stateful pods, waiting for 3
Jan 15 16:00:42.422: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 16:00:42.422: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 16:00:42.422: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 15 16:00:42.447: INFO: Updating stateful set ss2
Jan 15 16:00:42.453: INFO: Waiting for Pod e2e-tests-statefulset-mmkv8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 15 16:00:52.484: INFO: Updating stateful set ss2
Jan 15 16:00:52.489: INFO: Waiting for StatefulSet e2e-tests-statefulset-mmkv8/ss2 to complete update
Jan 15 16:00:52.489: INFO: Waiting for Pod e2e-tests-statefulset-mmkv8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 16:01:02.502: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mmkv8
Jan 15 16:01:02.504: INFO: Scaling statefulset ss2 to 0
Jan 15 16:01:12.523: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 16:01:12.526: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:01:12.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mmkv8" for this suite.
Jan 15 16:01:18.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:01:18.577: INFO: namespace: e2e-tests-statefulset-mmkv8, resource: bindings, ignored listing per whitelist
Jan 15 16:01:18.648: INFO: namespace e2e-tests-statefulset-mmkv8 deletion completed in 6.103620241s

 [SLOW TEST:76.418 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:01:18.648: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
STEP: Collecting events from namespace "e2e-tests-kubelet-test-xsg9d".
STEP: Found 4 events.
Jan 15 16:02:20.715: INFO: At 2019-01-15 16:01:18 +0000 UTC - event for busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4: {default-scheduler } Scheduled: Successfully assigned e2e-tests-kubelet-test-xsg9d/busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4 to ip-172-24-119-14.us-east-2.compute.internal
Jan 15 16:02:20.716: INFO: At 2019-01-15 16:01:19 +0000 UTC - event for busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4: {kubelet ip-172-24-119-14.us-east-2.compute.internal} Pulled: Container image "docker.io/library/busybox:1.29" already present on machine
Jan 15 16:02:20.716: INFO: At 2019-01-15 16:01:19 +0000 UTC - event for busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4: {kubelet ip-172-24-119-14.us-east-2.compute.internal} Created: Created container
Jan 15 16:02:20.716: INFO: At 2019-01-15 16:01:19 +0000 UTC - event for busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4: {kubelet ip-172-24-119-14.us-east-2.compute.internal} Started: Started container
Jan 15 16:02:20.727: INFO: POD                                                                  NODE                                         PHASE      GRACE  CONDITIONS
Jan 15 16:02:20.727: INFO: busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4             ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:01:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:01:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:01:18 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: sonobuoy                                                             ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:39:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:39:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:39:28 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: sonobuoy-e2e-job-dc6c6c575ffd4dbf                                    ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:39:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:39:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 14:39:31 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: default-http-backend-846b65fb5f-pmll5                                ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:09:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:09:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:09:14 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: nginx-ingress-controller-78bb4d5664-7mjzf                            ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:09:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:09:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:09:14 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-complete-upgrade-v331-68hdc                                   ip-172-24-87-161.us-east-2.compute.internal  Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:21 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-kube-controllers-77bb8588fc-hbrvc                             ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:22 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-node-46lhq                                                    ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:01 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-node-9kkf6                                                    ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:17 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-node-b7djp                                                    ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:58 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-node-fbxc9                                                    ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:07 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-node-ftx9x                                                    ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:59 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: calico-node-ttrhd                                                    ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:07 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: dns-controller-547884bc7f-ck7mm                                      ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:22 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: etcd-server-events-ip-172-24-124-80.us-east-2.compute.internal       ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: etcd-server-events-ip-172-24-45-174.us-east-2.compute.internal       ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: etcd-server-events-ip-172-24-82-195.us-east-2.compute.internal       ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: etcd-server-ip-172-24-124-80.us-east-2.compute.internal              ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: etcd-server-ip-172-24-45-174.us-east-2.compute.internal              ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: etcd-server-ip-172-24-82-195.us-east-2.compute.internal              ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: heapster-66b886659c-lndvb                                            ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:07:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:07:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:07:19 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: kube-apiserver-ip-172-24-124-80.us-east-2.compute.internal           ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: kube-apiserver-ip-172-24-45-174.us-east-2.compute.internal           ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  }]
Jan 15 16:02:20.727: INFO: kube-apiserver-ip-172-24-82-195.us-east-2.compute.internal           ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-controller-manager-ip-172-24-124-80.us-east-2.compute.internal  ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-controller-manager-ip-172-24-45-174.us-east-2.compute.internal  ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-controller-manager-ip-172-24-82-195.us-east-2.compute.internal  ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-dns-6b4f4b544c-l248h                                            ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:21 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-dns-6b4f4b544c-xw7bn                                            ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-dns-autoscaler-6b658bd4d5-6bgxt                                 ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:47:19 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-proxy-ip-172-24-119-14.us-east-2.compute.internal               ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:09 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-proxy-ip-172-24-124-80.us-east-2.compute.internal               ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-proxy-ip-172-24-45-174.us-east-2.compute.internal               ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-proxy-ip-172-24-62-130.us-east-2.compute.internal               ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:07 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-proxy-ip-172-24-82-195.us-east-2.compute.internal               ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-proxy-ip-172-24-87-161.us-east-2.compute.internal               ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:07 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-scheduler-ip-172-24-124-80.us-east-2.compute.internal           ip-172-24-124-80.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:19 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-scheduler-ip-172-24-45-174.us-east-2.compute.internal           ip-172-24-45-174.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:22 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: kube-scheduler-ip-172-24-82-195.us-east-2.compute.internal           ip-172-24-82-195.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:46:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 13:45:51 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: tiller-deploy-64ddd985c9-fjhs4                                       ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:10:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:10:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:10:18 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-bckvj                       ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:53:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:53:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:53:45 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-g9xsw                       ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:53:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:53:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:53:45 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-88r5r                ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:02:18 +0000 UTC ContainersNotReady containers with unready status: [dev-pf-act-svc-platform-activity-svc]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [dev-pf-act-svc-platform-activity-svc]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-vh7zc                ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 15:57:17 +0000 UTC ContainersNotReady containers with unready status: [dev-pf-act-svc-platform-activity-svc]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [dev-pf-act-svc-platform-activity-svc]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-7s94d                 ip-172-24-119-14.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:34:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:34:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:34:46 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-nvgqq                 ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:55:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:55:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:55:41 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-bfcxr                   ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:37:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:37:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:37:34 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-kb4xz                   ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:55:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:55:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:55:05 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-conf-svc-platform-conf-svc-958fddc8f-sl6vl                    ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:23:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:23:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:23:07 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-6snp6                      ip-172-24-119-14.us-east-2.compute.internal  Running    0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:25:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:26:48 +0000 UTC ContainersNotReady containers with unready status: [filebeat dev-pf-iam-svc-platform-iam-svc]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [filebeat dev-pf-iam-svc-platform-iam-svc]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:25:28 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-9jpmd                      ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:25:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:25:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:25:28 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: dev-pf-sign-ui-platform-signup-ui-57985cd7f8-gw4km                   ip-172-24-87-161.us-east-2.compute.internal  Pending           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC ContainersNotReady containers with unready status: [platform-signup-ui]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [platform-signup-ui]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: platform-utils-svc-7fbd5dd74c-zzz5q                                  ip-172-24-87-161.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:17:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:18:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:17:49 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: stg-pf-sign-svc-platform-signup-svc-74fb49b447-rqr8g                 ip-172-24-62-130.us-east-2.compute.internal  Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:00:42 +0000 UTC ContainersNotReady containers with unready status: [stg-pf-sign-svc-platform-signup-svc]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [stg-pf-sign-svc-platform-signup-svc]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-14 14:49:12 +0000 UTC  }]
Jan 15 16:02:20.728: INFO: 
Jan 15 16:02:20.732: INFO: 
Logging node info for node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 16:02:20.735: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-24-119-14.us-east-2.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-24-119-14.us-east-2.compute.internal,UID:de8b8e69-1802-11e9-a8cf-02ce79272a22,ResourceVersion:209135,Generation:0,CreationTimestamp:2019-01-14 13:47:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: m4.xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-east-2,failure-domain.beta.kubernetes.io/zone: us-east-2c,kops.k8s.io/instancegroup: nodes,kubernetes.io/hostname: ip-172-24-119-14.us-east-2.compute.internal,kubernetes.io/role: node,node-role.kubernetes.io/node: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.5.0/24,DoNotUse_ExternalID:,ProviderID:aws:///us-east-2c/i-0942d9c907d7f62dd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{128771407872 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{16829857792 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{115894266893 0} {<nil>} 115894266893 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{16725000192 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-15 16:02:11 +0000 UTC 2019-01-14 13:47:01 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-15 16:02:11 +0000 UTC 2019-01-14 13:47:01 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-15 16:02:11 +0000 UTC 2019-01-14 13:47:01 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-15 16:02:11 +0000 UTC 2019-01-14 13:47:01 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-15 16:02:11 +0000 UTC 2019-01-14 13:47:21 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.24.119.14} {InternalDNS ip-172-24-119-14.us-east-2.compute.internal} {Hostname ip-172-24-119-14.us-east-2.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:fc0dae2d0a2e478daf6ee99ba6bdcc26,SystemUUID:EC2E91F3-F249-A48D-97E6-1162494F6E90,BootID:3855e752-b4e8-4a41-a271-1b1a4ed14a98,KernelVersion:4.9.0-7-amd64,OSImage:Debian GNU/Linux 9 (stretch),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.11.6,KubeProxyVersion:v1.11.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google-samples/gb-frontend@sha256:35cb427341429fac3df10ff74600ea73e8ec0754d78f9ce89e0b4f3d70d53ba6 gcr.io/google-samples/gb-frontend:v6] 373099368} {[intellectdevcloud/platform-filebeat@sha256:0f126a960e7d4cc5babeca940e5df9d890085eb79f0bde04352cfb2cd7fd068c intellectdevcloud/platform-filebeat:latest] 318657334} {[protokube:1.11.0] 282689309} {[intellectdevcloud/platform-iam-service@sha256:ed9030dfea0c48a495302ec61d5b80471179ac69eecbb7c732af3e7fbb16c6b6 intellectdevcloud/platform-iam-service:18.2.0-k8s] 265112209} {[intellectdevcloud/platform-activity-service@sha256:fe226a687e323b30d1750fa550f8664cf6a87983e95de8bb1470c6f47020a734 intellectdevcloud/platform-activity-service:18.2.0-k8s] 249032901} {[intellectdevcloud/platform-audit-service@sha256:d2ce8320014616c30101ad9f2c71c226dcd9e70c2deff40bc56c837ab18e7f70 intellectdevcloud/platform-audit-service:18.2.0-k8s] 244818110} {[intellectdevcloud/leadcloser-service@sha256:55286962250062e82f931e7711d94de5f7d079ca85f694d509b205cb2c89a340 intellectdevcloud/leadcloser-service:18.2.1-k8s] 230711481} {[quay.io/kubernetes-ingress-controller/nginx-ingress-controller@sha256:39cc6ce23e5bcdf8aa78bc28bbcfe0999e449bf99fe2e8d60984b417facc5cd4 quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.9.0] 189891400} {[nginx@sha256:b543f6d0983fbc25b9874e22f4fe257a567111da96fd1d8f1b44315f1236398c nginx:latest] 109174343} {[gcr.io/google-samples/gb-redisslave@sha256:57730a481f97b3321138161ba2c8c9ca3b32df32ce9180e4029e6940446800ec gcr.io/google-samples/gb-redisslave:v3] 98945667} {[k8s.gcr.io/kube-proxy@sha256:de320f2611b72465371292c87d892e64b01bf5e27b211b9e8969a239d0f2523a k8s.gcr.io/kube-proxy:v1.11.6] 98120519} {[calico/upgrade@sha256:85f052cc57acf4acf13075c34d4cc0d4eb93e4b2358f593c43cbaca4ed9de42f calico/upgrade:v1.0.5] 87442255} {[quay.io/calico/cni@sha256:ad5603d0f7cdb0bbdc48b113bea75d621096502f4e770148104daa4629652029 quay.io/calico/cni:v3.3.1] 75355616} {[quay.io/calico/node@sha256:da1a7ee6bb1c66950a8a73965cc11bd80fda99c97870c188b08ffb6c646b8ddc quay.io/calico/node:v3.3.1] 75255172} {[k8s.gcr.io/heapster@sha256:b77cebeff2180d03e21cc9f9c6b69a0d9710caa9f6263e675eab7938019631ef k8s.gcr.io/heapster:v1.4.0] 73395475} {[k8s.gcr.io/addon-resizer@sha256:5eefa41bedca590bd855f0897b869d274e7432db42909218ee799adbd9aa2d9e k8s.gcr.io/addon-resizer:2.0] 36507505} {[gcr.io/kubernetes-helm/tiller@sha256:6662221447b20965c72ac1b0e0666794fcac38fb665e5332d3c0eca648154082 gcr.io/kubernetes-helm/tiller:v2.9.0] 36100294} {[gcr.io/kubernetes-e2e-test-images/nettest@sha256:6aa91bc71993260a87513e31b672ec14ce84bc253cd5233406c6946d3a8f55a1 gcr.io/kubernetes-e2e-test-images/nettest:1.0] 27413498} {[nginx@sha256:385fbcf0f04621981df6c6f1abd896101eb61a439746ee2921b26abc78f45571 nginx:1.15-alpine] 17759259} {[nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 nginx:1.14-alpine] 17724460} {[gcr.io/kubernetes-e2e-test-images/hostexec@sha256:90dfe59da029f9e536385037bc64e86cd3d6e55bae613ddbe69e554d79b0639d gcr.io/kubernetes-e2e-test-images/hostexec:1.1] 8490662} {[gcr.io/kubernetes-e2e-test-images/netexec@sha256:203f0e11dde4baf4b08e27de094890eb3447d807c8b3e990b764b799d3a9e8b7 gcr.io/kubernetes-e2e-test-images/netexec:1.1] 6705349} {[gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 gcr.io/kubernetes-e2e-test-images/redis:1.0] 5905732} {[gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1] 5851985} {[gcr.io/google_containers/defaultbackend@sha256:865b0c35e6da393b8e80b7e3799f777572399a4cff047eb02a81fa6e7a48ed4b gcr.io/google_containers/defaultbackend:1.4] 4844064} {[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc gcr.io/kubernetes-e2e-test-images/nautilus:1.0] 4753501} {[gcr.io/kubernetes-e2e-test-images/kitten@sha256:bcbc4875c982ab39aa7c4f6acf4a287f604e996d9f34a3fbda8c3d1a7457d1f6 gcr.io/kubernetes-e2e-test-images/kitten:1.0] 4747037} {[gcr.io/kubernetes-e2e-test-images/test-webserver@sha256:7f93d6e32798ff28bc6289254d0c2867fe2c849c8e46edc50f8624734309812e gcr.io/kubernetes-e2e-test-images/test-webserver:1.0] 4732240} {[gcr.io/kubernetes-e2e-test-images/porter@sha256:d6389405e453950618ae7749d9eee388f0eb32e0328a7e6583c41433aa5f2a77 gcr.io/kubernetes-e2e-test-images/porter:1.0] 4681408} {[gcr.io/kubernetes-e2e-test-images/liveness@sha256:748662321b68a4b73b5a56961b61b980ad3683fc6bcae62c1306018fcdba1809 gcr.io/kubernetes-e2e-test-images/liveness:1.0] 4608721} {[gcr.io/kubernetes-e2e-test-images/entrypoint-tester@sha256:ba4681b5299884a3adca70fbde40638373b437a881055ffcd0935b5f43eb15c9 gcr.io/kubernetes-e2e-test-images/entrypoint-tester:1.0] 2729534} {[gcr.io/kubernetes-e2e-test-images/mounttest@sha256:c0bd6f0755f42af09a68c9a47fb993136588a76b3200ec305796b60d629d85d2 gcr.io/kubernetes-e2e-test-images/mounttest:1.0] 1563521} {[gcr.io/kubernetes-e2e-test-images/mounttest-user@sha256:17319ca525ee003681fccf7e8c6b1b910ff4f49b653d939ac7f9b6e7c463933d gcr.io/kubernetes-e2e-test-images/mounttest-user:1.0] 1450451} {[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796 busybox:1.29] 1154361} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 15 16:02:20.735: INFO: 
Logging kubelet events for node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 16:02:20.738: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 16:02:20.745: INFO: kube-proxy-ip-172-24-119-14.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.745: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-6snp6 started at 2019-01-14 14:25:28 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: false, restart count 0
Jan 15 16:02:20.745: INFO: 	Container filebeat ready: false, restart count 0
Jan 15 16:02:20.745: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-g9xsw started at 2019-01-14 14:53:45 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 16:02:20.745: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.745: INFO: busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4 started at 2019-01-15 16:01:18 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container busybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4 ready: true, restart count 0
Jan 15 16:02:20.745: INFO: tiller-deploy-64ddd985c9-fjhs4 started at 2019-01-14 14:10:18 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container tiller ready: true, restart count 0
Jan 15 16:02:20.745: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-vh7zc started at 2019-01-14 14:49:12 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: false, restart count 256
Jan 15 16:02:20.745: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.745: INFO: nginx-ingress-controller-78bb4d5664-7mjzf started at 2019-01-14 14:09:14 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Jan 15 16:02:20.745: INFO: calico-node-46lhq started at 2019-01-14 13:47:01 +0000 UTC (1+2 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.745: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 16:02:20.745: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 16:02:20.745: INFO: default-http-backend-846b65fb5f-pmll5 started at 2019-01-14 14:09:14 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container default-http-backend ready: true, restart count 0
Jan 15 16:02:20.745: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-7s94d started at 2019-01-14 14:34:46 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.745: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 16:02:20.745: INFO: 	Container filebeat ready: true, restart count 0
W0115 16:02:20.748656      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:02:20.767: INFO: 
Latency metrics for node ip-172-24-119-14.us-east-2.compute.internal
Jan 15 16:02:20.767: INFO: 
Logging node info for node ip-172-24-124-80.us-east-2.compute.internal
Jan 15 16:02:20.770: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-24-124-80.us-east-2.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-24-124-80.us-east-2.compute.internal,UID:b2c32735-1802-11e9-8532-0a00a28bbe76,ResourceVersion:209154,Generation:0,CreationTimestamp:2019-01-14 13:45:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: c4.2xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-east-2,failure-domain.beta.kubernetes.io/zone: us-east-2c,kops.k8s.io/instancegroup: master-us-east-2c,kubernetes.io/hostname: ip-172-24-124-80.us-east-2.compute.internal,kubernetes.io/role: master,node-role.kubernetes.io/master: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.0.0/24,DoNotUse_ExternalID:,ProviderID:aws:///us-east-2c/i-0e8046a5cb8c24f7d,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{64351657984 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15772897280 0} {<nil>} 15403220Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{57916492090 0} {<nil>} 57916492090 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15668039680 0} {<nil>} 15300820Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-15 16:02:19 +0000 UTC 2019-01-14 13:45:40 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-15 16:02:19 +0000 UTC 2019-01-14 13:45:40 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-15 16:02:19 +0000 UTC 2019-01-14 13:45:40 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-15 16:02:19 +0000 UTC 2019-01-14 13:45:40 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-15 16:02:19 +0000 UTC 2019-01-14 13:46:28 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.24.124.80} {InternalDNS ip-172-24-124-80.us-east-2.compute.internal} {Hostname ip-172-24-124-80.us-east-2.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:6e994fcea5584ec99d0e209c7d4c7e83,SystemUUID:EC2E108C-7BD3-883C-B7DF-06EA487B59AB,BootID:e8e470d0-d80a-48b9-b70a-53e4cf628866,KernelVersion:4.9.0-7-amd64,OSImage:Debian GNU/Linux 9 (stretch),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.11.6,KubeProxyVersion:v1.11.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[protokube:1.11.0] 282689309} {[k8s.gcr.io/etcd@sha256:905d7ca17fd02bc24c0eba9a062753aba15db3e31422390bc3238eb762339b20 k8s.gcr.io/etcd:3.2.24] 219655340} {[k8s.gcr.io/kube-apiserver@sha256:85fd1cf5369ea09c6e57f202878454947be5d99045a67e7bf45412b58a95517e k8s.gcr.io/kube-apiserver:v1.11.6] 186736874} {[k8s.gcr.io/kube-controller-manager@sha256:8a19fb7f4a8b56149a040d6167333ff047cce00aa5e01f28c6a1b9d6503c4dd4 k8s.gcr.io/kube-controller-manager:v1.11.6] 155332297} {[k8s.gcr.io/kube-proxy@sha256:de320f2611b72465371292c87d892e64b01bf5e27b211b9e8969a239d0f2523a k8s.gcr.io/kube-proxy:v1.11.6] 98120519} {[calico/upgrade@sha256:85f052cc57acf4acf13075c34d4cc0d4eb93e4b2358f593c43cbaca4ed9de42f calico/upgrade:v1.0.5] 87442255} {[quay.io/calico/cni@sha256:ad5603d0f7cdb0bbdc48b113bea75d621096502f4e770148104daa4629652029 quay.io/calico/cni:v3.3.1] 75355616} {[quay.io/calico/node@sha256:da1a7ee6bb1c66950a8a73965cc11bd80fda99c97870c188b08ffb6c646b8ddc quay.io/calico/node:v3.3.1] 75255172} {[k8s.gcr.io/kube-scheduler@sha256:6fd68e815c4cb09df711a2c5f4242160e80d97867768ae4ba3f661ad2ab8ee76 k8s.gcr.io/kube-scheduler:v1.11.6] 56814410} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 15 16:02:20.770: INFO: 
Logging kubelet events for node ip-172-24-124-80.us-east-2.compute.internal
Jan 15 16:02:20.773: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-124-80.us-east-2.compute.internal
Jan 15 16:02:20.789: INFO: calico-node-fbxc9 started at 2019-01-14 13:46:07 +0000 UTC (1+2 container statuses recorded)
Jan 15 16:02:20.789: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.789: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 16:02:20.789: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 16:02:20.789: INFO: etcd-server-events-ip-172-24-124-80.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.789: INFO: etcd-server-ip-172-24-124-80.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.789: INFO: kube-apiserver-ip-172-24-124-80.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.789: INFO: kube-controller-manager-ip-172-24-124-80.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.789: INFO: kube-proxy-ip-172-24-124-80.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.789: INFO: kube-scheduler-ip-172-24-124-80.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
W0115 16:02:20.792898      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:02:20.807: INFO: 
Latency metrics for node ip-172-24-124-80.us-east-2.compute.internal
Jan 15 16:02:20.807: INFO: 
Logging node info for node ip-172-24-45-174.us-east-2.compute.internal
Jan 15 16:02:20.810: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-24-45-174.us-east-2.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-24-45-174.us-east-2.compute.internal,UID:b5b07cfb-1802-11e9-a8cf-02ce79272a22,ResourceVersion:209146,Generation:0,CreationTimestamp:2019-01-14 13:45:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: c4.2xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-east-2,failure-domain.beta.kubernetes.io/zone: us-east-2a,kops.k8s.io/instancegroup: master-us-east-2a,kubernetes.io/hostname: ip-172-24-45-174.us-east-2.compute.internal,kubernetes.io/role: master,node-role.kubernetes.io/master: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.1.0/24,DoNotUse_ExternalID:,ProviderID:aws:///us-east-2a/i-0df436d095c12452f,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{64351657984 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15772897280 0} {<nil>} 15403220Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{57916492090 0} {<nil>} 57916492090 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15668039680 0} {<nil>} 15300820Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-15 16:02:18 +0000 UTC 2019-01-14 13:45:46 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-15 16:02:18 +0000 UTC 2019-01-14 13:45:46 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-15 16:02:18 +0000 UTC 2019-01-14 13:45:46 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-15 16:02:18 +0000 UTC 2019-01-14 13:45:46 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-15 16:02:18 +0000 UTC 2019-01-14 13:46:22 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.24.45.174} {InternalDNS ip-172-24-45-174.us-east-2.compute.internal} {Hostname ip-172-24-45-174.us-east-2.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:b3caea8f3d8f46faba76247681645d5f,SystemUUID:EC234EA6-ABE6-2B34-7FA7-4FF59B227553,BootID:d0963451-6186-44ff-a503-4762f77539d6,KernelVersion:4.9.0-7-amd64,OSImage:Debian GNU/Linux 9 (stretch),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.11.6,KubeProxyVersion:v1.11.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/heptio-images/kube-conformance@sha256:ad05dd6563350277db4706010fbc237a4f25c558caa9d27a12be266055a48801 gcr.io/heptio-images/kube-conformance:latest] 462532101} {[protokube:1.11.0] 282689309} {[k8s.gcr.io/etcd@sha256:905d7ca17fd02bc24c0eba9a062753aba15db3e31422390bc3238eb762339b20 k8s.gcr.io/etcd:3.2.24] 219655340} {[k8s.gcr.io/kube-apiserver@sha256:85fd1cf5369ea09c6e57f202878454947be5d99045a67e7bf45412b58a95517e k8s.gcr.io/kube-apiserver:v1.11.6] 186736874} {[k8s.gcr.io/kube-controller-manager@sha256:8a19fb7f4a8b56149a040d6167333ff047cce00aa5e01f28c6a1b9d6503c4dd4 k8s.gcr.io/kube-controller-manager:v1.11.6] 155332297} {[kope/dns-controller@sha256:8fe88797f537df25615899d3bdd380632746320bb559cb220b854dc26334adc4 kope/dns-controller:1.11.0] 122828833} {[k8s.gcr.io/kube-proxy@sha256:de320f2611b72465371292c87d892e64b01bf5e27b211b9e8969a239d0f2523a k8s.gcr.io/kube-proxy:v1.11.6] 98120519} {[calico/upgrade@sha256:85f052cc57acf4acf13075c34d4cc0d4eb93e4b2358f593c43cbaca4ed9de42f calico/upgrade:v1.0.5] 87442255} {[quay.io/calico/cni@sha256:ad5603d0f7cdb0bbdc48b113bea75d621096502f4e770148104daa4629652029 quay.io/calico/cni:v3.3.1] 75355616} {[quay.io/calico/node@sha256:da1a7ee6bb1c66950a8a73965cc11bd80fda99c97870c188b08ffb6c646b8ddc quay.io/calico/node:v3.3.1] 75255172} {[k8s.gcr.io/kube-scheduler@sha256:6fd68e815c4cb09df711a2c5f4242160e80d97867768ae4ba3f661ad2ab8ee76 k8s.gcr.io/kube-scheduler:v1.11.6] 56814410} {[quay.io/calico/kube-controllers@sha256:9a0588e476308d4ac7373100404c7ad9d3d8fe07ce0e92463fac48913b1d7095 quay.io/calico/kube-controllers:v3.3.1] 56520348} {[gcr.io/heptio-images/sonobuoy@sha256:11d129bc56862d008e3351a458faa3ca36a0780cb25efa38a54d163ebc150c77 gcr.io/heptio-images/sonobuoy:v0.13] 33410348} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 15 16:02:20.810: INFO: 
Logging kubelet events for node ip-172-24-45-174.us-east-2.compute.internal
Jan 15 16:02:20.813: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-45-174.us-east-2.compute.internal
Jan 15 16:02:20.825: INFO: etcd-server-events-ip-172-24-45-174.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.825: INFO: dns-controller-547884bc7f-ck7mm started at 2019-01-14 13:46:22 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.825: INFO: 	Container dns-controller ready: true, restart count 0
Jan 15 16:02:20.825: INFO: calico-kube-controllers-77bb8588fc-hbrvc started at 2019-01-14 13:46:22 +0000 UTC (1+1 container statuses recorded)
Jan 15 16:02:20.825: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.825: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 15 16:02:20.825: INFO: sonobuoy-e2e-job-dc6c6c575ffd4dbf started at 2019-01-15 14:39:31 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.825: INFO: 	Container e2e ready: true, restart count 0
Jan 15 16:02:20.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 16:02:20.825: INFO: calico-node-ttrhd started at 2019-01-14 13:46:07 +0000 UTC (1+2 container statuses recorded)
Jan 15 16:02:20.825: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.825: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 16:02:20.825: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 16:02:20.825: INFO: kube-scheduler-ip-172-24-45-174.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.825: INFO: etcd-server-ip-172-24-45-174.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.825: INFO: kube-apiserver-ip-172-24-45-174.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.825: INFO: kube-controller-manager-ip-172-24-45-174.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.825: INFO: kube-proxy-ip-172-24-45-174.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
W0115 16:02:20.829040      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:02:20.853: INFO: 
Latency metrics for node ip-172-24-45-174.us-east-2.compute.internal
Jan 15 16:02:20.853: INFO: 
Logging node info for node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 16:02:20.856: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-24-62-130.us-east-2.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-24-62-130.us-east-2.compute.internal,UID:dd763ed7-1802-11e9-a8cf-02ce79272a22,ResourceVersion:209155,Generation:0,CreationTimestamp:2019-01-14 13:46:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: m4.xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-east-2,failure-domain.beta.kubernetes.io/zone: us-east-2a,kops.k8s.io/instancegroup: nodes,kubernetes.io/hostname: ip-172-24-62-130.us-east-2.compute.internal,kubernetes.io/role: node,node-role.kubernetes.io/node: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.4.0/24,DoNotUse_ExternalID:,ProviderID:aws:///us-east-2a/i-0dd767d24c6506237,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{128771407872 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{16829853696 0} {<nil>} 16435404Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{115894266893 0} {<nil>} 115894266893 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{16724996096 0} {<nil>} 16333004Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-15 16:02:20 +0000 UTC 2019-01-14 13:46:59 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-15 16:02:20 +0000 UTC 2019-01-14 13:46:59 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-15 16:02:20 +0000 UTC 2019-01-14 13:46:59 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-15 16:02:20 +0000 UTC 2019-01-14 13:46:59 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-15 16:02:20 +0000 UTC 2019-01-14 13:47:19 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.24.62.130} {InternalDNS ip-172-24-62-130.us-east-2.compute.internal} {Hostname ip-172-24-62-130.us-east-2.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:340387e0730c4a2899fb9745b88f92ab,SystemUUID:EC280494-238E-D6CC-9EF5-E98AF1C0464F,BootID:ecf103a4-a2cb-41ff-9cbf-1f66eb9f443f,KernelVersion:4.9.0-7-amd64,OSImage:Debian GNU/Linux 9 (stretch),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.11.6,KubeProxyVersion:v1.11.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google-samples/gb-frontend@sha256:35cb427341429fac3df10ff74600ea73e8ec0754d78f9ce89e0b4f3d70d53ba6 gcr.io/google-samples/gb-frontend:v6] 373099368} {[intellectdevcloud/platform-filebeat@sha256:0f126a960e7d4cc5babeca940e5df9d890085eb79f0bde04352cfb2cd7fd068c intellectdevcloud/platform-filebeat:latest] 318657334} {[protokube:1.11.0] 282689309} {[intellectdevcloud/platform-signup-service@sha256:24cc23290b0854b73b29f0c3893a40959c82ea2f084345267d52ada7079e9938 intellectdevcloud/platform-signup-service:18.2.0-k8s] 270618341} {[intellectdevcloud/platform-calendar-service@sha256:3dc41bce162c80e8d34bc08f4a94c000e00f6f9567683d5b049b1bdc9d79a064 intellectdevcloud/platform-calendar-service:18.2.0-k8s] 253867443} {[intellectdevcloud/platform-config-service@sha256:d2682cec7008ffc29141b60c880050ffa785fea70cf37faa21de8e4b17485a8a intellectdevcloud/platform-config-service:18.2.0-k8s] 249877135} {[intellectdevcloud/platform-activity-service@sha256:fe226a687e323b30d1750fa550f8664cf6a87983e95de8bb1470c6f47020a734 intellectdevcloud/platform-activity-service:18.2.0-k8s] 249032901} {[intellectdevcloud/platform-audit-service@sha256:d2ce8320014616c30101ad9f2c71c226dcd9e70c2deff40bc56c837ab18e7f70 intellectdevcloud/platform-audit-service:18.2.0-k8s] 244818110} {[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0] 195659796} {[nginx@sha256:b543f6d0983fbc25b9874e22f4fe257a567111da96fd1d8f1b44315f1236398c nginx:latest] 109174343} {[k8s.gcr.io/kube-proxy@sha256:de320f2611b72465371292c87d892e64b01bf5e27b211b9e8969a239d0f2523a k8s.gcr.io/kube-proxy:v1.11.6] 98120519} {[calico/upgrade@sha256:85f052cc57acf4acf13075c34d4cc0d4eb93e4b2358f593c43cbaca4ed9de42f calico/upgrade:v1.0.5] 87442255} {[quay.io/calico/cni@sha256:ad5603d0f7cdb0bbdc48b113bea75d621096502f4e770148104daa4629652029 quay.io/calico/cni:v3.3.1] 75355616} {[quay.io/calico/node@sha256:da1a7ee6bb1c66950a8a73965cc11bd80fda99c97870c188b08ffb6c646b8ddc quay.io/calico/node:v3.3.1] 75255172} {[k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:b99fc3eee2a9f052f7eb4cc00f15eb12fc405fa41019baa2d6b79847ae7284a8 k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.10] 49549457} {[k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:4f1ab957f87b94a5ec1edc26fae50da2175461f00afecf68940c4aa079bd08a4 k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.10] 41635309} {[k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:bbb2a290a568125b3b996028958eb773f33b5b87a6b37bf38a28f8b62dddb3c8 k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.10] 40372149} {[nginx@sha256:385fbcf0f04621981df6c6f1abd896101eb61a439746ee2921b26abc78f45571 nginx:1.15-alpine] 17759259} {[nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 nginx:1.14-alpine] 17724460} {[gcr.io/kubernetes-e2e-test-images/dnsutils@sha256:2abeee84efb79c14d731966e034af33bf324d3b26ca28497555511ff094b3ddd gcr.io/kubernetes-e2e-test-images/dnsutils:1.1] 9349974} {[gcr.io/kubernetes-e2e-test-images/hostexec@sha256:90dfe59da029f9e536385037bc64e86cd3d6e55bae613ddbe69e554d79b0639d gcr.io/kubernetes-e2e-test-images/hostexec:1.1] 8490662} {[gcr.io/kubernetes-e2e-test-images/netexec@sha256:203f0e11dde4baf4b08e27de094890eb3447d807c8b3e990b764b799d3a9e8b7 gcr.io/kubernetes-e2e-test-images/netexec:1.1] 6705349} {[gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 gcr.io/kubernetes-e2e-test-images/redis:1.0] 5905732} {[gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1] 5851985} {[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc gcr.io/kubernetes-e2e-test-images/nautilus:1.0] 4753501} {[gcr.io/kubernetes-e2e-test-images/test-webserver@sha256:7f93d6e32798ff28bc6289254d0c2867fe2c849c8e46edc50f8624734309812e gcr.io/kubernetes-e2e-test-images/test-webserver:1.0] 4732240} {[gcr.io/kubernetes-e2e-test-images/liveness@sha256:748662321b68a4b73b5a56961b61b980ad3683fc6bcae62c1306018fcdba1809 gcr.io/kubernetes-e2e-test-images/liveness:1.0] 4608721} {[gcr.io/kubernetes-e2e-test-images/mounttest@sha256:c0bd6f0755f42af09a68c9a47fb993136588a76b3200ec305796b60d629d85d2 gcr.io/kubernetes-e2e-test-images/mounttest:1.0] 1563521} {[gcr.io/kubernetes-e2e-test-images/mounttest-user@sha256:17319ca525ee003681fccf7e8c6b1b910ff4f49b653d939ac7f9b6e7c463933d gcr.io/kubernetes-e2e-test-images/mounttest-user:1.0] 1450451} {[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796 busybox:1.29] 1154361} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 15 16:02:20.856: INFO: 
Logging kubelet events for node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 16:02:20.859: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 16:02:20.864: INFO: calico-node-ftx9x started at 2019-01-14 13:46:59 +0000 UTC (1+2 container statuses recorded)
Jan 15 16:02:20.864: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 16:02:20.864: INFO: dev-pf-audit-svc-platform-audit-svc-86674fb5c6-nvgqq started at 2019-01-14 14:55:41 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.864: INFO: 	Container dev-pf-audit-svc-platform-audit-svc ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.864: INFO: kube-proxy-ip-172-24-62-130.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.864: INFO: stg-pf-sign-svc-platform-signup-svc-74fb49b447-rqr8g started at 2019-01-14 14:49:12 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.864: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container stg-pf-sign-svc-platform-signup-svc ready: false, restart count 258
Jan 15 16:02:20.864: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-bfcxr started at 2019-01-14 14:37:34 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.864: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.864: INFO: kube-dns-6b4f4b544c-l248h started at 2019-01-14 13:47:21 +0000 UTC (0+3 container statuses recorded)
Jan 15 16:02:20.864: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 16:02:20.864: INFO: dev-pf-conf-svc-platform-conf-svc-958fddc8f-sl6vl started at 2019-01-14 14:23:07 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.864: INFO: 	Container dev-pf-conf-svc-platform-conf-svc ready: true, restart count 0
Jan 15 16:02:20.864: INFO: 	Container filebeat ready: true, restart count 0
W0115 16:02:20.868734      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:02:20.884: INFO: 
Latency metrics for node ip-172-24-62-130.us-east-2.compute.internal
Jan 15 16:02:20.884: INFO: 
Logging node info for node ip-172-24-82-195.us-east-2.compute.internal
Jan 15 16:02:20.887: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-24-82-195.us-east-2.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-24-82-195.us-east-2.compute.internal,UID:c427a13e-1802-11e9-9f92-067e9883fa18,ResourceVersion:209138,Generation:0,CreationTimestamp:2019-01-14 13:46:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: c4.2xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-east-2,failure-domain.beta.kubernetes.io/zone: us-east-2b,kops.k8s.io/instancegroup: master-us-east-2b,kubernetes.io/hostname: ip-172-24-82-195.us-east-2.compute.internal,kubernetes.io/role: master,node-role.kubernetes.io/master: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.2.0/24,DoNotUse_ExternalID:,ProviderID:aws:///us-east-2b/i-06618be07b90ac86b,Unschedulable:false,Taints:[{node-role.kubernetes.io/master  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{64351657984 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15772897280 0} {<nil>} 15403220Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{8 0} {<nil>} 8 DecimalSI},ephemeral-storage: {{57916492090 0} {<nil>} 57916492090 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{15668039680 0} {<nil>} 15300820Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-15 16:02:13 +0000 UTC 2019-01-14 13:46:05 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-15 16:02:13 +0000 UTC 2019-01-14 13:46:05 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-15 16:02:13 +0000 UTC 2019-01-14 13:46:05 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-15 16:02:13 +0000 UTC 2019-01-14 13:46:05 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-15 16:02:13 +0000 UTC 2019-01-14 13:46:27 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.24.82.195} {InternalDNS ip-172-24-82-195.us-east-2.compute.internal} {Hostname ip-172-24-82-195.us-east-2.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:1a8d4fbe9c274757958dede25b4fe884,SystemUUID:EC25F9C3-F361-F1D7-A4F0-188B252543B3,BootID:a1dbf3f4-cbb5-4c56-a57a-c9d7b6cf762b,KernelVersion:4.9.0-7-amd64,OSImage:Debian GNU/Linux 9 (stretch),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.11.6,KubeProxyVersion:v1.11.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[protokube:1.11.0] 282689309} {[k8s.gcr.io/etcd@sha256:905d7ca17fd02bc24c0eba9a062753aba15db3e31422390bc3238eb762339b20 k8s.gcr.io/etcd:3.2.24] 219655340} {[k8s.gcr.io/kube-apiserver@sha256:85fd1cf5369ea09c6e57f202878454947be5d99045a67e7bf45412b58a95517e k8s.gcr.io/kube-apiserver:v1.11.6] 186736874} {[k8s.gcr.io/kube-controller-manager@sha256:8a19fb7f4a8b56149a040d6167333ff047cce00aa5e01f28c6a1b9d6503c4dd4 k8s.gcr.io/kube-controller-manager:v1.11.6] 155332297} {[k8s.gcr.io/kube-proxy@sha256:de320f2611b72465371292c87d892e64b01bf5e27b211b9e8969a239d0f2523a k8s.gcr.io/kube-proxy:v1.11.6] 98120519} {[calico/upgrade@sha256:85f052cc57acf4acf13075c34d4cc0d4eb93e4b2358f593c43cbaca4ed9de42f calico/upgrade:v1.0.5] 87442255} {[quay.io/calico/cni@sha256:ad5603d0f7cdb0bbdc48b113bea75d621096502f4e770148104daa4629652029 quay.io/calico/cni:v3.3.1] 75355616} {[quay.io/calico/node@sha256:da1a7ee6bb1c66950a8a73965cc11bd80fda99c97870c188b08ffb6c646b8ddc quay.io/calico/node:v3.3.1] 75255172} {[k8s.gcr.io/kube-scheduler@sha256:6fd68e815c4cb09df711a2c5f4242160e80d97867768ae4ba3f661ad2ab8ee76 k8s.gcr.io/kube-scheduler:v1.11.6] 56814410} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 15 16:02:20.887: INFO: 
Logging kubelet events for node ip-172-24-82-195.us-east-2.compute.internal
Jan 15 16:02:20.890: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-82-195.us-east-2.compute.internal
Jan 15 16:02:20.905: INFO: calico-node-9kkf6 started at 2019-01-14 13:46:17 +0000 UTC (1+2 container statuses recorded)
Jan 15 16:02:20.905: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.905: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 16:02:20.905: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 16:02:20.905: INFO: kube-apiserver-ip-172-24-82-195.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.905: INFO: kube-controller-manager-ip-172-24-82-195.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.905: INFO: kube-proxy-ip-172-24-82-195.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.905: INFO: kube-scheduler-ip-172-24-82-195.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.905: INFO: etcd-server-events-ip-172-24-82-195.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.905: INFO: etcd-server-ip-172-24-82-195.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
W0115 16:02:20.909215      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:02:20.923: INFO: 
Latency metrics for node ip-172-24-82-195.us-east-2.compute.internal
Jan 15 16:02:20.923: INFO: 
Logging node info for node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 16:02:20.926: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:ip-172-24-87-161.us-east-2.compute.internal,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/ip-172-24-87-161.us-east-2.compute.internal,UID:dd14a539-1802-11e9-a8cf-02ce79272a22,ResourceVersion:209141,Generation:0,CreationTimestamp:2019-01-14 13:46:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: m4.xlarge,beta.kubernetes.io/os: linux,failure-domain.beta.kubernetes.io/region: us-east-2,failure-domain.beta.kubernetes.io/zone: us-east-2b,kops.k8s.io/instancegroup: nodes,kubernetes.io/hostname: ip-172-24-87-161.us-east-2.compute.internal,kubernetes.io/role: node,node-role.kubernetes.io/node: ,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:NodeSpec{PodCIDR:100.96.3.0/24,DoNotUse_ExternalID:,ProviderID:aws:///us-east-2b/i-0f7615f8bfaa79c50,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{128771407872 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{16829857792 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{4 0} {<nil>} 4 DecimalSI},ephemeral-storage: {{115894266893 0} {<nil>} 115894266893 DecimalSI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{16725000192 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{OutOfDisk False 2019-01-15 16:02:14 +0000 UTC 2019-01-14 13:46:58 +0000 UTC KubeletHasSufficientDisk kubelet has sufficient disk space available} {MemoryPressure False 2019-01-15 16:02:14 +0000 UTC 2019-01-14 13:46:58 +0000 UTC KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-01-15 16:02:14 +0000 UTC 2019-01-14 13:46:58 +0000 UTC KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-01-15 16:02:14 +0000 UTC 2019-01-14 13:46:58 +0000 UTC KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-01-15 16:02:14 +0000 UTC 2019-01-14 13:47:18 +0000 UTC KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 172.24.87.161} {InternalDNS ip-172-24-87-161.us-east-2.compute.internal} {Hostname ip-172-24-87-161.us-east-2.compute.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:46e562fe622948b1b059273a5da96004,SystemUUID:EC2B4C11-43CC-445A-E9BC-25EA567D8051,BootID:d5c72694-069b-4f68-8dab-645ff5442f7a,KernelVersion:4.9.0-7-amd64,OSImage:Debian GNU/Linux 9 (stretch),ContainerRuntimeVersion:docker://17.3.2,KubeletVersion:v1.11.6,KubeProxyVersion:v1.11.6,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/google-samples/gb-frontend@sha256:35cb427341429fac3df10ff74600ea73e8ec0754d78f9ce89e0b4f3d70d53ba6 gcr.io/google-samples/gb-frontend:v6] 373099368} {[intellectdevcloud/platform-filebeat@sha256:0f126a960e7d4cc5babeca940e5df9d890085eb79f0bde04352cfb2cd7fd068c intellectdevcloud/platform-filebeat:latest] 318657334} {[protokube:1.11.0] 282689309} {[intellectdevcloud/platform-signup-service@sha256:24cc23290b0854b73b29f0c3893a40959c82ea2f084345267d52ada7079e9938 intellectdevcloud/platform-signup-service:18.2.0-k8s] 270618341} {[intellectdevcloud/platform-iam-service@sha256:ed9030dfea0c48a495302ec61d5b80471179ac69eecbb7c732af3e7fbb16c6b6 intellectdevcloud/platform-iam-service:18.2.0-k8s] 265112209} {[intellectdevcloud/platform-calendar-service@sha256:3dc41bce162c80e8d34bc08f4a94c000e00f6f9567683d5b049b1bdc9d79a064 intellectdevcloud/platform-calendar-service:18.2.0-k8s] 253867443} {[intellectdevcloud/platform-config-service@sha256:d2682cec7008ffc29141b60c880050ffa785fea70cf37faa21de8e4b17485a8a intellectdevcloud/platform-config-service:18.2.0-k8s] 249877135} {[intellectdevcloud/platform-activity-service@sha256:fe226a687e323b30d1750fa550f8664cf6a87983e95de8bb1470c6f47020a734 intellectdevcloud/platform-activity-service:18.2.0-k8s] 249032901} {[intellectdevcloud/leadcloser-service@sha256:55286962250062e82f931e7711d94de5f7d079ca85f694d509b205cb2c89a340 intellectdevcloud/leadcloser-service:18.2.1-k8s] 230711481} {[gcr.io/kubernetes-e2e-test-images/jessie-dnsutils@sha256:ad583e33cb284f7ef046673809b146ec4053cda19b54a85d2b180a86169715eb gcr.io/kubernetes-e2e-test-images/jessie-dnsutils:1.0] 195659796} {[intellectdevcloud/platform-util-service@sha256:ce2cb2047a82af3cb824daba46ffdb32005efb7986abee527c41bcd80f49e4bc intellectdevcloud/platform-util-service:qa-18.3.1.2] 190651464} {[nginx@sha256:b543f6d0983fbc25b9874e22f4fe257a567111da96fd1d8f1b44315f1236398c nginx:latest] 109174343} {[gcr.io/google-samples/gb-redisslave@sha256:57730a481f97b3321138161ba2c8c9ca3b32df32ce9180e4029e6940446800ec gcr.io/google-samples/gb-redisslave:v3] 98945667} {[k8s.gcr.io/kube-proxy@sha256:de320f2611b72465371292c87d892e64b01bf5e27b211b9e8969a239d0f2523a k8s.gcr.io/kube-proxy:v1.11.6] 98120519} {[calico/upgrade@sha256:85f052cc57acf4acf13075c34d4cc0d4eb93e4b2358f593c43cbaca4ed9de42f calico/upgrade:v1.0.5] 87442255} {[quay.io/calico/cni@sha256:ad5603d0f7cdb0bbdc48b113bea75d621096502f4e770148104daa4629652029 quay.io/calico/cni:v3.3.1] 75355616} {[quay.io/calico/node@sha256:da1a7ee6bb1c66950a8a73965cc11bd80fda99c97870c188b08ffb6c646b8ddc quay.io/calico/node:v3.3.1] 75255172} {[k8s.gcr.io/heapster@sha256:b77cebeff2180d03e21cc9f9c6b69a0d9710caa9f6263e675eab7938019631ef k8s.gcr.io/heapster:v1.4.0] 73395475} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:003f98d9f411ddfa6ff6d539196355e03ddd69fa4ed38c7ffb8fec6f729afe2d k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2-r2] 49648481} {[k8s.gcr.io/k8s-dns-kube-dns-amd64@sha256:b99fc3eee2a9f052f7eb4cc00f15eb12fc405fa41019baa2d6b79847ae7284a8 k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.10] 49549457} {[gcr.io/heptio-images/namespace-deleter@sha256:3ae93c027111ac894a5093663572e1afd5872597d7ecc6af0a2a75d6e6be8b3d gcr.io/heptio-images/namespace-deleter:v0.0.1] 43017056} {[k8s.gcr.io/k8s-dns-sidecar-amd64@sha256:4f1ab957f87b94a5ec1edc26fae50da2175461f00afecf68940c4aa079bd08a4 k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.10] 41635309} {[k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64@sha256:bbb2a290a568125b3b996028958eb773f33b5b87a6b37bf38a28f8b62dddb3c8 k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.10] 40372149} {[k8s.gcr.io/addon-resizer@sha256:5eefa41bedca590bd855f0897b869d274e7432db42909218ee799adbd9aa2d9e k8s.gcr.io/addon-resizer:2.0] 36507505} {[gcr.io/heptio-images/sonobuoy@sha256:11d129bc56862d008e3351a458faa3ca36a0780cb25efa38a54d163ebc150c77 gcr.io/heptio-images/sonobuoy:v0.13] 33410348} {[nginx@sha256:385fbcf0f04621981df6c6f1abd896101eb61a439746ee2921b26abc78f45571 nginx:1.15-alpine] 17759259} {[nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 nginx:1.14-alpine] 17724460} {[gcr.io/heptio-images/scanner-forwarder@sha256:a4a1761a4cb5c6aed71302e8a605926cc297c58907018fefe5436a65aaaf884f gcr.io/heptio-images/scanner-forwarder:v0.0.4] 10905495} {[gcr.io/kubernetes-e2e-test-images/dnsutils@sha256:2abeee84efb79c14d731966e034af33bf324d3b26ca28497555511ff094b3ddd gcr.io/kubernetes-e2e-test-images/dnsutils:1.1] 9349974} {[gcr.io/kubernetes-e2e-test-images/hostexec@sha256:90dfe59da029f9e536385037bc64e86cd3d6e55bae613ddbe69e554d79b0639d gcr.io/kubernetes-e2e-test-images/hostexec:1.1] 8490662} {[gcr.io/kubernetes-e2e-test-images/netexec@sha256:203f0e11dde4baf4b08e27de094890eb3447d807c8b3e990b764b799d3a9e8b7 gcr.io/kubernetes-e2e-test-images/netexec:1.1] 6705349} {[gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 gcr.io/kubernetes-e2e-test-images/redis:1.0] 5905732} {[gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1] 5851985} {[gcr.io/kubernetes-e2e-test-images/nautilus@sha256:33a732d4c42a266912a5091598a0f07653c9134db4b8d571690d8afd509e0bfc gcr.io/kubernetes-e2e-test-images/nautilus:1.0] 4753501} {[gcr.io/kubernetes-e2e-test-images/kitten@sha256:bcbc4875c982ab39aa7c4f6acf4a287f604e996d9f34a3fbda8c3d1a7457d1f6 gcr.io/kubernetes-e2e-test-images/kitten:1.0] 4747037} {[gcr.io/kubernetes-e2e-test-images/test-webserver@sha256:7f93d6e32798ff28bc6289254d0c2867fe2c849c8e46edc50f8624734309812e gcr.io/kubernetes-e2e-test-images/test-webserver:1.0] 4732240} {[gcr.io/kubernetes-e2e-test-images/entrypoint-tester@sha256:ba4681b5299884a3adca70fbde40638373b437a881055ffcd0935b5f43eb15c9 gcr.io/kubernetes-e2e-test-images/entrypoint-tester:1.0] 2729534} {[gcr.io/kubernetes-e2e-test-images/mounttest@sha256:c0bd6f0755f42af09a68c9a47fb993136588a76b3200ec305796b60d629d85d2 gcr.io/kubernetes-e2e-test-images/mounttest:1.0] 1563521} {[gcr.io/kubernetes-e2e-test-images/mounttest-user@sha256:17319ca525ee003681fccf7e8c6b1b910ff4f49b653d939ac7f9b6e7c463933d gcr.io/kubernetes-e2e-test-images/mounttest-user:1.0] 1450451} {[busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796 busybox:1.29] 1154361} {[k8s.gcr.io/pause-amd64@sha256:163ac025575b775d1c0f9bf0bdd0f086883171eb475b5068e7defa4ca9e76516 k8s.gcr.io/pause-amd64:3.0] 746888} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
Jan 15 16:02:20.926: INFO: 
Logging kubelet events for node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 16:02:20.929: INFO: 
Logging pods the kubelet thinks is on node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 16:02:20.936: INFO: calico-complete-upgrade-v331-68hdc started at 2019-01-14 13:47:19 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container migrate-completion ready: false, restart count 0
Jan 15 16:02:20.936: INFO: sonobuoy started at 2019-01-15 14:39:28 +0000 UTC (0+3 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container cleanup ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container forwarder ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 16:02:20.936: INFO: dev-pf-act-svc-platform-activity-svc-5b8f476bf8-88r5r started at 2019-01-14 14:49:12 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container dev-pf-act-svc-platform-activity-svc ready: false, restart count 257
Jan 15 16:02:20.936: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.936: INFO: kube-dns-6b4f4b544c-xw7bn started at 2019-01-14 13:47:19 +0000 UTC (0+3 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 16:02:20.936: INFO: kube-dns-autoscaler-6b658bd4d5-6bgxt started at 2019-01-14 13:47:19 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container autoscaler ready: true, restart count 0
Jan 15 16:02:20.936: INFO: dev-dss-lc-svc-dss-lc-service-5455ccdc6f-bckvj started at 2019-01-14 14:53:45 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container dss-lc-service ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.936: INFO: dev-pf-iam-svc-platform-iam-svc-b8c66ffc7-9jpmd started at 2019-01-14 14:25:28 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container dev-pf-iam-svc-platform-iam-svc ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.936: INFO: dev-pf-sign-ui-platform-signup-ui-57985cd7f8-gw4km started at 2019-01-14 14:49:12 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container platform-signup-ui ready: false, restart count 0
Jan 15 16:02:20.936: INFO: dev-pf-cal-svc-platform-calen-svc-5c986c4fd5-kb4xz started at 2019-01-14 14:55:05 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container dev-pf-cal-svc-platform-calen-svc ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container filebeat ready: true, restart count 0
Jan 15 16:02:20.936: INFO: platform-utils-svc-7fbd5dd74c-zzz5q started at 2019-01-14 14:17:49 +0000 UTC (0+1 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container platform-utils-svc ready: true, restart count 0
Jan 15 16:02:20.936: INFO: kube-proxy-ip-172-24-87-161.us-east-2.compute.internal started at <nil> (0+0 container statuses recorded)
Jan 15 16:02:20.936: INFO: calico-node-b7djp started at 2019-01-14 13:46:58 +0000 UTC (1+2 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Init container migrate ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container calico-node ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container install-cni ready: true, restart count 0
Jan 15 16:02:20.936: INFO: heapster-66b886659c-lndvb started at 2019-01-14 14:07:19 +0000 UTC (0+2 container statuses recorded)
Jan 15 16:02:20.936: INFO: 	Container heapster ready: true, restart count 0
Jan 15 16:02:20.936: INFO: 	Container heapster-nanny ready: true, restart count 0
W0115 16:02:20.939692      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:02:20.971: INFO: 
Latency metrics for node ip-172-24-87-161.us-east-2.compute.internal
Jan 15 16:02:20.971: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:2m3.000994s}
Jan 15 16:02:20.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xsg9d" for this suite.
Jan 15 16:02:58.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:02:58.996: INFO: namespace: e2e-tests-kubelet-test-xsg9d, resource: bindings, ignored listing per whitelist
Jan 15 16:02:59.078: INFO: namespace e2e-tests-kubelet-test-xsg9d deletion completed in 38.103578313s

 Failure [100.430 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance] [It]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

    Timed out after 60.000s.
    Expected
        <*errors.errorString | 0xc002b246c0>: {
            s: "expected hosts file to contain entries from HostAliases. Got:\n# Kubernetes-managed hosts file.\n127.0.0.1\tlocalhost\n::1\tlocalhost ip6-localhost ip6-loopback\nfe00::0\tip6-localnet\nfe00::0\tip6-mcastprefix\nfe00::1\tip6-allnodes\nfe00::2\tip6-allrouters\n100.107.48.33\tbusybox-host-aliases64f5657e-18d3-11e9-9d2c-c274f07984f4\n\n# Entries added by HostAliases.\n123.45.67.89\tfoo\n123.45.67.89\tbar\n",
        }
    to be nil

    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:183
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:02:59.078: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 16:02:59.119: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:03:09.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-bkknb" for this suite.
Jan 15 16:03:15.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:03:15.204: INFO: namespace: e2e-tests-custom-resource-definition-bkknb, resource: bindings, ignored listing per whitelist
Jan 15 16:03:15.259: INFO: namespace e2e-tests-custom-resource-definition-bkknb deletion completed in 6.094750988s

 [SLOW TEST:16.181 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:03:15.260: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-10f903a0-18df-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-10f903a0-18df-11e9-9d2c-c274f07984f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:03:19.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xfsvh" for this suite.
Jan 15 16:03:41.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:03:41.409: INFO: namespace: e2e-tests-projected-xfsvh, resource: bindings, ignored listing per whitelist
Jan 15 16:03:41.472: INFO: namespace e2e-tests-projected-xfsvh deletion completed in 22.105025279s

 [SLOW TEST:26.213 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:03:41.472: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0115 16:03:51.549798      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 16:03:51.549: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:03:51.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g9s2m" for this suite.
Jan 15 16:03:57.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:03:57.647: INFO: namespace: e2e-tests-gc-g9s2m, resource: bindings, ignored listing per whitelist
Jan 15 16:03:57.652: INFO: namespace e2e-tests-gc-g9s2m deletion completed in 6.098436299s

 [SLOW TEST:16.180 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:03:57.652: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2a3dbe57-18df-11e9-9d2c-c274f07984f4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:03:59.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ll7fs" for this suite.
Jan 15 16:04:21.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:04:21.796: INFO: namespace: e2e-tests-configmap-ll7fs, resource: bindings, ignored listing per whitelist
Jan 15 16:04:21.838: INFO: namespace e2e-tests-configmap-ll7fs deletion completed in 22.0955954s

 [SLOW TEST:24.186 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:04:21.838: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 15 16:04:21.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 --namespace=e2e-tests-kubectl-hf5bw run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 15 16:04:23.228: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 15 16:04:23.228: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:04:25.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hf5bw" for this suite.
Jan 15 16:04:31.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:04:31.291: INFO: namespace: e2e-tests-kubectl-hf5bw, resource: bindings, ignored listing per whitelist
Jan 15 16:04:31.345: INFO: namespace e2e-tests-kubectl-hf5bw deletion completed in 6.099795524s

 [SLOW TEST:9.507 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:04:31.346: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 16:04:31.384: INFO: PodSpec: initContainers in spec.initContainers
Jan 15 16:05:16.144: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3e51f278-18df-11e9-9d2c-c274f07984f4", GenerateName:"", Namespace:"e2e-tests-init-container-gf8cx", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-gf8cx/pods/pod-init-3e51f278-18df-11e9-9d2c-c274f07984f4", UID:"3e52750a-18df-11e9-a8cf-02ce79272a22", ResourceVersion:"209700", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683165071, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"384234121", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-wskj2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00202a040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wskj2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wskj2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wskj2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024be4c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-24-119-14.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0022ca060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024be540)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024be560)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0024be568), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683165071, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683165071, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683165071, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.24.119.14", PodIP:"100.107.48.31", StartTime:(*v1.Time)(0xc00245e040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00245e080), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0028a00e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f1e32c5679c7a561a84e425094c1b648b3b58203fa7b4d7c3002a4982f13b424"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00245e0a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00245e060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:05:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gf8cx" for this suite.
Jan 15 16:05:38.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:05:38.214: INFO: namespace: e2e-tests-init-container-gf8cx, resource: bindings, ignored listing per whitelist
Jan 15 16:05:38.271: INFO: namespace e2e-tests-init-container-gf8cx deletion completed in 22.113923145s

 [SLOW TEST:66.926 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:05:38.271: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 16:05:38.323: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-cb22p" to be "success or failure"
Jan 15 16:05:38.328: INFO: Pod "downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.721012ms
Jan 15 16:05:40.332: INFO: Pod "downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009208995s
STEP: Saw pod success
Jan 15 16:05:40.332: INFO: Pod "downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:05:40.336: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 16:05:40.358: INFO: Waiting for pod downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:05:40.362: INFO: Pod downwardapi-volume-66368c14-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:05:40.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cb22p" for this suite.
Jan 15 16:05:46.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:05:46.412: INFO: namespace: e2e-tests-downward-api-cb22p, resource: bindings, ignored listing per whitelist
Jan 15 16:05:46.477: INFO: namespace e2e-tests-downward-api-cb22p deletion completed in 6.110958573s

 [SLOW TEST:8.206 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:05:46.477: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 16:05:46.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-kwmfd'
Jan 15 16:05:46.595: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jan 15 16:05:46.595: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jan 15 16:05:50.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-kwmfd'
Jan 15 16:05:50.679: INFO: stderr: ""
Jan 15 16:05:50.679: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:05:50.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kwmfd" for this suite.
Jan 15 16:05:56.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:05:56.750: INFO: namespace: e2e-tests-kubectl-kwmfd, resource: bindings, ignored listing per whitelist
Jan 15 16:05:56.777: INFO: namespace e2e-tests-kubectl-kwmfd deletion completed in 6.093593904s

 [SLOW TEST:10.300 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:05:56.777: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-713df351-18df-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 16:05:56.831: INFO: Waiting up to 5m0s for pod "pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-rp48s" to be "success or failure"
Jan 15 16:05:56.835: INFO: Pod "pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.499692ms
Jan 15 16:05:58.845: INFO: Pod "pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013480242s
STEP: Saw pod success
Jan 15 16:05:58.845: INFO: Pod "pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:05:58.848: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 16:05:58.869: INFO: Waiting for pod pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:05:58.872: INFO: Pod pod-configmaps-713f3502-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:05:58.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rp48s" for this suite.
Jan 15 16:06:04.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:06:04.951: INFO: namespace: e2e-tests-configmap-rp48s, resource: bindings, ignored listing per whitelist
Jan 15 16:06:04.973: INFO: namespace e2e-tests-configmap-rp48s deletion completed in 6.095882963s

 [SLOW TEST:8.196 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:06:04.973: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-76203402-18df-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 16:06:05.024: INFO: Waiting up to 5m0s for pod "pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-njtqs" to be "success or failure"
Jan 15 16:06:05.028: INFO: Pod "pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034877ms
Jan 15 16:06:07.032: INFO: Pod "pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007616745s
STEP: Saw pod success
Jan 15 16:06:07.032: INFO: Pod "pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:06:07.034: INFO: Trying to get logs from node ip-172-24-87-161.us-east-2.compute.internal pod pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 16:06:07.056: INFO: Waiting for pod pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:06:07.059: INFO: Pod pod-configmaps-76213483-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:06:07.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-njtqs" for this suite.
Jan 15 16:06:13.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:06:13.153: INFO: namespace: e2e-tests-configmap-njtqs, resource: bindings, ignored listing per whitelist
Jan 15 16:06:13.161: INFO: namespace e2e-tests-configmap-njtqs deletion completed in 6.098092182s

 [SLOW TEST:8.188 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:06:13.161: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7b01d969-18df-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume secrets
Jan 15 16:06:13.213: INFO: Waiting up to 5m0s for pod "pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-secrets-hjntr" to be "success or failure"
Jan 15 16:06:13.217: INFO: Pod "pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.384318ms
Jan 15 16:06:15.220: INFO: Pod "pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006697544s
STEP: Saw pod success
Jan 15 16:06:15.220: INFO: Pod "pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:06:15.223: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 16:06:15.247: INFO: Waiting for pod pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:06:15.251: INFO: Pod pod-secrets-7b02d347-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:06:15.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hjntr" for this suite.
Jan 15 16:06:21.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:06:21.282: INFO: namespace: e2e-tests-secrets-hjntr, resource: bindings, ignored listing per whitelist
Jan 15 16:06:21.353: INFO: namespace e2e-tests-secrets-hjntr deletion completed in 6.098944112s

 [SLOW TEST:8.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:06:21.353: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 16:06:21.404: INFO: Waiting up to 5m0s for pod "downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-g6tzr" to be "success or failure"
Jan 15 16:06:21.407: INFO: Pod "downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.405476ms
Jan 15 16:06:23.411: INFO: Pod "downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006998387s
STEP: Saw pod success
Jan 15 16:06:23.411: INFO: Pod "downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:06:23.413: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 16:06:23.434: INFO: Waiting for pod downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:06:23.437: INFO: Pod downward-api-7fe3f3b5-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:06:23.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g6tzr" for this suite.
Jan 15 16:06:29.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:06:29.507: INFO: namespace: e2e-tests-downward-api-g6tzr, resource: bindings, ignored listing per whitelist
Jan 15 16:06:29.552: INFO: namespace e2e-tests-downward-api-g6tzr deletion completed in 6.11156907s

 [SLOW TEST:8.199 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:06:29.552: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jan 15 16:06:29.604: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 15 16:06:34.608: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:06:35.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-rjmpg" for this suite.
Jan 15 16:06:41.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:06:41.718: INFO: namespace: e2e-tests-replication-controller-rjmpg, resource: bindings, ignored listing per whitelist
Jan 15 16:06:41.731: INFO: namespace e2e-tests-replication-controller-rjmpg deletion completed in 6.102840094s

 [SLOW TEST:12.179 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:06:41.732: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 15 16:06:43.795: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8c09b39c-18df-11e9-9d2c-c274f07984f4,GenerateName:,Namespace:e2e-tests-events-gmgnk,SelfLink:/api/v1/namespaces/e2e-tests-events-gmgnk/pods/send-events-8c09b39c-18df-11e9-9d2c-c274f07984f4,UID:8c0a2bfa-18df-11e9-a8cf-02ce79272a22,ResourceVersion:210115,Generation:0,CreationTimestamp:2019-01-15 16:06:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 773050280,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-77p6r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-77p6r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-77p6r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-24-119-14.us-east-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018f97b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018f97d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:06:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:06:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:06:41 +0000 UTC  }],Message:,Reason:,HostIP:172.24.119.14,PodIP:100.107.48.32,StartTime:2019-01-15 16:06:41 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-15 16:06:42 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://b1592647570e7b0753a49740c4360b3a87264114137e011ab056025629624212}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 15 16:06:45.798: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 15 16:06:47.802: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:06:47.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-gmgnk" for this suite.
Jan 15 16:07:25.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:07:25.908: INFO: namespace: e2e-tests-events-gmgnk, resource: bindings, ignored listing per whitelist
Jan 15 16:07:25.928: INFO: namespace e2e-tests-events-gmgnk deletion completed in 38.116428178s

 [SLOW TEST:44.197 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:07:25.929: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:07:26.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-sv84l" for this suite.
Jan 15 16:07:32.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:07:32.041: INFO: namespace: e2e-tests-kubelet-test-sv84l, resource: bindings, ignored listing per whitelist
Jan 15 16:07:32.103: INFO: namespace e2e-tests-kubelet-test-sv84l deletion completed in 6.096867305s

 [SLOW TEST:6.175 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:07:32.104: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 16:07:32.142: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:07:34.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gmw4l" for this suite.
Jan 15 16:07:40.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:07:40.374: INFO: namespace: e2e-tests-init-container-gmw4l, resource: bindings, ignored listing per whitelist
Jan 15 16:07:40.374: INFO: namespace e2e-tests-init-container-gmw4l deletion completed in 6.106287514s

 [SLOW TEST:8.271 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:07:40.374: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 16:07:40.426: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-downward-api-cbsmd" to be "success or failure"
Jan 15 16:07:40.429: INFO: Pod "downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.755542ms
Jan 15 16:07:42.433: INFO: Pod "downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007217663s
STEP: Saw pod success
Jan 15 16:07:42.433: INFO: Pod "downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:07:42.436: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4 container client-container: <nil>
STEP: delete the pod
Jan 15 16:07:42.457: INFO: Waiting for pod downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:07:42.460: INFO: Pod downwardapi-volume-aefe0049-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:07:42.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cbsmd" for this suite.
Jan 15 16:07:48.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:07:48.483: INFO: namespace: e2e-tests-downward-api-cbsmd, resource: bindings, ignored listing per whitelist
Jan 15 16:07:48.564: INFO: namespace e2e-tests-downward-api-cbsmd deletion completed in 6.100801942s

 [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:07:48.564: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 15 16:07:51.136: INFO: Successfully updated pod "pod-update-b3df7057-18df-11e9-9d2c-c274f07984f4"
STEP: verifying the updated pod is in kubernetes
Jan 15 16:07:51.142: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:07:51.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-48xw7" for this suite.
Jan 15 16:08:13.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:08:13.189: INFO: namespace: e2e-tests-pods-48xw7, resource: bindings, ignored listing per whitelist
Jan 15 16:08:13.245: INFO: namespace e2e-tests-pods-48xw7 deletion completed in 22.098222296s

 [SLOW TEST:24.681 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:08:13.246: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 15 16:08:13.297: INFO: Waiting up to 5m0s for pod "var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-var-expansion-knzjt" to be "success or failure"
Jan 15 16:08:13.301: INFO: Pod "var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.555579ms
Jan 15 16:08:15.304: INFO: Pod "var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006945629s
STEP: Saw pod success
Jan 15 16:08:15.304: INFO: Pod "var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:08:15.307: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4 container dapi-container: <nil>
STEP: delete the pod
Jan 15 16:08:15.327: INFO: Waiting for pod var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:08:15.331: INFO: Pod var-expansion-c295c802-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:08:15.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-knzjt" for this suite.
Jan 15 16:08:21.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:08:21.397: INFO: namespace: e2e-tests-var-expansion-knzjt, resource: bindings, ignored listing per whitelist
Jan 15 16:08:21.433: INFO: namespace e2e-tests-var-expansion-knzjt deletion completed in 6.097561517s

 [SLOW TEST:8.187 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:08:21.433: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 15 16:08:21.478: INFO: Waiting up to 5m0s for pod "pod-c77627eb-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-b5t6b" to be "success or failure"
Jan 15 16:08:21.482: INFO: Pod "pod-c77627eb-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.518387ms
Jan 15 16:08:23.485: INFO: Pod "pod-c77627eb-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00651331s
STEP: Saw pod success
Jan 15 16:08:23.485: INFO: Pod "pod-c77627eb-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:08:23.488: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-c77627eb-18df-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 16:08:23.509: INFO: Waiting for pod pod-c77627eb-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:08:23.511: INFO: Pod pod-c77627eb-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:08:23.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b5t6b" for this suite.
Jan 15 16:08:29.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:08:29.573: INFO: namespace: e2e-tests-emptydir-b5t6b, resource: bindings, ignored listing per whitelist
Jan 15 16:08:29.618: INFO: namespace e2e-tests-emptydir-b5t6b deletion completed in 6.10199837s

 [SLOW TEST:8.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:08:29.618: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 15 16:08:29.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 cluster-info'
Jan 15 16:08:29.720: INFO: stderr: ""
Jan 15 16:08:29.720: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://100.64.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:08:29.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wz5sk" for this suite.
Jan 15 16:08:35.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:08:35.772: INFO: namespace: e2e-tests-kubectl-wz5sk, resource: bindings, ignored listing per whitelist
Jan 15 16:08:35.824: INFO: namespace e2e-tests-kubectl-wz5sk deletion completed in 6.100131498s

 [SLOW TEST:6.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:08:35.824: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 15 16:08:37.888: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-d00a8cd5-18df-11e9-9d2c-c274f07984f4", GenerateName:"", Namespace:"e2e-tests-pods-jgp6s", SelfLink:"/api/v1/namespaces/e2e-tests-pods-jgp6s/pods/pod-submit-remove-d00a8cd5-18df-11e9-9d2c-c274f07984f4", UID:"d00b8afd-18df-11e9-a8cf-02ce79272a22", ResourceVersion:"210539", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683165315, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"863681886"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-56fmd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0019e71c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-56fmd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000a1def8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-24-87-161.us-east-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0016f1c20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000a1df30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000a1df50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000a1df58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683165315, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683165317, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683165315, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.24.87.161", PodIP:"100.100.156.208", StartTime:(*v1.Time)(0xc0011968a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0011968c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://a630d4b9aaa6ff446b80b96b42470206337c22f187219a409e07d45bf62a0815"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 15 16:08:42.908: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:08:42.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jgp6s" for this suite.
Jan 15 16:08:48.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:08:48.988: INFO: namespace: e2e-tests-pods-jgp6s, resource: bindings, ignored listing per whitelist
Jan 15 16:08:49.017: INFO: namespace e2e-tests-pods-jgp6s deletion completed in 6.102186782s

 [SLOW TEST:13.193 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:08:49.017: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d7e808db-18df-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 16:08:49.072: INFO: Waiting up to 5m0s for pod "pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-configmap-wls5g" to be "success or failure"
Jan 15 16:08:49.076: INFO: Pod "pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.484003ms
Jan 15 16:08:51.080: INFO: Pod "pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007946413s
STEP: Saw pod success
Jan 15 16:08:51.080: INFO: Pod "pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:08:51.083: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 16:08:51.103: INFO: Waiting for pod pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:08:51.106: INFO: Pod pod-configmaps-d7e902a0-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:08:51.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wls5g" for this suite.
Jan 15 16:08:57.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:08:57.135: INFO: namespace: e2e-tests-configmap-wls5g, resource: bindings, ignored listing per whitelist
Jan 15 16:08:57.210: INFO: namespace e2e-tests-configmap-wls5g deletion completed in 6.099839225s

 [SLOW TEST:8.193 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:08:57.210: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-dcc9d7e3-18df-11e9-9d2c-c274f07984f4
STEP: Creating a pod to test consume configMaps
Jan 15 16:08:57.264: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-projected-hcgr9" to be "success or failure"
Jan 15 16:08:57.268: INFO: Pod "pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.160705ms
Jan 15 16:08:59.272: INFO: Pod "pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007148807s
STEP: Saw pod success
Jan 15 16:08:59.272: INFO: Pod "pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:08:59.275: INFO: Trying to get logs from node ip-172-24-119-14.us-east-2.compute.internal pod pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 16:08:59.298: INFO: Waiting for pod pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:08:59.300: INFO: Pod pod-projected-configmaps-dccb0776-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:08:59.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hcgr9" for this suite.
Jan 15 16:09:05.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:09:05.321: INFO: namespace: e2e-tests-projected-hcgr9, resource: bindings, ignored listing per whitelist
Jan 15 16:09:05.404: INFO: namespace e2e-tests-projected-hcgr9 deletion completed in 6.099532725s

 [SLOW TEST:8.193 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:09:05.404: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 15 16:09:05.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 create -f - --namespace=e2e-tests-kubectl-wzvbn'
Jan 15 16:09:05.577: INFO: stderr: ""
Jan 15 16:09:05.577: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 16:09:06.581: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 16:09:06.581: INFO: Found 1 / 1
Jan 15 16:09:06.581: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 15 16:09:06.585: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 16:09:06.585: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 16:09:06.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 patch pod redis-master-bs6rg --namespace=e2e-tests-kubectl-wzvbn -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 15 16:09:06.654: INFO: stderr: ""
Jan 15 16:09:06.654: INFO: stdout: "pod/redis-master-bs6rg patched\n"
STEP: checking annotations
Jan 15 16:09:06.658: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 16:09:06.658: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:09:06.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wzvbn" for this suite.
Jan 15 16:09:28.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:09:28.735: INFO: namespace: e2e-tests-kubectl-wzvbn, resource: bindings, ignored listing per whitelist
Jan 15 16:09:28.769: INFO: namespace e2e-tests-kubectl-wzvbn deletion completed in 22.107122776s

 [SLOW TEST:23.365 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:09:28.769: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 15 16:09:28.819: INFO: Waiting up to 5m0s for pod "pod-ef9984c2-18df-11e9-9d2c-c274f07984f4" in namespace "e2e-tests-emptydir-42tmv" to be "success or failure"
Jan 15 16:09:28.823: INFO: Pod "pod-ef9984c2-18df-11e9-9d2c-c274f07984f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.858993ms
Jan 15 16:09:30.826: INFO: Pod "pod-ef9984c2-18df-11e9-9d2c-c274f07984f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007170828s
STEP: Saw pod success
Jan 15 16:09:30.826: INFO: Pod "pod-ef9984c2-18df-11e9-9d2c-c274f07984f4" satisfied condition "success or failure"
Jan 15 16:09:30.829: INFO: Trying to get logs from node ip-172-24-62-130.us-east-2.compute.internal pod pod-ef9984c2-18df-11e9-9d2c-c274f07984f4 container test-container: <nil>
STEP: delete the pod
Jan 15 16:09:30.849: INFO: Waiting for pod pod-ef9984c2-18df-11e9-9d2c-c274f07984f4 to disappear
Jan 15 16:09:30.851: INFO: Pod pod-ef9984c2-18df-11e9-9d2c-c274f07984f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:09:30.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-42tmv" for this suite.
Jan 15 16:09:36.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:09:36.949: INFO: namespace: e2e-tests-emptydir-42tmv, resource: bindings, ignored listing per whitelist
Jan 15 16:09:36.957: INFO: namespace e2e-tests-emptydir-42tmv deletion completed in 6.10165454s

 [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jan 15 16:09:36.957: INFO: >>> kubeConfig: /tmp/kubeconfig-889858361
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8x2gq
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-8x2gq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-8x2gq
Jan 15 16:09:37.009: INFO: Found 0 stateful pods, waiting for 1
Jan 15 16:09:47.018: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 15 16:09:47.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 16:09:47.149: INFO: stderr: ""
Jan 15 16:09:47.149: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 16:09:47.149: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 16:09:47.153: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 15 16:09:57.162: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 16:09:57.162: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 16:09:57.175: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Jan 15 16:09:57.175: INFO: ss-0  ip-172-24-119-14.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:37 +0000 UTC  }]
Jan 15 16:09:57.175: INFO: 
Jan 15 16:09:57.175: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 15 16:09:58.179: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996507461s
Jan 15 16:09:59.183: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992712678s
Jan 15 16:10:00.186: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988984131s
Jan 15 16:10:01.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985438931s
Jan 15 16:10:02.195: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98144454s
Jan 15 16:10:03.200: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976824013s
Jan 15 16:10:04.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97208584s
Jan 15 16:10:05.207: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968291151s
Jan 15 16:10:06.211: INFO: Verifying statefulset ss doesn't scale past 3 for another 964.782864ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-8x2gq
Jan 15 16:10:07.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 16:10:07.354: INFO: stderr: ""
Jan 15 16:10:07.354: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 16:10:07.354: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 16:10:07.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 16:10:07.482: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 15 16:10:07.482: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 16:10:07.482: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 16:10:07.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 16:10:07.611: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 15 16:10:07.611: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 16:10:07.611: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 16:10:07.614: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jan 15 16:10:17.623: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 16:10:17.623: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 16:10:17.623: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 15 16:10:17.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 16:10:17.760: INFO: stderr: ""
Jan 15 16:10:17.760: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 16:10:17.760: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 16:10:17.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 16:10:17.893: INFO: stderr: ""
Jan 15 16:10:17.893: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 16:10:17.893: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 16:10:17.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-889858361 exec --namespace=e2e-tests-statefulset-8x2gq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 16:10:18.012: INFO: stderr: ""
Jan 15 16:10:18.012: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 16:10:18.012: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 16:10:18.012: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 16:10:18.015: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan 15 16:10:28.027: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 16:10:28.027: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 16:10:28.027: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 16:10:28.038: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Jan 15 16:10:28.038: INFO: ss-0  ip-172-24-119-14.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:37 +0000 UTC  }]
Jan 15 16:10:28.038: INFO: ss-1  ip-172-24-87-161.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  }]
Jan 15 16:10:28.038: INFO: ss-2  ip-172-24-62-130.us-east-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  }]
Jan 15 16:10:28.038: INFO: 
Jan 15 16:10:28.038: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 16:10:29.041: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Jan 15 16:10:29.041: INFO: ss-0  ip-172-24-119-14.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:37 +0000 UTC  }]
Jan 15 16:10:29.041: INFO: ss-1  ip-172-24-87-161.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  }]
Jan 15 16:10:29.041: INFO: ss-2  ip-172-24-62-130.us-east-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  }]
Jan 15 16:10:29.041: INFO: 
Jan 15 16:10:29.041: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 16:10:30.047: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Jan 15 16:10:30.047: INFO: ss-2  ip-172-24-62-130.us-east-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:10:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 16:09:57 +0000 UTC  }]
Jan 15 16:10:30.047: INFO: 
Jan 15 16:10:30.047: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 15 16:10:31.050: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.9878932s
Jan 15 16:10:32.053: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.984597334s
Jan 15 16:10:33.057: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.981517492s
Jan 15 16:10:34.060: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.977983237s
Jan 15 16:10:35.063: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.974721189s
Jan 15 16:10:36.067: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.971193557s
Jan 15 16:10:37.070: INFO: Verifying statefulset ss doesn't scale past 0 for another 967.793871ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-8x2gq
Jan 15 16:10:38.080: INFO: Scaling statefulset ss to 0
Jan 15 16:10:38.089: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 16:10:38.092: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8x2gq
Jan 15 16:10:38.095: INFO: Scaling statefulset ss to 0
Jan 15 16:10:38.103: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 16:10:38.106: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jan 15 16:10:38.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8x2gq" for this suite.
Jan 15 16:10:44.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 16:10:44.167: INFO: namespace: e2e-tests-statefulset-8x2gq, resource: bindings, ignored listing per whitelist
Jan 15 16:10:44.223: INFO: namespace e2e-tests-statefulset-8x2gq deletion completed in 6.099170381s

 [SLOW TEST:67.266 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SJan 15 16:10:44.223: INFO: Running AfterSuite actions on all nodes
Jan 15 16:10:44.223: INFO: Running AfterSuite actions on node 1
Jan 15 16:10:44.223: INFO: Skipping dumping logs from cluster


Ran 199 of 1946 Specs in 5461.493 secondsSUCCESS! -- 199 Passed | 0 Failed | 0 Pending | 1747 Skipped --- PASSGinkgo ran 1 suite in 1h31m2.047273765s
Test Suite Passed
