Dec  6 01:56:59.160: INFO: Overriding default scale value of zero to 1
Dec  6 01:56:59.160: INFO: Overriding default milliseconds value of zero to 5000
I1206 01:56:59.257522      19 test_context.go:382] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-630354635
I1206 01:56:59.257600      19 e2e.go:333] Starting e2e run "377b980a-f8fa-11e8-a2c6-1eb929de0ff1" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544061419 - Will randomize all specs
Will run 166 of 996 specs

Dec  6 01:56:59.308: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 01:56:59.309: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  6 01:56:59.320: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  6 01:56:59.347: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  6 01:56:59.347: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  6 01:56:59.353: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Dec  6 01:56:59.353: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt
Dec  6 01:56:59.441: INFO: e2e test version: v1.11.3
Dec  6 01:56:59.443: INFO: kube-apiserver version: v1.11.5
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:56:59.443: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
Dec  6 01:56:59.764: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Dec  6 01:56:59.766: INFO: namespace e2e-tests-kubectl-qfcmt
Dec  6 01:56:59.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-qfcmt'
Dec  6 01:57:02.686: INFO: stderr: ""
Dec  6 01:57:02.686: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  6 01:57:03.691: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:03.691: INFO: Found 0 / 1
Dec  6 01:57:04.690: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:04.690: INFO: Found 0 / 1
Dec  6 01:57:05.690: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:05.690: INFO: Found 0 / 1
Dec  6 01:57:06.691: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:06.691: INFO: Found 0 / 1
Dec  6 01:57:07.691: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:07.691: INFO: Found 0 / 1
Dec  6 01:57:08.690: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:08.690: INFO: Found 1 / 1
Dec  6 01:57:08.690: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  6 01:57:08.693: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 01:57:08.693: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  6 01:57:08.693: INFO: wait on redis-master startup in e2e-tests-kubectl-qfcmt 
Dec  6 01:57:08.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 logs redis-master-78pq5 redis-master --namespace=e2e-tests-kubectl-qfcmt'
Dec  6 01:57:08.775: INFO: stderr: ""
Dec  6 01:57:08.775: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Dec 01:57:07.903 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Dec 01:57:07.903 # Server started, Redis version 3.2.12\n1:M 06 Dec 01:57:07.903 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Dec 01:57:07.903 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  6 01:57:08.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-qfcmt'
Dec  6 01:57:09.012: INFO: stderr: ""
Dec  6 01:57:09.012: INFO: stdout: "service/rm2 exposed\n"
Dec  6 01:57:09.019: INFO: Service rm2 in namespace e2e-tests-kubectl-qfcmt found.
STEP: exposing service
Dec  6 01:57:11.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-qfcmt'
Dec  6 01:57:11.163: INFO: stderr: ""
Dec  6 01:57:11.163: INFO: stdout: "service/rm3 exposed\n"
Dec  6 01:57:11.231: INFO: Service rm3 in namespace e2e-tests-kubectl-qfcmt found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:57:13.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qfcmt" for this suite.
Dec  6 01:57:37.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:57:37.411: INFO: namespace: e2e-tests-kubectl-qfcmt, resource: bindings, ignored listing per whitelist
Dec  6 01:57:37.444: INFO: namespace e2e-tests-kubectl-qfcmt deletion completed in 24.199276077s

• [SLOW TEST:38.001 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create services for rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:57:37.444: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-4e77969b-f8fa-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 01:57:37.734: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-sdzm9" to be "success or failure"
Dec  6 01:57:37.810: INFO: Pod "pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 75.879247ms
Dec  6 01:57:39.815: INFO: Pod "pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080454327s
Dec  6 01:57:41.819: INFO: Pod "pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084790643s
Dec  6 01:57:43.823: INFO: Pod "pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.088897281s
STEP: Saw pod success
Dec  6 01:57:43.823: INFO: Pod "pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:57:43.826: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 01:57:43.902: INFO: Waiting for pod pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:57:43.947: INFO: Pod pod-configmaps-4e7ccb14-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:57:43.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sdzm9" for this suite.
Dec  6 01:57:49.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:57:50.140: INFO: namespace: e2e-tests-configmap-sdzm9, resource: bindings, ignored listing per whitelist
Dec  6 01:57:50.158: INFO: namespace e2e-tests-configmap-sdzm9 deletion completed in 6.204233162s

• [SLOW TEST:12.714 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:57:50.159: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  6 01:57:50.474: INFO: Waiting up to 5m0s for pod "pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-5kzbr" to be "success or failure"
Dec  6 01:57:50.479: INFO: Pod "pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.703079ms
Dec  6 01:57:52.484: INFO: Pod "pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009531641s
Dec  6 01:57:54.488: INFO: Pod "pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013939302s
Dec  6 01:57:56.493: INFO: Pod "pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018261675s
STEP: Saw pod success
Dec  6 01:57:56.493: INFO: Pod "pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:57:56.496: INFO: Trying to get logs from node k8s-g1 pod pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 01:57:56.601: INFO: Waiting for pod pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:57:56.607: INFO: Pod pod-5611cfda-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:57:56.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5kzbr" for this suite.
Dec  6 01:58:02.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:58:02.670: INFO: namespace: e2e-tests-emptydir-5kzbr, resource: bindings, ignored listing per whitelist
Dec  6 01:58:02.783: INFO: namespace e2e-tests-emptydir-5kzbr deletion completed in 6.169603531s

• [SLOW TEST:12.625 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:58:02.783: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 01:58:03.119: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-nx9h4" to be "success or failure"
Dec  6 01:58:03.159: INFO: Pod "downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 39.625483ms
Dec  6 01:58:05.163: INFO: Pod "downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043885635s
Dec  6 01:58:07.167: INFO: Pod "downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048169685s
STEP: Saw pod success
Dec  6 01:58:07.167: INFO: Pod "downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:58:07.171: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 01:58:07.286: INFO: Waiting for pod downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:58:07.293: INFO: Pod downwardapi-volume-5d9e9919-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:58:07.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nx9h4" for this suite.
Dec  6 01:58:13.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:58:13.367: INFO: namespace: e2e-tests-projected-nx9h4, resource: bindings, ignored listing per whitelist
Dec  6 01:58:13.516: INFO: namespace e2e-tests-projected-nx9h4 deletion completed in 6.214320561s

• [SLOW TEST:10.733 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:58:13.517: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  6 01:58:13.822: INFO: Waiting up to 5m0s for pod "pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-tcbt6" to be "success or failure"
Dec  6 01:58:13.825: INFO: Pod "pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.191575ms
Dec  6 01:58:15.828: INFO: Pod "pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006848105s
Dec  6 01:58:17.833: INFO: Pod "pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011821006s
STEP: Saw pod success
Dec  6 01:58:17.833: INFO: Pod "pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:58:17.837: INFO: Trying to get logs from node k8s-g1 pod pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 01:58:17.901: INFO: Waiting for pod pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:58:17.937: INFO: Pod pod-63f6edb8-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:58:17.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tcbt6" for this suite.
Dec  6 01:58:23.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:58:24.031: INFO: namespace: e2e-tests-emptydir-tcbt6, resource: bindings, ignored listing per whitelist
Dec  6 01:58:24.109: INFO: namespace e2e-tests-emptydir-tcbt6 deletion completed in 6.164840808s

• [SLOW TEST:10.593 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:58:24.109: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  6 01:58:24.598: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-qf5fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-qf5fw/configmaps/e2e-watch-test-resource-version,UID:6a464e19-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127105,Generation:0,CreationTimestamp:2018-12-06 01:58:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  6 01:58:24.598: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-qf5fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-qf5fw/configmaps/e2e-watch-test-resource-version,UID:6a464e19-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127106,Generation:0,CreationTimestamp:2018-12-06 01:58:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:58:24.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qf5fw" for this suite.
Dec  6 01:58:30.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:58:30.656: INFO: namespace: e2e-tests-watch-qf5fw, resource: bindings, ignored listing per whitelist
Dec  6 01:58:30.758: INFO: namespace e2e-tests-watch-qf5fw deletion completed in 6.154315152s

• [SLOW TEST:6.649 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:58:30.758: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  6 01:58:31.008: INFO: Waiting up to 5m0s for pod "pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-fcctr" to be "success or failure"
Dec  6 01:58:31.012: INFO: Pod "pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14534ms
Dec  6 01:58:33.017: INFO: Pod "pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008815929s
Dec  6 01:58:35.021: INFO: Pod "pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013448176s
Dec  6 01:58:37.026: INFO: Pod "pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018627026s
STEP: Saw pod success
Dec  6 01:58:37.026: INFO: Pod "pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:58:37.030: INFO: Trying to get logs from node k8s-g2 pod pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 01:58:37.146: INFO: Waiting for pod pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:58:37.150: INFO: Pod pod-6e3beb91-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:58:37.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fcctr" for this suite.
Dec  6 01:58:43.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:58:43.306: INFO: namespace: e2e-tests-emptydir-fcctr, resource: bindings, ignored listing per whitelist
Dec  6 01:58:43.322: INFO: namespace e2e-tests-emptydir-fcctr deletion completed in 6.163504946s

• [SLOW TEST:12.564 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:58:43.322: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-75b9c9c2-f8fa-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 01:58:43.609: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-bx9vh" to be "success or failure"
Dec  6 01:58:43.689: INFO: Pod "pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 80.39477ms
Dec  6 01:58:45.694: INFO: Pod "pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084475479s
Dec  6 01:58:47.699: INFO: Pod "pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.089773042s
STEP: Saw pod success
Dec  6 01:58:47.699: INFO: Pod "pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:58:47.703: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 01:58:47.792: INFO: Waiting for pod pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:58:47.796: INFO: Pod pod-projected-configmaps-75bc4e98-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:58:47.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bx9vh" for this suite.
Dec  6 01:58:53.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:58:54.000: INFO: namespace: e2e-tests-projected-bx9vh, resource: bindings, ignored listing per whitelist
Dec  6 01:58:54.120: INFO: namespace e2e-tests-projected-bx9vh deletion completed in 6.316717835s

• [SLOW TEST:10.798 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:58:54.120: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
Dec  6 01:58:54.400: INFO: Waiting up to 5m0s for pod "client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-containers-z8jp4" to be "success or failure"
Dec  6 01:58:54.404: INFO: Pod "client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035598ms
Dec  6 01:58:56.409: INFO: Pod "client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008734374s
Dec  6 01:58:58.414: INFO: Pod "client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013468858s
Dec  6 01:59:00.418: INFO: Pod "client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01819307s
STEP: Saw pod success
Dec  6 01:59:00.419: INFO: Pod "client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:59:00.422: INFO: Trying to get logs from node k8s-g2 pod client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 01:59:00.502: INFO: Waiting for pod client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:59:00.506: INFO: Pod client-containers-7c306426-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:59:00.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-z8jp4" for this suite.
Dec  6 01:59:06.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:59:06.578: INFO: namespace: e2e-tests-containers-z8jp4, resource: bindings, ignored listing per whitelist
Dec  6 01:59:06.670: INFO: namespace e2e-tests-containers-z8jp4 deletion completed in 6.155750902s

• [SLOW TEST:12.549 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:59:06.670: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-83b47044-f8fa-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 01:59:07.027: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-f25s2" to be "success or failure"
Dec  6 01:59:07.030: INFO: Pod "pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.707146ms
Dec  6 01:59:09.054: INFO: Pod "pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027436707s
Dec  6 01:59:11.059: INFO: Pod "pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032047442s
STEP: Saw pod success
Dec  6 01:59:11.059: INFO: Pod "pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:59:11.062: INFO: Trying to get logs from node k8s-g1 pod pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  6 01:59:11.123: INFO: Waiting for pod pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:59:11.126: INFO: Pod pod-projected-secrets-83b6c614-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:59:11.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f25s2" for this suite.
Dec  6 01:59:17.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:59:17.301: INFO: namespace: e2e-tests-projected-f25s2, resource: bindings, ignored listing per whitelist
Dec  6 01:59:17.352: INFO: namespace e2e-tests-projected-f25s2 deletion completed in 6.218388167s

• [SLOW TEST:10.683 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:59:17.353: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-8a04e23e-f8fa-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 01:59:17.660: INFO: Waiting up to 5m0s for pod "pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-qcqfl" to be "success or failure"
Dec  6 01:59:17.702: INFO: Pod "pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 42.459666ms
Dec  6 01:59:19.706: INFO: Pod "pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046199299s
Dec  6 01:59:21.713: INFO: Pod "pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052782494s
STEP: Saw pod success
Dec  6 01:59:21.713: INFO: Pod "pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 01:59:21.720: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 01:59:21.794: INFO: Waiting for pod pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 01:59:21.799: INFO: Pod pod-secrets-8a09bf77-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:59:21.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qcqfl" for this suite.
Dec  6 01:59:27.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:59:27.877: INFO: namespace: e2e-tests-secrets-qcqfl, resource: bindings, ignored listing per whitelist
Dec  6 01:59:27.981: INFO: namespace e2e-tests-secrets-qcqfl deletion completed in 6.17237642s

• [SLOW TEST:10.629 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:59:27.981: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 01:59:28.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-4ws5d'
Dec  6 01:59:28.339: INFO: stderr: ""
Dec  6 01:59:28.339: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
Dec  6 01:59:32.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-4ws5d'
Dec  6 01:59:32.444: INFO: stderr: ""
Dec  6 01:59:32.444: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 01:59:32.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4ws5d" for this suite.
Dec  6 01:59:38.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 01:59:38.573: INFO: namespace: e2e-tests-kubectl-4ws5d, resource: bindings, ignored listing per whitelist
Dec  6 01:59:38.697: INFO: namespace e2e-tests-kubectl-4ws5d deletion completed in 6.246328636s

• [SLOW TEST:10.716 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 01:59:38.697: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  6 01:59:39.223: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127422,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  6 01:59:39.223: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127422,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  6 01:59:49.292: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127440,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  6 01:59:49.292: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127440,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  6 01:59:59.325: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127459,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  6 01:59:59.325: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127459,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  6 02:00:09.352: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127478,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  6 02:00:09.352: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-a,UID:96dfe941-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127478,Generation:0,CreationTimestamp:2018-12-06 01:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  6 02:00:19.428: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-b,UID:aece967d-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127497,Generation:0,CreationTimestamp:2018-12-06 02:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  6 02:00:19.428: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-b,UID:aece967d-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127497,Generation:0,CreationTimestamp:2018-12-06 02:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  6 02:00:29.510: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-b,UID:aece967d-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127516,Generation:0,CreationTimestamp:2018-12-06 02:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  6 02:00:29.510: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-t9r9f,SelfLink:/api/v1/namespaces/e2e-tests-watch-t9r9f/configmaps/e2e-watch-test-configmap-b,UID:aece967d-f8fa-11e8-bab4-448a5b81d79a,ResourceVersion:127516,Generation:0,CreationTimestamp:2018-12-06 02:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:00:39.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-t9r9f" for this suite.
Dec  6 02:00:45.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:00:45.700: INFO: namespace: e2e-tests-watch-t9r9f, resource: bindings, ignored listing per whitelist
Dec  6 02:00:45.770: INFO: namespace e2e-tests-watch-t9r9f deletion completed in 6.199704368s

• [SLOW TEST:67.073 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:00:45.770: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-jxc2l/configmap-test-bebb07df-f8fa-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:00:46.089: INFO: Waiting up to 5m0s for pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-jxc2l" to be "success or failure"
Dec  6 02:00:46.094: INFO: Pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.603106ms
Dec  6 02:00:48.098: INFO: Pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009097387s
Dec  6 02:00:50.103: INFO: Pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013660412s
Dec  6 02:00:52.107: INFO: Pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018153268s
Dec  6 02:00:54.112: INFO: Pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.022351965s
STEP: Saw pod success
Dec  6 02:00:54.112: INFO: Pod "pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:00:54.115: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1 container env-test: <nil>
STEP: delete the pod
Dec  6 02:00:54.162: INFO: Waiting for pod pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:00:54.169: INFO: Pod pod-configmaps-bec14f75-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:00:54.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jxc2l" for this suite.
Dec  6 02:01:02.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:01:02.332: INFO: namespace: e2e-tests-configmap-jxc2l, resource: bindings, ignored listing per whitelist
Dec  6 02:01:02.377: INFO: namespace e2e-tests-configmap-jxc2l deletion completed in 8.19885466s

• [SLOW TEST:16.607 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:01:02.377: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:01:02.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-6vhbd" to be "success or failure"
Dec  6 02:01:02.717: INFO: Pod "downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.458962ms
Dec  6 02:01:04.722: INFO: Pod "downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007958531s
Dec  6 02:01:06.726: INFO: Pod "downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012603705s
STEP: Saw pod success
Dec  6 02:01:06.726: INFO: Pod "downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:01:06.730: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:01:06.801: INFO: Waiting for pod downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:01:06.806: INFO: Pod downwardapi-volume-c8a86e75-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:01:06.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vhbd" for this suite.
Dec  6 02:01:12.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:01:12.896: INFO: namespace: e2e-tests-projected-6vhbd, resource: bindings, ignored listing per whitelist
Dec  6 02:01:12.996: INFO: namespace e2e-tests-projected-6vhbd deletion completed in 6.182076367s

• [SLOW TEST:10.619 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:01:12.996: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xgdhr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  6 02:01:13.269: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  6 02:01:43.693: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.55:8080/dial?request=hostName&protocol=http&host=10.244.3.51&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xgdhr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:01:43.693: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:01:43.787: INFO: Waiting for endpoints: map[]
Dec  6 02:01:43.813: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.55:8080/dial?request=hostName&protocol=http&host=10.244.4.54&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-xgdhr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:01:43.813: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:01:43.884: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:01:43.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xgdhr" for this suite.
Dec  6 02:02:07.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:02:07.997: INFO: namespace: e2e-tests-pod-network-test-xgdhr, resource: bindings, ignored listing per whitelist
Dec  6 02:02:08.098: INFO: namespace e2e-tests-pod-network-test-xgdhr deletion completed in 24.207656434s

• [SLOW TEST:55.102 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:02:08.098: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:02:08.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-4fwvq" to be "success or failure"
Dec  6 02:02:08.445: INFO: Pod "downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.639451ms
Dec  6 02:02:10.461: INFO: Pod "downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019862376s
Dec  6 02:02:12.467: INFO: Pod "downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025670759s
STEP: Saw pod success
Dec  6 02:02:12.467: INFO: Pod "downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:02:12.476: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:02:12.592: INFO: Waiting for pod downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:02:12.596: INFO: Pod downwardapi-volume-efce791a-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:02:12.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4fwvq" for this suite.
Dec  6 02:02:18.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:02:18.751: INFO: namespace: e2e-tests-downward-api-4fwvq, resource: bindings, ignored listing per whitelist
Dec  6 02:02:18.832: INFO: namespace e2e-tests-downward-api-4fwvq deletion completed in 6.229239629s

• [SLOW TEST:10.734 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:02:18.832: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:02:19.139: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-t2xdk" to be "success or failure"
Dec  6 02:02:19.143: INFO: Pod "downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.839128ms
Dec  6 02:02:21.148: INFO: Pod "downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008523501s
Dec  6 02:02:23.155: INFO: Pod "downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015813534s
STEP: Saw pod success
Dec  6 02:02:23.155: INFO: Pod "downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:02:23.161: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:02:23.281: INFO: Waiting for pod downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:02:23.288: INFO: Pod downwardapi-volume-f634e17c-f8fa-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:02:23.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t2xdk" for this suite.
Dec  6 02:02:29.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:02:29.430: INFO: namespace: e2e-tests-projected-t2xdk, resource: bindings, ignored listing per whitelist
Dec  6 02:02:29.467: INFO: namespace e2e-tests-projected-t2xdk deletion completed in 6.168957586s

• [SLOW TEST:10.635 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:02:29.467: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 02:02:29.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-xb9nt'
Dec  6 02:02:30.007: INFO: stderr: ""
Dec  6 02:02:30.007: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
Dec  6 02:02:30.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xb9nt'
Dec  6 02:02:34.271: INFO: stderr: ""
Dec  6 02:02:34.271: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:02:34.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xb9nt" for this suite.
Dec  6 02:02:40.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:02:40.451: INFO: namespace: e2e-tests-kubectl-xb9nt, resource: bindings, ignored listing per whitelist
Dec  6 02:02:40.617: INFO: namespace e2e-tests-kubectl-xb9nt deletion completed in 6.33869282s

• [SLOW TEST:11.150 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:02:40.617: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:02:40.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 version --client'
Dec  6 02:02:40.893: INFO: stderr: ""
Dec  6 02:02:40.893: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  6 02:02:40.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-p4rkq'
Dec  6 02:02:41.156: INFO: stderr: ""
Dec  6 02:02:41.156: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  6 02:02:41.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-p4rkq'
Dec  6 02:02:41.572: INFO: stderr: ""
Dec  6 02:02:41.572: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  6 02:02:42.596: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:02:42.596: INFO: Found 0 / 1
Dec  6 02:02:43.577: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:02:43.577: INFO: Found 0 / 1
Dec  6 02:02:44.576: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:02:44.576: INFO: Found 1 / 1
Dec  6 02:02:44.576: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  6 02:02:44.580: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:02:44.580: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  6 02:02:44.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 describe pod redis-master-5s4wb --namespace=e2e-tests-kubectl-p4rkq'
Dec  6 02:02:44.664: INFO: stderr: ""
Dec  6 02:02:44.664: INFO: stdout: "Name:               redis-master-5s4wb\nNamespace:          e2e-tests-kubectl-p4rkq\nPriority:           0\nPriorityClassName:  <none>\nNode:               k8s-g1/172.22.132.13\nStart Time:         Thu, 06 Dec 2018 02:02:41 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP=10.244.3.54/32\nStatus:             Running\nIP:                 10.244.3.54\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://bde9a77caaba1f588dfcd9a7c8aef6f04d7c9fa51b1ba05cdfd8621409576c49\n    Image:          gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis-amd64@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 06 Dec 2018 02:02:43 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-nr69g (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-nr69g:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-nr69g\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-p4rkq/redis-master-5s4wb to k8s-g1\n  Normal  Pulled     2s    kubelet, k8s-g1    Container image \"gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\" already present on machine\n  Normal  Created    1s    kubelet, k8s-g1    Created container\n  Normal  Started    1s    kubelet, k8s-g1    Started container\n"
Dec  6 02:02:44.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 describe rc redis-master --namespace=e2e-tests-kubectl-p4rkq'
Dec  6 02:02:44.769: INFO: stderr: ""
Dec  6 02:02:44.769: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-p4rkq\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-5s4wb\n"
Dec  6 02:02:44.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 describe service redis-master --namespace=e2e-tests-kubectl-p4rkq'
Dec  6 02:02:44.846: INFO: stderr: ""
Dec  6 02:02:44.846: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-p4rkq\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.2.33\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.3.54:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  6 02:02:44.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 describe node k8s-g1'
Dec  6 02:02:44.937: INFO: stderr: ""
Dec  6 02:02:44.937: INFO: stdout: "Name:               k8s-g1\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=k8s-g1\nAnnotations:        node.alpha.kubernetes.io/ttl=0\n                    projectcalico.org/IPv4Address=172.22.132.13/24\n                    volumes.kubernetes.io/controller-managed-attach-detach=true\nCreationTimestamp:  Wed, 05 Dec 2018 06:20:36 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Thu, 06 Dec 2018 02:02:40 +0000   Wed, 05 Dec 2018 06:20:36 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Thu, 06 Dec 2018 02:02:40 +0000   Wed, 05 Dec 2018 06:20:36 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 06 Dec 2018 02:02:40 +0000   Wed, 05 Dec 2018 06:20:36 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 06 Dec 2018 02:02:40 +0000   Wed, 05 Dec 2018 06:20:36 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 06 Dec 2018 02:02:40 +0000   Wed, 05 Dec 2018 06:21:27 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.22.132.13\n  Hostname:    k8s-g1\nCapacity:\n cpu:                4\n ephemeral-storage:  961302540Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16365776Ki\n nvidia.com/gpu:     1\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  885936419398\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16263376Ki\n nvidia.com/gpu:     1\n pods:               110\nSystem Info:\n Machine ID:                 5d9197e8949045c890fc367ea7126bc2\n System UUID:                00000000-0000-0000-0000-448A5BA4BD34\n Boot ID:                    9b22f364-d7cf-4023-bf5a-9f64e88a9c02\n Kernel Version:             4.4.0-138-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.3.0\n Kubelet Version:            v1.11.5\n Kube-Proxy Version:         v1.11.5\nPodCIDR:                     10.244.3.0/24\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-p4rkq    redis-master-5s4wb                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-8vjk4    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-4mdfp                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-7jvxn                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                nvidia-device-plugin-daemonset-smpqz                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource        Requests   Limits\n  --------        --------   ------\n  cpu             250m (6%)  0 (0%)\n  memory          0 (0%)     0 (0%)\n  nvidia.com/gpu  0          0\nEvents:           <none>\n"
Dec  6 02:02:44.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 describe namespace e2e-tests-kubectl-p4rkq'
Dec  6 02:02:45.017: INFO: stderr: ""
Dec  6 02:02:45.017: INFO: stdout: "Name:         e2e-tests-kubectl-p4rkq\nLabels:       e2e-framework=kubectl\n              e2e-run=377b980a-f8fa-11e8-a2c6-1eb929de0ff1\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:02:45.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p4rkq" for this suite.
Dec  6 02:03:09.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:03:09.187: INFO: namespace: e2e-tests-kubectl-p4rkq, resource: bindings, ignored listing per whitelist
Dec  6 02:03:09.254: INFO: namespace e2e-tests-kubectl-p4rkq deletion completed in 24.230483354s

• [SLOW TEST:28.637 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:03:09.254: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:03:09.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-5xz7h" to be "success or failure"
Dec  6 02:03:09.540: INFO: Pod "downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.565877ms
Dec  6 02:03:11.545: INFO: Pod "downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03943283s
Dec  6 02:03:13.549: INFO: Pod "downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043968886s
STEP: Saw pod success
Dec  6 02:03:13.549: INFO: Pod "downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:03:13.585: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:03:13.708: INFO: Waiting for pod downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:03:13.713: INFO: Pod downwardapi-volume-143c5b38-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:03:13.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5xz7h" for this suite.
Dec  6 02:03:19.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:03:19.928: INFO: namespace: e2e-tests-downward-api-5xz7h, resource: bindings, ignored listing per whitelist
Dec  6 02:03:19.976: INFO: namespace e2e-tests-downward-api-5xz7h deletion completed in 6.254882281s

• [SLOW TEST:10.722 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:03:19.976: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating api versions
Dec  6 02:03:20.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 api-versions'
Dec  6 02:03:20.403: INFO: stderr: ""
Dec  6 02:03:20.403: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:03:20.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rf9kf" for this suite.
Dec  6 02:03:26.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:03:26.451: INFO: namespace: e2e-tests-kubectl-rf9kf, resource: bindings, ignored listing per whitelist
Dec  6 02:03:26.628: INFO: namespace e2e-tests-kubectl-rf9kf deletion completed in 6.219552932s

• [SLOW TEST:6.653 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:03:26.628: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  6 02:03:36.997: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:36.997: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.077: INFO: Exec stderr: ""
Dec  6 02:03:37.077: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.077: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.152: INFO: Exec stderr: ""
Dec  6 02:03:37.152: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.152: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.243: INFO: Exec stderr: ""
Dec  6 02:03:37.243: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.243: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.321: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  6 02:03:37.321: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.321: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.391: INFO: Exec stderr: ""
Dec  6 02:03:37.391: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.391: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.453: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  6 02:03:37.453: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.453: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.577: INFO: Exec stderr: ""
Dec  6 02:03:37.577: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.577: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.641: INFO: Exec stderr: ""
Dec  6 02:03:37.641: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.641: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.718: INFO: Exec stderr: ""
Dec  6 02:03:37.718: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-2nf44 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:03:37.718: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:03:37.786: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:03:37.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-2nf44" for this suite.
Dec  6 02:04:17.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:04:17.981: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-2nf44, resource: bindings, ignored listing per whitelist
Dec  6 02:04:18.003: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-2nf44 deletion completed in 40.210762424s

• [SLOW TEST:51.375 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:04:18.003: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-3d4a5150-f8fb-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:04:18.517: INFO: Waiting up to 5m0s for pod "pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-pp9k7" to be "success or failure"
Dec  6 02:04:18.542: INFO: Pod "pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 25.110023ms
Dec  6 02:04:20.557: INFO: Pod "pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039737864s
Dec  6 02:04:22.561: INFO: Pod "pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044100442s
STEP: Saw pod success
Dec  6 02:04:22.561: INFO: Pod "pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:04:22.565: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:04:22.645: INFO: Waiting for pod pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:04:22.650: INFO: Pod pod-secrets-3d5da477-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:04:22.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pp9k7" for this suite.
Dec  6 02:04:28.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:04:28.776: INFO: namespace: e2e-tests-secrets-pp9k7, resource: bindings, ignored listing per whitelist
Dec  6 02:04:28.859: INFO: namespace e2e-tests-secrets-pp9k7 deletion completed in 6.200145347s

• [SLOW TEST:10.855 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:04:28.859: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:04:29.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-j9hnk" to be "success or failure"
Dec  6 02:04:29.290: INFO: Pod "downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 87.082621ms
Dec  6 02:04:31.322: INFO: Pod "downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119389858s
Dec  6 02:04:33.326: INFO: Pod "downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123192557s
STEP: Saw pod success
Dec  6 02:04:33.326: INFO: Pod "downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:04:33.329: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:04:33.450: INFO: Waiting for pod downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:04:33.454: INFO: Pod downwardapi-volume-43b6ca1b-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:04:33.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j9hnk" for this suite.
Dec  6 02:04:39.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:04:39.699: INFO: namespace: e2e-tests-downward-api-j9hnk, resource: bindings, ignored listing per whitelist
Dec  6 02:04:39.739: INFO: namespace e2e-tests-downward-api-j9hnk deletion completed in 6.26463749s

• [SLOW TEST:10.880 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:04:39.739: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-zg6sb
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-zg6sb
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-zg6sb
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-zg6sb
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-zg6sb
Dec  6 02:04:44.164: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zg6sb, name: ss-0, uid: 4b7332a5-f8fb-11e8-95b4-54a05085d523, status phase: Failed. Waiting for statefulset controller to delete.
Dec  6 02:04:46.663: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zg6sb, name: ss-0, uid: 4b7332a5-f8fb-11e8-95b4-54a05085d523, status phase: Failed. Waiting for statefulset controller to delete.
Dec  6 02:04:46.671: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-zg6sb
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-zg6sb
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-zg6sb and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Dec  6 02:04:50.875: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zg6sb
Dec  6 02:04:50.879: INFO: Scaling statefulset ss to 0
Dec  6 02:05:00.972: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:05:00.976: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:05:01.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zg6sb" for this suite.
Dec  6 02:05:09.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:05:09.252: INFO: namespace: e2e-tests-statefulset-zg6sb, resource: bindings, ignored listing per whitelist
Dec  6 02:05:09.270: INFO: namespace e2e-tests-statefulset-zg6sb deletion completed in 8.23291951s

• [SLOW TEST:29.531 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:05:09.270: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-5bc653ed-f8fb-11e8-a2c6-1eb929de0ff1
STEP: Creating configMap with name cm-test-opt-upd-5bc65459-f8fb-11e8-a2c6-1eb929de0ff1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5bc653ed-f8fb-11e8-a2c6-1eb929de0ff1
STEP: Updating configmap cm-test-opt-upd-5bc65459-f8fb-11e8-a2c6-1eb929de0ff1
STEP: Creating configMap with name cm-test-opt-create-5bc65487-f8fb-11e8-a2c6-1eb929de0ff1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:05:17.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zqqr7" for this suite.
Dec  6 02:05:42.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:05:42.101: INFO: namespace: e2e-tests-projected-zqqr7, resource: bindings, ignored listing per whitelist
Dec  6 02:05:42.168: INFO: namespace e2e-tests-projected-zqqr7 deletion completed in 24.166843165s

• [SLOW TEST:32.897 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:05:42.168: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:05:42.457: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-6w56s" to be "success or failure"
Dec  6 02:05:42.512: INFO: Pod "downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 55.404976ms
Dec  6 02:05:44.537: INFO: Pod "downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08036236s
Dec  6 02:05:46.579: INFO: Pod "downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122239281s
STEP: Saw pod success
Dec  6 02:05:46.579: INFO: Pod "downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:05:46.583: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:05:46.639: INFO: Waiting for pod downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:05:46.643: INFO: Pod downwardapi-volume-6f664ff3-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:05:46.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6w56s" for this suite.
Dec  6 02:05:52.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:05:52.777: INFO: namespace: e2e-tests-downward-api-6w56s, resource: bindings, ignored listing per whitelist
Dec  6 02:05:52.877: INFO: namespace e2e-tests-downward-api-6w56s deletion completed in 6.225664269s

• [SLOW TEST:10.709 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:05:52.877: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: executing a command with run --rm and attach with stdin
Dec  6 02:05:53.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 --namespace=e2e-tests-kubectl-zd2pm run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  6 02:06:01.425: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
Dec  6 02:06:01.425: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:06:03.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zd2pm" for this suite.
Dec  6 02:06:09.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:06:09.522: INFO: namespace: e2e-tests-kubectl-zd2pm, resource: bindings, ignored listing per whitelist
Dec  6 02:06:09.672: INFO: namespace e2e-tests-kubectl-zd2pm deletion completed in 6.231968999s

• [SLOW TEST:16.795 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:06:09.672: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 02:06:09.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-2nv6v'
Dec  6 02:06:10.029: INFO: stderr: ""
Dec  6 02:06:10.029: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  6 02:06:12.076: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-shl5r]
Dec  6 02:06:12.076: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-shl5r" in namespace "e2e-tests-kubectl-2nv6v" to be "running and ready"
Dec  6 02:06:12.081: INFO: Pod "e2e-test-nginx-rc-shl5r": Phase="Pending", Reason="", readiness=false. Elapsed: 5.125952ms
Dec  6 02:06:14.086: INFO: Pod "e2e-test-nginx-rc-shl5r": Phase="Running", Reason="", readiness=true. Elapsed: 2.009941973s
Dec  6 02:06:14.086: INFO: Pod "e2e-test-nginx-rc-shl5r" satisfied condition "running and ready"
Dec  6 02:06:14.086: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-shl5r]
Dec  6 02:06:14.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2nv6v'
Dec  6 02:06:14.166: INFO: stderr: ""
Dec  6 02:06:14.166: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
Dec  6 02:06:14.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2nv6v'
Dec  6 02:06:14.288: INFO: stderr: ""
Dec  6 02:06:14.288: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:06:14.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2nv6v" for this suite.
Dec  6 02:06:38.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:06:38.508: INFO: namespace: e2e-tests-kubectl-2nv6v, resource: bindings, ignored listing per whitelist
Dec  6 02:06:38.569: INFO: namespace e2e-tests-kubectl-2nv6v deletion completed in 24.2745103s

• [SLOW TEST:28.898 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:06:38.569: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
Dec  6 02:06:38.936: INFO: Waiting up to 5m0s for pod "client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-containers-xslw2" to be "success or failure"
Dec  6 02:06:38.939: INFO: Pod "client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.641933ms
Dec  6 02:06:40.944: INFO: Pod "client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008090918s
Dec  6 02:06:42.957: INFO: Pod "client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021407298s
Dec  6 02:06:44.962: INFO: Pod "client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026193808s
STEP: Saw pod success
Dec  6 02:06:44.962: INFO: Pod "client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:06:44.967: INFO: Trying to get logs from node k8s-g1 pod client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:06:45.031: INFO: Waiting for pod client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:06:45.038: INFO: Pod client-containers-9109fe0b-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:06:45.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xslw2" for this suite.
Dec  6 02:06:51.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:06:51.242: INFO: namespace: e2e-tests-containers-xslw2, resource: bindings, ignored listing per whitelist
Dec  6 02:06:51.321: INFO: namespace e2e-tests-containers-xslw2 deletion completed in 6.275565869s

• [SLOW TEST:12.752 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:06:51.321: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:06:51.732: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-p5t2c" to be "success or failure"
Dec  6 02:06:51.737: INFO: Pod "downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.120859ms
Dec  6 02:06:53.741: INFO: Pod "downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008497059s
Dec  6 02:06:55.746: INFO: Pod "downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013500106s
STEP: Saw pod success
Dec  6 02:06:55.746: INFO: Pod "downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:06:55.750: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:06:55.823: INFO: Waiting for pod downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:06:55.827: INFO: Pod downwardapi-volume-98a528cf-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:06:55.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p5t2c" for this suite.
Dec  6 02:07:01.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:07:01.917: INFO: namespace: e2e-tests-projected-p5t2c, resource: bindings, ignored listing per whitelist
Dec  6 02:07:01.999: INFO: namespace e2e-tests-projected-p5t2c deletion completed in 6.164595673s

• [SLOW TEST:10.678 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:07:01.999: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Dec  6 02:07:02.402: INFO: Waiting up to 5m0s for pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-wvnbj" to be "success or failure"
Dec  6 02:07:02.434: INFO: Pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 31.412711ms
Dec  6 02:07:04.438: INFO: Pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036118847s
Dec  6 02:07:06.443: INFO: Pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040281054s
Dec  6 02:07:08.485: INFO: Pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082780681s
Dec  6 02:07:10.489: INFO: Pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.086854019s
STEP: Saw pod success
Dec  6 02:07:10.489: INFO: Pod "downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:07:10.493: INFO: Trying to get logs from node k8s-g1 pod downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 02:07:10.574: INFO: Waiting for pod downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:07:10.579: INFO: Pod downward-api-9f026f79-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:07:10.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wvnbj" for this suite.
Dec  6 02:07:16.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:07:16.769: INFO: namespace: e2e-tests-downward-api-wvnbj, resource: bindings, ignored listing per whitelist
Dec  6 02:07:16.783: INFO: namespace e2e-tests-downward-api-wvnbj deletion completed in 6.195761136s

• [SLOW TEST:14.784 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:07:16.783: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-a7c5850d-f8fb-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:07:17.112: INFO: Waiting up to 5m0s for pod "pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-xw6wb" to be "success or failure"
Dec  6 02:07:17.116: INFO: Pod "pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.695283ms
Dec  6 02:07:19.120: INFO: Pod "pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007723201s
Dec  6 02:07:21.124: INFO: Pod "pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011741577s
STEP: Saw pod success
Dec  6 02:07:21.124: INFO: Pod "pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:07:21.128: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:07:21.198: INFO: Waiting for pod pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:07:21.202: INFO: Pod pod-secrets-a7d0c640-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:07:21.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xw6wb" for this suite.
Dec  6 02:07:27.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:07:27.361: INFO: namespace: e2e-tests-secrets-xw6wb, resource: bindings, ignored listing per whitelist
Dec  6 02:07:27.368: INFO: namespace e2e-tests-secrets-xw6wb deletion completed in 6.158763743s

• [SLOW TEST:10.585 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:07:27.368: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-vmxbq.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-vmxbq.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-vmxbq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-vmxbq.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-vmxbq.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-vmxbq.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  6 02:07:59.826: INFO: DNS probes using dns-test-ae19a355-f8fb-11e8-a2c6-1eb929de0ff1 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:07:59.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-vmxbq" for this suite.
Dec  6 02:08:07.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:08:07.948: INFO: namespace: e2e-tests-dns-vmxbq, resource: bindings, ignored listing per whitelist
Dec  6 02:08:08.074: INFO: namespace e2e-tests-dns-vmxbq deletion completed in 8.168295037s

• [SLOW TEST:40.706 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:08:08.075: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  6 02:08:08.398: INFO: Waiting up to 5m0s for pod "pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-8drnn" to be "success or failure"
Dec  6 02:08:08.490: INFO: Pod "pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 92.060767ms
Dec  6 02:08:10.494: INFO: Pod "pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095877136s
Dec  6 02:08:12.500: INFO: Pod "pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.101793811s
STEP: Saw pod success
Dec  6 02:08:12.500: INFO: Pod "pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:08:12.503: INFO: Trying to get logs from node k8s-g2 pod pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:08:12.590: INFO: Waiting for pod pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:08:12.598: INFO: Pod pod-c6609e34-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:08:12.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8drnn" for this suite.
Dec  6 02:08:18.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:08:18.764: INFO: namespace: e2e-tests-emptydir-8drnn, resource: bindings, ignored listing per whitelist
Dec  6 02:08:18.774: INFO: namespace e2e-tests-emptydir-8drnn deletion completed in 6.167459596s

• [SLOW TEST:10.700 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:08:18.774: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Dec  6 02:08:23.680: INFO: Successfully updated pod "labelsupdateccc6650e-f8fb-11e8-a2c6-1eb929de0ff1"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:08:25.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6nrq9" for this suite.
Dec  6 02:08:47.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:08:47.848: INFO: namespace: e2e-tests-projected-6nrq9, resource: bindings, ignored listing per whitelist
Dec  6 02:08:47.944: INFO: namespace e2e-tests-projected-6nrq9 deletion completed in 22.233705569s

• [SLOW TEST:29.170 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:08:47.945: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  6 02:08:48.400: INFO: Waiting up to 5m0s for pod "pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-95t8v" to be "success or failure"
Dec  6 02:08:48.423: INFO: Pod "pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.531404ms
Dec  6 02:08:50.428: INFO: Pod "pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027776505s
Dec  6 02:08:52.432: INFO: Pod "pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031526105s
STEP: Saw pod success
Dec  6 02:08:52.432: INFO: Pod "pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:08:52.435: INFO: Trying to get logs from node k8s-g2 pod pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:08:52.547: INFO: Waiting for pod pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:08:52.551: INFO: Pod pod-de33b228-f8fb-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:08:52.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-95t8v" for this suite.
Dec  6 02:08:58.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:08:58.728: INFO: namespace: e2e-tests-emptydir-95t8v, resource: bindings, ignored listing per whitelist
Dec  6 02:08:58.826: INFO: namespace e2e-tests-emptydir-95t8v deletion completed in 6.267823826s

• [SLOW TEST:10.881 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:08:58.826: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:09:23.228: INFO: Container started at 2018-12-06 02:09:01 +0000 UTC, pod became ready at 2018-12-06 02:09:22 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:09:23.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-46k6j" for this suite.
Dec  6 02:09:47.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:09:47.362: INFO: namespace: e2e-tests-container-probe-46k6j, resource: bindings, ignored listing per whitelist
Dec  6 02:09:47.490: INFO: namespace e2e-tests-container-probe-46k6j deletion completed in 24.226647415s

• [SLOW TEST:48.664 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:09:47.491: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  6 02:09:47.786: INFO: Waiting up to 5m0s for pod "pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-b2gn8" to be "success or failure"
Dec  6 02:09:47.789: INFO: Pod "pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.079453ms
Dec  6 02:09:49.807: INFO: Pod "pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020365072s
Dec  6 02:09:51.814: INFO: Pod "pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027585289s
STEP: Saw pod success
Dec  6 02:09:51.814: INFO: Pod "pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:09:51.823: INFO: Trying to get logs from node k8s-g2 pod pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:09:51.879: INFO: Waiting for pod pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:09:51.884: INFO: Pod pod-019c01e9-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:09:51.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b2gn8" for this suite.
Dec  6 02:09:57.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:09:58.014: INFO: namespace: e2e-tests-emptydir-b2gn8, resource: bindings, ignored listing per whitelist
Dec  6 02:09:58.109: INFO: namespace e2e-tests-emptydir-b2gn8 deletion completed in 6.216327639s

• [SLOW TEST:10.619 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:09:58.110: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Dec  6 02:09:58.395: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  6 02:10:58.428: INFO: Waiting for terminating namespaces to be deleted...
Dec  6 02:10:58.435: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  6 02:10:58.449: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  6 02:10:58.449: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  6 02:10:58.455: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Dec  6 02:10:58.455: INFO: 
Logging pods the kubelet thinks is on node k8s-g1 before test
Dec  6 02:10:58.464: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-06 01:55:44 +0000 UTC (1 container statuses recorded)
Dec  6 02:10:58.464: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  6 02:10:58.464: INFO: sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-8vjk4 from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 02:10:58.464: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  6 02:10:58.464: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  6 02:10:58.464: INFO: nvidia-device-plugin-daemonset-smpqz from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:10:58.464: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  6 02:10:58.464: INFO: kube-proxy-7jvxn from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:10:58.464: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  6 02:10:58.464: INFO: calico-node-4mdfp from kube-system started at 2018-12-05 06:20:39 +0000 UTC (2 container statuses recorded)
Dec  6 02:10:58.464: INFO: 	Container calico-node ready: true, restart count 0
Dec  6 02:10:58.464: INFO: 	Container install-cni ready: true, restart count 0
Dec  6 02:10:58.464: INFO: 
Logging pods the kubelet thinks is on node k8s-g2 before test
Dec  6 02:10:58.472: INFO: nvidia-device-plugin-daemonset-nkqbb from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:10:58.472: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  6 02:10:58.472: INFO: kube-proxy-bvq6r from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:10:58.472: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  6 02:10:58.472: INFO: calico-node-q6m2b from kube-system started at 2018-12-05 06:20:39 +0000 UTC (2 container statuses recorded)
Dec  6 02:10:58.472: INFO: 	Container calico-node ready: true, restart count 0
Dec  6 02:10:58.472: INFO: 	Container install-cni ready: true, restart count 0
Dec  6 02:10:58.472: INFO: tf-gpu-1-56564965df-4kqpb from default started at 2018-12-05 06:32:16 +0000 UTC (1 container statuses recorded)
Dec  6 02:10:58.472: INFO: 	Container tensorflow ready: true, restart count 0
Dec  6 02:10:58.472: INFO: sonobuoy-e2e-job-9cb377fd61834674 from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 02:10:58.472: INFO: 	Container e2e ready: true, restart count 0
Dec  6 02:10:58.472: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  6 02:10:58.472: INFO: sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-nl2hx from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 02:10:58.472: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  6 02:10:58.472: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2e3c3b10-f8fc-11e8-a2c6-1eb929de0ff1 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-2e3c3b10-f8fc-11e8-a2c6-1eb929de0ff1 off the node k8s-g1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2e3c3b10-f8fc-11e8-a2c6-1eb929de0ff1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:11:06.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9sx29" for this suite.
Dec  6 02:11:18.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:11:19.137: INFO: namespace: e2e-tests-sched-pred-9sx29, resource: bindings, ignored listing per whitelist
Dec  6 02:11:19.159: INFO: namespace e2e-tests-sched-pred-9sx29 deletion completed in 12.236984197s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:81.049 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:11:19.159: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-383fd4da-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating secret with name s-test-opt-upd-383fd502-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-383fd4da-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Updating secret s-test-opt-upd-383fd502-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating secret with name s-test-opt-create-383fd510-f8fc-11e8-a2c6-1eb929de0ff1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:11:26.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pqggn" for this suite.
Dec  6 02:11:50.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:11:50.118: INFO: namespace: e2e-tests-secrets-pqggn, resource: bindings, ignored listing per whitelist
Dec  6 02:11:50.225: INFO: namespace e2e-tests-secrets-pqggn deletion completed in 24.217158701s

• [SLOW TEST:31.065 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:11:50.225: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:11:50.668: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4ac43cf7-f8fc-11e8-bab4-448a5b81d79a", Controller:(*bool)(0xc420a0176a), BlockOwnerDeletion:(*bool)(0xc420a0176b)}}
Dec  6 02:11:50.739: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4aba4fce-f8fc-11e8-bab4-448a5b81d79a", Controller:(*bool)(0xc4224da21a), BlockOwnerDeletion:(*bool)(0xc4224da21b)}}
Dec  6 02:11:50.759: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4abc9e5f-f8fc-11e8-bab4-448a5b81d79a", Controller:(*bool)(0xc420a01952), BlockOwnerDeletion:(*bool)(0xc420a01953)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:11:55.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-x8z2f" for this suite.
Dec  6 02:12:01.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:12:02.031: INFO: namespace: e2e-tests-gc-x8z2f, resource: bindings, ignored listing per whitelist
Dec  6 02:12:02.105: INFO: namespace e2e-tests-gc-x8z2f deletion completed in 6.197496953s

• [SLOW TEST:11.880 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:12:02.105: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-51d81aed-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:12:02.458: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-bsf7v" to be "success or failure"
Dec  6 02:12:02.496: INFO: Pod "pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 38.326717ms
Dec  6 02:12:04.511: INFO: Pod "pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052966867s
Dec  6 02:12:06.516: INFO: Pod "pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058003797s
STEP: Saw pod success
Dec  6 02:12:06.516: INFO: Pod "pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:12:06.521: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:12:06.603: INFO: Waiting for pod pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:12:06.606: INFO: Pod pod-projected-configmaps-51e2dccb-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:12:06.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bsf7v" for this suite.
Dec  6 02:12:12.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:12:12.713: INFO: namespace: e2e-tests-projected-bsf7v, resource: bindings, ignored listing per whitelist
Dec  6 02:12:12.803: INFO: namespace e2e-tests-projected-bsf7v deletion completed in 6.189926381s

• [SLOW TEST:10.698 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:12:12.803: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-wb5wz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wb5wz to expose endpoints map[]
Dec  6 02:12:13.211: INFO: Get endpoints failed (3.774358ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  6 02:12:14.239: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wb5wz exposes endpoints map[] (1.032019463s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-wb5wz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wb5wz to expose endpoints map[pod1:[100]]
Dec  6 02:12:17.414: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wb5wz exposes endpoints map[pod1:[100]] (3.156465469s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-wb5wz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wb5wz to expose endpoints map[pod1:[100] pod2:[101]]
Dec  6 02:12:20.552: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wb5wz exposes endpoints map[pod1:[100] pod2:[101]] (3.109835033s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-wb5wz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wb5wz to expose endpoints map[pod2:[101]]
Dec  6 02:12:21.617: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wb5wz exposes endpoints map[pod2:[101]] (1.03822848s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-wb5wz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wb5wz to expose endpoints map[]
Dec  6 02:12:22.666: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wb5wz exposes endpoints map[] (1.009310665s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:12:22.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wb5wz" for this suite.
Dec  6 02:12:29.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:12:29.044: INFO: namespace: e2e-tests-services-wb5wz, resource: bindings, ignored listing per whitelist
Dec  6 02:12:29.134: INFO: namespace e2e-tests-services-wb5wz deletion completed in 6.160266888s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:16.331 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:12:29.134: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-61f85e57-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:12:29.477: INFO: Waiting up to 5m0s for pod "pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-bh7fb" to be "success or failure"
Dec  6 02:12:29.510: INFO: Pod "pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 33.079114ms
Dec  6 02:12:31.514: INFO: Pod "pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03700128s
Dec  6 02:12:33.518: INFO: Pod "pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040852968s
STEP: Saw pod success
Dec  6 02:12:33.518: INFO: Pod "pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:12:33.552: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:12:33.665: INFO: Waiting for pod pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:12:33.669: INFO: Pod pod-configmaps-6202316f-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:12:33.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bh7fb" for this suite.
Dec  6 02:12:39.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:12:39.809: INFO: namespace: e2e-tests-configmap-bh7fb, resource: bindings, ignored listing per whitelist
Dec  6 02:12:39.840: INFO: namespace e2e-tests-configmap-bh7fb deletion completed in 6.163657338s

• [SLOW TEST:10.706 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:12:39.840: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:12:40.173: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  6 02:12:40.226: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:40.226: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:40.226: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:40.230: INFO: Number of nodes with available pods: 0
Dec  6 02:12:40.230: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:12:41.235: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:41.235: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:41.235: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:41.239: INFO: Number of nodes with available pods: 0
Dec  6 02:12:41.239: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:12:42.235: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:42.236: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:42.236: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:42.239: INFO: Number of nodes with available pods: 0
Dec  6 02:12:42.239: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:12:43.281: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:43.281: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:43.281: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:43.287: INFO: Number of nodes with available pods: 0
Dec  6 02:12:43.287: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:12:44.284: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:44.284: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:44.284: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:44.288: INFO: Number of nodes with available pods: 0
Dec  6 02:12:44.288: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:12:45.235: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:45.235: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:45.235: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:45.239: INFO: Number of nodes with available pods: 2
Dec  6 02:12:45.239: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  6 02:12:45.290: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:45.290: INFO: Wrong image for pod: daemon-set-67k4p. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:45.320: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:45.320: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:45.320: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:46.324: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:46.324: INFO: Wrong image for pod: daemon-set-67k4p. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:46.331: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:46.331: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:46.331: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:47.325: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:47.325: INFO: Wrong image for pod: daemon-set-67k4p. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:47.334: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:47.334: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:47.334: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:48.326: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:48.326: INFO: Wrong image for pod: daemon-set-67k4p. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:48.326: INFO: Pod daemon-set-67k4p is not available
Dec  6 02:12:48.332: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:48.332: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:48.332: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:49.325: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:49.325: INFO: Pod daemon-set-jz8bk is not available
Dec  6 02:12:49.332: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:49.332: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:49.332: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:50.325: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:50.325: INFO: Pod daemon-set-jz8bk is not available
Dec  6 02:12:50.331: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:50.331: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:50.331: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:51.324: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:51.324: INFO: Pod daemon-set-jz8bk is not available
Dec  6 02:12:51.340: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:51.340: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:51.340: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:52.324: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:52.329: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:52.329: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:52.329: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:53.363: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:53.363: INFO: Pod daemon-set-4r67z is not available
Dec  6 02:12:53.368: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:53.368: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:53.368: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:54.331: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:54.331: INFO: Pod daemon-set-4r67z is not available
Dec  6 02:12:54.335: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:54.336: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:54.336: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:55.325: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:55.325: INFO: Pod daemon-set-4r67z is not available
Dec  6 02:12:55.330: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:55.330: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:55.330: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:56.325: INFO: Wrong image for pod: daemon-set-4r67z. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
Dec  6 02:12:56.325: INFO: Pod daemon-set-4r67z is not available
Dec  6 02:12:56.330: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:56.330: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:56.330: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:57.325: INFO: Pod daemon-set-txz2b is not available
Dec  6 02:12:57.329: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:57.329: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:57.329: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  6 02:12:57.333: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:57.333: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:57.333: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:57.336: INFO: Number of nodes with available pods: 1
Dec  6 02:12:57.336: INFO: Node k8s-g2 is running more than one daemon pod
Dec  6 02:12:58.341: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:58.341: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:58.341: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:58.345: INFO: Number of nodes with available pods: 1
Dec  6 02:12:58.345: INFO: Node k8s-g2 is running more than one daemon pod
Dec  6 02:12:59.341: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:59.341: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:59.341: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:12:59.345: INFO: Number of nodes with available pods: 1
Dec  6 02:12:59.345: INFO: Node k8s-g2 is running more than one daemon pod
Dec  6 02:13:00.342: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:00.342: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:00.342: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:00.354: INFO: Number of nodes with available pods: 1
Dec  6 02:13:00.354: INFO: Node k8s-g2 is running more than one daemon pod
Dec  6 02:13:01.344: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:01.344: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:01.344: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:01.348: INFO: Number of nodes with available pods: 1
Dec  6 02:13:01.348: INFO: Node k8s-g2 is running more than one daemon pod
Dec  6 02:13:02.342: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:02.342: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:02.342: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:13:02.346: INFO: Number of nodes with available pods: 2
Dec  6 02:13:02.346: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rshcd, will wait for the garbage collector to delete the pods
Dec  6 02:13:02.436: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.113613ms
Dec  6 02:13:02.636: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.163002ms
Dec  6 02:13:06.740: INFO: Number of nodes with available pods: 0
Dec  6 02:13:06.740: INFO: Number of running nodes: 0, number of available pods: 0
Dec  6 02:13:06.744: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rshcd/daemonsets","resourceVersion":"130146"},"items":null}

Dec  6 02:13:06.747: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rshcd/pods","resourceVersion":"130146"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:13:06.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rshcd" for this suite.
Dec  6 02:13:14.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:13:14.910: INFO: namespace: e2e-tests-daemonsets-rshcd, resource: bindings, ignored listing per whitelist
Dec  6 02:13:15.013: INFO: namespace e2e-tests-daemonsets-rshcd deletion completed in 8.209246735s

• [SLOW TEST:35.173 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:13:15.013: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:13:15.287: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
Dec  6 02:13:15.296: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-d4s6d/daemonsets","resourceVersion":"130196"},"items":null}

Dec  6 02:13:15.300: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-d4s6d/pods","resourceVersion":"130196"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:13:15.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-d4s6d" for this suite.
Dec  6 02:13:21.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:13:21.419: INFO: namespace: e2e-tests-daemonsets-d4s6d, resource: bindings, ignored listing per whitelist
Dec  6 02:13:21.555: INFO: namespace e2e-tests-daemonsets-d4s6d deletion completed in 6.238560243s

S [SKIPPING] [6.542 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

  Dec  6 02:13:15.287: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:13:21.555: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t6fgv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  6 02:13:21.787: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  6 02:13:48.260: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.3.74:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t6fgv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:13:48.260: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:13:48.332: INFO: Found all expected endpoints: [netserver-0]
Dec  6 02:13:48.336: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.4.69:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t6fgv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:13:48.336: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:13:48.400: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:13:48.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t6fgv" for this suite.
Dec  6 02:14:12.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:14:12.597: INFO: namespace: e2e-tests-pod-network-test-t6fgv, resource: bindings, ignored listing per whitelist
Dec  6 02:14:12.635: INFO: namespace e2e-tests-pod-network-test-t6fgv deletion completed in 24.229093978s

• [SLOW TEST:51.080 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:14:12.636: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-9fa8dc87-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:14:12.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-t7hfv" to be "success or failure"
Dec  6 02:14:12.987: INFO: Pod "pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900723ms
Dec  6 02:14:15.017: INFO: Pod "pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034324523s
Dec  6 02:14:17.021: INFO: Pod "pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038852827s
STEP: Saw pod success
Dec  6 02:14:17.021: INFO: Pod "pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:14:17.025: INFO: Trying to get logs from node k8s-g2 pod pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:14:17.117: INFO: Waiting for pod pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:14:17.121: INFO: Pod pod-configmaps-9fb1354c-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:14:17.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t7hfv" for this suite.
Dec  6 02:14:23.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:14:23.318: INFO: namespace: e2e-tests-configmap-t7hfv, resource: bindings, ignored listing per whitelist
Dec  6 02:14:23.329: INFO: namespace e2e-tests-configmap-t7hfv deletion completed in 6.199305308s

• [SLOW TEST:10.693 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:14:23.329: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-q2xrb
Dec  6 02:14:29.587: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-q2xrb
STEP: checking the pod's current state and verifying that restartCount is present
Dec  6 02:14:29.590: INFO: Initial restart count of pod liveness-http is 0
Dec  6 02:14:45.642: INFO: Restart count of pod e2e-tests-container-probe-q2xrb/liveness-http is now 1 (16.051966654s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:14:45.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q2xrb" for this suite.
Dec  6 02:14:51.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:14:51.937: INFO: namespace: e2e-tests-container-probe-q2xrb, resource: bindings, ignored listing per whitelist
Dec  6 02:14:52.015: INFO: namespace e2e-tests-container-probe-q2xrb deletion completed in 6.20547323s

• [SLOW TEST:28.686 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:14:52.015: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:14:52.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-k6z9v" to be "success or failure"
Dec  6 02:14:52.313: INFO: Pod "downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033777ms
Dec  6 02:14:54.360: INFO: Pod "downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051796929s
Dec  6 02:14:56.383: INFO: Pod "downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074542462s
STEP: Saw pod success
Dec  6 02:14:56.383: INFO: Pod "downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:14:56.393: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:14:56.551: INFO: Waiting for pod downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:14:56.555: INFO: Pod downwardapi-volume-b721a718-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:14:56.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k6z9v" for this suite.
Dec  6 02:15:02.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:15:02.643: INFO: namespace: e2e-tests-downward-api-k6z9v, resource: bindings, ignored listing per whitelist
Dec  6 02:15:02.742: INFO: namespace e2e-tests-downward-api-k6z9v deletion completed in 6.180284229s

• [SLOW TEST:10.728 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:15:02.743: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
Dec  6 02:15:02.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-9md8c'
Dec  6 02:15:05.861: INFO: stderr: ""
Dec  6 02:15:05.861: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  6 02:15:06.866: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:15:06.866: INFO: Found 0 / 1
Dec  6 02:15:07.865: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:15:07.865: INFO: Found 0 / 1
Dec  6 02:15:08.865: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:15:08.865: INFO: Found 1 / 1
Dec  6 02:15:08.865: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  6 02:15:08.868: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:15:08.868: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  6 02:15:08.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 patch pod redis-master-wgxmc --namespace=e2e-tests-kubectl-9md8c -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  6 02:15:09.044: INFO: stderr: ""
Dec  6 02:15:09.044: INFO: stdout: "pod/redis-master-wgxmc patched\n"
STEP: checking annotations
Dec  6 02:15:09.047: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:15:09.047: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:15:09.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9md8c" for this suite.
Dec  6 02:15:29.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:15:29.170: INFO: namespace: e2e-tests-kubectl-9md8c, resource: bindings, ignored listing per whitelist
Dec  6 02:15:29.270: INFO: namespace e2e-tests-kubectl-9md8c deletion completed in 20.217750572s

• [SLOW TEST:26.527 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:15:29.270: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  6 02:15:29.560: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:29.560: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:29.560: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:29.635: INFO: Number of nodes with available pods: 0
Dec  6 02:15:29.635: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:15:30.641: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:30.641: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:30.641: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:30.645: INFO: Number of nodes with available pods: 0
Dec  6 02:15:30.645: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:15:31.662: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:31.662: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:31.662: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:31.667: INFO: Number of nodes with available pods: 0
Dec  6 02:15:31.667: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:15:32.644: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:32.644: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:32.644: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:32.649: INFO: Number of nodes with available pods: 2
Dec  6 02:15:32.649: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  6 02:15:32.754: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:32.754: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:32.754: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:32.792: INFO: Number of nodes with available pods: 1
Dec  6 02:15:32.792: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:15:33.799: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:33.799: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:33.799: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:33.803: INFO: Number of nodes with available pods: 1
Dec  6 02:15:33.803: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:15:34.797: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:34.797: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:34.797: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:34.801: INFO: Number of nodes with available pods: 1
Dec  6 02:15:34.801: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:15:35.804: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:35.804: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:35.804: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:15:35.808: INFO: Number of nodes with available pods: 2
Dec  6 02:15:35.808: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-lf8xd, will wait for the garbage collector to delete the pods
Dec  6 02:15:35.897: INFO: Deleting {extensions DaemonSet} daemon-set took: 27.545146ms
Dec  6 02:15:36.097: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.114897ms
Dec  6 02:15:47.132: INFO: Number of nodes with available pods: 0
Dec  6 02:15:47.132: INFO: Number of running nodes: 0, number of available pods: 0
Dec  6 02:15:47.135: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lf8xd/daemonsets","resourceVersion":"130720"},"items":null}

Dec  6 02:15:47.138: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lf8xd/pods","resourceVersion":"130720"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:15:47.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lf8xd" for this suite.
Dec  6 02:15:55.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:15:55.391: INFO: namespace: e2e-tests-daemonsets-lf8xd, resource: bindings, ignored listing per whitelist
Dec  6 02:15:55.417: INFO: namespace e2e-tests-daemonsets-lf8xd deletion completed in 8.264694971s

• [SLOW TEST:26.147 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:15:55.418: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 02:15:55.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lwfxb'
Dec  6 02:15:55.883: INFO: stderr: ""
Dec  6 02:15:55.883: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  6 02:16:00.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lwfxb -o json'
Dec  6 02:16:01.059: INFO: stderr: ""
Dec  6 02:16:01.059: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.4.74/32\"\n        },\n        \"creationTimestamp\": \"2018-12-06T02:15:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-lwfxb\",\n        \"resourceVersion\": \"130774\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-lwfxb/pods/e2e-test-nginx-pod\",\n        \"uid\": \"dcfe04ee-f8fc-11e8-bab4-448a5b81d79a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-v77m2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"k8s-g2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-v77m2\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-v77m2\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-06T02:15:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-06T02:15:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-06T02:15:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://afb8f0e18cf8216bbe10a2d60c5fc7407a181d2b2a47e5317fbc60c47e980274\",\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-06T02:15:57Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.22.132.14\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.4.74\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-06T02:15:55Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  6 02:16:01.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 replace -f - --namespace=e2e-tests-kubectl-lwfxb'
Dec  6 02:16:01.337: INFO: stderr: ""
Dec  6 02:16:01.337: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
Dec  6 02:16:01.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lwfxb'
Dec  6 02:16:07.014: INFO: stderr: ""
Dec  6 02:16:07.014: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:16:07.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lwfxb" for this suite.
Dec  6 02:16:13.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:16:13.085: INFO: namespace: e2e-tests-kubectl-lwfxb, resource: bindings, ignored listing per whitelist
Dec  6 02:16:13.172: INFO: namespace e2e-tests-kubectl-lwfxb deletion completed in 6.148774888s

• [SLOW TEST:17.755 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:16:13.172: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:16:17.656: INFO: Waiting up to 5m0s for pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-pods-zrkpx" to be "success or failure"
Dec  6 02:16:17.753: INFO: Pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 97.122985ms
Dec  6 02:16:19.760: INFO: Pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104195691s
Dec  6 02:16:21.765: INFO: Pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108720273s
Dec  6 02:16:23.769: INFO: Pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.113104078s
Dec  6 02:16:25.774: INFO: Pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.117650094s
STEP: Saw pod success
Dec  6 02:16:25.774: INFO: Pod "client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:16:25.778: INFO: Trying to get logs from node k8s-g2 pod client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1 container env3cont: <nil>
STEP: delete the pod
Dec  6 02:16:25.863: INFO: Waiting for pod client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:16:25.960: INFO: Pod client-envvars-e9fc293a-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:16:25.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zrkpx" for this suite.
Dec  6 02:16:50.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:16:50.163: INFO: namespace: e2e-tests-pods-zrkpx, resource: bindings, ignored listing per whitelist
Dec  6 02:16:50.171: INFO: namespace e2e-tests-pods-zrkpx deletion completed in 24.163476249s

• [SLOW TEST:36.998 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:16:50.171: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-fd94141c-f8fc-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:16:50.532: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-jfqvk" to be "success or failure"
Dec  6 02:16:50.536: INFO: Pod "pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.942647ms
Dec  6 02:16:52.540: INFO: Pod "pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007602686s
Dec  6 02:16:54.547: INFO: Pod "pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014707125s
STEP: Saw pod success
Dec  6 02:16:54.547: INFO: Pod "pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:16:54.555: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:16:54.643: INFO: Waiting for pod pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:16:54.649: INFO: Pod pod-projected-configmaps-fd99d9fd-f8fc-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:16:54.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jfqvk" for this suite.
Dec  6 02:17:00.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:17:00.719: INFO: namespace: e2e-tests-projected-jfqvk, resource: bindings, ignored listing per whitelist
Dec  6 02:17:00.828: INFO: namespace e2e-tests-projected-jfqvk deletion completed in 6.169387592s

• [SLOW TEST:10.657 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:17:00.828: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  6 02:17:05.695: INFO: Successfully updated pod "pod-update-activedeadlineseconds-03e347c2-f8fd-11e8-a2c6-1eb929de0ff1"
Dec  6 02:17:05.696: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-03e347c2-f8fd-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-pods-7srxr" to be "terminated due to deadline exceeded"
Dec  6 02:17:05.704: INFO: Pod "pod-update-activedeadlineseconds-03e347c2-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Running", Reason="", readiness=true. Elapsed: 8.738199ms
Dec  6 02:17:07.746: INFO: Pod "pod-update-activedeadlineseconds-03e347c2-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.049982786s
Dec  6 02:17:07.746: INFO: Pod "pod-update-activedeadlineseconds-03e347c2-f8fd-11e8-a2c6-1eb929de0ff1" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:17:07.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7srxr" for this suite.
Dec  6 02:17:13.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:17:13.877: INFO: namespace: e2e-tests-pods-7srxr, resource: bindings, ignored listing per whitelist
Dec  6 02:17:13.979: INFO: namespace e2e-tests-pods-7srxr deletion completed in 6.227557628s

• [SLOW TEST:13.152 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:17:13.980: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-2jxtx
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
Dec  6 02:17:14.284: INFO: Found 0 stateful pods, waiting for 3
Dec  6 02:17:24.289: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:17:24.289: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:17:24.289: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Dec  6 02:17:24.365: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  6 02:17:34.413: INFO: Updating stateful set ss2
Dec  6 02:17:34.422: INFO: Waiting for Pod e2e-tests-statefulset-2jxtx/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:17:44.431: INFO: Waiting for Pod e2e-tests-statefulset-2jxtx/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
Dec  6 02:17:54.637: INFO: Found 2 stateful pods, waiting for 3
Dec  6 02:18:04.642: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:18:04.642: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:18:04.642: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  6 02:18:04.711: INFO: Updating stateful set ss2
Dec  6 02:18:04.719: INFO: Waiting for Pod e2e-tests-statefulset-2jxtx/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:18:14.760: INFO: Updating stateful set ss2
Dec  6 02:18:14.767: INFO: Waiting for StatefulSet e2e-tests-statefulset-2jxtx/ss2 to complete update
Dec  6 02:18:14.767: INFO: Waiting for Pod e2e-tests-statefulset-2jxtx/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Dec  6 02:18:24.777: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2jxtx
Dec  6 02:18:24.781: INFO: Scaling statefulset ss2 to 0
Dec  6 02:18:54.813: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:18:54.817: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:18:54.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2jxtx" for this suite.
Dec  6 02:19:02.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:19:03.111: INFO: namespace: e2e-tests-statefulset-2jxtx, resource: bindings, ignored listing per whitelist
Dec  6 02:19:03.161: INFO: namespace e2e-tests-statefulset-2jxtx deletion completed in 8.260518916s

• [SLOW TEST:109.181 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:19:03.161: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-4cd8b5e3-f8fd-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:19:03.524: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-fvm8k" to be "success or failure"
Dec  6 02:19:03.529: INFO: Pod "pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.203558ms
Dec  6 02:19:05.532: INFO: Pod "pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007767099s
Dec  6 02:19:07.542: INFO: Pod "pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017287572s
STEP: Saw pod success
Dec  6 02:19:07.542: INFO: Pod "pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:19:07.545: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:19:07.609: INFO: Waiting for pod pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:19:07.613: INFO: Pod pod-configmaps-4ce1ccf2-f8fd-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:19:07.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fvm8k" for this suite.
Dec  6 02:19:13.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:19:13.765: INFO: namespace: e2e-tests-configmap-fvm8k, resource: bindings, ignored listing per whitelist
Dec  6 02:19:13.847: INFO: namespace e2e-tests-configmap-fvm8k deletion completed in 6.226491922s

• [SLOW TEST:10.686 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:19:13.847: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:19:14.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sdtzm" for this suite.
Dec  6 02:19:36.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:19:36.582: INFO: namespace: e2e-tests-pods-sdtzm, resource: bindings, ignored listing per whitelist
Dec  6 02:19:36.618: INFO: namespace e2e-tests-pods-sdtzm deletion completed in 22.323011166s

• [SLOW TEST:22.770 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:19:36.618: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
STEP: creating the pod
Dec  6 02:19:36.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:37.290: INFO: stderr: ""
Dec  6 02:19:37.290: INFO: stdout: "pod/pause created\n"
Dec  6 02:19:37.290: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  6 02:19:37.290: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-kprw2" to be "running and ready"
Dec  6 02:19:37.415: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 125.538215ms
Dec  6 02:19:39.420: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.130270616s
Dec  6 02:19:41.428: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.138290206s
Dec  6 02:19:41.428: INFO: Pod "pause" satisfied condition "running and ready"
Dec  6 02:19:41.428: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  6 02:19:41.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:41.579: INFO: stderr: ""
Dec  6 02:19:41.579: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  6 02:19:41.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pod pause -L testing-label --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:41.640: INFO: stderr: ""
Dec  6 02:19:41.640: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          4s        testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  6 02:19:41.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 label pods pause testing-label- --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:41.730: INFO: stderr: ""
Dec  6 02:19:41.730: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  6 02:19:41.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pod pause -L testing-label --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:41.791: INFO: stderr: ""
Dec  6 02:19:41.791: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          4s        \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
STEP: using delete to clean up resources
Dec  6 02:19:41.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:41.927: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:19:41.927: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  6 02:19:41.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-kprw2'
Dec  6 02:19:42.003: INFO: stderr: "No resources found.\n"
Dec  6 02:19:42.003: INFO: stdout: ""
Dec  6 02:19:42.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -l name=pause --namespace=e2e-tests-kubectl-kprw2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  6 02:19:42.064: INFO: stderr: ""
Dec  6 02:19:42.064: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:19:42.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kprw2" for this suite.
Dec  6 02:19:48.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:19:48.178: INFO: namespace: e2e-tests-kubectl-kprw2, resource: bindings, ignored listing per whitelist
Dec  6 02:19:48.350: INFO: namespace e2e-tests-kubectl-kprw2 deletion completed in 6.279975676s

• [SLOW TEST:11.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:19:48.350: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with configMap that has name projected-configmap-test-upd-67c5d586-f8fd-11e8-a2c6-1eb929de0ff1
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-67c5d586-f8fd-11e8-a2c6-1eb929de0ff1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:21:11.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4x6kw" for this suite.
Dec  6 02:21:35.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:21:35.827: INFO: namespace: e2e-tests-projected-4x6kw, resource: bindings, ignored listing per whitelist
Dec  6 02:21:35.827: INFO: namespace e2e-tests-projected-4x6kw deletion completed in 24.176486968s

• [SLOW TEST:107.477 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:21:35.827: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Dec  6 02:21:36.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:36.320: INFO: stderr: ""
Dec  6 02:21:36.320: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  6 02:21:36.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:36.383: INFO: stderr: ""
Dec  6 02:21:36.383: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Dec  6 02:21:41.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.445: INFO: stderr: ""
Dec  6 02:21:41.445: INFO: stdout: "update-demo-nautilus-7x82s update-demo-nautilus-dtsgf "
Dec  6 02:21:41.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-7x82s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.507: INFO: stderr: ""
Dec  6 02:21:41.507: INFO: stdout: "true"
Dec  6 02:21:41.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-7x82s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.569: INFO: stderr: ""
Dec  6 02:21:41.569: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:21:41.569: INFO: validating pod update-demo-nautilus-7x82s
Dec  6 02:21:41.575: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:21:41.575: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:21:41.575: INFO: update-demo-nautilus-7x82s is verified up and running
Dec  6 02:21:41.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-dtsgf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.635: INFO: stderr: ""
Dec  6 02:21:41.635: INFO: stdout: "true"
Dec  6 02:21:41.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-dtsgf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.696: INFO: stderr: ""
Dec  6 02:21:41.696: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:21:41.696: INFO: validating pod update-demo-nautilus-dtsgf
Dec  6 02:21:41.700: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:21:41.700: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:21:41.700: INFO: update-demo-nautilus-dtsgf is verified up and running
STEP: using delete to clean up resources
Dec  6 02:21:41.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.782: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:21:41.783: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  6 02:21:41.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7spw6'
Dec  6 02:21:41.879: INFO: stderr: "No resources found.\n"
Dec  6 02:21:41.879: INFO: stdout: ""
Dec  6 02:21:41.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7spw6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  6 02:21:41.942: INFO: stderr: ""
Dec  6 02:21:41.942: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:21:41.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7spw6" for this suite.
Dec  6 02:21:48.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:21:48.279: INFO: namespace: e2e-tests-kubectl-7spw6, resource: bindings, ignored listing per whitelist
Dec  6 02:21:48.397: INFO: namespace e2e-tests-kubectl-7spw6 deletion completed in 6.417772422s

• [SLOW TEST:12.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:21:48.397: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 02:21:48.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-zzs2w'
Dec  6 02:21:48.931: INFO: stderr: ""
Dec  6 02:21:48.931: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
Dec  6 02:21:48.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-zzs2w'
Dec  6 02:21:49.211: INFO: stderr: ""
Dec  6 02:21:49.211: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:21:49.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zzs2w" for this suite.
Dec  6 02:22:11.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:22:11.453: INFO: namespace: e2e-tests-kubectl-zzs2w, resource: bindings, ignored listing per whitelist
Dec  6 02:22:11.582: INFO: namespace e2e-tests-kubectl-zzs2w deletion completed in 22.282460021s

• [SLOW TEST:23.185 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:22:11.582: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-bd1ee11c-f8fd-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:22:11.848: INFO: Waiting up to 5m0s for pod "pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-mbqq5" to be "success or failure"
Dec  6 02:22:11.901: INFO: Pod "pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 52.571819ms
Dec  6 02:22:13.917: INFO: Pod "pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068567254s
Dec  6 02:22:15.922: INFO: Pod "pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074034939s
STEP: Saw pod success
Dec  6 02:22:15.922: INFO: Pod "pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:22:15.927: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:22:16.042: INFO: Waiting for pod pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:22:16.047: INFO: Pod pod-secrets-bd22dfc4-f8fd-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:22:16.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mbqq5" for this suite.
Dec  6 02:22:22.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:22:22.207: INFO: namespace: e2e-tests-secrets-mbqq5, resource: bindings, ignored listing per whitelist
Dec  6 02:22:22.263: INFO: namespace e2e-tests-secrets-mbqq5 deletion completed in 6.208562144s

• [SLOW TEST:10.681 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:22:22.263: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:22:22.583: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-hdcnj" to be "success or failure"
Dec  6 02:22:22.588: INFO: Pod "downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.00156ms
Dec  6 02:22:24.592: INFO: Pod "downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008785009s
Dec  6 02:22:26.596: INFO: Pod "downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012751067s
STEP: Saw pod success
Dec  6 02:22:26.596: INFO: Pod "downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:22:26.599: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:22:26.748: INFO: Waiting for pod downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:22:26.753: INFO: Pod downwardapi-volume-c3844c49-f8fd-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:22:26.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hdcnj" for this suite.
Dec  6 02:22:32.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:22:32.907: INFO: namespace: e2e-tests-projected-hdcnj, resource: bindings, ignored listing per whitelist
Dec  6 02:22:32.944: INFO: namespace e2e-tests-projected-hdcnj deletion completed in 6.183573497s

• [SLOW TEST:10.680 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:22:32.944: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-c9d9625a-f8fd-11e8-a2c6-1eb929de0ff1,GenerateName:,Namespace:e2e-tests-events-c6xn9,SelfLink:/api/v1/namespaces/e2e-tests-events-c6xn9/pods/send-events-c9d9625a-f8fd-11e8-a2c6-1eb929de0ff1,UID:c9d0d179-f8fd-11e8-bab4-448a5b81d79a,ResourceVersion:132126,Generation:0,CreationTimestamp:2018-12-06 02:22:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 168140664,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.244.4.84/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9rk59 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9rk59,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-9rk59 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-g2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4223c0130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4223c0150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:22:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:22:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:22:33 +0000 UTC  }],Message:,Reason:,HostIP:172.22.132.14,PodIP:10.244.4.84,StartTime:2018-12-06 02:22:33 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-06 02:22:35 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 docker://9e2a2c392ae399cb24509173a3df0a85d1bd8c05673e878b8017fd527b730d94}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:22:41.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-c6xn9" for this suite.
Dec  6 02:22:47.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:22:47.351: INFO: namespace: e2e-tests-events-c6xn9, resource: bindings, ignored listing per whitelist
Dec  6 02:22:47.468: INFO: namespace e2e-tests-events-c6xn9 deletion completed in 6.196720953s

• [SLOW TEST:14.525 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:22:47.469: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-9wsxx
Dec  6 02:22:51.783: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-9wsxx
STEP: checking the pod's current state and verifying that restartCount is present
Dec  6 02:22:51.787: INFO: Initial restart count of pod liveness-http is 0
Dec  6 02:23:09.840: INFO: Restart count of pod e2e-tests-container-probe-9wsxx/liveness-http is now 1 (18.053040442s elapsed)
Dec  6 02:23:27.883: INFO: Restart count of pod e2e-tests-container-probe-9wsxx/liveness-http is now 2 (36.096274022s elapsed)
Dec  6 02:23:47.930: INFO: Restart count of pod e2e-tests-container-probe-9wsxx/liveness-http is now 3 (56.142707775s elapsed)
Dec  6 02:24:08.002: INFO: Restart count of pod e2e-tests-container-probe-9wsxx/liveness-http is now 4 (1m16.215161522s elapsed)
Dec  6 02:25:10.208: INFO: Restart count of pod e2e-tests-container-probe-9wsxx/liveness-http is now 5 (2m18.421275937s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:25:10.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9wsxx" for this suite.
Dec  6 02:25:16.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:25:16.422: INFO: namespace: e2e-tests-container-probe-9wsxx, resource: bindings, ignored listing per whitelist
Dec  6 02:25:16.482: INFO: namespace e2e-tests-container-probe-9wsxx deletion completed in 6.193672877s

• [SLOW TEST:149.014 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:25:16.482: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1206 02:25:27.411374      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  6 02:25:27.411: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:25:27.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2gn9q" for this suite.
Dec  6 02:25:35.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:25:35.537: INFO: namespace: e2e-tests-gc-2gn9q, resource: bindings, ignored listing per whitelist
Dec  6 02:25:35.678: INFO: namespace e2e-tests-gc-2gn9q deletion completed in 8.261505574s

• [SLOW TEST:19.196 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:25:35.678: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 02:25:35.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-62b66'
Dec  6 02:25:38.482: INFO: stderr: ""
Dec  6 02:25:38.482: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
Dec  6 02:25:40.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-62b66'
Dec  6 02:25:40.572: INFO: stderr: ""
Dec  6 02:25:40.572: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:25:40.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-62b66" for this suite.
Dec  6 02:26:04.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:26:04.809: INFO: namespace: e2e-tests-kubectl-62b66, resource: bindings, ignored listing per whitelist
Dec  6 02:26:04.850: INFO: namespace e2e-tests-kubectl-62b66 deletion completed in 24.219998468s

• [SLOW TEST:29.172 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:26:04.850: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  6 02:26:05.185: INFO: Waiting up to 5m0s for pod "pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-2gs8g" to be "success or failure"
Dec  6 02:26:05.189: INFO: Pod "pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.184984ms
Dec  6 02:26:07.193: INFO: Pod "pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008603773s
Dec  6 02:26:09.197: INFO: Pod "pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012259182s
STEP: Saw pod success
Dec  6 02:26:09.197: INFO: Pod "pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:26:09.201: INFO: Trying to get logs from node k8s-g1 pod pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:26:09.287: INFO: Waiting for pod pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:26:09.367: INFO: Pod pod-482fcdc8-f8fe-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:26:09.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2gs8g" for this suite.
Dec  6 02:26:15.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:26:15.532: INFO: namespace: e2e-tests-emptydir-2gs8g, resource: bindings, ignored listing per whitelist
Dec  6 02:26:15.541: INFO: namespace e2e-tests-emptydir-2gs8g deletion completed in 6.162996446s

• [SLOW TEST:10.692 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:26:15.541: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-mm8nb
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
Dec  6 02:26:15.887: INFO: Found 0 stateful pods, waiting for 3
Dec  6 02:26:25.925: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:26:25.925: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:26:25.925: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:26:25.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-mm8nb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:26:26.146: INFO: stderr: ""
Dec  6 02:26:26.146: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:26:26.146: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
Dec  6 02:26:36.230: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  6 02:26:46.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-mm8nb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:26:46.429: INFO: stderr: ""
Dec  6 02:26:46.429: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:26:46.429: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:26:56.501: INFO: Waiting for StatefulSet e2e-tests-statefulset-mm8nb/ss2 to complete update
Dec  6 02:26:56.501: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:26:56.501: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:26:56.501: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:27:06.512: INFO: Waiting for StatefulSet e2e-tests-statefulset-mm8nb/ss2 to complete update
Dec  6 02:27:06.512: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:27:06.512: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
Dec  6 02:27:16.508: INFO: Waiting for StatefulSet e2e-tests-statefulset-mm8nb/ss2 to complete update
Dec  6 02:27:16.508: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Rolling back to a previous revision
Dec  6 02:27:26.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-mm8nb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:27:26.693: INFO: stderr: ""
Dec  6 02:27:26.693: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:27:26.693: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:27:36.804: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  6 02:27:46.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-mm8nb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:27:46.980: INFO: stderr: ""
Dec  6 02:27:46.980: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:27:46.980: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:27:57.029: INFO: Waiting for StatefulSet e2e-tests-statefulset-mm8nb/ss2 to complete update
Dec  6 02:27:57.029: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
Dec  6 02:27:57.029: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-1 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
Dec  6 02:28:07.077: INFO: Waiting for StatefulSet e2e-tests-statefulset-mm8nb/ss2 to complete update
Dec  6 02:28:07.077: INFO: Waiting for Pod e2e-tests-statefulset-mm8nb/ss2-0 to have revision ss2-76cb68b6ff update revision ss2-56dd5fb9c4
Dec  6 02:28:17.036: INFO: Waiting for StatefulSet e2e-tests-statefulset-mm8nb/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Dec  6 02:28:27.038: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mm8nb
Dec  6 02:28:27.042: INFO: Scaling statefulset ss2 to 0
Dec  6 02:28:47.095: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:28:47.099: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:28:47.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mm8nb" for this suite.
Dec  6 02:28:55.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:28:55.351: INFO: namespace: e2e-tests-statefulset-mm8nb, resource: bindings, ignored listing per whitelist
Dec  6 02:28:55.381: INFO: namespace e2e-tests-statefulset-mm8nb deletion completed in 8.223218487s

• [SLOW TEST:159.840 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:28:55.381: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:28:55.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-bfdtt" to be "success or failure"
Dec  6 02:28:55.742: INFO: Pod "downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.728832ms
Dec  6 02:28:57.769: INFO: Pod "downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031790224s
Dec  6 02:28:59.773: INFO: Pod "downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036537384s
STEP: Saw pod success
Dec  6 02:28:59.773: INFO: Pod "downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:28:59.777: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:28:59.859: INFO: Waiting for pod downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:28:59.863: INFO: Pod downwardapi-volume-adceebbf-f8fe-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:28:59.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bfdtt" for this suite.
Dec  6 02:29:05.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:29:06.030: INFO: namespace: e2e-tests-downward-api-bfdtt, resource: bindings, ignored listing per whitelist
Dec  6 02:29:06.123: INFO: namespace e2e-tests-downward-api-bfdtt deletion completed in 6.253006017s

• [SLOW TEST:10.742 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:29:06.123: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Dec  6 02:29:06.399: INFO: Waiting up to 5m0s for pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-l2jcn" to be "success or failure"
Dec  6 02:29:06.477: INFO: Pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 77.745211ms
Dec  6 02:29:08.482: INFO: Pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082572416s
Dec  6 02:29:10.486: INFO: Pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.087310283s
Dec  6 02:29:12.491: INFO: Pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0922802s
Dec  6 02:29:14.495: INFO: Pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.096115815s
STEP: Saw pod success
Dec  6 02:29:14.495: INFO: Pod "downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:29:14.498: INFO: Trying to get logs from node k8s-g1 pod downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 02:29:14.586: INFO: Waiting for pod downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:29:14.603: INFO: Pod downward-api-b4362a0a-f8fe-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:29:14.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l2jcn" for this suite.
Dec  6 02:29:20.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:29:20.820: INFO: namespace: e2e-tests-downward-api-l2jcn, resource: bindings, ignored listing per whitelist
Dec  6 02:29:20.935: INFO: namespace e2e-tests-downward-api-l2jcn deletion completed in 6.323682754s

• [SLOW TEST:14.811 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:29:20.935: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating all guestbook components
Dec  6 02:29:21.279: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  6 02:29:21.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:29:21.631: INFO: stderr: ""
Dec  6 02:29:21.631: INFO: stdout: "service/redis-slave created\n"
Dec  6 02:29:21.631: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  6 02:29:21.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:29:21.939: INFO: stderr: ""
Dec  6 02:29:21.939: INFO: stdout: "service/redis-master created\n"
Dec  6 02:29:21.939: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  6 02:29:21.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:29:22.275: INFO: stderr: ""
Dec  6 02:29:22.275: INFO: stdout: "service/frontend created\n"
Dec  6 02:29:22.275: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  6 02:29:22.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:29:22.542: INFO: stderr: ""
Dec  6 02:29:22.542: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  6 02:29:22.542: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  6 02:29:22.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:29:22.867: INFO: stderr: ""
Dec  6 02:29:22.867: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  6 02:29:22.867: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  6 02:29:22.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:29:23.209: INFO: stderr: ""
Dec  6 02:29:23.209: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  6 02:29:23.209: INFO: Waiting for all frontend pods to be Running.
Dec  6 02:30:33.261: INFO: Waiting for frontend to serve content.
Dec  6 02:30:33.275: INFO: Trying to add a new entry to the guestbook.
Dec  6 02:30:33.287: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  6 02:30:33.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:30:33.456: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:30:33.456: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  6 02:30:33.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:30:33.687: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:30:33.687: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  6 02:30:33.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:30:34.011: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:30:34.011: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  6 02:30:34.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:30:34.161: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:30:34.161: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  6 02:30:34.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:30:34.332: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:30:34.332: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  6 02:30:34.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pkf5q'
Dec  6 02:30:34.487: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:30:34.487: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:30:34.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pkf5q" for this suite.
Dec  6 02:31:18.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:31:18.582: INFO: namespace: e2e-tests-kubectl-pkf5q, resource: bindings, ignored listing per whitelist
Dec  6 02:31:18.797: INFO: namespace e2e-tests-kubectl-pkf5q deletion completed in 44.303372144s

• [SLOW TEST:117.862 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:31:18.797: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-034c253a-f8ff-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:31:19.113: INFO: Waiting up to 5m0s for pod "pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-zpf6w" to be "success or failure"
Dec  6 02:31:19.180: INFO: Pod "pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 67.131893ms
Dec  6 02:31:21.184: INFO: Pod "pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071466447s
Dec  6 02:31:23.189: INFO: Pod "pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07595908s
STEP: Saw pod success
Dec  6 02:31:23.189: INFO: Pod "pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:31:23.193: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:31:23.289: INFO: Waiting for pod pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:31:23.292: INFO: Pod pod-configmaps-03523481-f8ff-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:31:23.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zpf6w" for this suite.
Dec  6 02:31:29.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:31:29.464: INFO: namespace: e2e-tests-configmap-zpf6w, resource: bindings, ignored listing per whitelist
Dec  6 02:31:29.464: INFO: namespace e2e-tests-configmap-zpf6w deletion completed in 6.163616607s

• [SLOW TEST:10.667 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:31:29.464: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the initial replication controller
Dec  6 02:31:29.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:29.983: INFO: stderr: ""
Dec  6 02:31:29.983: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  6 02:31:29.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:30.134: INFO: stderr: ""
Dec  6 02:31:30.134: INFO: stdout: "update-demo-nautilus-2nnbn update-demo-nautilus-4cm62 "
Dec  6 02:31:30.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-2nnbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:30.277: INFO: stderr: ""
Dec  6 02:31:30.277: INFO: stdout: ""
Dec  6 02:31:30.277: INFO: update-demo-nautilus-2nnbn is created but not running
Dec  6 02:31:35.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:35.341: INFO: stderr: ""
Dec  6 02:31:35.341: INFO: stdout: "update-demo-nautilus-2nnbn update-demo-nautilus-4cm62 "
Dec  6 02:31:35.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-2nnbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:35.403: INFO: stderr: ""
Dec  6 02:31:35.403: INFO: stdout: "true"
Dec  6 02:31:35.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-2nnbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:35.463: INFO: stderr: ""
Dec  6 02:31:35.463: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:31:35.463: INFO: validating pod update-demo-nautilus-2nnbn
Dec  6 02:31:35.468: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:31:35.468: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:31:35.468: INFO: update-demo-nautilus-2nnbn is verified up and running
Dec  6 02:31:35.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-4cm62 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:35.529: INFO: stderr: ""
Dec  6 02:31:35.529: INFO: stdout: "true"
Dec  6 02:31:35.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-4cm62 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:31:35.589: INFO: stderr: ""
Dec  6 02:31:35.589: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:31:35.589: INFO: validating pod update-demo-nautilus-4cm62
Dec  6 02:31:35.596: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:31:35.596: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:31:35.596: INFO: update-demo-nautilus-4cm62 is verified up and running
STEP: rolling-update to new replication controller
Dec  6 02:31:35.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:32:00.476: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  6 02:32:00.477: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  6 02:32:00.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:32:00.539: INFO: stderr: ""
Dec  6 02:32:00.539: INFO: stdout: "update-demo-kitten-j4mhc update-demo-kitten-s9m46 "
Dec  6 02:32:00.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-kitten-j4mhc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:32:00.679: INFO: stderr: ""
Dec  6 02:32:00.679: INFO: stdout: "true"
Dec  6 02:32:00.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-kitten-j4mhc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:32:00.771: INFO: stderr: ""
Dec  6 02:32:00.771: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Dec  6 02:32:00.771: INFO: validating pod update-demo-kitten-j4mhc
Dec  6 02:32:00.777: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  6 02:32:00.777: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  6 02:32:00.777: INFO: update-demo-kitten-j4mhc is verified up and running
Dec  6 02:32:00.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-kitten-s9m46 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:32:00.836: INFO: stderr: ""
Dec  6 02:32:00.836: INFO: stdout: "true"
Dec  6 02:32:00.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-kitten-s9m46 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n4fdl'
Dec  6 02:32:00.895: INFO: stderr: ""
Dec  6 02:32:00.895: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
Dec  6 02:32:00.895: INFO: validating pod update-demo-kitten-s9m46
Dec  6 02:32:00.901: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  6 02:32:00.901: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  6 02:32:00.901: INFO: update-demo-kitten-s9m46 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:32:00.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n4fdl" for this suite.
Dec  6 02:32:24.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:32:25.004: INFO: namespace: e2e-tests-kubectl-n4fdl, resource: bindings, ignored listing per whitelist
Dec  6 02:32:25.105: INFO: namespace e2e-tests-kubectl-n4fdl deletion completed in 24.196292371s

• [SLOW TEST:55.641 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:32:25.105: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-2ad45d27-f8ff-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:32:25.427: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-kpnxf" to be "success or failure"
Dec  6 02:32:25.432: INFO: Pod "pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057686ms
Dec  6 02:32:27.435: INFO: Pod "pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00762574s
Dec  6 02:32:29.440: INFO: Pod "pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012368444s
STEP: Saw pod success
Dec  6 02:32:29.440: INFO: Pod "pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:32:29.444: INFO: Trying to get logs from node k8s-g2 pod pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:32:29.531: INFO: Waiting for pod pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:32:29.539: INFO: Pod pod-projected-secrets-2ad9ee88-f8ff-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:32:29.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kpnxf" for this suite.
Dec  6 02:32:35.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:32:35.673: INFO: namespace: e2e-tests-projected-kpnxf, resource: bindings, ignored listing per whitelist
Dec  6 02:32:35.707: INFO: namespace e2e-tests-projected-kpnxf deletion completed in 6.159880492s

• [SLOW TEST:10.602 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:32:35.707: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  6 02:32:40.594: INFO: Successfully updated pod "pod-update-312354d6-f8ff-11e8-a2c6-1eb929de0ff1"
STEP: verifying the updated pod is in kubernetes
Dec  6 02:32:40.627: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:32:40.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-thxwh" for this suite.
Dec  6 02:33:04.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:33:04.766: INFO: namespace: e2e-tests-pods-thxwh, resource: bindings, ignored listing per whitelist
Dec  6 02:33:04.840: INFO: namespace e2e-tests-pods-thxwh deletion completed in 24.206979521s

• [SLOW TEST:29.133 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:33:04.841: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-5dxlt
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-5dxlt
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-5dxlt
Dec  6 02:33:05.261: INFO: Found 0 stateful pods, waiting for 1
Dec  6 02:33:15.265: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  6 02:33:15.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:33:15.449: INFO: stderr: ""
Dec  6 02:33:15.449: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:33:15.449: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:33:15.452: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  6 02:33:25.457: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:33:25.457: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:33:25.554: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999789s
Dec  6 02:33:26.559: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995385821s
Dec  6 02:33:27.565: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990722033s
Dec  6 02:33:28.608: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98398512s
Dec  6 02:33:29.612: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.941422334s
Dec  6 02:33:30.658: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.936931586s
Dec  6 02:33:31.662: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.891543338s
Dec  6 02:33:32.691: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.887495765s
Dec  6 02:33:33.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.858547274s
Dec  6 02:33:34.699: INFO: Verifying statefulset ss doesn't scale past 1 for another 854.168754ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-5dxlt
Dec  6 02:33:35.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:33:35.882: INFO: stderr: ""
Dec  6 02:33:35.882: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:33:35.882: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:33:35.885: INFO: Found 1 stateful pods, waiting for 3
Dec  6 02:33:45.890: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:33:45.890: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:33:45.890: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  6 02:33:45.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:33:46.024: INFO: stderr: ""
Dec  6 02:33:46.024: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:33:46.024: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:33:46.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:33:46.205: INFO: stderr: ""
Dec  6 02:33:46.205: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:33:46.205: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:33:46.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:33:46.390: INFO: stderr: ""
Dec  6 02:33:46.390: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:33:46.390: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:33:46.390: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:33:46.395: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  6 02:33:56.403: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:33:56.403: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:33:56.403: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:33:56.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999836s
Dec  6 02:33:57.439: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996273552s
Dec  6 02:33:58.446: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992030743s
Dec  6 02:33:59.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985479274s
Dec  6 02:34:00.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980780111s
Dec  6 02:34:01.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976318268s
Dec  6 02:34:02.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962677843s
Dec  6 02:34:03.478: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958334327s
Dec  6 02:34:04.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.953365786s
Dec  6 02:34:05.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.483297ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-5dxlt
Dec  6 02:34:06.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:34:06.620: INFO: stderr: ""
Dec  6 02:34:06.620: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:34:06.620: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:34:06.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:34:06.742: INFO: stderr: ""
Dec  6 02:34:06.742: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:34:06.742: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:34:06.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-5dxlt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:34:06.955: INFO: stderr: ""
Dec  6 02:34:06.955: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:34:06.955: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:34:06.955: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Dec  6 02:34:46.971: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5dxlt
Dec  6 02:34:46.976: INFO: Scaling statefulset ss to 0
Dec  6 02:34:46.990: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:34:46.994: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:34:47.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5dxlt" for this suite.
Dec  6 02:34:55.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:34:55.235: INFO: namespace: e2e-tests-statefulset-5dxlt, resource: bindings, ignored listing per whitelist
Dec  6 02:34:55.270: INFO: namespace e2e-tests-statefulset-5dxlt deletion completed in 8.245365707s

• [SLOW TEST:110.430 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:34:55.270: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-s55rc/configmap-test-846164bd-f8ff-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:34:55.662: INFO: Waiting up to 5m0s for pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-s55rc" to be "success or failure"
Dec  6 02:34:55.665: INFO: Pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.847816ms
Dec  6 02:34:57.671: INFO: Pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008979016s
Dec  6 02:34:59.675: INFO: Pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013596592s
Dec  6 02:35:01.680: INFO: Pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018156903s
Dec  6 02:35:03.683: INFO: Pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021823307s
STEP: Saw pod success
Dec  6 02:35:03.683: INFO: Pod "pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:35:03.687: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1 container env-test: <nil>
STEP: delete the pod
Dec  6 02:35:03.771: INFO: Waiting for pod pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:35:03.774: INFO: Pod pod-configmaps-8466815e-f8ff-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:35:03.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s55rc" for this suite.
Dec  6 02:35:09.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:35:10.015: INFO: namespace: e2e-tests-configmap-s55rc, resource: bindings, ignored listing per whitelist
Dec  6 02:35:10.034: INFO: namespace e2e-tests-configmap-s55rc deletion completed in 6.252968666s

• [SLOW TEST:14.764 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:35:10.034: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gqzf6;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gqzf6.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 155.31.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.31.155_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 155.31.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.31.155_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gqzf6;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-gqzf6.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-gqzf6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-gqzf6.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 155.31.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.31.155_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 155.31.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.31.155_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  6 02:35:24.565: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.572: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.585: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6 from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.597: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.644: INFO: Unable to read jessie_udp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.650: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.655: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqzf6 from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.661: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6 from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.667: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.672: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.682: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:24.707: INFO: Lookups using dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6 wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gqzf6 jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6 jessie_udp@dns-test-service.e2e-tests-dns-gqzf6.svc jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc]

Dec  6 02:35:34.563: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.569: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.579: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6 from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.589: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.599: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.634: INFO: Unable to read jessie_udp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.640: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.645: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqzf6 from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.651: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6 from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.656: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.662: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.672: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc from pod dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1: the server could not find the requested resource (get pods dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1)
Dec  6 02:35:34.699: INFO: Lookups using dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6 wheezy_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-gqzf6 jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6 jessie_udp@dns-test-service.e2e-tests-dns-gqzf6.svc jessie_tcp@dns-test-service.e2e-tests-dns-gqzf6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-gqzf6.svc]

Dec  6 02:35:44.693: INFO: DNS probes using dns-test-8d34c50c-f8ff-11e8-a2c6-1eb929de0ff1 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:35:45.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-gqzf6" for this suite.
Dec  6 02:35:51.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:35:51.470: INFO: namespace: e2e-tests-dns-gqzf6, resource: bindings, ignored listing per whitelist
Dec  6 02:35:51.484: INFO: namespace e2e-tests-dns-gqzf6 deletion completed in 6.333729439s

• [SLOW TEST:41.450 seconds]
[sig-network] DNS
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:35:51.485: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-a5d628a6-f8ff-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:35:51.827: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-nqtf9" to be "success or failure"
Dec  6 02:35:51.860: INFO: Pod "pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 32.528098ms
Dec  6 02:35:53.891: INFO: Pod "pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063820446s
Dec  6 02:35:55.896: INFO: Pod "pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068408933s
STEP: Saw pod success
Dec  6 02:35:55.896: INFO: Pod "pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:35:55.900: INFO: Trying to get logs from node k8s-g1 pod pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:35:55.981: INFO: Waiting for pod pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:35:55.985: INFO: Pod pod-projected-secrets-a5e02549-f8ff-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:35:55.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nqtf9" for this suite.
Dec  6 02:36:02.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:36:02.210: INFO: namespace: e2e-tests-projected-nqtf9, resource: bindings, ignored listing per whitelist
Dec  6 02:36:02.239: INFO: namespace e2e-tests-projected-nqtf9 deletion completed in 6.246183929s

• [SLOW TEST:10.755 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:36:02.239: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-qb9lz
Dec  6 02:36:10.536: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-qb9lz
STEP: checking the pod's current state and verifying that restartCount is present
Dec  6 02:36:10.542: INFO: Initial restart count of pod liveness-exec is 0
Dec  6 02:37:02.740: INFO: Restart count of pod e2e-tests-container-probe-qb9lz/liveness-exec is now 1 (52.197471701s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:37:02.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qb9lz" for this suite.
Dec  6 02:37:08.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:37:08.931: INFO: namespace: e2e-tests-container-probe-qb9lz, resource: bindings, ignored listing per whitelist
Dec  6 02:37:09.011: INFO: namespace e2e-tests-container-probe-qb9lz deletion completed in 6.167102657s

• [SLOW TEST:66.772 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:37:09.011: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:37:09.245: INFO: Creating ReplicaSet my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1
Dec  6 02:37:09.306: INFO: Pod name my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1: Found 0 pods out of 1
Dec  6 02:37:14.319: INFO: Pod name my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1: Found 1 pods out of 1
Dec  6 02:37:14.319: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1" is running
Dec  6 02:37:14.324: INFO: Pod "my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1-xjt9z" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-06 02:37:09 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-06 02:37:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-06 02:37:09 +0000 UTC Reason: Message:}])
Dec  6 02:37:14.324: INFO: Trying to dial the pod
Dec  6 02:37:19.339: INFO: Controller my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1: Got expected result from replica 1 [my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1-xjt9z]: "my-hostname-basic-d4083341-f8ff-11e8-a2c6-1eb929de0ff1-xjt9z", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:37:19.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9xplf" for this suite.
Dec  6 02:37:25.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:37:25.389: INFO: namespace: e2e-tests-replicaset-9xplf, resource: bindings, ignored listing per whitelist
Dec  6 02:37:25.558: INFO: namespace e2e-tests-replicaset-9xplf deletion completed in 6.212214954s

• [SLOW TEST:16.546 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:37:25.558: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
Dec  6 02:37:25.913: INFO: Waiting up to 5m0s for pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-var-expansion-xxn5z" to be "success or failure"
Dec  6 02:37:25.916: INFO: Pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.656416ms
Dec  6 02:37:27.921: INFO: Pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00825407s
Dec  6 02:37:29.925: INFO: Pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012450793s
Dec  6 02:37:31.960: INFO: Pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.047168449s
Dec  6 02:37:34.010: INFO: Pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.096726174s
STEP: Saw pod success
Dec  6 02:37:34.010: INFO: Pod "var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:37:34.013: INFO: Trying to get logs from node k8s-g2 pod var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 02:37:34.141: INFO: Waiting for pod var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:37:34.146: INFO: Pod var-expansion-ddf23b8b-f8ff-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:37:34.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xxn5z" for this suite.
Dec  6 02:37:40.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:37:40.420: INFO: namespace: e2e-tests-var-expansion-xxn5z, resource: bindings, ignored listing per whitelist
Dec  6 02:37:40.440: INFO: namespace e2e-tests-var-expansion-xxn5z deletion completed in 6.27357496s

• [SLOW TEST:14.882 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:37:40.441: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
Dec  6 02:37:40.767: INFO: Waiting up to 5m0s for pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-var-expansion-qwp9m" to be "success or failure"
Dec  6 02:37:40.771: INFO: Pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.980007ms
Dec  6 02:37:42.775: INFO: Pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00790793s
Dec  6 02:37:44.780: INFO: Pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012643379s
Dec  6 02:37:46.784: INFO: Pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01721554s
Dec  6 02:37:48.788: INFO: Pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021136838s
STEP: Saw pod success
Dec  6 02:37:48.788: INFO: Pod "var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:37:48.792: INFO: Trying to get logs from node k8s-g1 pod var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 02:37:48.893: INFO: Waiting for pod var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:37:48.896: INFO: Pod var-expansion-e6c63878-f8ff-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:37:48.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-qwp9m" for this suite.
Dec  6 02:37:56.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:37:57.104: INFO: namespace: e2e-tests-var-expansion-qwp9m, resource: bindings, ignored listing per whitelist
Dec  6 02:37:57.134: INFO: namespace e2e-tests-var-expansion-qwp9m deletion completed in 8.229748727s

• [SLOW TEST:16.693 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:37:57.134: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
STEP: creating an rc
Dec  6 02:37:57.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-m8z9n'
Dec  6 02:38:00.435: INFO: stderr: ""
Dec  6 02:38:00.435: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Waiting for Redis master to start.
Dec  6 02:38:01.440: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:38:01.440: INFO: Found 0 / 1
Dec  6 02:38:02.440: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:38:02.440: INFO: Found 0 / 1
Dec  6 02:38:03.440: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:38:03.440: INFO: Found 1 / 1
Dec  6 02:38:03.440: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  6 02:38:03.443: INFO: Selector matched 1 pods for map[app:redis]
Dec  6 02:38:03.443: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  6 02:38:03.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 logs redis-master-7frbq redis-master --namespace=e2e-tests-kubectl-m8z9n'
Dec  6 02:38:03.520: INFO: stderr: ""
Dec  6 02:38:03.520: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Dec 02:38:02.603 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Dec 02:38:02.603 # Server started, Redis version 3.2.12\n1:M 06 Dec 02:38:02.603 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Dec 02:38:02.603 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  6 02:38:03.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 log redis-master-7frbq redis-master --namespace=e2e-tests-kubectl-m8z9n --tail=1'
Dec  6 02:38:03.596: INFO: stderr: ""
Dec  6 02:38:03.596: INFO: stdout: "1:M 06 Dec 02:38:02.603 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  6 02:38:03.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 log redis-master-7frbq redis-master --namespace=e2e-tests-kubectl-m8z9n --limit-bytes=1'
Dec  6 02:38:03.669: INFO: stderr: ""
Dec  6 02:38:03.669: INFO: stdout: " "
STEP: exposing timestamps
Dec  6 02:38:03.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 log redis-master-7frbq redis-master --namespace=e2e-tests-kubectl-m8z9n --tail=1 --timestamps'
Dec  6 02:38:03.741: INFO: stderr: ""
Dec  6 02:38:03.741: INFO: stdout: "2018-12-06T02:38:02.603288524Z 1:M 06 Dec 02:38:02.603 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  6 02:38:06.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 log redis-master-7frbq redis-master --namespace=e2e-tests-kubectl-m8z9n --since=1s'
Dec  6 02:38:06.312: INFO: stderr: ""
Dec  6 02:38:06.312: INFO: stdout: ""
Dec  6 02:38:06.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 log redis-master-7frbq redis-master --namespace=e2e-tests-kubectl-m8z9n --since=24h'
Dec  6 02:38:06.387: INFO: stderr: ""
Dec  6 02:38:06.387: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Dec 02:38:02.603 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Dec 02:38:02.603 # Server started, Redis version 3.2.12\n1:M 06 Dec 02:38:02.603 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Dec 02:38:02.603 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
STEP: using delete to clean up resources
Dec  6 02:38:06.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-m8z9n'
Dec  6 02:38:06.463: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:38:06.463: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  6 02:38:06.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-m8z9n'
Dec  6 02:38:06.571: INFO: stderr: "No resources found.\n"
Dec  6 02:38:06.571: INFO: stdout: ""
Dec  6 02:38:06.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -l name=nginx --namespace=e2e-tests-kubectl-m8z9n -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  6 02:38:06.631: INFO: stderr: ""
Dec  6 02:38:06.631: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:38:06.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m8z9n" for this suite.
Dec  6 02:38:12.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:38:12.814: INFO: namespace: e2e-tests-kubectl-m8z9n, resource: bindings, ignored listing per whitelist
Dec  6 02:38:12.926: INFO: namespace e2e-tests-kubectl-m8z9n deletion completed in 6.28757442s

• [SLOW TEST:15.793 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:38:12.926: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Dec  6 02:38:17.845: INFO: Successfully updated pod "annotationupdatefa248583-f8ff-11e8-a2c6-1eb929de0ff1"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:38:19.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g5sbs" for this suite.
Dec  6 02:38:43.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:38:44.002: INFO: namespace: e2e-tests-projected-g5sbs, resource: bindings, ignored listing per whitelist
Dec  6 02:38:44.060: INFO: namespace e2e-tests-projected-g5sbs deletion completed in 24.181484391s

• [SLOW TEST:31.133 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:38:44.060: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating cluster-info
Dec  6 02:38:44.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 cluster-info'
Dec  6 02:38:44.430: INFO: stderr: ""
Dec  6 02:38:44.430: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:38:44.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7fbp8" for this suite.
Dec  6 02:38:50.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:38:50.552: INFO: namespace: e2e-tests-kubectl-7fbp8, resource: bindings, ignored listing per whitelist
Dec  6 02:38:50.622: INFO: namespace e2e-tests-kubectl-7fbp8 deletion completed in 6.184928346s

• [SLOW TEST:6.562 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:38:50.622: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
Dec  6 02:38:51.462: INFO: created pod pod-service-account-defaultsa
Dec  6 02:38:51.462: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  6 02:38:51.496: INFO: created pod pod-service-account-mountsa
Dec  6 02:38:51.496: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  6 02:38:51.588: INFO: created pod pod-service-account-nomountsa
Dec  6 02:38:51.588: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  6 02:38:51.714: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  6 02:38:51.714: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  6 02:38:51.775: INFO: created pod pod-service-account-mountsa-mountspec
Dec  6 02:38:51.775: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  6 02:38:51.913: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  6 02:38:51.913: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  6 02:38:51.955: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  6 02:38:51.955: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  6 02:38:52.024: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  6 02:38:52.024: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  6 02:38:52.165: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  6 02:38:52.165: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:38:52.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-dw84h" for this suite.
Dec  6 02:39:16.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:39:16.458: INFO: namespace: e2e-tests-svcaccounts-dw84h, resource: bindings, ignored listing per whitelist
Dec  6 02:39:16.640: INFO: namespace e2e-tests-svcaccounts-dw84h deletion completed in 24.377910295s

• [SLOW TEST:26.018 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:39:16.640: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-201add17-f900-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:39:16.932: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-gvv6k" to be "success or failure"
Dec  6 02:39:16.936: INFO: Pod "pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05765ms
Dec  6 02:39:18.941: INFO: Pod "pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008777568s
Dec  6 02:39:20.945: INFO: Pod "pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012808153s
STEP: Saw pod success
Dec  6 02:39:20.945: INFO: Pod "pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:39:20.948: INFO: Trying to get logs from node k8s-g1 pod pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:39:21.015: INFO: Waiting for pod pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:39:21.018: INFO: Pod pod-projected-configmaps-2020bcb5-f900-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:39:21.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gvv6k" for this suite.
Dec  6 02:39:27.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:39:27.314: INFO: namespace: e2e-tests-projected-gvv6k, resource: bindings, ignored listing per whitelist
Dec  6 02:39:27.319: INFO: namespace e2e-tests-projected-gvv6k deletion completed in 6.253095294s

• [SLOW TEST:10.679 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:39:27.320: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1206 02:40:07.790217      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  6 02:40:07.790: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:40:07.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-ksxnz" for this suite.
Dec  6 02:40:17.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:40:17.933: INFO: namespace: e2e-tests-gc-ksxnz, resource: bindings, ignored listing per whitelist
Dec  6 02:40:17.988: INFO: namespace e2e-tests-gc-ksxnz deletion completed in 10.193666085s

• [SLOW TEST:50.667 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:40:17.988: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  6 02:40:18.264: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:18.264: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:18.264: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:18.269: INFO: Number of nodes with available pods: 0
Dec  6 02:40:18.269: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:19.275: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:19.275: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:19.275: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:19.278: INFO: Number of nodes with available pods: 0
Dec  6 02:40:19.278: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:20.274: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:20.274: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:20.274: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:20.277: INFO: Number of nodes with available pods: 0
Dec  6 02:40:20.277: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:21.274: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:21.274: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:21.274: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:21.278: INFO: Number of nodes with available pods: 2
Dec  6 02:40:21.278: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  6 02:40:21.387: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:21.387: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:21.387: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:21.391: INFO: Number of nodes with available pods: 1
Dec  6 02:40:21.391: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:22.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:22.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:22.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:22.400: INFO: Number of nodes with available pods: 1
Dec  6 02:40:22.400: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:23.417: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:23.417: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:23.417: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:23.421: INFO: Number of nodes with available pods: 1
Dec  6 02:40:23.421: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:24.396: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:24.396: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:24.396: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:24.400: INFO: Number of nodes with available pods: 1
Dec  6 02:40:24.400: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:25.453: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:25.453: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:25.453: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:25.457: INFO: Number of nodes with available pods: 1
Dec  6 02:40:25.457: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:26.397: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:26.397: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:26.397: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:26.402: INFO: Number of nodes with available pods: 1
Dec  6 02:40:26.402: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 02:40:27.434: INFO: DaemonSet pods can't tolerate node k8s-m1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:27.434: INFO: DaemonSet pods can't tolerate node k8s-m2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:27.434: INFO: DaemonSet pods can't tolerate node k8s-m3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  6 02:40:27.438: INFO: Number of nodes with available pods: 2
Dec  6 02:40:27.438: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rp87c, will wait for the garbage collector to delete the pods
Dec  6 02:40:27.514: INFO: Deleting {extensions DaemonSet} daemon-set took: 18.717779ms
Dec  6 02:40:27.614: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.136621ms
Dec  6 02:40:37.119: INFO: Number of nodes with available pods: 0
Dec  6 02:40:37.119: INFO: Number of running nodes: 0, number of available pods: 0
Dec  6 02:40:37.122: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rp87c/daemonsets","resourceVersion":"136092"},"items":null}

Dec  6 02:40:37.124: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rp87c/pods","resourceVersion":"136092"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:40:37.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rp87c" for this suite.
Dec  6 02:40:45.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:40:45.265: INFO: namespace: e2e-tests-daemonsets-rp87c, resource: bindings, ignored listing per whitelist
Dec  6 02:40:45.387: INFO: namespace e2e-tests-daemonsets-rp87c deletion completed in 8.246652027s

• [SLOW TEST:27.399 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:40:45.387: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-550a4193-f900-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:40:45.800: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-lrr67" to be "success or failure"
Dec  6 02:40:45.803: INFO: Pod "pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.360891ms
Dec  6 02:40:47.809: INFO: Pod "pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009732138s
Dec  6 02:40:49.814: INFO: Pod "pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014218317s
STEP: Saw pod success
Dec  6 02:40:49.814: INFO: Pod "pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:40:49.817: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:40:49.918: INFO: Waiting for pod pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:40:49.922: INFO: Pod pod-projected-configmaps-55156838-f900-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:40:49.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lrr67" for this suite.
Dec  6 02:40:56.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:40:56.208: INFO: namespace: e2e-tests-projected-lrr67, resource: bindings, ignored listing per whitelist
Dec  6 02:40:56.215: INFO: namespace e2e-tests-projected-lrr67 deletion completed in 6.246289635s

• [SLOW TEST:10.828 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:40:56.215: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  6 02:40:56.468: INFO: Waiting up to 5m0s for pod "pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-ln4q6" to be "success or failure"
Dec  6 02:40:56.472: INFO: Pod "pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.117758ms
Dec  6 02:40:58.478: INFO: Pod "pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009532801s
Dec  6 02:41:00.483: INFO: Pod "pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014752081s
Dec  6 02:41:02.487: INFO: Pod "pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018785325s
STEP: Saw pod success
Dec  6 02:41:02.487: INFO: Pod "pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:41:02.491: INFO: Trying to get logs from node k8s-g1 pod pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:41:02.535: INFO: Waiting for pod pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:41:02.540: INFO: Pod pod-5b7298f9-f900-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:41:02.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ln4q6" for this suite.
Dec  6 02:41:08.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:41:08.762: INFO: namespace: e2e-tests-emptydir-ln4q6, resource: bindings, ignored listing per whitelist
Dec  6 02:41:08.794: INFO: namespace e2e-tests-emptydir-ln4q6 deletion completed in 6.243823288s

• [SLOW TEST:12.578 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:41:08.794: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-62fa8af8-f900-11e8-a2c6-1eb929de0ff1
STEP: Creating configMap with name cm-test-opt-upd-62fa8b1b-f900-11e8-a2c6-1eb929de0ff1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-62fa8af8-f900-11e8-a2c6-1eb929de0ff1
STEP: Updating configmap cm-test-opt-upd-62fa8b1b-f900-11e8-a2c6-1eb929de0ff1
STEP: Creating configMap with name cm-test-opt-create-62fa8b27-f900-11e8-a2c6-1eb929de0ff1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:41:15.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8vfgz" for this suite.
Dec  6 02:41:39.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:41:39.663: INFO: namespace: e2e-tests-configmap-8vfgz, resource: bindings, ignored listing per whitelist
Dec  6 02:41:39.710: INFO: namespace e2e-tests-configmap-8vfgz deletion completed in 24.184733407s

• [SLOW TEST:30.916 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:41:39.710: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-nb2p2
Dec  6 02:41:48.072: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-nb2p2
STEP: checking the pod's current state and verifying that restartCount is present
Dec  6 02:41:48.075: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:45:49.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nb2p2" for this suite.
Dec  6 02:45:55.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:45:55.852: INFO: namespace: e2e-tests-container-probe-nb2p2, resource: bindings, ignored listing per whitelist
Dec  6 02:45:55.864: INFO: namespace e2e-tests-container-probe-nb2p2 deletion completed in 6.232428625s

• [SLOW TEST:256.155 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:45:55.865: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-wwf9d
I1206 02:45:56.130101      19 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-wwf9d, replica count: 1
I1206 02:45:57.180346      19 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 02:45:58.180463      19 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 02:45:59.180618      19 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  6 02:45:59.352: INFO: Created: latency-svc-t2jfl
Dec  6 02:45:59.421: INFO: Got endpoints: latency-svc-t2jfl [140.489385ms]
Dec  6 02:45:59.499: INFO: Created: latency-svc-pvkz9
Dec  6 02:45:59.594: INFO: Got endpoints: latency-svc-pvkz9 [173.258445ms]
Dec  6 02:45:59.600: INFO: Created: latency-svc-k68rt
Dec  6 02:45:59.655: INFO: Got endpoints: latency-svc-k68rt [234.473149ms]
Dec  6 02:45:59.668: INFO: Created: latency-svc-jpk6s
Dec  6 02:45:59.773: INFO: Got endpoints: latency-svc-jpk6s [352.22773ms]
Dec  6 02:45:59.785: INFO: Created: latency-svc-tqsxd
Dec  6 02:45:59.913: INFO: Got endpoints: latency-svc-tqsxd [491.533483ms]
Dec  6 02:45:59.975: INFO: Created: latency-svc-6qclz
Dec  6 02:46:00.071: INFO: Got endpoints: latency-svc-6qclz [650.196983ms]
Dec  6 02:46:00.111: INFO: Created: latency-svc-ljmm2
Dec  6 02:46:00.165: INFO: Got endpoints: latency-svc-ljmm2 [743.961327ms]
Dec  6 02:46:00.240: INFO: Created: latency-svc-dbmkw
Dec  6 02:46:00.270: INFO: Got endpoints: latency-svc-dbmkw [848.657096ms]
Dec  6 02:46:00.388: INFO: Created: latency-svc-xhq4v
Dec  6 02:46:00.485: INFO: Got endpoints: latency-svc-xhq4v [1.063818182s]
Dec  6 02:46:00.572: INFO: Created: latency-svc-24l9x
Dec  6 02:46:00.623: INFO: Got endpoints: latency-svc-24l9x [1.201452922s]
Dec  6 02:46:00.665: INFO: Created: latency-svc-jvng7
Dec  6 02:46:00.765: INFO: Got endpoints: latency-svc-jvng7 [1.344352189s]
Dec  6 02:46:00.914: INFO: Created: latency-svc-wmrb9
Dec  6 02:46:00.940: INFO: Got endpoints: latency-svc-wmrb9 [1.519180089s]
Dec  6 02:46:01.096: INFO: Created: latency-svc-nczxr
Dec  6 02:46:01.151: INFO: Got endpoints: latency-svc-nczxr [1.729949968s]
Dec  6 02:46:01.174: INFO: Created: latency-svc-gs7nt
Dec  6 02:46:01.277: INFO: Got endpoints: latency-svc-gs7nt [1.855480555s]
Dec  6 02:46:01.325: INFO: Created: latency-svc-tpgfd
Dec  6 02:46:01.454: INFO: Got endpoints: latency-svc-tpgfd [2.033498283s]
Dec  6 02:46:01.466: INFO: Created: latency-svc-rgztm
Dec  6 02:46:01.525: INFO: Got endpoints: latency-svc-rgztm [2.103901961s]
Dec  6 02:46:01.534: INFO: Created: latency-svc-pdjb8
Dec  6 02:46:01.654: INFO: Got endpoints: latency-svc-pdjb8 [2.060133358s]
Dec  6 02:46:01.668: INFO: Created: latency-svc-sn44k
Dec  6 02:46:01.829: INFO: Got endpoints: latency-svc-sn44k [2.173786938s]
Dec  6 02:46:01.831: INFO: Created: latency-svc-7s8mz
Dec  6 02:46:02.012: INFO: Got endpoints: latency-svc-7s8mz [2.239276373s]
Dec  6 02:46:02.015: INFO: Created: latency-svc-z76b6
Dec  6 02:46:02.077: INFO: Got endpoints: latency-svc-z76b6 [2.164160758s]
Dec  6 02:46:02.105: INFO: Created: latency-svc-p2mzx
Dec  6 02:46:02.187: INFO: Got endpoints: latency-svc-p2mzx [2.11596441s]
Dec  6 02:46:02.263: INFO: Created: latency-svc-dxmkr
Dec  6 02:46:02.388: INFO: Got endpoints: latency-svc-dxmkr [2.222536682s]
Dec  6 02:46:02.423: INFO: Created: latency-svc-c6kl6
Dec  6 02:46:02.480: INFO: Got endpoints: latency-svc-c6kl6 [2.21019024s]
Dec  6 02:46:02.571: INFO: Created: latency-svc-9z4lk
Dec  6 02:46:02.660: INFO: Got endpoints: latency-svc-9z4lk [2.175355977s]
Dec  6 02:46:02.747: INFO: Created: latency-svc-x99ll
Dec  6 02:46:02.844: INFO: Got endpoints: latency-svc-x99ll [2.221849823s]
Dec  6 02:46:02.929: INFO: Created: latency-svc-phl5f
Dec  6 02:46:02.996: INFO: Got endpoints: latency-svc-phl5f [2.230089675s]
Dec  6 02:46:03.096: INFO: Created: latency-svc-qcr88
Dec  6 02:46:03.165: INFO: Got endpoints: latency-svc-qcr88 [2.224941469s]
Dec  6 02:46:03.271: INFO: Created: latency-svc-v59n9
Dec  6 02:46:03.370: INFO: Got endpoints: latency-svc-v59n9 [2.218547316s]
Dec  6 02:46:03.446: INFO: Created: latency-svc-kx2b9
Dec  6 02:46:03.495: INFO: Got endpoints: latency-svc-kx2b9 [2.21841639s]
Dec  6 02:46:03.517: INFO: Created: latency-svc-rdw9h
Dec  6 02:46:03.604: INFO: Got endpoints: latency-svc-rdw9h [2.149620645s]
Dec  6 02:46:03.651: INFO: Created: latency-svc-p2l6j
Dec  6 02:46:03.812: INFO: Got endpoints: latency-svc-p2l6j [2.287292241s]
Dec  6 02:46:03.851: INFO: Created: latency-svc-sncpz
Dec  6 02:46:03.896: INFO: Got endpoints: latency-svc-sncpz [2.241827985s]
Dec  6 02:46:03.988: INFO: Created: latency-svc-2x5ln
Dec  6 02:46:04.185: INFO: Got endpoints: latency-svc-2x5ln [2.355684054s]
Dec  6 02:46:04.205: INFO: Created: latency-svc-dvn49
Dec  6 02:46:04.346: INFO: Got endpoints: latency-svc-dvn49 [2.333285718s]
Dec  6 02:46:04.370: INFO: Created: latency-svc-t7pt7
Dec  6 02:46:04.530: INFO: Got endpoints: latency-svc-t7pt7 [2.453737447s]
Dec  6 02:46:04.537: INFO: Created: latency-svc-f6znb
Dec  6 02:46:04.573: INFO: Got endpoints: latency-svc-f6znb [2.385264355s]
Dec  6 02:46:04.721: INFO: Created: latency-svc-bh7sn
Dec  6 02:46:04.748: INFO: Got endpoints: latency-svc-bh7sn [2.360419854s]
Dec  6 02:46:04.864: INFO: Created: latency-svc-s9rv5
Dec  6 02:46:04.905: INFO: Got endpoints: latency-svc-s9rv5 [2.424776219s]
Dec  6 02:46:05.029: INFO: Created: latency-svc-vlr8p
Dec  6 02:46:05.114: INFO: Got endpoints: latency-svc-vlr8p [2.453737799s]
Dec  6 02:46:05.229: INFO: Created: latency-svc-j9t88
Dec  6 02:46:05.261: INFO: Got endpoints: latency-svc-j9t88 [2.416944624s]
Dec  6 02:46:05.437: INFO: Created: latency-svc-tprjg
Dec  6 02:46:05.473: INFO: Got endpoints: latency-svc-tprjg [2.477594089s]
Dec  6 02:46:05.640: INFO: Created: latency-svc-kl5cs
Dec  6 02:46:05.804: INFO: Got endpoints: latency-svc-kl5cs [2.638568934s]
Dec  6 02:46:05.842: INFO: Created: latency-svc-dgdkb
Dec  6 02:46:05.888: INFO: Got endpoints: latency-svc-dgdkb [2.518330376s]
Dec  6 02:46:05.996: INFO: Created: latency-svc-r6j96
Dec  6 02:46:06.058: INFO: Got endpoints: latency-svc-r6j96 [2.562833275s]
Dec  6 02:46:06.165: INFO: Created: latency-svc-6gx5r
Dec  6 02:46:06.222: INFO: Got endpoints: latency-svc-6gx5r [2.617733986s]
Dec  6 02:46:06.329: INFO: Created: latency-svc-t5mzr
Dec  6 02:46:06.405: INFO: Got endpoints: latency-svc-t5mzr [2.592563731s]
Dec  6 02:46:06.521: INFO: Created: latency-svc-zls44
Dec  6 02:46:06.606: INFO: Got endpoints: latency-svc-zls44 [2.710072814s]
Dec  6 02:46:06.618: INFO: Created: latency-svc-9995l
Dec  6 02:46:06.732: INFO: Got endpoints: latency-svc-9995l [2.546791353s]
Dec  6 02:46:06.913: INFO: Created: latency-svc-tds7p
Dec  6 02:46:06.930: INFO: Got endpoints: latency-svc-tds7p [2.584517823s]
Dec  6 02:46:07.116: INFO: Created: latency-svc-dbx6w
Dec  6 02:46:07.149: INFO: Got endpoints: latency-svc-dbx6w [2.618969315s]
Dec  6 02:46:07.273: INFO: Created: latency-svc-m69c7
Dec  6 02:46:07.318: INFO: Got endpoints: latency-svc-m69c7 [2.745610925s]
Dec  6 02:46:07.344: INFO: Created: latency-svc-bdn87
Dec  6 02:46:07.445: INFO: Got endpoints: latency-svc-bdn87 [2.697098486s]
Dec  6 02:46:07.630: INFO: Created: latency-svc-xnmr8
Dec  6 02:46:07.677: INFO: Got endpoints: latency-svc-xnmr8 [2.772594937s]
Dec  6 02:46:07.727: INFO: Created: latency-svc-4fdq9
Dec  6 02:46:07.812: INFO: Got endpoints: latency-svc-4fdq9 [2.698181539s]
Dec  6 02:46:07.979: INFO: Created: latency-svc-p7kvt
Dec  6 02:46:08.077: INFO: Got endpoints: latency-svc-p7kvt [2.815906335s]
Dec  6 02:46:08.172: INFO: Created: latency-svc-hncg4
Dec  6 02:46:08.320: INFO: Got endpoints: latency-svc-hncg4 [2.847199808s]
Dec  6 02:46:08.412: INFO: Created: latency-svc-vbcnc
Dec  6 02:46:08.536: INFO: Got endpoints: latency-svc-vbcnc [2.732398104s]
Dec  6 02:46:08.557: INFO: Created: latency-svc-r4nll
Dec  6 02:46:08.745: INFO: Got endpoints: latency-svc-r4nll [2.85744316s]
Dec  6 02:46:08.761: INFO: Created: latency-svc-gjmvq
Dec  6 02:46:08.827: INFO: Got endpoints: latency-svc-gjmvq [2.768915069s]
Dec  6 02:46:09.056: INFO: Created: latency-svc-td9tv
Dec  6 02:46:09.079: INFO: Got endpoints: latency-svc-td9tv [2.857645509s]
Dec  6 02:46:09.228: INFO: Created: latency-svc-hrg2x
Dec  6 02:46:09.362: INFO: Created: latency-svc-zzk82
Dec  6 02:46:09.363: INFO: Got endpoints: latency-svc-hrg2x [2.958203349s]
Dec  6 02:46:09.575: INFO: Got endpoints: latency-svc-zzk82 [2.969101761s]
Dec  6 02:46:09.581: INFO: Created: latency-svc-2dpj8
Dec  6 02:46:09.755: INFO: Created: latency-svc-rn6g5
Dec  6 02:46:09.791: INFO: Got endpoints: latency-svc-2dpj8 [3.058956775s]
Dec  6 02:46:09.839: INFO: Got endpoints: latency-svc-rn6g5 [2.908712866s]
Dec  6 02:46:09.938: INFO: Created: latency-svc-6bvx7
Dec  6 02:46:09.988: INFO: Got endpoints: latency-svc-6bvx7 [2.838516071s]
Dec  6 02:46:10.006: INFO: Created: latency-svc-vp9mk
Dec  6 02:46:10.138: INFO: Got endpoints: latency-svc-vp9mk [2.820306059s]
Dec  6 02:46:10.173: INFO: Created: latency-svc-gz9kg
Dec  6 02:46:10.287: INFO: Got endpoints: latency-svc-gz9kg [2.841751023s]
Dec  6 02:46:10.356: INFO: Created: latency-svc-wbfnc
Dec  6 02:46:10.479: INFO: Got endpoints: latency-svc-wbfnc [2.801359867s]
Dec  6 02:46:10.508: INFO: Created: latency-svc-t6lpf
Dec  6 02:46:10.566: INFO: Got endpoints: latency-svc-t6lpf [2.754132726s]
Dec  6 02:46:10.687: INFO: Created: latency-svc-kdt5q
Dec  6 02:46:10.770: INFO: Got endpoints: latency-svc-kdt5q [2.692807935s]
Dec  6 02:46:10.890: INFO: Created: latency-svc-w2dsm
Dec  6 02:46:10.949: INFO: Got endpoints: latency-svc-w2dsm [2.628223139s]
Dec  6 02:46:11.058: INFO: Created: latency-svc-gxxfm
Dec  6 02:46:11.237: INFO: Got endpoints: latency-svc-gxxfm [2.70037022s]
Dec  6 02:46:11.238: INFO: Created: latency-svc-p5k8s
Dec  6 02:46:11.407: INFO: Got endpoints: latency-svc-p5k8s [2.66184512s]
Dec  6 02:46:11.429: INFO: Created: latency-svc-kp2pd
Dec  6 02:46:11.582: INFO: Got endpoints: latency-svc-kp2pd [2.755586806s]
Dec  6 02:46:11.635: INFO: Created: latency-svc-bqcj7
Dec  6 02:46:11.762: INFO: Got endpoints: latency-svc-bqcj7 [2.682503661s]
Dec  6 02:46:11.799: INFO: Created: latency-svc-2tpmm
Dec  6 02:46:11.945: INFO: Got endpoints: latency-svc-2tpmm [2.582168412s]
Dec  6 02:46:11.991: INFO: Created: latency-svc-8s762
Dec  6 02:46:12.138: INFO: Got endpoints: latency-svc-8s762 [2.56231632s]
Dec  6 02:46:12.174: INFO: Created: latency-svc-nmxzn
Dec  6 02:46:12.320: INFO: Got endpoints: latency-svc-nmxzn [2.529558547s]
Dec  6 02:46:12.365: INFO: Created: latency-svc-255w5
Dec  6 02:46:12.495: INFO: Got endpoints: latency-svc-255w5 [2.656013528s]
Dec  6 02:46:12.559: INFO: Created: latency-svc-x67ht
Dec  6 02:46:12.591: INFO: Got endpoints: latency-svc-x67ht [2.602894549s]
Dec  6 02:46:12.751: INFO: Created: latency-svc-cr8ls
Dec  6 02:46:12.862: INFO: Got endpoints: latency-svc-cr8ls [2.723213248s]
Dec  6 02:46:12.875: INFO: Created: latency-svc-szg6d
Dec  6 02:46:13.037: INFO: Got endpoints: latency-svc-szg6d [2.749811153s]
Dec  6 02:46:13.079: INFO: Created: latency-svc-xxz94
Dec  6 02:46:13.100: INFO: Got endpoints: latency-svc-xxz94 [2.621408627s]
Dec  6 02:46:13.242: INFO: Created: latency-svc-qpz4m
Dec  6 02:46:13.293: INFO: Got endpoints: latency-svc-qpz4m [2.726254045s]
Dec  6 02:46:13.438: INFO: Created: latency-svc-vcmc7
Dec  6 02:46:13.578: INFO: Got endpoints: latency-svc-vcmc7 [2.808155816s]
Dec  6 02:46:13.615: INFO: Created: latency-svc-5bvp2
Dec  6 02:46:13.663: INFO: Got endpoints: latency-svc-5bvp2 [2.714652041s]
Dec  6 02:46:13.763: INFO: Created: latency-svc-npwtw
Dec  6 02:46:13.860: INFO: Got endpoints: latency-svc-npwtw [2.6233507s]
Dec  6 02:46:13.946: INFO: Created: latency-svc-tghzb
Dec  6 02:46:14.179: INFO: Got endpoints: latency-svc-tghzb [2.7711893s]
Dec  6 02:46:14.179: INFO: Created: latency-svc-jkp5x
Dec  6 02:46:14.345: INFO: Got endpoints: latency-svc-jkp5x [2.762554691s]
Dec  6 02:46:14.395: INFO: Created: latency-svc-dbm56
Dec  6 02:46:14.520: INFO: Got endpoints: latency-svc-dbm56 [2.758460529s]
Dec  6 02:46:14.713: INFO: Created: latency-svc-cqr4k
Dec  6 02:46:14.790: INFO: Got endpoints: latency-svc-cqr4k [2.844671629s]
Dec  6 02:46:14.879: INFO: Created: latency-svc-8vt88
Dec  6 02:46:15.037: INFO: Got endpoints: latency-svc-8vt88 [2.898885078s]
Dec  6 02:46:15.075: INFO: Created: latency-svc-ptxcs
Dec  6 02:46:15.245: INFO: Got endpoints: latency-svc-ptxcs [2.924668074s]
Dec  6 02:46:15.302: INFO: Created: latency-svc-9tgqf
Dec  6 02:46:15.437: INFO: Got endpoints: latency-svc-9tgqf [2.941339819s]
Dec  6 02:46:15.507: INFO: Created: latency-svc-jml4s
Dec  6 02:46:15.646: INFO: Got endpoints: latency-svc-jml4s [3.05540991s]
Dec  6 02:46:15.717: INFO: Created: latency-svc-9vwbw
Dec  6 02:46:15.851: INFO: Got endpoints: latency-svc-9vwbw [2.989134371s]
Dec  6 02:46:15.877: INFO: Created: latency-svc-pxc8k
Dec  6 02:46:15.923: INFO: Got endpoints: latency-svc-pxc8k [2.886295926s]
Dec  6 02:46:15.951: INFO: Created: latency-svc-grvvw
Dec  6 02:46:16.037: INFO: Got endpoints: latency-svc-grvvw [2.936686333s]
Dec  6 02:46:16.128: INFO: Created: latency-svc-fhmn4
Dec  6 02:46:16.270: INFO: Got endpoints: latency-svc-fhmn4 [2.977268806s]
Dec  6 02:46:16.295: INFO: Created: latency-svc-ct5x5
Dec  6 02:46:16.334: INFO: Got endpoints: latency-svc-ct5x5 [2.755207493s]
Dec  6 02:46:16.487: INFO: Created: latency-svc-wvjnk
Dec  6 02:46:16.645: INFO: Got endpoints: latency-svc-wvjnk [2.981876037s]
Dec  6 02:46:16.646: INFO: Created: latency-svc-45dtw
Dec  6 02:46:16.732: INFO: Got endpoints: latency-svc-45dtw [2.871579529s]
Dec  6 02:46:16.839: INFO: Created: latency-svc-g87cg
Dec  6 02:46:17.029: INFO: Got endpoints: latency-svc-g87cg [2.850557686s]
Dec  6 02:46:17.065: INFO: Created: latency-svc-msfb4
Dec  6 02:46:17.213: INFO: Got endpoints: latency-svc-msfb4 [2.868040361s]
Dec  6 02:46:17.233: INFO: Created: latency-svc-vh9zc
Dec  6 02:46:17.362: INFO: Got endpoints: latency-svc-vh9zc [2.841341147s]
Dec  6 02:46:17.442: INFO: Created: latency-svc-7w68q
Dec  6 02:46:17.553: INFO: Got endpoints: latency-svc-7w68q [2.76314012s]
Dec  6 02:46:17.745: INFO: Created: latency-svc-8jsct
Dec  6 02:46:17.776: INFO: Got endpoints: latency-svc-8jsct [2.739048289s]
Dec  6 02:46:17.946: INFO: Created: latency-svc-l92wn
Dec  6 02:46:17.993: INFO: Got endpoints: latency-svc-l92wn [2.747566642s]
Dec  6 02:46:18.132: INFO: Created: latency-svc-mpspq
Dec  6 02:46:18.295: INFO: Got endpoints: latency-svc-mpspq [2.858487176s]
Dec  6 02:46:18.343: INFO: Created: latency-svc-nsqlp
Dec  6 02:46:18.494: INFO: Got endpoints: latency-svc-nsqlp [2.847188313s]
Dec  6 02:46:18.518: INFO: Created: latency-svc-hpzbv
Dec  6 02:46:18.558: INFO: Got endpoints: latency-svc-hpzbv [2.706685156s]
Dec  6 02:46:18.685: INFO: Created: latency-svc-qw2pl
Dec  6 02:46:18.718: INFO: Got endpoints: latency-svc-qw2pl [2.79517049s]
Dec  6 02:46:19.005: INFO: Created: latency-svc-wjtdt
Dec  6 02:46:19.039: INFO: Got endpoints: latency-svc-wjtdt [3.001583284s]
Dec  6 02:46:19.088: INFO: Created: latency-svc-lmnts
Dec  6 02:46:19.249: INFO: Got endpoints: latency-svc-lmnts [2.978712934s]
Dec  6 02:46:19.310: INFO: Created: latency-svc-nmm8l
Dec  6 02:46:19.468: INFO: Got endpoints: latency-svc-nmm8l [3.134246411s]
Dec  6 02:46:19.645: INFO: Created: latency-svc-7ts2q
Dec  6 02:46:19.686: INFO: Got endpoints: latency-svc-7ts2q [3.040277812s]
Dec  6 02:46:19.732: INFO: Created: latency-svc-rxgr9
Dec  6 02:46:19.952: INFO: Got endpoints: latency-svc-rxgr9 [3.220066485s]
Dec  6 02:46:19.985: INFO: Created: latency-svc-wvm4p
Dec  6 02:46:20.174: INFO: Created: latency-svc-rr649
Dec  6 02:46:20.345: INFO: Got endpoints: latency-svc-wvm4p [3.31582383s]
Dec  6 02:46:20.346: INFO: Created: latency-svc-n76k5
Dec  6 02:46:20.429: INFO: Got endpoints: latency-svc-n76k5 [3.067363641s]
Dec  6 02:46:20.528: INFO: Got endpoints: latency-svc-rr649 [3.315274915s]
Dec  6 02:46:20.529: INFO: Created: latency-svc-k2k9w
Dec  6 02:46:20.739: INFO: Got endpoints: latency-svc-k2k9w [3.185630892s]
Dec  6 02:46:20.739: INFO: Created: latency-svc-gzgdr
Dec  6 02:46:20.928: INFO: Got endpoints: latency-svc-gzgdr [3.152234071s]
Dec  6 02:46:20.997: INFO: Created: latency-svc-l9627
Dec  6 02:46:21.136: INFO: Got endpoints: latency-svc-l9627 [3.143697472s]
Dec  6 02:46:21.174: INFO: Created: latency-svc-dfw7v
Dec  6 02:46:21.328: INFO: Got endpoints: latency-svc-dfw7v [3.033201304s]
Dec  6 02:46:21.331: INFO: Created: latency-svc-svfs5
Dec  6 02:46:21.397: INFO: Got endpoints: latency-svc-svfs5 [2.903584708s]
Dec  6 02:46:21.420: INFO: Created: latency-svc-ddq9n
Dec  6 02:46:21.561: INFO: Got endpoints: latency-svc-ddq9n [3.003604844s]
Dec  6 02:46:21.603: INFO: Created: latency-svc-7g6xz
Dec  6 02:46:21.648: INFO: Got endpoints: latency-svc-7g6xz [2.93006945s]
Dec  6 02:46:21.798: INFO: Created: latency-svc-grbml
Dec  6 02:46:21.813: INFO: Got endpoints: latency-svc-grbml [2.774717034s]
Dec  6 02:46:21.954: INFO: Created: latency-svc-nl2nf
Dec  6 02:46:22.030: INFO: Got endpoints: latency-svc-nl2nf [2.781609776s]
Dec  6 02:46:22.133: INFO: Created: latency-svc-8cwx4
Dec  6 02:46:22.223: INFO: Got endpoints: latency-svc-8cwx4 [2.755203913s]
Dec  6 02:46:22.322: INFO: Created: latency-svc-bcpp4
Dec  6 02:46:22.375: INFO: Got endpoints: latency-svc-bcpp4 [2.689789224s]
Dec  6 02:46:22.490: INFO: Created: latency-svc-fqk5x
Dec  6 02:46:22.620: INFO: Got endpoints: latency-svc-fqk5x [2.667846245s]
Dec  6 02:46:22.646: INFO: Created: latency-svc-l4xpm
Dec  6 02:46:22.655: INFO: Got endpoints: latency-svc-l4xpm [2.310406674s]
Dec  6 02:46:22.816: INFO: Created: latency-svc-xz67x
Dec  6 02:46:22.936: INFO: Got endpoints: latency-svc-xz67x [2.507103227s]
Dec  6 02:46:22.975: INFO: Created: latency-svc-lfthx
Dec  6 02:46:23.035: INFO: Got endpoints: latency-svc-lfthx [2.506317029s]
Dec  6 02:46:23.128: INFO: Created: latency-svc-xjj4g
Dec  6 02:46:23.278: INFO: Got endpoints: latency-svc-xjj4g [2.539188802s]
Dec  6 02:46:23.304: INFO: Created: latency-svc-9lfsl
Dec  6 02:46:23.445: INFO: Got endpoints: latency-svc-9lfsl [2.516610915s]
Dec  6 02:46:23.519: INFO: Created: latency-svc-mnk8t
Dec  6 02:46:23.645: INFO: Got endpoints: latency-svc-mnk8t [2.508507856s]
Dec  6 02:46:23.820: INFO: Created: latency-svc-lc8gv
Dec  6 02:46:23.888: INFO: Got endpoints: latency-svc-lc8gv [2.559866557s]
Dec  6 02:46:23.913: INFO: Created: latency-svc-6q766
Dec  6 02:46:24.061: INFO: Got endpoints: latency-svc-6q766 [2.663274259s]
Dec  6 02:46:24.121: INFO: Created: latency-svc-7s6fc
Dec  6 02:46:24.269: INFO: Got endpoints: latency-svc-7s6fc [2.708157529s]
Dec  6 02:46:24.316: INFO: Created: latency-svc-qf6b9
Dec  6 02:46:24.503: INFO: Got endpoints: latency-svc-qf6b9 [2.854516515s]
Dec  6 02:46:24.524: INFO: Created: latency-svc-swdft
Dec  6 02:46:24.570: INFO: Got endpoints: latency-svc-swdft [2.756573464s]
Dec  6 02:46:24.706: INFO: Created: latency-svc-kkr9l
Dec  6 02:46:24.772: INFO: Got endpoints: latency-svc-kkr9l [2.741218451s]
Dec  6 02:46:24.903: INFO: Created: latency-svc-hrdz9
Dec  6 02:46:24.956: INFO: Got endpoints: latency-svc-hrdz9 [2.732656065s]
Dec  6 02:46:25.079: INFO: Created: latency-svc-n999b
Dec  6 02:46:25.254: INFO: Created: latency-svc-kzk5j
Dec  6 02:46:25.254: INFO: Got endpoints: latency-svc-n999b [2.878092084s]
Dec  6 02:46:25.344: INFO: Got endpoints: latency-svc-kzk5j [2.724118705s]
Dec  6 02:46:25.453: INFO: Created: latency-svc-g69hz
Dec  6 02:46:25.477: INFO: Got endpoints: latency-svc-g69hz [2.821965637s]
Dec  6 02:46:25.534: INFO: Created: latency-svc-2chgx
Dec  6 02:46:25.786: INFO: Got endpoints: latency-svc-2chgx [2.849695341s]
Dec  6 02:46:25.867: INFO: Created: latency-svc-d56v4
Dec  6 02:46:26.016: INFO: Got endpoints: latency-svc-d56v4 [2.980802251s]
Dec  6 02:46:26.088: INFO: Created: latency-svc-27fsq
Dec  6 02:46:26.224: INFO: Got endpoints: latency-svc-27fsq [2.946189315s]
Dec  6 02:46:26.300: INFO: Created: latency-svc-bz4dw
Dec  6 02:46:26.463: INFO: Got endpoints: latency-svc-bz4dw [3.01793414s]
Dec  6 02:46:26.464: INFO: Created: latency-svc-l9gqh
Dec  6 02:46:26.526: INFO: Got endpoints: latency-svc-l9gqh [2.88097123s]
Dec  6 02:46:26.640: INFO: Created: latency-svc-5plwn
Dec  6 02:46:26.795: INFO: Got endpoints: latency-svc-5plwn [2.906327868s]
Dec  6 02:46:26.795: INFO: Created: latency-svc-svjmv
Dec  6 02:46:26.871: INFO: Got endpoints: latency-svc-svjmv [2.810721994s]
Dec  6 02:46:26.889: INFO: Created: latency-svc-mq2p8
Dec  6 02:46:27.001: INFO: Got endpoints: latency-svc-mq2p8 [2.73105268s]
Dec  6 02:46:27.031: INFO: Created: latency-svc-rlq7q
Dec  6 02:46:27.203: INFO: Got endpoints: latency-svc-rlq7q [2.700138024s]
Dec  6 02:46:27.211: INFO: Created: latency-svc-k2dn7
Dec  6 02:46:27.265: INFO: Got endpoints: latency-svc-k2dn7 [2.694436851s]
Dec  6 02:46:27.536: INFO: Created: latency-svc-hrtgh
Dec  6 02:46:27.584: INFO: Got endpoints: latency-svc-hrtgh [2.812262123s]
Dec  6 02:46:27.608: INFO: Created: latency-svc-lphw2
Dec  6 02:46:27.765: INFO: Got endpoints: latency-svc-lphw2 [2.809493197s]
Dec  6 02:46:27.919: INFO: Created: latency-svc-jlp9m
Dec  6 02:46:28.018: INFO: Got endpoints: latency-svc-jlp9m [2.764047792s]
Dec  6 02:46:28.095: INFO: Created: latency-svc-shcdb
Dec  6 02:46:28.176: INFO: Got endpoints: latency-svc-shcdb [2.832479478s]
Dec  6 02:46:28.279: INFO: Created: latency-svc-6cvs4
Dec  6 02:46:28.492: INFO: Got endpoints: latency-svc-6cvs4 [3.01469264s]
Dec  6 02:46:28.540: INFO: Created: latency-svc-v2kxx
Dec  6 02:46:28.669: INFO: Got endpoints: latency-svc-v2kxx [2.883379392s]
Dec  6 02:46:28.697: INFO: Created: latency-svc-8qc2s
Dec  6 02:46:28.765: INFO: Got endpoints: latency-svc-8qc2s [2.749242819s]
Dec  6 02:46:28.945: INFO: Created: latency-svc-wwnt2
Dec  6 02:46:29.196: INFO: Got endpoints: latency-svc-wwnt2 [2.971473833s]
Dec  6 02:46:29.250: INFO: Created: latency-svc-7x8hx
Dec  6 02:46:29.292: INFO: Got endpoints: latency-svc-7x8hx [2.829710771s]
Dec  6 02:46:29.402: INFO: Created: latency-svc-8fkvn
Dec  6 02:46:29.544: INFO: Got endpoints: latency-svc-8fkvn [3.018234894s]
Dec  6 02:46:29.601: INFO: Created: latency-svc-rpjcc
Dec  6 02:46:29.711: INFO: Got endpoints: latency-svc-rpjcc [2.916420804s]
Dec  6 02:46:29.733: INFO: Created: latency-svc-r982d
Dec  6 02:46:29.917: INFO: Got endpoints: latency-svc-r982d [3.045309114s]
Dec  6 02:46:29.937: INFO: Created: latency-svc-bcnxt
Dec  6 02:46:29.994: INFO: Got endpoints: latency-svc-bcnxt [2.993132799s]
Dec  6 02:46:30.078: INFO: Created: latency-svc-74nl5
Dec  6 02:46:30.278: INFO: Created: latency-svc-mw82r
Dec  6 02:46:30.279: INFO: Got endpoints: latency-svc-74nl5 [3.075384467s]
Dec  6 02:46:30.305: INFO: Got endpoints: latency-svc-mw82r [3.0407128s]
Dec  6 02:46:30.355: INFO: Created: latency-svc-2mh6z
Dec  6 02:46:30.511: INFO: Created: latency-svc-s9chd
Dec  6 02:46:30.514: INFO: Got endpoints: latency-svc-2mh6z [2.930514827s]
Dec  6 02:46:30.521: INFO: Got endpoints: latency-svc-s9chd [2.755469716s]
Dec  6 02:46:30.662: INFO: Created: latency-svc-wf4dh
Dec  6 02:46:30.720: INFO: Got endpoints: latency-svc-wf4dh [2.702020656s]
Dec  6 02:46:30.921: INFO: Created: latency-svc-rhgsn
Dec  6 02:46:31.103: INFO: Got endpoints: latency-svc-rhgsn [2.926255534s]
Dec  6 02:46:31.125: INFO: Created: latency-svc-rtzf5
Dec  6 02:46:31.261: INFO: Got endpoints: latency-svc-rtzf5 [2.768404897s]
Dec  6 02:46:31.285: INFO: Created: latency-svc-m445q
Dec  6 02:46:31.301: INFO: Got endpoints: latency-svc-m445q [2.631434731s]
Dec  6 02:46:31.545: INFO: Created: latency-svc-ddczs
Dec  6 02:46:31.637: INFO: Got endpoints: latency-svc-ddczs [2.872223504s]
Dec  6 02:46:31.695: INFO: Created: latency-svc-8ktkl
Dec  6 02:46:31.853: INFO: Got endpoints: latency-svc-8ktkl [2.656829706s]
Dec  6 02:46:31.880: INFO: Created: latency-svc-h2w9t
Dec  6 02:46:32.027: INFO: Got endpoints: latency-svc-h2w9t [2.734876877s]
Dec  6 02:46:32.054: INFO: Created: latency-svc-d8vd9
Dec  6 02:46:32.202: INFO: Got endpoints: latency-svc-d8vd9 [2.658312121s]
Dec  6 02:46:32.222: INFO: Created: latency-svc-nh77q
Dec  6 02:46:32.286: INFO: Got endpoints: latency-svc-nh77q [2.574648782s]
Dec  6 02:46:32.369: INFO: Created: latency-svc-bs9hn
Dec  6 02:46:32.531: INFO: Got endpoints: latency-svc-bs9hn [2.614843669s]
Dec  6 02:46:32.563: INFO: Created: latency-svc-k7c6v
Dec  6 02:46:32.789: INFO: Got endpoints: latency-svc-k7c6v [2.795079276s]
Dec  6 02:46:32.901: INFO: Created: latency-svc-fs4dd
Dec  6 02:46:32.915: INFO: Got endpoints: latency-svc-fs4dd [2.636450532s]
Dec  6 02:46:33.053: INFO: Created: latency-svc-fn6tj
Dec  6 02:46:33.136: INFO: Got endpoints: latency-svc-fn6tj [2.830243061s]
Dec  6 02:46:33.237: INFO: Created: latency-svc-4h9f4
Dec  6 02:46:33.319: INFO: Got endpoints: latency-svc-4h9f4 [2.804123316s]
Dec  6 02:46:33.332: INFO: Created: latency-svc-nj4rp
Dec  6 02:46:33.423: INFO: Got endpoints: latency-svc-nj4rp [2.901964701s]
Dec  6 02:46:33.512: INFO: Created: latency-svc-m8vcz
Dec  6 02:46:33.634: INFO: Got endpoints: latency-svc-m8vcz [2.914559203s]
Dec  6 02:46:33.692: INFO: Created: latency-svc-fdqdx
Dec  6 02:46:33.819: INFO: Got endpoints: latency-svc-fdqdx [2.71638732s]
Dec  6 02:46:33.842: INFO: Created: latency-svc-nxqnm
Dec  6 02:46:34.011: INFO: Created: latency-svc-4drj8
Dec  6 02:46:34.012: INFO: Got endpoints: latency-svc-nxqnm [2.751180207s]
Dec  6 02:46:34.053: INFO: Got endpoints: latency-svc-4drj8 [2.75197348s]
Dec  6 02:46:34.179: INFO: Created: latency-svc-gxrpw
Dec  6 02:46:34.357: INFO: Got endpoints: latency-svc-gxrpw [2.719512886s]
Dec  6 02:46:34.536: INFO: Created: latency-svc-mgq9d
Dec  6 02:46:34.619: INFO: Got endpoints: latency-svc-mgq9d [2.76596743s]
Dec  6 02:46:34.719: INFO: Created: latency-svc-gxkfx
Dec  6 02:46:34.784: INFO: Got endpoints: latency-svc-gxkfx [2.756167s]
Dec  6 02:46:34.944: INFO: Created: latency-svc-rlfvg
Dec  6 02:46:35.037: INFO: Got endpoints: latency-svc-rlfvg [2.834416464s]
Dec  6 02:46:35.111: INFO: Created: latency-svc-9jj9g
Dec  6 02:46:35.162: INFO: Got endpoints: latency-svc-9jj9g [2.876344626s]
Dec  6 02:46:35.197: INFO: Created: latency-svc-k949v
Dec  6 02:46:35.355: INFO: Got endpoints: latency-svc-k949v [2.82308734s]
Dec  6 02:46:35.373: INFO: Created: latency-svc-k56n6
Dec  6 02:46:35.380: INFO: Got endpoints: latency-svc-k56n6 [2.591462998s]
Dec  6 02:46:35.380: INFO: Latencies: [173.258445ms 234.473149ms 352.22773ms 491.533483ms 650.196983ms 743.961327ms 848.657096ms 1.063818182s 1.201452922s 1.344352189s 1.519180089s 1.729949968s 1.855480555s 2.033498283s 2.060133358s 2.103901961s 2.11596441s 2.149620645s 2.164160758s 2.173786938s 2.175355977s 2.21019024s 2.21841639s 2.218547316s 2.221849823s 2.222536682s 2.224941469s 2.230089675s 2.239276373s 2.241827985s 2.287292241s 2.310406674s 2.333285718s 2.355684054s 2.360419854s 2.385264355s 2.416944624s 2.424776219s 2.453737447s 2.453737799s 2.477594089s 2.506317029s 2.507103227s 2.508507856s 2.516610915s 2.518330376s 2.529558547s 2.539188802s 2.546791353s 2.559866557s 2.56231632s 2.562833275s 2.574648782s 2.582168412s 2.584517823s 2.591462998s 2.592563731s 2.602894549s 2.614843669s 2.617733986s 2.618969315s 2.621408627s 2.6233507s 2.628223139s 2.631434731s 2.636450532s 2.638568934s 2.656013528s 2.656829706s 2.658312121s 2.66184512s 2.663274259s 2.667846245s 2.682503661s 2.689789224s 2.692807935s 2.694436851s 2.697098486s 2.698181539s 2.700138024s 2.70037022s 2.702020656s 2.706685156s 2.708157529s 2.710072814s 2.714652041s 2.71638732s 2.719512886s 2.723213248s 2.724118705s 2.726254045s 2.73105268s 2.732398104s 2.732656065s 2.734876877s 2.739048289s 2.741218451s 2.745610925s 2.747566642s 2.749242819s 2.749811153s 2.751180207s 2.75197348s 2.754132726s 2.755203913s 2.755207493s 2.755469716s 2.755586806s 2.756167s 2.756573464s 2.758460529s 2.762554691s 2.76314012s 2.764047792s 2.76596743s 2.768404897s 2.768915069s 2.7711893s 2.772594937s 2.774717034s 2.781609776s 2.795079276s 2.79517049s 2.801359867s 2.804123316s 2.808155816s 2.809493197s 2.810721994s 2.812262123s 2.815906335s 2.820306059s 2.821965637s 2.82308734s 2.829710771s 2.830243061s 2.832479478s 2.834416464s 2.838516071s 2.841341147s 2.841751023s 2.844671629s 2.847188313s 2.847199808s 2.849695341s 2.850557686s 2.854516515s 2.85744316s 2.857645509s 2.858487176s 2.868040361s 2.871579529s 2.872223504s 2.876344626s 2.878092084s 2.88097123s 2.883379392s 2.886295926s 2.898885078s 2.901964701s 2.903584708s 2.906327868s 2.908712866s 2.914559203s 2.916420804s 2.924668074s 2.926255534s 2.93006945s 2.930514827s 2.936686333s 2.941339819s 2.946189315s 2.958203349s 2.969101761s 2.971473833s 2.977268806s 2.978712934s 2.980802251s 2.981876037s 2.989134371s 2.993132799s 3.001583284s 3.003604844s 3.01469264s 3.01793414s 3.018234894s 3.033201304s 3.040277812s 3.0407128s 3.045309114s 3.05540991s 3.058956775s 3.067363641s 3.075384467s 3.134246411s 3.143697472s 3.152234071s 3.185630892s 3.220066485s 3.315274915s 3.31582383s]
Dec  6 02:46:35.384: INFO: 50 %ile: 2.749811153s
Dec  6 02:46:35.384: INFO: 90 %ile: 3.001583284s
Dec  6 02:46:35.384: INFO: 99 %ile: 3.315274915s
Dec  6 02:46:35.384: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:46:35.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-wwf9d" for this suite.
Dec  6 02:47:31.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:47:31.527: INFO: namespace: e2e-tests-svc-latency-wwf9d, resource: bindings, ignored listing per whitelist
Dec  6 02:47:31.588: INFO: namespace e2e-tests-svc-latency-wwf9d deletion completed in 56.194991587s

• [SLOW TEST:95.723 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:47:31.588: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  6 02:47:31.893: INFO: Waiting up to 5m0s for pod "pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-ns2xn" to be "success or failure"
Dec  6 02:47:31.939: INFO: Pod "pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 45.593384ms
Dec  6 02:47:33.943: INFO: Pod "pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049438183s
Dec  6 02:47:35.947: INFO: Pod "pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054091837s
STEP: Saw pod success
Dec  6 02:47:35.947: INFO: Pod "pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:47:35.951: INFO: Trying to get logs from node k8s-g1 pod pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:47:36.045: INFO: Waiting for pod pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:47:36.049: INFO: Pod pod-4723a0fb-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:47:36.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ns2xn" for this suite.
Dec  6 02:47:42.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:47:42.213: INFO: namespace: e2e-tests-emptydir-ns2xn, resource: bindings, ignored listing per whitelist
Dec  6 02:47:42.257: INFO: namespace e2e-tests-emptydir-ns2xn deletion completed in 6.200333821s

• [SLOW TEST:10.669 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:47:42.257: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-4d8188a0-f901-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:47:42.638: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-n69l6" to be "success or failure"
Dec  6 02:47:42.641: INFO: Pod "pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.935954ms
Dec  6 02:47:44.645: INFO: Pod "pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00773741s
Dec  6 02:47:46.681: INFO: Pod "pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043874629s
STEP: Saw pod success
Dec  6 02:47:46.681: INFO: Pod "pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:47:46.686: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:47:46.864: INFO: Waiting for pod pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:47:46.868: INFO: Pod pod-projected-configmaps-4d864f48-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:47:46.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n69l6" for this suite.
Dec  6 02:47:52.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:47:53.049: INFO: namespace: e2e-tests-projected-n69l6, resource: bindings, ignored listing per whitelist
Dec  6 02:47:53.049: INFO: namespace e2e-tests-projected-n69l6 deletion completed in 6.173706733s

• [SLOW TEST:10.791 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:47:53.049: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:47:53.291: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-shqx4" to be "success or failure"
Dec  6 02:47:53.295: INFO: Pod "downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885358ms
Dec  6 02:47:55.299: INFO: Pod "downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007727612s
Dec  6 02:47:57.304: INFO: Pod "downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012248418s
STEP: Saw pod success
Dec  6 02:47:57.304: INFO: Pod "downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:47:57.307: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:47:57.393: INFO: Waiting for pod downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:47:57.397: INFO: Pod downwardapi-volume-53e77fd3-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:47:57.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-shqx4" for this suite.
Dec  6 02:48:03.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:48:03.494: INFO: namespace: e2e-tests-downward-api-shqx4, resource: bindings, ignored listing per whitelist
Dec  6 02:48:03.583: INFO: namespace e2e-tests-downward-api-shqx4 deletion completed in 6.17959029s

• [SLOW TEST:10.535 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:48:03.583: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1206 02:48:13.898913      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  6 02:48:13.898: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:48:13.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l8rcs" for this suite.
Dec  6 02:48:19.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:48:20.020: INFO: namespace: e2e-tests-gc-l8rcs, resource: bindings, ignored listing per whitelist
Dec  6 02:48:20.076: INFO: namespace e2e-tests-gc-l8rcs deletion completed in 6.17086808s

• [SLOW TEST:16.493 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:48:20.076: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-64035720-f901-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:48:20.369: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-ncgsq" to be "success or failure"
Dec  6 02:48:20.466: INFO: Pod "pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 97.371345ms
Dec  6 02:48:22.471: INFO: Pod "pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102663921s
Dec  6 02:48:24.479: INFO: Pod "pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109942937s
STEP: Saw pod success
Dec  6 02:48:24.479: INFO: Pod "pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:48:24.485: INFO: Trying to get logs from node k8s-g2 pod pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:48:24.585: INFO: Waiting for pod pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:48:24.593: INFO: Pod pod-projected-secrets-6406ca9b-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:48:24.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ncgsq" for this suite.
Dec  6 02:48:30.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:48:30.696: INFO: namespace: e2e-tests-projected-ncgsq, resource: bindings, ignored listing per whitelist
Dec  6 02:48:30.808: INFO: namespace e2e-tests-projected-ncgsq deletion completed in 6.207225594s

• [SLOW TEST:10.732 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:48:30.808: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qvsjv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  6 02:48:31.159: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  6 02:48:49.465: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.138:8080/dial?request=hostName&protocol=udp&host=10.244.4.121&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-qvsjv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:48:49.465: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:48:49.542: INFO: Waiting for endpoints: map[]
Dec  6 02:48:49.546: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.138:8080/dial?request=hostName&protocol=udp&host=10.244.3.137&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-qvsjv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 02:48:49.546: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 02:48:49.617: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:48:49.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qvsjv" for this suite.
Dec  6 02:49:13.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:49:13.670: INFO: namespace: e2e-tests-pod-network-test-qvsjv, resource: bindings, ignored listing per whitelist
Dec  6 02:49:13.858: INFO: namespace e2e-tests-pod-network-test-qvsjv deletion completed in 24.234868126s

• [SLOW TEST:43.050 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:49:13.858: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-8419ff81-f901-11e8-a2c6-1eb929de0ff1
STEP: Creating secret with name s-test-opt-upd-8419ffe4-f901-11e8-a2c6-1eb929de0ff1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8419ff81-f901-11e8-a2c6-1eb929de0ff1
STEP: Updating secret s-test-opt-upd-8419ffe4-f901-11e8-a2c6-1eb929de0ff1
STEP: Creating secret with name s-test-opt-create-841a0012-f901-11e8-a2c6-1eb929de0ff1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:50:47.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4h55j" for this suite.
Dec  6 02:51:11.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:51:11.245: INFO: namespace: e2e-tests-projected-4h55j, resource: bindings, ignored listing per whitelist
Dec  6 02:51:11.314: INFO: namespace e2e-tests-projected-4h55j deletion completed in 24.169130243s

• [SLOW TEST:117.456 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:51:11.314: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:51:11.605: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:51:12.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-4t5s7" for this suite.
Dec  6 02:51:18.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:51:18.843: INFO: namespace: e2e-tests-custom-resource-definition-4t5s7, resource: bindings, ignored listing per whitelist
Dec  6 02:51:18.983: INFO: namespace e2e-tests-custom-resource-definition-4t5s7 deletion completed in 6.190915179s

• [SLOW TEST:7.669 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:51:18.983: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
Dec  6 02:51:19.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 create -f - --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:22.097: INFO: stderr: ""
Dec  6 02:51:22.097: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  6 02:51:22.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:22.165: INFO: stderr: ""
Dec  6 02:51:22.165: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Dec  6 02:51:27.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:27.246: INFO: stderr: ""
Dec  6 02:51:27.246: INFO: stdout: "update-demo-nautilus-h2mjv update-demo-nautilus-nklxj "
Dec  6 02:51:27.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:27.305: INFO: stderr: ""
Dec  6 02:51:27.305: INFO: stdout: "true"
Dec  6 02:51:27.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:27.366: INFO: stderr: ""
Dec  6 02:51:27.366: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:51:27.366: INFO: validating pod update-demo-nautilus-h2mjv
Dec  6 02:51:27.371: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:51:27.371: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:51:27.371: INFO: update-demo-nautilus-h2mjv is verified up and running
Dec  6 02:51:27.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-nklxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:27.431: INFO: stderr: ""
Dec  6 02:51:27.431: INFO: stdout: "true"
Dec  6 02:51:27.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-nklxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:27.491: INFO: stderr: ""
Dec  6 02:51:27.491: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:51:27.491: INFO: validating pod update-demo-nautilus-nklxj
Dec  6 02:51:27.497: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:51:27.497: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:51:27.497: INFO: update-demo-nautilus-nklxj is verified up and running
STEP: scaling down the replication controller
Dec  6 02:51:27.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:28.629: INFO: stderr: ""
Dec  6 02:51:28.629: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  6 02:51:28.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:28.691: INFO: stderr: ""
Dec  6 02:51:28.691: INFO: stdout: "update-demo-nautilus-h2mjv update-demo-nautilus-nklxj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  6 02:51:33.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:33.777: INFO: stderr: ""
Dec  6 02:51:33.777: INFO: stdout: "update-demo-nautilus-h2mjv update-demo-nautilus-nklxj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  6 02:51:38.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:38.845: INFO: stderr: ""
Dec  6 02:51:38.845: INFO: stdout: "update-demo-nautilus-h2mjv "
Dec  6 02:51:38.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:38.908: INFO: stderr: ""
Dec  6 02:51:38.908: INFO: stdout: "true"
Dec  6 02:51:38.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:38.977: INFO: stderr: ""
Dec  6 02:51:38.977: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:51:38.977: INFO: validating pod update-demo-nautilus-h2mjv
Dec  6 02:51:38.982: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:51:38.982: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:51:38.982: INFO: update-demo-nautilus-h2mjv is verified up and running
STEP: scaling up the replication controller
Dec  6 02:51:38.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:40.162: INFO: stderr: ""
Dec  6 02:51:40.162: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  6 02:51:40.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:40.226: INFO: stderr: ""
Dec  6 02:51:40.226: INFO: stdout: "update-demo-nautilus-h2mjv update-demo-nautilus-ndbd5 "
Dec  6 02:51:40.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:40.285: INFO: stderr: ""
Dec  6 02:51:40.285: INFO: stdout: "true"
Dec  6 02:51:40.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:40.346: INFO: stderr: ""
Dec  6 02:51:40.346: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:51:40.346: INFO: validating pod update-demo-nautilus-h2mjv
Dec  6 02:51:40.351: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:51:40.351: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:51:40.351: INFO: update-demo-nautilus-h2mjv is verified up and running
Dec  6 02:51:40.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-ndbd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:40.410: INFO: stderr: ""
Dec  6 02:51:40.410: INFO: stdout: ""
Dec  6 02:51:40.410: INFO: update-demo-nautilus-ndbd5 is created but not running
Dec  6 02:51:45.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.482: INFO: stderr: ""
Dec  6 02:51:45.482: INFO: stdout: "update-demo-nautilus-h2mjv update-demo-nautilus-ndbd5 "
Dec  6 02:51:45.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.542: INFO: stderr: ""
Dec  6 02:51:45.542: INFO: stdout: "true"
Dec  6 02:51:45.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-h2mjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.601: INFO: stderr: ""
Dec  6 02:51:45.601: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:51:45.601: INFO: validating pod update-demo-nautilus-h2mjv
Dec  6 02:51:45.606: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:51:45.606: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:51:45.606: INFO: update-demo-nautilus-h2mjv is verified up and running
Dec  6 02:51:45.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-ndbd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.666: INFO: stderr: ""
Dec  6 02:51:45.666: INFO: stdout: "true"
Dec  6 02:51:45.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods update-demo-nautilus-ndbd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.725: INFO: stderr: ""
Dec  6 02:51:45.725: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
Dec  6 02:51:45.725: INFO: validating pod update-demo-nautilus-ndbd5
Dec  6 02:51:45.730: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  6 02:51:45.730: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  6 02:51:45.730: INFO: update-demo-nautilus-ndbd5 is verified up and running
STEP: using delete to clean up resources
Dec  6 02:51:45.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.815: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  6 02:51:45.815: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  6 02:51:45.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7w47k'
Dec  6 02:51:45.910: INFO: stderr: "No resources found.\n"
Dec  6 02:51:45.910: INFO: stdout: ""
Dec  6 02:51:45.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7w47k -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  6 02:51:46.021: INFO: stderr: ""
Dec  6 02:51:46.021: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:51:46.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7w47k" for this suite.
Dec  6 02:52:10.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:52:10.113: INFO: namespace: e2e-tests-kubectl-7w47k, resource: bindings, ignored listing per whitelist
Dec  6 02:52:10.257: INFO: namespace e2e-tests-kubectl-7w47k deletion completed in 24.230081438s

• [SLOW TEST:51.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:52:10.257: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
Dec  6 02:52:10.636: INFO: Waiting up to 5m0s for pod "client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-containers-qvpz2" to be "success or failure"
Dec  6 02:52:10.640: INFO: Pod "client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.997319ms
Dec  6 02:52:12.666: INFO: Pod "client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029339218s
Dec  6 02:52:14.670: INFO: Pod "client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033825549s
STEP: Saw pod success
Dec  6 02:52:14.670: INFO: Pod "client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:52:14.674: INFO: Trying to get logs from node k8s-g1 pod client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:52:14.769: INFO: Waiting for pod client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:52:14.775: INFO: Pod client-containers-ed44cfb4-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:52:14.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qvpz2" for this suite.
Dec  6 02:52:20.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:52:20.903: INFO: namespace: e2e-tests-containers-qvpz2, resource: bindings, ignored listing per whitelist
Dec  6 02:52:20.946: INFO: namespace e2e-tests-containers-qvpz2 deletion completed in 6.163662801s

• [SLOW TEST:10.689 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:52:20.946: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 02:52:21.277: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-vs8qh" to be "success or failure"
Dec  6 02:52:21.292: INFO: Pod "downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.828138ms
Dec  6 02:52:23.296: INFO: Pod "downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018731164s
Dec  6 02:52:25.300: INFO: Pod "downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022699854s
STEP: Saw pod success
Dec  6 02:52:25.300: INFO: Pod "downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:52:25.304: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 02:52:25.395: INFO: Waiting for pod downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:52:25.399: INFO: Pod downwardapi-volume-f3a17135-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:52:25.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vs8qh" for this suite.
Dec  6 02:52:31.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:52:31.521: INFO: namespace: e2e-tests-downward-api-vs8qh, resource: bindings, ignored listing per whitelist
Dec  6 02:52:31.578: INFO: namespace e2e-tests-downward-api-vs8qh deletion completed in 6.172230457s

• [SLOW TEST:10.632 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:52:31.578: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting the proxy server
Dec  6 02:52:31.866: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-630354635 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:52:31.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5s2nx" for this suite.
Dec  6 02:52:37.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:52:38.096: INFO: namespace: e2e-tests-kubectl-5s2nx, resource: bindings, ignored listing per whitelist
Dec  6 02:52:38.126: INFO: namespace e2e-tests-kubectl-5s2nx deletion completed in 6.197599599s

• [SLOW TEST:6.548 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:52:38.126: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Dec  6 02:52:38.514: INFO: Waiting up to 5m0s for pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-rclhp" to be "success or failure"
Dec  6 02:52:38.518: INFO: Pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535127ms
Dec  6 02:52:40.617: INFO: Pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102501237s
Dec  6 02:52:42.623: INFO: Pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.10910068s
Dec  6 02:52:44.629: INFO: Pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.114538598s
Dec  6 02:52:46.663: INFO: Pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.149001359s
STEP: Saw pod success
Dec  6 02:52:46.663: INFO: Pod "downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:52:46.667: INFO: Trying to get logs from node k8s-g1 pod downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 02:52:46.734: INFO: Waiting for pod downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:52:46.738: INFO: Pod downward-api-fdd9c4d3-f901-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:52:46.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rclhp" for this suite.
Dec  6 02:52:52.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:52:52.846: INFO: namespace: e2e-tests-downward-api-rclhp, resource: bindings, ignored listing per whitelist
Dec  6 02:52:52.971: INFO: namespace e2e-tests-downward-api-rclhp deletion completed in 6.225951383s

• [SLOW TEST:14.844 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:52:52.971: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-06b3aa79-f902-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:52:53.295: INFO: Waiting up to 5m0s for pod "pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-wcx22" to be "success or failure"
Dec  6 02:52:53.298: INFO: Pod "pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.629792ms
Dec  6 02:52:55.302: INFO: Pod "pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007612269s
Dec  6 02:52:57.307: INFO: Pod "pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012100913s
STEP: Saw pod success
Dec  6 02:52:57.307: INFO: Pod "pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:52:57.310: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:52:57.362: INFO: Waiting for pod pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:52:57.368: INFO: Pod pod-secrets-06b7d19a-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:52:57.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wcx22" for this suite.
Dec  6 02:53:03.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:53:03.418: INFO: namespace: e2e-tests-secrets-wcx22, resource: bindings, ignored listing per whitelist
Dec  6 02:53:03.546: INFO: namespace e2e-tests-secrets-wcx22 deletion completed in 6.169416186s

• [SLOW TEST:10.575 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:53:03.546: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 Pods, got 2 Pods
STEP: Gathering metrics
W1206 02:53:04.924989      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  6 02:53:04.925: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:53:04.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rbnbm" for this suite.
Dec  6 02:53:10.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:53:11.073: INFO: namespace: e2e-tests-gc-rbnbm, resource: bindings, ignored listing per whitelist
Dec  6 02:53:11.136: INFO: namespace e2e-tests-gc-rbnbm deletion completed in 6.205467994s

• [SLOW TEST:7.590 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:53:11.136: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:54:11.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zlq4h" for this suite.
Dec  6 02:54:35.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:54:35.664: INFO: namespace: e2e-tests-container-probe-zlq4h, resource: bindings, ignored listing per whitelist
Dec  6 02:54:35.683: INFO: namespace e2e-tests-container-probe-zlq4h deletion completed in 24.16738485s

• [SLOW TEST:84.547 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:54:35.683: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-43efc11e-f902-11e8-a2c6-1eb929de0ff1
STEP: Creating secret with name secret-projected-all-test-volume-43efc10e-f902-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  6 02:54:36.107: INFO: Waiting up to 5m0s for pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-9c6xk" to be "success or failure"
Dec  6 02:54:36.130: INFO: Pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.887954ms
Dec  6 02:54:38.134: INFO: Pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026971216s
Dec  6 02:54:40.139: INFO: Pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031944665s
Dec  6 02:54:42.143: INFO: Pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035951356s
Dec  6 02:54:44.147: INFO: Pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.040046239s
STEP: Saw pod success
Dec  6 02:54:44.147: INFO: Pod "projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:54:44.151: INFO: Trying to get logs from node k8s-g2 pod projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  6 02:54:44.265: INFO: Waiting for pod projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:54:44.269: INFO: Pod projected-volume-43efc0e6-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:54:44.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9c6xk" for this suite.
Dec  6 02:54:50.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:54:50.526: INFO: namespace: e2e-tests-projected-9c6xk, resource: bindings, ignored listing per whitelist
Dec  6 02:54:50.530: INFO: namespace e2e-tests-projected-9c6xk deletion completed in 6.252526652s

• [SLOW TEST:14.847 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:54:50.530: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-4cd0f034-f902-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 02:54:51.115: INFO: Waiting up to 5m0s for pod "pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-kfcpt" to be "success or failure"
Dec  6 02:54:51.119: INFO: Pod "pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.255695ms
Dec  6 02:54:53.124: INFO: Pod "pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008465711s
Dec  6 02:54:55.128: INFO: Pod "pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012461355s
STEP: Saw pod success
Dec  6 02:54:55.128: INFO: Pod "pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:54:55.132: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 02:54:55.365: INFO: Waiting for pod pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:54:55.370: INFO: Pod pod-configmaps-4cdb1958-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:54:55.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kfcpt" for this suite.
Dec  6 02:55:03.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:55:03.499: INFO: namespace: e2e-tests-configmap-kfcpt, resource: bindings, ignored listing per whitelist
Dec  6 02:55:03.557: INFO: namespace e2e-tests-configmap-kfcpt deletion completed in 8.178382117s

• [SLOW TEST:13.027 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:55:03.557: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
Dec  6 02:55:03.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-9c4ks'
Dec  6 02:55:03.934: INFO: stderr: ""
Dec  6 02:55:03.934: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  6 02:55:03.941: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  6 02:55:04.047: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  6 02:55:04.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-9c4ks'
Dec  6 02:55:20.091: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  6 02:55:20.091: INFO: stdout: "Created e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7\nScaling up e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  6 02:55:20.092: INFO: stdout: "Created e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7\nScaling up e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  6 02:55:20.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9c4ks'
Dec  6 02:55:20.225: INFO: stderr: ""
Dec  6 02:55:20.225: INFO: stdout: "e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7-lhl7r "
Dec  6 02:55:20.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7-lhl7r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9c4ks'
Dec  6 02:55:20.307: INFO: stderr: ""
Dec  6 02:55:20.308: INFO: stdout: "true"
Dec  6 02:55:20.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 get pods e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7-lhl7r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9c4ks'
Dec  6 02:55:20.376: INFO: stderr: ""
Dec  6 02:55:20.376: INFO: stdout: "k8s.gcr.io/nginx-slim-amd64:0.20"
Dec  6 02:55:20.376: INFO: e2e-test-nginx-rc-acb4404bd9f4de6a82916a82e4831cf7-lhl7r is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
Dec  6 02:55:20.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9c4ks'
Dec  6 02:55:20.465: INFO: stderr: ""
Dec  6 02:55:20.465: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:55:20.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9c4ks" for this suite.
Dec  6 02:55:44.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:55:44.822: INFO: namespace: e2e-tests-kubectl-9c4ks, resource: bindings, ignored listing per whitelist
Dec  6 02:55:44.830: INFO: namespace e2e-tests-kubectl-9c4ks deletion completed in 24.357590734s

• [SLOW TEST:41.273 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:55:44.830: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Dec  6 02:55:49.746: INFO: Successfully updated pod "labelsupdate6d1f46b6-f902-11e8-a2c6-1eb929de0ff1"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:55:51.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wl5kq" for this suite.
Dec  6 02:56:15.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:56:16.062: INFO: namespace: e2e-tests-downward-api-wl5kq, resource: bindings, ignored listing per whitelist
Dec  6 02:56:16.094: INFO: namespace e2e-tests-downward-api-wl5kq deletion completed in 24.190407985s

• [SLOW TEST:31.264 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:56:16.094: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  6 02:56:16.361: INFO: Waiting up to 5m0s for pod "pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-rtbfr" to be "success or failure"
Dec  6 02:56:16.365: INFO: Pod "pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.60634ms
Dec  6 02:56:18.369: INFO: Pod "pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007924401s
Dec  6 02:56:20.374: INFO: Pod "pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012542865s
STEP: Saw pod success
Dec  6 02:56:20.374: INFO: Pod "pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:56:20.378: INFO: Trying to get logs from node k8s-g1 pod pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 02:56:20.420: INFO: Waiting for pod pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:56:20.426: INFO: Pod pod-7fc0c799-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:56:20.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rtbfr" for this suite.
Dec  6 02:56:26.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:56:26.508: INFO: namespace: e2e-tests-emptydir-rtbfr, resource: bindings, ignored listing per whitelist
Dec  6 02:56:26.694: INFO: namespace e2e-tests-emptydir-rtbfr deletion completed in 6.259790564s

• [SLOW TEST:10.600 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:56:26.694: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-qbwdb
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qbwdb
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qbwdb
Dec  6 02:56:27.008: INFO: Found 0 stateful pods, waiting for 1
Dec  6 02:56:37.012: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  6 02:56:37.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:56:37.207: INFO: stderr: ""
Dec  6 02:56:37.207: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:56:37.207: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:56:37.211: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  6 02:56:47.216: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:56:47.216: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:56:47.281: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:56:47.281: INFO: ss-0  k8s-g2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:56:47.281: INFO: 
Dec  6 02:56:47.281: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  6 02:56:48.287: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995671408s
Dec  6 02:56:49.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990372521s
Dec  6 02:56:50.301: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985959422s
Dec  6 02:56:51.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97642402s
Dec  6 02:56:52.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971452522s
Dec  6 02:56:53.346: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.935899782s
Dec  6 02:56:54.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.93137332s
Dec  6 02:56:55.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.927051464s
Dec  6 02:56:56.359: INFO: Verifying statefulset ss doesn't scale past 3 for another 921.857423ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qbwdb
Dec  6 02:56:57.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:56:57.523: INFO: stderr: ""
Dec  6 02:56:57.523: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  6 02:56:57.523: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  6 02:56:57.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:56:57.665: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Dec  6 02:56:57.665: INFO: stdout: ""
Dec  6 02:56:57.665: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Dec  6 02:56:57.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  6 02:56:57.802: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
Dec  6 02:56:57.802: INFO: stdout: ""
Dec  6 02:56:57.802: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec  6 02:56:57.816: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec  6 02:57:07.821: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:57:07.821: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  6 02:57:07.821: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  6 02:57:07.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:57:07.956: INFO: stderr: ""
Dec  6 02:57:07.956: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:57:07.956: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:57:07.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:57:08.152: INFO: stderr: ""
Dec  6 02:57:08.152: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:57:08.152: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:57:08.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 exec --namespace=e2e-tests-statefulset-qbwdb ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  6 02:57:08.526: INFO: stderr: ""
Dec  6 02:57:08.526: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  6 02:57:08.526: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  6 02:57:08.526: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:57:08.531: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  6 02:57:18.539: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:57:18.540: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:57:18.540: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  6 02:57:18.574: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:18.574: INFO: ss-0  k8s-g2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:18.574: INFO: ss-1  k8s-g1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:18.574: INFO: ss-2  k8s-g2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:18.574: INFO: 
Dec  6 02:57:18.574: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:19.579: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:19.579: INFO: ss-0  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:19.579: INFO: ss-1  k8s-g1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:19.579: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:19.579: INFO: 
Dec  6 02:57:19.579: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:20.611: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:20.611: INFO: ss-0  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:20.611: INFO: ss-1  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:20.611: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:20.611: INFO: 
Dec  6 02:57:20.611: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:21.616: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:21.616: INFO: ss-0  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:21.616: INFO: ss-1  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:21.616: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:21.616: INFO: 
Dec  6 02:57:21.616: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:22.620: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:22.620: INFO: ss-0  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:22.620: INFO: ss-1  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:22.620: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:22.620: INFO: 
Dec  6 02:57:22.620: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:23.625: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:23.625: INFO: ss-0  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:23.625: INFO: ss-1  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:23.625: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:23.625: INFO: 
Dec  6 02:57:23.625: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:24.631: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:24.631: INFO: ss-0  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:24.631: INFO: ss-1  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:24.631: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:24.631: INFO: 
Dec  6 02:57:24.631: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:25.636: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:25.636: INFO: ss-0  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:25.636: INFO: ss-1  k8s-g1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:25.637: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:25.637: INFO: 
Dec  6 02:57:25.637: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:26.681: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Dec  6 02:57:26.681: INFO: ss-0  k8s-g2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:27 +0000 UTC  }]
Dec  6 02:57:26.681: INFO: ss-1  k8s-g1  Pending  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:26.681: INFO: ss-2  k8s-g2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:57:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-06 02:56:47 +0000 UTC  }]
Dec  6 02:57:26.681: INFO: 
Dec  6 02:57:26.681: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  6 02:57:27.686: INFO: Verifying statefulset ss doesn't scale past 0 for another 888.060784ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qbwdb
Dec  6 02:57:28.697: INFO: Scaling statefulset ss to 0
Dec  6 02:57:28.710: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
Dec  6 02:57:28.714: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qbwdb
Dec  6 02:57:28.718: INFO: Scaling statefulset ss to 0
Dec  6 02:57:28.730: INFO: Waiting for statefulset status.replicas updated to 0
Dec  6 02:57:28.734: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:57:28.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qbwdb" for this suite.
Dec  6 02:57:36.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:57:36.965: INFO: namespace: e2e-tests-statefulset-qbwdb, resource: bindings, ignored listing per whitelist
Dec  6 02:57:37.044: INFO: namespace e2e-tests-statefulset-qbwdb deletion completed in 8.267073702s

• [SLOW TEST:70.349 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:57:37.044: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-b0070261-f902-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:57:37.467: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-tvpwz" to be "success or failure"
Dec  6 02:57:37.486: INFO: Pod "pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.830492ms
Dec  6 02:57:39.491: INFO: Pod "pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024399754s
Dec  6 02:57:41.496: INFO: Pod "pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029176899s
STEP: Saw pod success
Dec  6 02:57:41.496: INFO: Pod "pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:57:41.500: INFO: Trying to get logs from node k8s-g1 pod pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  6 02:57:41.626: INFO: Waiting for pod pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:57:41.631: INFO: Pod pod-projected-secrets-b013c908-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:57:41.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tvpwz" for this suite.
Dec  6 02:57:49.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:57:49.776: INFO: namespace: e2e-tests-projected-tvpwz, resource: bindings, ignored listing per whitelist
Dec  6 02:57:49.826: INFO: namespace e2e-tests-projected-tvpwz deletion completed in 8.187577799s

• [SLOW TEST:12.782 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:57:49.826: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Dec  6 02:57:50.053: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  6 02:58:50.084: INFO: Waiting for terminating namespaces to be deleted...
Dec  6 02:58:50.105: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  6 02:58:50.123: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  6 02:58:50.123: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  6 02:58:50.129: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Dec  6 02:58:50.129: INFO: 
Logging pods the kubelet thinks is on node k8s-g1 before test
Dec  6 02:58:50.140: INFO: calico-node-4mdfp from kube-system started at 2018-12-05 06:20:39 +0000 UTC (2 container statuses recorded)
Dec  6 02:58:50.140: INFO: 	Container calico-node ready: true, restart count 0
Dec  6 02:58:50.140: INFO: 	Container install-cni ready: true, restart count 0
Dec  6 02:58:50.140: INFO: sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-8vjk4 from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 02:58:50.140: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  6 02:58:50.140: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  6 02:58:50.140: INFO: nvidia-device-plugin-daemonset-smpqz from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:58:50.140: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  6 02:58:50.140: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-06 01:55:44 +0000 UTC (1 container statuses recorded)
Dec  6 02:58:50.140: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  6 02:58:50.140: INFO: kube-proxy-7jvxn from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:58:50.140: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  6 02:58:50.140: INFO: 
Logging pods the kubelet thinks is on node k8s-g2 before test
Dec  6 02:58:50.151: INFO: tf-gpu-1-56564965df-4kqpb from default started at 2018-12-05 06:32:16 +0000 UTC (1 container statuses recorded)
Dec  6 02:58:50.151: INFO: 	Container tensorflow ready: true, restart count 0
Dec  6 02:58:50.151: INFO: sonobuoy-e2e-job-9cb377fd61834674 from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 02:58:50.151: INFO: 	Container e2e ready: true, restart count 0
Dec  6 02:58:50.151: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  6 02:58:50.151: INFO: sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-nl2hx from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 02:58:50.151: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  6 02:58:50.151: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  6 02:58:50.151: INFO: nvidia-device-plugin-daemonset-nkqbb from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:58:50.151: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  6 02:58:50.151: INFO: calico-node-q6m2b from kube-system started at 2018-12-05 06:20:39 +0000 UTC (2 container statuses recorded)
Dec  6 02:58:50.151: INFO: 	Container calico-node ready: true, restart count 0
Dec  6 02:58:50.151: INFO: 	Container install-cni ready: true, restart count 0
Dec  6 02:58:50.151: INFO: kube-proxy-bvq6r from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 02:58:50.151: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156d9f0e1d45c8cc], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:58:51.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wtrvf" for this suite.
Dec  6 02:58:57.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:58:57.428: INFO: namespace: e2e-tests-sched-pred-wtrvf, resource: bindings, ignored listing per whitelist
Dec  6 02:58:57.428: INFO: namespace e2e-tests-sched-pred-wtrvf deletion completed in 6.192514688s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:67.601 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:58:57.428: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-dfe5c68e-f902-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 02:58:57.696: INFO: Waiting up to 5m0s for pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-6b9b2" to be "success or failure"
Dec  6 02:58:57.750: INFO: Pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 53.726172ms
Dec  6 02:58:59.754: INFO: Pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058145071s
Dec  6 02:59:01.758: INFO: Pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062567483s
Dec  6 02:59:03.791: INFO: Pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.095566798s
Dec  6 02:59:05.800: INFO: Pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.10456497s
STEP: Saw pod success
Dec  6 02:59:05.800: INFO: Pod "pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:59:05.810: INFO: Trying to get logs from node k8s-g2 pod pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1 container secret-env-test: <nil>
STEP: delete the pod
Dec  6 02:59:05.891: INFO: Waiting for pod pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:59:05.897: INFO: Pod pod-secrets-dfe8203a-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:59:05.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6b9b2" for this suite.
Dec  6 02:59:13.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:59:14.055: INFO: namespace: e2e-tests-secrets-6b9b2, resource: bindings, ignored listing per whitelist
Dec  6 02:59:14.061: INFO: namespace e2e-tests-secrets-6b9b2 deletion completed in 8.156152092s

• [SLOW TEST:16.634 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:59:14.061: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 02:59:14.334: INFO: (0) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 8.394748ms)
Dec  6 02:59:14.339: INFO: (1) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.170666ms)
Dec  6 02:59:14.345: INFO: (2) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.228485ms)
Dec  6 02:59:14.349: INFO: (3) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.810809ms)
Dec  6 02:59:14.355: INFO: (4) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.875324ms)
Dec  6 02:59:14.361: INFO: (5) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.270745ms)
Dec  6 02:59:14.366: INFO: (6) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.231495ms)
Dec  6 02:59:14.371: INFO: (7) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.104852ms)
Dec  6 02:59:14.377: INFO: (8) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.934147ms)
Dec  6 02:59:14.383: INFO: (9) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.78756ms)
Dec  6 02:59:14.388: INFO: (10) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.128701ms)
Dec  6 02:59:14.394: INFO: (11) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.84985ms)
Dec  6 02:59:14.399: INFO: (12) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.513637ms)
Dec  6 02:59:14.405: INFO: (13) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.628168ms)
Dec  6 02:59:14.410: INFO: (14) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.358567ms)
Dec  6 02:59:14.416: INFO: (15) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.759767ms)
Dec  6 02:59:14.422: INFO: (16) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 6.243688ms)
Dec  6 02:59:14.428: INFO: (17) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.807041ms)
Dec  6 02:59:14.434: INFO: (18) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.719997ms)
Dec  6 02:59:14.439: INFO: (19) /api/v1/nodes/k8s-g1:10250/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.519479ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:59:14.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wr5gw" for this suite.
Dec  6 02:59:20.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:59:20.549: INFO: namespace: e2e-tests-proxy-wr5gw, resource: bindings, ignored listing per whitelist
Dec  6 02:59:20.706: INFO: namespace e2e-tests-proxy-wr5gw deletion completed in 6.26273898s

• [SLOW TEST:6.644 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:59:20.706: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Dec  6 02:59:20.937: INFO: Waiting up to 5m0s for pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-7hfmx" to be "success or failure"
Dec  6 02:59:21.024: INFO: Pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 87.266493ms
Dec  6 02:59:23.066: INFO: Pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.129252957s
Dec  6 02:59:25.091: INFO: Pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153840998s
Dec  6 02:59:27.100: INFO: Pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16309385s
Dec  6 02:59:29.105: INFO: Pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.168065033s
STEP: Saw pod success
Dec  6 02:59:29.105: INFO: Pod "downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 02:59:29.109: INFO: Trying to get logs from node k8s-g1 pod downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 02:59:29.174: INFO: Waiting for pod downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 02:59:29.177: INFO: Pod downward-api-edc593f5-f902-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:59:29.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7hfmx" for this suite.
Dec  6 02:59:35.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:59:35.355: INFO: namespace: e2e-tests-downward-api-7hfmx, resource: bindings, ignored listing per whitelist
Dec  6 02:59:35.367: INFO: namespace e2e-tests-downward-api-7hfmx deletion completed in 6.183569928s

• [SLOW TEST:14.661 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:59:35.367: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1206 02:59:41.772263      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  6 02:59:41.772: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 02:59:41.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-t7446" for this suite.
Dec  6 02:59:49.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 02:59:49.900: INFO: namespace: e2e-tests-gc-t7446, resource: bindings, ignored listing per whitelist
Dec  6 02:59:49.942: INFO: namespace e2e-tests-gc-t7446 deletion completed in 8.164544766s

• [SLOW TEST:14.575 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 02:59:49.943: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  6 02:59:54.209: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-ff342452-f902-11e8-a2c6-1eb929de0ff1", GenerateName:"", Namespace:"e2e-tests-pods-fbj7v", SelfLink:"/api/v1/namespaces/e2e-tests-pods-fbj7v/pods/pod-submit-remove-ff342452-f902-11e8-a2c6-1eb929de0ff1", UID:"ff2e1f37-f902-11e8-bab4-448a5b81d79a", ResourceVersion:"140994", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679661990, loc:(*time.Location)(0x642e6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"165823645", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.4.135/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-cqtkf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42209f0c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cqtkf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4220ad638), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-g2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc422061260), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4220ad680)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4220ad6a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4220ad6a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679661990, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679661992, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679661990, loc:(*time.Location)(0x642e6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.22.132.14", PodIP:"10.244.4.135", StartTime:(*v1.Time)(0xc4219d68c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4219d6900), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"docker://c2d1d0b1fc80c580cdb903dd9c0d0bf46c2adb63cef9c9aaaa3d11a2c1549880"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:00:07.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fbj7v" for this suite.
Dec  6 03:00:13.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:00:13.226: INFO: namespace: e2e-tests-pods-fbj7v, resource: bindings, ignored listing per whitelist
Dec  6 03:00:13.372: INFO: namespace e2e-tests-pods-fbj7v deletion completed in 6.205212432s

• [SLOW TEST:23.430 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:00:13.372: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
Dec  6 03:00:13.797: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-2pvj5" to be "success or failure"
Dec  6 03:00:13.834: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 36.710577ms
Dec  6 03:00:15.839: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041642993s
Dec  6 03:00:17.842: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045479177s
STEP: Saw pod success
Dec  6 03:00:17.842: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  6 03:00:17.846: INFO: Trying to get logs from node k8s-g1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  6 03:00:17.908: INFO: Waiting for pod pod-host-path-test to disappear
Dec  6 03:00:17.914: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:00:17.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-2pvj5" for this suite.
Dec  6 03:00:25.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:00:26.064: INFO: namespace: e2e-tests-hostpath-2pvj5, resource: bindings, ignored listing per whitelist
Dec  6 03:00:26.098: INFO: namespace e2e-tests-hostpath-2pvj5 deletion completed in 8.175357256s

• [SLOW TEST:12.726 seconds]
[sig-storage] HostPath
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:00:26.098: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-upd-14d06ca4-f903-11e8-a2c6-1eb929de0ff1
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-14d06ca4-f903-11e8-a2c6-1eb929de0ff1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:02:01.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h822j" for this suite.
Dec  6 03:02:25.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:02:25.444: INFO: namespace: e2e-tests-configmap-h822j, resource: bindings, ignored listing per whitelist
Dec  6 03:02:25.559: INFO: namespace e2e-tests-configmap-h822j deletion completed in 24.185323914s

• [SLOW TEST:119.461 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:02:25.559: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
Dec  6 03:02:30.406: INFO: Successfully updated pod "annotationupdate5bf64b72-f903-11e8-a2c6-1eb929de0ff1"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:02:32.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4pvkl" for this suite.
Dec  6 03:02:56.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:02:56.678: INFO: namespace: e2e-tests-downward-api-4pvkl, resource: bindings, ignored listing per whitelist
Dec  6 03:02:56.683: INFO: namespace e2e-tests-downward-api-4pvkl deletion completed in 24.239822493s

• [SLOW TEST:31.124 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:02:56.683: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  6 03:02:57.560: INFO: Waiting up to 5m0s for pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq" in namespace "e2e-tests-svcaccounts-845ps" to be "success or failure"
Dec  6 03:02:57.565: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.238286ms
Dec  6 03:02:59.570: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009725524s
Dec  6 03:03:01.575: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014180255s
Dec  6 03:03:03.585: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025062579s
STEP: Saw pod success
Dec  6 03:03:03.585: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq" satisfied condition "success or failure"
Dec  6 03:03:03.590: INFO: Trying to get logs from node k8s-g1 pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq container token-test: <nil>
STEP: delete the pod
Dec  6 03:03:03.676: INFO: Waiting for pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq to disappear
Dec  6 03:03:03.681: INFO: Pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-cbwbq no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  6 03:03:03.727: INFO: Waiting up to 5m0s for pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk" in namespace "e2e-tests-svcaccounts-845ps" to be "success or failure"
Dec  6 03:03:03.731: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.777087ms
Dec  6 03:03:05.735: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008169214s
Dec  6 03:03:07.744: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016807352s
Dec  6 03:03:09.749: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021837893s
STEP: Saw pod success
Dec  6 03:03:09.749: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk" satisfied condition "success or failure"
Dec  6 03:03:09.753: INFO: Trying to get logs from node k8s-g1 pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk container root-ca-test: <nil>
STEP: delete the pod
Dec  6 03:03:09.843: INFO: Waiting for pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk to disappear
Dec  6 03:03:09.847: INFO: Pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-mtnvk no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  6 03:03:09.951: INFO: Waiting up to 5m0s for pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j" in namespace "e2e-tests-svcaccounts-845ps" to be "success or failure"
Dec  6 03:03:09.956: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j": Phase="Pending", Reason="", readiness=false. Elapsed: 4.198928ms
Dec  6 03:03:11.968: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01670723s
Dec  6 03:03:13.972: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020943326s
Dec  6 03:03:15.977: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025233441s
STEP: Saw pod success
Dec  6 03:03:15.977: INFO: Pod "pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j" satisfied condition "success or failure"
Dec  6 03:03:15.980: INFO: Trying to get logs from node k8s-g1 pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j container namespace-test: <nil>
STEP: delete the pod
Dec  6 03:03:16.061: INFO: Waiting for pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j to disappear
Dec  6 03:03:16.069: INFO: Pod pod-service-account-6ed310a7-f903-11e8-a2c6-1eb929de0ff1-p5z5j no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:03:16.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-845ps" for this suite.
Dec  6 03:03:24.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:03:24.186: INFO: namespace: e2e-tests-svcaccounts-845ps, resource: bindings, ignored listing per whitelist
Dec  6 03:03:24.293: INFO: namespace e2e-tests-svcaccounts-845ps deletion completed in 8.214669599s

• [SLOW TEST:27.610 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:03:24.293: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 03:03:24.717: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-zcwl5" to be "success or failure"
Dec  6 03:03:24.722: INFO: Pod "downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.020704ms
Dec  6 03:03:26.767: INFO: Pod "downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049820164s
Dec  6 03:03:28.771: INFO: Pod "downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054187841s
STEP: Saw pod success
Dec  6 03:03:28.771: INFO: Pod "downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:03:28.775: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 03:03:28.820: INFO: Waiting for pod downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:03:28.823: INFO: Pod downwardapi-volume-7f03f1c3-f903-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:03:28.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zcwl5" for this suite.
Dec  6 03:03:36.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:03:36.998: INFO: namespace: e2e-tests-projected-zcwl5, resource: bindings, ignored listing per whitelist
Dec  6 03:03:37.067: INFO: namespace e2e-tests-projected-zcwl5 deletion completed in 8.235909902s

• [SLOW TEST:12.774 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:03:37.067: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-nhcht
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-nhcht
STEP: Deleting pre-stop pod
Dec  6 03:03:56.656: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:03:56.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-nhcht" for this suite.
Dec  6 03:04:36.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:04:36.993: INFO: namespace: e2e-tests-prestop-nhcht, resource: bindings, ignored listing per whitelist
Dec  6 03:04:37.021: INFO: namespace e2e-tests-prestop-nhcht deletion completed in 40.308343645s

• [SLOW TEST:59.954 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:04:37.021: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 03:04:37.400: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-2ppxr" to be "success or failure"
Dec  6 03:04:37.420: INFO: Pod "downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.174635ms
Dec  6 03:04:39.425: INFO: Pod "downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025383644s
Dec  6 03:04:41.431: INFO: Pod "downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030431092s
STEP: Saw pod success
Dec  6 03:04:41.431: INFO: Pod "downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:04:41.435: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 03:04:41.529: INFO: Waiting for pod downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:04:41.532: INFO: Pod downwardapi-volume-aa633544-f903-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:04:41.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2ppxr" for this suite.
Dec  6 03:04:47.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:04:47.664: INFO: namespace: e2e-tests-projected-2ppxr, resource: bindings, ignored listing per whitelist
Dec  6 03:04:47.728: INFO: namespace e2e-tests-projected-2ppxr deletion completed in 6.187772505s

• [SLOW TEST:10.707 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:04:47.728: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  6 03:04:48.042: INFO: Waiting up to 5m0s for pod "pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-l6ztz" to be "success or failure"
Dec  6 03:04:48.045: INFO: Pod "pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.714785ms
Dec  6 03:04:50.050: INFO: Pod "pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00789054s
Dec  6 03:04:52.054: INFO: Pod "pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01203015s
STEP: Saw pod success
Dec  6 03:04:52.054: INFO: Pod "pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:04:52.060: INFO: Trying to get logs from node k8s-g1 pod pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 03:04:52.163: INFO: Waiting for pod pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:04:52.166: INFO: Pod pod-b0b6bf4c-f903-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:04:52.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-l6ztz" for this suite.
Dec  6 03:04:58.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:04:58.293: INFO: namespace: e2e-tests-emptydir-l6ztz, resource: bindings, ignored listing per whitelist
Dec  6 03:04:58.334: INFO: namespace e2e-tests-emptydir-l6ztz deletion completed in 6.160805671s

• [SLOW TEST:10.606 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:04:58.334: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-twfl6
Dec  6 03:05:02.610: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-twfl6
STEP: checking the pod's current state and verifying that restartCount is present
Dec  6 03:05:02.614: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:09:03.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-twfl6" for this suite.
Dec  6 03:09:09.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:09:09.513: INFO: namespace: e2e-tests-container-probe-twfl6, resource: bindings, ignored listing per whitelist
Dec  6 03:09:09.662: INFO: namespace e2e-tests-container-probe-twfl6 deletion completed in 6.222759131s

• [SLOW TEST:251.328 seconds]
[k8s.io] Probing container
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:09:09.663: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  6 03:09:09.916: INFO: Waiting up to 5m0s for pod "pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-blfj2" to be "success or failure"
Dec  6 03:09:09.955: INFO: Pod "pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 39.201113ms
Dec  6 03:09:11.959: INFO: Pod "pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043066499s
Dec  6 03:09:13.964: INFO: Pod "pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047602914s
STEP: Saw pod success
Dec  6 03:09:13.964: INFO: Pod "pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:09:13.968: INFO: Trying to get logs from node k8s-g1 pod pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 03:09:14.067: INFO: Waiting for pod pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:09:14.071: INFO: Pod pod-4cd4e623-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:09:14.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-blfj2" for this suite.
Dec  6 03:09:20.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:09:20.204: INFO: namespace: e2e-tests-emptydir-blfj2, resource: bindings, ignored listing per whitelist
Dec  6 03:09:20.262: INFO: namespace e2e-tests-emptydir-blfj2 deletion completed in 6.182244564s

• [SLOW TEST:10.600 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:09:20.262: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  6 03:09:20.607: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bqgqh,SelfLink:/api/v1/namespaces/e2e-tests-watch-bqgqh/configmaps/e2e-watch-test-watch-closed,UID:532a40ab-f904-11e8-bab4-448a5b81d79a,ResourceVersion:142378,Generation:0,CreationTimestamp:2018-12-06 03:09:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  6 03:09:20.607: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bqgqh,SelfLink:/api/v1/namespaces/e2e-tests-watch-bqgqh/configmaps/e2e-watch-test-watch-closed,UID:532a40ab-f904-11e8-bab4-448a5b81d79a,ResourceVersion:142379,Generation:0,CreationTimestamp:2018-12-06 03:09:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  6 03:09:20.658: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bqgqh,SelfLink:/api/v1/namespaces/e2e-tests-watch-bqgqh/configmaps/e2e-watch-test-watch-closed,UID:532a40ab-f904-11e8-bab4-448a5b81d79a,ResourceVersion:142380,Generation:0,CreationTimestamp:2018-12-06 03:09:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  6 03:09:20.658: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-bqgqh,SelfLink:/api/v1/namespaces/e2e-tests-watch-bqgqh/configmaps/e2e-watch-test-watch-closed,UID:532a40ab-f904-11e8-bab4-448a5b81d79a,ResourceVersion:142381,Generation:0,CreationTimestamp:2018-12-06 03:09:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:09:20.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bqgqh" for this suite.
Dec  6 03:09:26.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:09:26.753: INFO: namespace: e2e-tests-watch-bqgqh, resource: bindings, ignored listing per whitelist
Dec  6 03:09:26.928: INFO: namespace e2e-tests-watch-bqgqh deletion completed in 6.264961394s

• [SLOW TEST:6.666 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:09:26.929: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 03:09:27.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-tgptb" to be "success or failure"
Dec  6 03:09:27.344: INFO: Pod "downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 45.83972ms
Dec  6 03:09:29.349: INFO: Pod "downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050981233s
Dec  6 03:09:31.354: INFO: Pod "downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056014017s
STEP: Saw pod success
Dec  6 03:09:31.354: INFO: Pod "downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:09:31.361: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 03:09:31.448: INFO: Waiting for pod downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:09:31.480: INFO: Pod downwardapi-volume-572b13fc-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:09:31.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tgptb" for this suite.
Dec  6 03:09:37.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:09:37.662: INFO: namespace: e2e-tests-projected-tgptb, resource: bindings, ignored listing per whitelist
Dec  6 03:09:37.700: INFO: namespace e2e-tests-projected-tgptb deletion completed in 6.212781715s

• [SLOW TEST:10.772 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:09:37.700: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
Dec  6 03:09:37.957: INFO: Waiting up to 5m0s for pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-var-expansion-pvw47" to be "success or failure"
Dec  6 03:09:37.961: INFO: Pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.003728ms
Dec  6 03:09:39.965: INFO: Pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007890963s
Dec  6 03:09:41.969: INFO: Pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011965569s
Dec  6 03:09:43.996: INFO: Pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039709475s
Dec  6 03:09:46.021: INFO: Pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.06411298s
STEP: Saw pod success
Dec  6 03:09:46.021: INFO: Pod "var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:09:46.024: INFO: Trying to get logs from node k8s-g1 pod var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 03:09:46.109: INFO: Waiting for pod var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:09:46.114: INFO: Pod var-expansion-5d85c3d6-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:09:46.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-pvw47" for this suite.
Dec  6 03:09:52.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:09:52.262: INFO: namespace: e2e-tests-var-expansion-pvw47, resource: bindings, ignored listing per whitelist
Dec  6 03:09:52.422: INFO: namespace e2e-tests-var-expansion-pvw47 deletion completed in 6.299162459s

• [SLOW TEST:14.722 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:09:52.423: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gw572
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  6 03:09:52.683: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  6 03:10:16.931: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.3.168 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gw572 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 03:10:16.931: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 03:10:17.996: INFO: Found all expected endpoints: [netserver-0]
Dec  6 03:10:17.999: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.4.139 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gw572 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  6 03:10:17.999: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
Dec  6 03:10:19.069: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:10:19.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gw572" for this suite.
Dec  6 03:10:43.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:10:43.215: INFO: namespace: e2e-tests-pod-network-test-gw572, resource: bindings, ignored listing per whitelist
Dec  6 03:10:43.342: INFO: namespace e2e-tests-pod-network-test-gw572 deletion completed in 24.267132532s

• [SLOW TEST:50.919 seconds]
[sig-network] Networking
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:10:43.342: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-84b18d67-f904-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 03:10:43.732: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-z8w5p" to be "success or failure"
Dec  6 03:10:43.737: INFO: Pod "pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.941227ms
Dec  6 03:10:45.771: INFO: Pod "pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038153349s
Dec  6 03:10:47.774: INFO: Pod "pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041820087s
STEP: Saw pod success
Dec  6 03:10:47.774: INFO: Pod "pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:10:47.777: INFO: Trying to get logs from node k8s-g2 pod pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 03:10:47.910: INFO: Waiting for pod pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:10:47.974: INFO: Pod pod-projected-configmaps-84bddf69-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:10:47.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z8w5p" for this suite.
Dec  6 03:10:54.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:10:54.128: INFO: namespace: e2e-tests-projected-z8w5p, resource: bindings, ignored listing per whitelist
Dec  6 03:10:54.211: INFO: namespace e2e-tests-projected-z8w5p deletion completed in 6.229446387s

• [SLOW TEST:10.869 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:10:54.212: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-tqm6m in namespace e2e-tests-proxy-cxkf2
I1206 03:10:54.591912      19 runners.go:177] Created replication controller with name: proxy-service-tqm6m, namespace: e2e-tests-proxy-cxkf2, replica count: 1
I1206 03:10:55.642174      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 03:10:56.642313      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 03:10:57.642422      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 03:10:58.642551      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 03:10:59.642657      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1206 03:11:00.642782      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:01.642905      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:02.643036      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:03.643146      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:04.643280      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:05.643385      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:06.643512      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1206 03:11:07.643636      19 runners.go:177] proxy-service-tqm6m Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  6 03:11:07.684: INFO: setup took 13.240708948s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  6 03:11:07.691: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 6.531667ms)
Dec  6 03:11:07.692: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 7.452557ms)
Dec  6 03:11:07.692: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.540861ms)
Dec  6 03:11:07.693: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 8.020531ms)
Dec  6 03:11:07.693: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.23148ms)
Dec  6 03:11:07.693: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 8.170016ms)
Dec  6 03:11:07.693: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 8.833273ms)
Dec  6 03:11:07.693: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 9.324483ms)
Dec  6 03:11:07.697: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 12.041498ms)
Dec  6 03:11:07.697: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 12.531219ms)
Dec  6 03:11:07.697: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 12.42439ms)
Dec  6 03:11:07.703: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 18.052482ms)
Dec  6 03:11:07.704: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 20.259641ms)
Dec  6 03:11:07.705: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 20.576062ms)
Dec  6 03:11:07.707: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 23.2138ms)
Dec  6 03:11:07.708: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 23.820783ms)
Dec  6 03:11:07.762: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 53.774111ms)
Dec  6 03:11:07.762: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 53.910235ms)
Dec  6 03:11:07.762: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 53.879229ms)
Dec  6 03:11:07.762: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 53.830561ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 54.478717ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 54.537579ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 54.528066ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 54.657217ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 54.604563ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 54.675929ms)
Dec  6 03:11:07.763: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 55.035497ms)
Dec  6 03:11:07.764: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 55.600502ms)
Dec  6 03:11:07.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 57.629622ms)
Dec  6 03:11:07.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 57.71504ms)
Dec  6 03:11:07.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 57.591592ms)
Dec  6 03:11:07.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 57.649575ms)
Dec  6 03:11:07.772: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 6.521227ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 8.92829ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 9.033781ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.994776ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 9.023888ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.984525ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 8.989575ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.090052ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 9.179801ms)
Dec  6 03:11:07.775: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 9.053775ms)
Dec  6 03:11:07.776: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 9.811155ms)
Dec  6 03:11:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 10.726625ms)
Dec  6 03:11:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 10.760555ms)
Dec  6 03:11:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 10.800273ms)
Dec  6 03:11:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 10.703851ms)
Dec  6 03:11:07.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 11.510162ms)
Dec  6 03:11:07.844: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 66.50893ms)
Dec  6 03:11:07.844: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 66.739877ms)
Dec  6 03:11:07.844: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 66.782504ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 67.167493ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 67.143452ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 67.455251ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 67.137058ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 67.123453ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 67.359322ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 67.34046ms)
Dec  6 03:11:07.845: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 67.397958ms)
Dec  6 03:11:07.847: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 69.254969ms)
Dec  6 03:11:07.847: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 69.462623ms)
Dec  6 03:11:07.847: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 69.302601ms)
Dec  6 03:11:07.847: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 69.11333ms)
Dec  6 03:11:07.847: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 69.220231ms)
Dec  6 03:11:07.853: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 5.559878ms)
Dec  6 03:11:07.856: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 8.771251ms)
Dec  6 03:11:07.856: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.832407ms)
Dec  6 03:11:07.856: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.729389ms)
Dec  6 03:11:07.856: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.76706ms)
Dec  6 03:11:07.901: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 53.991489ms)
Dec  6 03:11:07.901: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 54.095459ms)
Dec  6 03:11:07.903: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 56.13222ms)
Dec  6 03:11:07.903: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 56.126057ms)
Dec  6 03:11:07.903: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 56.20182ms)
Dec  6 03:11:07.903: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 56.246734ms)
Dec  6 03:11:07.903: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 56.371105ms)
Dec  6 03:11:07.904: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 57.196021ms)
Dec  6 03:11:07.906: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 59.117827ms)
Dec  6 03:11:07.906: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 59.074323ms)
Dec  6 03:11:07.906: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 59.16534ms)
Dec  6 03:11:07.919: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 12.82711ms)
Dec  6 03:11:07.919: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 12.6605ms)
Dec  6 03:11:07.920: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 12.927854ms)
Dec  6 03:11:07.924: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 17.023509ms)
Dec  6 03:11:07.924: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 17.348589ms)
Dec  6 03:11:07.925: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 17.856254ms)
Dec  6 03:11:07.925: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 18.426684ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 22.175457ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 22.026917ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 21.700653ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 21.650301ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 22.156631ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 21.932809ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 21.811806ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 22.096014ms)
Dec  6 03:11:07.929: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 21.953408ms)
Dec  6 03:11:07.936: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 6.664326ms)
Dec  6 03:11:07.937: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.988027ms)
Dec  6 03:11:07.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 8.819515ms)
Dec  6 03:11:07.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.453055ms)
Dec  6 03:11:07.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 9.422217ms)
Dec  6 03:11:07.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 9.554427ms)
Dec  6 03:11:07.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.498095ms)
Dec  6 03:11:07.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 9.479262ms)
Dec  6 03:11:07.939: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 10.345958ms)
Dec  6 03:11:07.939: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 10.239511ms)
Dec  6 03:11:07.940: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 11.315873ms)
Dec  6 03:11:07.940: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 11.354914ms)
Dec  6 03:11:07.942: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 13.209775ms)
Dec  6 03:11:07.942: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 13.236057ms)
Dec  6 03:11:07.985: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 56.089417ms)
Dec  6 03:11:07.985: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 56.100383ms)
Dec  6 03:11:07.991: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 5.62401ms)
Dec  6 03:11:07.991: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 6.254241ms)
Dec  6 03:11:07.992: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 6.35545ms)
Dec  6 03:11:07.992: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 6.325331ms)
Dec  6 03:11:07.992: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 6.43053ms)
Dec  6 03:11:07.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.284565ms)
Dec  6 03:11:07.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.340655ms)
Dec  6 03:11:07.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.316897ms)
Dec  6 03:11:07.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 8.344577ms)
Dec  6 03:11:07.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 8.532762ms)
Dec  6 03:11:07.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 9.11566ms)
Dec  6 03:11:07.996: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 10.566045ms)
Dec  6 03:11:07.996: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 10.646489ms)
Dec  6 03:11:07.996: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 10.577492ms)
Dec  6 03:11:07.996: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 10.522961ms)
Dec  6 03:11:07.996: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 10.701955ms)
Dec  6 03:11:08.004: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.006661ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 8.6641ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 8.614123ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 8.622525ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 8.652569ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 8.753359ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.665279ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.796238ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 8.727831ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.874538ms)
Dec  6 03:11:08.005: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 9.413712ms)
Dec  6 03:11:08.006: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 9.402527ms)
Dec  6 03:11:08.007: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 11.068606ms)
Dec  6 03:11:08.007: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 11.028293ms)
Dec  6 03:11:08.007: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 11.128384ms)
Dec  6 03:11:08.007: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 11.077654ms)
Dec  6 03:11:08.014: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 6.668347ms)
Dec  6 03:11:08.014: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 6.518714ms)
Dec  6 03:11:08.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 7.184623ms)
Dec  6 03:11:08.015: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.412308ms)
Dec  6 03:11:08.016: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 7.875787ms)
Dec  6 03:11:08.016: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 8.026818ms)
Dec  6 03:11:08.016: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 7.961411ms)
Dec  6 03:11:08.016: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.180311ms)
Dec  6 03:11:08.017: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 9.104142ms)
Dec  6 03:11:08.017: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.207113ms)
Dec  6 03:11:08.017: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 9.020208ms)
Dec  6 03:11:08.018: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 10.541093ms)
Dec  6 03:11:08.018: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 10.721535ms)
Dec  6 03:11:08.018: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 10.471745ms)
Dec  6 03:11:08.018: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 10.663821ms)
Dec  6 03:11:08.018: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 10.232179ms)
Dec  6 03:11:08.023: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 5.045037ms)
Dec  6 03:11:08.025: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 6.513343ms)
Dec  6 03:11:08.025: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 6.835546ms)
Dec  6 03:11:08.026: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 6.960478ms)
Dec  6 03:11:08.027: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.427657ms)
Dec  6 03:11:08.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 8.957629ms)
Dec  6 03:11:08.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 9.358484ms)
Dec  6 03:11:08.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 9.16216ms)
Dec  6 03:11:08.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 9.214558ms)
Dec  6 03:11:08.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 9.043082ms)
Dec  6 03:11:08.028: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 10.09683ms)
Dec  6 03:11:08.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 10.883145ms)
Dec  6 03:11:08.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 11.252346ms)
Dec  6 03:11:08.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 11.215747ms)
Dec  6 03:11:08.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 11.313443ms)
Dec  6 03:11:08.030: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 11.519887ms)
Dec  6 03:11:08.035: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 5.656218ms)
Dec  6 03:11:08.036: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 6.719906ms)
Dec  6 03:11:08.036: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 6.57745ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.044475ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 7.213542ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 7.135024ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 7.068115ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 7.18747ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.174584ms)
Dec  6 03:11:08.037: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 7.139219ms)
Dec  6 03:11:08.040: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 9.921653ms)
Dec  6 03:11:08.087: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 56.796521ms)
Dec  6 03:11:08.087: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 56.983663ms)
Dec  6 03:11:08.087: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 56.98137ms)
Dec  6 03:11:08.087: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 57.435221ms)
Dec  6 03:11:08.087: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 57.501473ms)
Dec  6 03:11:08.106: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 18.74796ms)
Dec  6 03:11:08.112: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 24.217992ms)
Dec  6 03:11:08.114: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 26.316344ms)
Dec  6 03:11:08.114: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 26.466616ms)
Dec  6 03:11:08.114: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 26.406123ms)
Dec  6 03:11:08.115: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 27.017677ms)
Dec  6 03:11:08.115: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 27.08428ms)
Dec  6 03:11:08.115: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 27.003891ms)
Dec  6 03:11:08.115: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 27.627571ms)
Dec  6 03:11:08.115: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 27.693256ms)
Dec  6 03:11:08.115: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 27.879337ms)
Dec  6 03:11:08.117: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 29.476257ms)
Dec  6 03:11:08.117: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 29.561112ms)
Dec  6 03:11:08.117: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 29.630939ms)
Dec  6 03:11:08.118: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 30.38655ms)
Dec  6 03:11:08.118: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 30.457486ms)
Dec  6 03:11:08.123: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 4.857029ms)
Dec  6 03:11:08.124: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 5.772382ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 6.631901ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 6.757676ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 7.315186ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 7.263157ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 7.468845ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 7.356017ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 7.391488ms)
Dec  6 03:11:08.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.289179ms)
Dec  6 03:11:08.127: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 8.751285ms)
Dec  6 03:11:08.130: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 12.064472ms)
Dec  6 03:11:08.130: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 12.021404ms)
Dec  6 03:11:08.130: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 12.227536ms)
Dec  6 03:11:08.130: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 12.126016ms)
Dec  6 03:11:08.130: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 12.156657ms)
Dec  6 03:11:08.137: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 6.458647ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.358809ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.356696ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 8.444559ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 8.365402ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 8.991388ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 9.004822ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 9.181387ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.105743ms)
Dec  6 03:11:08.139: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 9.1157ms)
Dec  6 03:11:08.141: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 10.922013ms)
Dec  6 03:11:08.144: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 14.017786ms)
Dec  6 03:11:08.144: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 13.909175ms)
Dec  6 03:11:08.144: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 14.072301ms)
Dec  6 03:11:08.144: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 14.053128ms)
Dec  6 03:11:08.144: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 14.099997ms)
Dec  6 03:11:08.150: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 5.894753ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 8.22802ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 8.329016ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 8.185094ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.24896ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.249068ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 8.266496ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.808506ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 8.902147ms)
Dec  6 03:11:08.153: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 8.945599ms)
Dec  6 03:11:08.154: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 9.550342ms)
Dec  6 03:11:08.157: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 12.097684ms)
Dec  6 03:11:08.157: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 12.115488ms)
Dec  6 03:11:08.157: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 12.206006ms)
Dec  6 03:11:08.157: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 12.35458ms)
Dec  6 03:11:08.157: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 12.322945ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 7.797291ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.617085ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 8.455667ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 8.501857ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 8.541482ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 8.770393ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 8.689634ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.655672ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 8.606015ms)
Dec  6 03:11:08.165: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.591476ms)
Dec  6 03:11:08.167: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 10.007516ms)
Dec  6 03:11:08.167: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 10.016265ms)
Dec  6 03:11:08.169: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 12.464706ms)
Dec  6 03:11:08.169: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 12.47306ms)
Dec  6 03:11:08.169: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 12.504037ms)
Dec  6 03:11:08.169: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 12.631195ms)
Dec  6 03:11:08.175: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 5.422938ms)
Dec  6 03:11:08.178: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 9.040344ms)
Dec  6 03:11:08.178: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.063046ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.113563ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 8.996766ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 9.05656ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 9.145874ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 9.070217ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 9.245132ms)
Dec  6 03:11:08.179: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 9.247653ms)
Dec  6 03:11:08.182: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 12.160199ms)
Dec  6 03:11:08.182: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 12.099382ms)
Dec  6 03:11:08.182: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 12.724277ms)
Dec  6 03:11:08.182: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 12.769017ms)
Dec  6 03:11:08.182: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 12.888395ms)
Dec  6 03:11:08.182: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 12.776241ms)
Dec  6 03:11:08.227: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 44.368822ms)
Dec  6 03:11:08.227: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 44.747662ms)
Dec  6 03:11:08.227: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 44.505351ms)
Dec  6 03:11:08.227: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 44.818263ms)
Dec  6 03:11:08.228: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 45.682241ms)
Dec  6 03:11:08.229: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 46.22224ms)
Dec  6 03:11:08.229: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 45.952123ms)
Dec  6 03:11:08.229: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 46.05253ms)
Dec  6 03:11:08.229: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 46.037962ms)
Dec  6 03:11:08.229: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 46.5226ms)
Dec  6 03:11:08.231: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 48.519546ms)
Dec  6 03:11:08.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 49.27601ms)
Dec  6 03:11:08.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 49.229223ms)
Dec  6 03:11:08.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 49.094093ms)
Dec  6 03:11:08.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 49.169273ms)
Dec  6 03:11:08.233: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 49.855386ms)
Dec  6 03:11:08.242: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 9.209976ms)
Dec  6 03:11:08.242: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:462/proxy/: tls qux (200; 9.159974ms)
Dec  6 03:11:08.242: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:162/proxy/: bar (200; 8.942376ms)
Dec  6 03:11:08.242: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 8.964503ms)
Dec  6 03:11:08.242: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/http:proxy-service-tqm6m-wlwpp:1080/proxy/... (200; 9.080226ms)
Dec  6 03:11:08.242: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp/proxy/rewriteme"... (200; 9.023214ms)
Dec  6 03:11:08.243: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:443/proxy/... (200; 9.783984ms)
Dec  6 03:11:08.243: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/https:proxy-service-tqm6m-wlwpp:460/proxy/: tls baz (200; 9.827138ms)
Dec  6 03:11:08.243: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:1080/proxy/rewri... (200; 9.861907ms)
Dec  6 03:11:08.243: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname2/proxy/: bar (200; 9.785252ms)
Dec  6 03:11:08.243: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/pods/proxy-service-tqm6m-wlwpp:160/proxy/: foo (200; 10.055675ms)
Dec  6 03:11:08.244: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname1/proxy/: tls baz (200; 11.586657ms)
Dec  6 03:11:08.244: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/proxy-service-tqm6m:portname1/proxy/: foo (200; 11.481308ms)
Dec  6 03:11:08.244: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/https:proxy-service-tqm6m:tlsportname2/proxy/: tls qux (200; 11.579962ms)
Dec  6 03:11:08.244: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname1/proxy/: foo (200; 11.54708ms)
Dec  6 03:11:08.244: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cxkf2/services/http:proxy-service-tqm6m:portname2/proxy/: bar (200; 11.626202ms)
STEP: deleting { ReplicationController} proxy-service-tqm6m in namespace e2e-tests-proxy-cxkf2, will wait for the garbage collector to delete the pods
Dec  6 03:11:08.346: INFO: Deleting { ReplicationController} proxy-service-tqm6m took: 48.185506ms
Dec  6 03:11:08.447: INFO: Terminating { ReplicationController} proxy-service-tqm6m pods took: 100.10674ms
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:11:16.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-cxkf2" for this suite.
Dec  6 03:11:24.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:11:24.937: INFO: namespace: e2e-tests-proxy-cxkf2, resource: bindings, ignored listing per whitelist
Dec  6 03:11:24.980: INFO: namespace e2e-tests-proxy-cxkf2 deletion completed in 8.219711521s

• [SLOW TEST:30.768 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:11:24.980: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-9d81bc1a-f904-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 03:11:25.318: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-ngjs9" to be "success or failure"
Dec  6 03:11:25.341: INFO: Pod "pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 23.560135ms
Dec  6 03:11:27.345: INFO: Pod "pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027718987s
Dec  6 03:11:29.349: INFO: Pod "pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031727219s
STEP: Saw pod success
Dec  6 03:11:29.349: INFO: Pod "pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:11:29.353: INFO: Trying to get logs from node k8s-g2 pod pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  6 03:11:29.418: INFO: Waiting for pod pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:11:29.423: INFO: Pod pod-projected-secrets-9d855928-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:11:29.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ngjs9" for this suite.
Dec  6 03:11:35.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:11:35.545: INFO: namespace: e2e-tests-projected-ngjs9, resource: bindings, ignored listing per whitelist
Dec  6 03:11:35.593: INFO: namespace e2e-tests-projected-ngjs9 deletion completed in 6.163350251s

• [SLOW TEST:10.613 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:11:35.593: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Starting the proxy
Dec  6 03:11:35.856: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-630354635 proxy --unix-socket=/tmp/kubectl-proxy-unix566684590/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:11:35.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mx5b9" for this suite.
Dec  6 03:11:41.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:11:42.051: INFO: namespace: e2e-tests-kubectl-mx5b9, resource: bindings, ignored listing per whitelist
Dec  6 03:11:42.117: INFO: namespace e2e-tests-kubectl-mx5b9 deletion completed in 6.201361268s

• [SLOW TEST:6.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:11:42.117: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 03:11:42.417: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-projected-28kkt" to be "success or failure"
Dec  6 03:11:42.420: INFO: Pod "downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.681415ms
Dec  6 03:11:44.457: INFO: Pod "downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040506551s
Dec  6 03:11:46.461: INFO: Pod "downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044547469s
STEP: Saw pod success
Dec  6 03:11:46.461: INFO: Pod "downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:11:46.465: INFO: Trying to get logs from node k8s-g1 pod downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 03:11:46.559: INFO: Waiting for pod downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:11:46.563: INFO: Pod downwardapi-volume-a7b809f4-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:11:46.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28kkt" for this suite.
Dec  6 03:11:52.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:11:52.669: INFO: namespace: e2e-tests-projected-28kkt, resource: bindings, ignored listing per whitelist
Dec  6 03:11:52.804: INFO: namespace e2e-tests-projected-28kkt deletion completed in 6.234700648s

• [SLOW TEST:10.687 seconds]
[sig-storage] Projected
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:11:52.804: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 03:11:53.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-630354635 version'
Dec  6 03:11:53.172: INFO: stderr: ""
Dec  6 03:11:53.172: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.5\", GitCommit:\"753b2dbc622f5cc417845f0ff8a77f539a4213ea\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T14:31:35Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:11:53.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4d9mw" for this suite.
Dec  6 03:11:59.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:11:59.376: INFO: namespace: e2e-tests-kubectl-4d9mw, resource: bindings, ignored listing per whitelist
Dec  6 03:11:59.405: INFO: namespace e2e-tests-kubectl-4d9mw deletion completed in 6.2259598s

• [SLOW TEST:6.600 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:11:59.405: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
Dec  6 03:12:03.648: INFO: Pod pod-hostip-b1fc246b-f904-11e8-a2c6-1eb929de0ff1 has hostIP: 172.22.132.14
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:12:03.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6g89n" for this suite.
Dec  6 03:12:27.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:12:27.805: INFO: namespace: e2e-tests-pods-6g89n, resource: bindings, ignored listing per whitelist
Dec  6 03:12:27.906: INFO: namespace e2e-tests-pods-6g89n deletion completed in 24.251156426s

• [SLOW TEST:28.501 seconds]
[k8s.io] Pods
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:12:27.906: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  6 03:12:28.346: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tpkzz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tpkzz/configmaps/e2e-watch-test-label-changed,UID:c2fc05bd-f904-11e8-bab4-448a5b81d79a,ResourceVersion:143022,Generation:0,CreationTimestamp:2018-12-06 03:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  6 03:12:28.346: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tpkzz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tpkzz/configmaps/e2e-watch-test-label-changed,UID:c2fc05bd-f904-11e8-bab4-448a5b81d79a,ResourceVersion:143024,Generation:0,CreationTimestamp:2018-12-06 03:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  6 03:12:28.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tpkzz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tpkzz/configmaps/e2e-watch-test-label-changed,UID:c2fc05bd-f904-11e8-bab4-448a5b81d79a,ResourceVersion:143025,Generation:0,CreationTimestamp:2018-12-06 03:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  6 03:12:38.464: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tpkzz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tpkzz/configmaps/e2e-watch-test-label-changed,UID:c2fc05bd-f904-11e8-bab4-448a5b81d79a,ResourceVersion:143045,Generation:0,CreationTimestamp:2018-12-06 03:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  6 03:12:38.464: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tpkzz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tpkzz/configmaps/e2e-watch-test-label-changed,UID:c2fc05bd-f904-11e8-bab4-448a5b81d79a,ResourceVersion:143046,Generation:0,CreationTimestamp:2018-12-06 03:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  6 03:12:38.464: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tpkzz,SelfLink:/api/v1/namespaces/e2e-tests-watch-tpkzz/configmaps/e2e-watch-test-label-changed,UID:c2fc05bd-f904-11e8-bab4-448a5b81d79a,ResourceVersion:143047,Generation:0,CreationTimestamp:2018-12-06 03:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:12:38.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tpkzz" for this suite.
Dec  6 03:12:44.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:12:44.527: INFO: namespace: e2e-tests-watch-tpkzz, resource: bindings, ignored listing per whitelist
Dec  6 03:12:44.646: INFO: namespace e2e-tests-watch-tpkzz deletion completed in 6.173468675s

• [SLOW TEST:16.741 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:12:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-ccfb1e4f-f904-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume configMaps
Dec  6 03:12:44.956: INFO: Waiting up to 5m0s for pod "pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-configmap-zf7zv" to be "success or failure"
Dec  6 03:12:44.959: INFO: Pod "pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.522631ms
Dec  6 03:12:46.963: INFO: Pod "pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007689507s
Dec  6 03:12:48.968: INFO: Pod "pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011750316s
STEP: Saw pod success
Dec  6 03:12:48.968: INFO: Pod "pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:12:48.971: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  6 03:12:49.040: INFO: Waiting for pod pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:12:49.043: INFO: Pod pod-configmaps-ccfd759d-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:12:49.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zf7zv" for this suite.
Dec  6 03:12:55.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:12:55.142: INFO: namespace: e2e-tests-configmap-zf7zv, resource: bindings, ignored listing per whitelist
Dec  6 03:12:55.248: INFO: namespace e2e-tests-configmap-zf7zv deletion completed in 6.198187763s

• [SLOW TEST:10.602 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:12:55.248: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 03:12:55.527: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  6 03:12:55.616: INFO: Number of nodes with available pods: 0
Dec  6 03:12:55.616: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  6 03:12:55.781: INFO: Number of nodes with available pods: 0
Dec  6 03:12:55.781: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:12:56.784: INFO: Number of nodes with available pods: 0
Dec  6 03:12:56.785: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:12:57.785: INFO: Number of nodes with available pods: 0
Dec  6 03:12:57.785: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:12:58.785: INFO: Number of nodes with available pods: 1
Dec  6 03:12:58.785: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  6 03:12:58.949: INFO: Number of nodes with available pods: 1
Dec  6 03:12:58.949: INFO: Number of running nodes: 0, number of available pods: 1
Dec  6 03:12:59.954: INFO: Number of nodes with available pods: 0
Dec  6 03:12:59.954: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  6 03:12:59.982: INFO: Number of nodes with available pods: 0
Dec  6 03:12:59.982: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:00.987: INFO: Number of nodes with available pods: 0
Dec  6 03:13:00.987: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:01.986: INFO: Number of nodes with available pods: 0
Dec  6 03:13:01.986: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:02.986: INFO: Number of nodes with available pods: 0
Dec  6 03:13:02.986: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:03.987: INFO: Number of nodes with available pods: 0
Dec  6 03:13:03.987: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:04.987: INFO: Number of nodes with available pods: 0
Dec  6 03:13:04.987: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:05.986: INFO: Number of nodes with available pods: 0
Dec  6 03:13:05.986: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:06.986: INFO: Number of nodes with available pods: 0
Dec  6 03:13:06.986: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:07.987: INFO: Number of nodes with available pods: 0
Dec  6 03:13:07.987: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:09.009: INFO: Number of nodes with available pods: 0
Dec  6 03:13:09.009: INFO: Node k8s-g1 is running more than one daemon pod
Dec  6 03:13:09.987: INFO: Number of nodes with available pods: 1
Dec  6 03:13:09.987: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-nxnsx, will wait for the garbage collector to delete the pods
Dec  6 03:13:10.068: INFO: Deleting {extensions DaemonSet} daemon-set took: 18.978117ms
Dec  6 03:13:10.268: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.100778ms
Dec  6 03:13:13.372: INFO: Number of nodes with available pods: 0
Dec  6 03:13:13.372: INFO: Number of running nodes: 0, number of available pods: 0
Dec  6 03:13:13.376: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nxnsx/daemonsets","resourceVersion":"143193"},"items":null}

Dec  6 03:13:13.379: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nxnsx/pods","resourceVersion":"143193"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:13:13.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nxnsx" for this suite.
Dec  6 03:13:21.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:13:21.769: INFO: namespace: e2e-tests-daemonsets-nxnsx, resource: bindings, ignored listing per whitelist
Dec  6 03:13:21.789: INFO: namespace e2e-tests-daemonsets-nxnsx deletion completed in 8.207955241s

• [SLOW TEST:26.541 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:13:21.789: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1
Dec  6 03:13:22.117: INFO: Pod name my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1: Found 0 pods out of 1
Dec  6 03:13:27.121: INFO: Pod name my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1: Found 1 pods out of 1
Dec  6 03:13:27.121: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1" are running
Dec  6 03:13:27.124: INFO: Pod "my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1-xzddt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-06 03:13:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-06 03:13:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-06 03:13:22 +0000 UTC Reason: Message:}])
Dec  6 03:13:27.124: INFO: Trying to dial the pod
Dec  6 03:13:32.138: INFO: Controller my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1: Got expected result from replica 1 [my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1-xzddt]: "my-hostname-basic-e3205f2e-f904-11e8-a2c6-1eb929de0ff1-xzddt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:13:32.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-7c8b8" for this suite.
Dec  6 03:13:38.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:13:38.216: INFO: namespace: e2e-tests-replication-controller-7c8b8, resource: bindings, ignored listing per whitelist
Dec  6 03:13:38.344: INFO: namespace e2e-tests-replication-controller-7c8b8 deletion completed in 6.198972032s

• [SLOW TEST:16.555 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:13:38.344: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  6 03:13:38.656: INFO: Waiting up to 5m0s for pod "pod-ed019646-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-dxlf5" to be "success or failure"
Dec  6 03:13:38.660: INFO: Pod "pod-ed019646-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.437962ms
Dec  6 03:13:40.664: INFO: Pod "pod-ed019646-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008296126s
Dec  6 03:13:42.668: INFO: Pod "pod-ed019646-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012691386s
STEP: Saw pod success
Dec  6 03:13:42.668: INFO: Pod "pod-ed019646-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:13:42.672: INFO: Trying to get logs from node k8s-g1 pod pod-ed019646-f904-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 03:13:42.713: INFO: Waiting for pod pod-ed019646-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:13:42.718: INFO: Pod pod-ed019646-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:13:42.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dxlf5" for this suite.
Dec  6 03:13:48.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:13:48.875: INFO: namespace: e2e-tests-emptydir-dxlf5, resource: bindings, ignored listing per whitelist
Dec  6 03:13:48.966: INFO: namespace e2e-tests-emptydir-dxlf5 deletion completed in 6.239390095s

• [SLOW TEST:10.622 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:13:48.966: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  6 03:13:49.398: INFO: Waiting up to 5m0s for pod "pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-emptydir-rgsfw" to be "success or failure"
Dec  6 03:13:49.431: INFO: Pod "pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 33.387427ms
Dec  6 03:13:51.435: INFO: Pod "pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036966164s
Dec  6 03:13:53.449: INFO: Pod "pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051484416s
STEP: Saw pod success
Dec  6 03:13:53.449: INFO: Pod "pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:13:53.453: INFO: Trying to get logs from node k8s-g2 pod pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 03:13:53.540: INFO: Waiting for pod pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:13:53.544: INFO: Pod pod-f35975b3-f904-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:13:53.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rgsfw" for this suite.
Dec  6 03:14:01.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:14:01.791: INFO: namespace: e2e-tests-emptydir-rgsfw, resource: bindings, ignored listing per whitelist
Dec  6 03:14:01.795: INFO: namespace e2e-tests-emptydir-rgsfw deletion completed in 8.242284555s

• [SLOW TEST:12.829 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:14:01.795: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:14:02.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-glbvs" for this suite.
Dec  6 03:14:08.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:14:08.289: INFO: namespace: e2e-tests-services-glbvs, resource: bindings, ignored listing per whitelist
Dec  6 03:14:08.294: INFO: namespace e2e-tests-services-glbvs deletion completed in 6.205136683s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.499 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:14:08.294: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
Dec  6 03:14:08.652: INFO: (0) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 8.949916ms)
Dec  6 03:14:08.658: INFO: (1) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 6.123928ms)
Dec  6 03:14:08.663: INFO: (2) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.482469ms)
Dec  6 03:14:08.669: INFO: (3) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.66988ms)
Dec  6 03:14:08.675: INFO: (4) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.839538ms)
Dec  6 03:14:08.681: INFO: (5) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.503059ms)
Dec  6 03:14:08.686: INFO: (6) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.269595ms)
Dec  6 03:14:08.692: INFO: (7) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.769604ms)
Dec  6 03:14:08.726: INFO: (8) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 34.537489ms)
Dec  6 03:14:08.732: INFO: (9) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 6.272246ms)
Dec  6 03:14:08.738: INFO: (10) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.242198ms)
Dec  6 03:14:08.744: INFO: (11) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.922648ms)
Dec  6 03:14:08.749: INFO: (12) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.301686ms)
Dec  6 03:14:08.754: INFO: (13) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.389079ms)
Dec  6 03:14:08.760: INFO: (14) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.215833ms)
Dec  6 03:14:08.765: INFO: (15) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.494672ms)
Dec  6 03:14:08.770: INFO: (16) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.975076ms)
Dec  6 03:14:08.775: INFO: (17) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.359858ms)
Dec  6 03:14:08.780: INFO: (18) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 4.992639ms)
Dec  6 03:14:08.786: INFO: (19) /api/v1/nodes/k8s-g1/proxy/logs/: <pre>
<a href="Xorg.0.log">Xorg.0.log</a>
<a href="Xorg.0.log.old">Xorg.0.log.old</a>
<a href="al... (200; 5.214856ms)
[AfterEach] version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:14:08.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2snqk" for this suite.
Dec  6 03:14:14.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:14:14.841: INFO: namespace: e2e-tests-proxy-2snqk, resource: bindings, ignored listing per whitelist
Dec  6 03:14:14.957: INFO: namespace e2e-tests-proxy-2snqk deletion completed in 6.167515596s

• [SLOW TEST:6.663 seconds]
[sig-network] Proxy
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:14:14.957: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-02d70708-f905-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 03:14:15.391: INFO: Waiting up to 5m0s for pod "pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-pr6bn" to be "success or failure"
Dec  6 03:14:15.394: INFO: Pod "pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.723088ms
Dec  6 03:14:17.399: INFO: Pod "pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0087004s
Dec  6 03:14:19.404: INFO: Pod "pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0128943s
STEP: Saw pod success
Dec  6 03:14:19.404: INFO: Pod "pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:14:19.407: INFO: Trying to get logs from node k8s-g1 pod pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1 container secret-volume-test: <nil>
STEP: delete the pod
Dec  6 03:14:19.493: INFO: Waiting for pod pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:14:19.497: INFO: Pod pod-secrets-02dfe196-f905-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:14:19.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pr6bn" for this suite.
Dec  6 03:14:25.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:14:25.642: INFO: namespace: e2e-tests-secrets-pr6bn, resource: bindings, ignored listing per whitelist
Dec  6 03:14:25.723: INFO: namespace e2e-tests-secrets-pr6bn deletion completed in 6.167321555s

• [SLOW TEST:10.766 seconds]
[sig-storage] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:14:25.724: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
Dec  6 03:14:26.001: INFO: Waiting up to 5m0s for pod "downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-9rtlv" to be "success or failure"
Dec  6 03:14:26.006: INFO: Pod "downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.779079ms
Dec  6 03:14:28.010: INFO: Pod "downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008776622s
Dec  6 03:14:30.014: INFO: Pod "downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012596012s
STEP: Saw pod success
Dec  6 03:14:30.014: INFO: Pod "downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:14:30.017: INFO: Trying to get logs from node k8s-g2 pod downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1 container client-container: <nil>
STEP: delete the pod
Dec  6 03:14:30.128: INFO: Waiting for pod downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:14:30.133: INFO: Pod downwardapi-volume-093b6e1b-f905-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:14:30.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9rtlv" for this suite.
Dec  6 03:14:36.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:14:36.212: INFO: namespace: e2e-tests-downward-api-9rtlv, resource: bindings, ignored listing per whitelist
Dec  6 03:14:36.369: INFO: namespace e2e-tests-downward-api-9rtlv deletion completed in 6.227811228s

• [SLOW TEST:10.646 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:14:36.369: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
Dec  6 03:14:36.611: INFO: Waiting up to 5m0s for pod "client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-containers-9m9bf" to be "success or failure"
Dec  6 03:14:36.616: INFO: Pod "client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.315099ms
Dec  6 03:14:38.627: INFO: Pod "client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016387949s
Dec  6 03:14:40.631: INFO: Pod "client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020724921s
STEP: Saw pod success
Dec  6 03:14:40.631: INFO: Pod "client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:14:40.635: INFO: Trying to get logs from node k8s-g1 pod client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1 container test-container: <nil>
STEP: delete the pod
Dec  6 03:14:40.754: INFO: Waiting for pod client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:14:40.758: INFO: Pod client-containers-0f8cb541-f905-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:14:40.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9m9bf" for this suite.
Dec  6 03:14:46.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:14:46.907: INFO: namespace: e2e-tests-containers-9m9bf, resource: bindings, ignored listing per whitelist
Dec  6 03:14:46.924: INFO: namespace e2e-tests-containers-9m9bf deletion completed in 6.158104069s

• [SLOW TEST:10.554 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:14:46.924: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
Dec  6 03:14:47.256: INFO: Waiting up to 5m0s for pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-downward-api-m47f9" to be "success or failure"
Dec  6 03:14:47.260: INFO: Pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.924747ms
Dec  6 03:14:49.265: INFO: Pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008904323s
Dec  6 03:14:51.273: INFO: Pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017327524s
Dec  6 03:14:53.277: INFO: Pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021293812s
Dec  6 03:14:55.281: INFO: Pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.024995123s
STEP: Saw pod success
Dec  6 03:14:55.281: INFO: Pod "downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:14:55.285: INFO: Trying to get logs from node k8s-g1 pod downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1 container dapi-container: <nil>
STEP: delete the pod
Dec  6 03:14:55.379: INFO: Waiting for pod downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:14:55.383: INFO: Pod downward-api-15e2dbb0-f905-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:14:55.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m47f9" for this suite.
Dec  6 03:15:01.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:15:01.577: INFO: namespace: e2e-tests-downward-api-m47f9, resource: bindings, ignored listing per whitelist
Dec  6 03:15:01.607: INFO: namespace e2e-tests-downward-api-m47f9 deletion completed in 6.215699157s

• [SLOW TEST:14.683 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:15:01.607: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-rftnt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rftnt to expose endpoints map[]
Dec  6 03:15:02.114: INFO: Get endpoints failed (5.638701ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  6 03:15:03.122: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rftnt exposes endpoints map[] (1.014000875s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rftnt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rftnt to expose endpoints map[pod1:[80]]
Dec  6 03:15:06.208: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rftnt exposes endpoints map[pod1:[80]] (3.058699046s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rftnt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rftnt to expose endpoints map[pod1:[80] pod2:[80]]
Dec  6 03:15:09.372: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rftnt exposes endpoints map[pod1:[80] pod2:[80]] (3.117455589s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rftnt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rftnt to expose endpoints map[pod2:[80]]
Dec  6 03:15:09.458: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rftnt exposes endpoints map[pod2:[80]] (57.587296ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rftnt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rftnt to expose endpoints map[]
Dec  6 03:15:10.487: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rftnt exposes endpoints map[] (1.012827062s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:15:10.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rftnt" for this suite.
Dec  6 03:15:28.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:15:28.821: INFO: namespace: e2e-tests-services-rftnt, resource: bindings, ignored listing per whitelist
Dec  6 03:15:28.865: INFO: namespace e2e-tests-services-rftnt deletion completed in 18.188835856s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.258 seconds]
[sig-network] Services
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:15:28.865: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
Dec  6 03:15:29.093: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  6 03:16:29.126: INFO: Waiting for terminating namespaces to be deleted...
Dec  6 03:16:29.134: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  6 03:16:29.148: INFO: 29 / 29 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  6 03:16:29.148: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  6 03:16:29.154: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
Dec  6 03:16:29.154: INFO: 
Logging pods the kubelet thinks is on node k8s-g1 before test
Dec  6 03:16:29.167: INFO: calico-node-4mdfp from kube-system started at 2018-12-05 06:20:39 +0000 UTC (2 container statuses recorded)
Dec  6 03:16:29.167: INFO: 	Container calico-node ready: true, restart count 0
Dec  6 03:16:29.167: INFO: 	Container install-cni ready: true, restart count 0
Dec  6 03:16:29.167: INFO: sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-8vjk4 from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 03:16:29.167: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  6 03:16:29.167: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  6 03:16:29.167: INFO: nvidia-device-plugin-daemonset-smpqz from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 03:16:29.167: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  6 03:16:29.167: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-06 01:55:44 +0000 UTC (1 container statuses recorded)
Dec  6 03:16:29.167: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  6 03:16:29.167: INFO: kube-proxy-7jvxn from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 03:16:29.167: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  6 03:16:29.167: INFO: 
Logging pods the kubelet thinks is on node k8s-g2 before test
Dec  6 03:16:29.182: INFO: nvidia-device-plugin-daemonset-nkqbb from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 03:16:29.182: INFO: 	Container nvidia-device-plugin-ctr ready: true, restart count 0
Dec  6 03:16:29.182: INFO: tf-gpu-1-56564965df-4kqpb from default started at 2018-12-05 06:32:16 +0000 UTC (1 container statuses recorded)
Dec  6 03:16:29.182: INFO: 	Container tensorflow ready: true, restart count 0
Dec  6 03:16:29.182: INFO: sonobuoy-e2e-job-9cb377fd61834674 from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 03:16:29.182: INFO: 	Container e2e ready: true, restart count 0
Dec  6 03:16:29.182: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  6 03:16:29.182: INFO: sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-nl2hx from heptio-sonobuoy started at 2018-12-06 01:55:51 +0000 UTC (2 container statuses recorded)
Dec  6 03:16:29.182: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  6 03:16:29.182: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  6 03:16:29.182: INFO: kube-proxy-bvq6r from kube-system started at 2018-12-05 06:20:37 +0000 UTC (1 container statuses recorded)
Dec  6 03:16:29.182: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  6 03:16:29.182: INFO: calico-node-q6m2b from kube-system started at 2018-12-05 06:20:39 +0000 UTC (2 container statuses recorded)
Dec  6 03:16:29.182: INFO: 	Container calico-node ready: true, restart count 0
Dec  6 03:16:29.182: INFO: 	Container install-cni ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node k8s-g1
STEP: verifying the node has the label node k8s-g2
Dec  6 03:16:29.328: INFO: Pod tf-gpu-1-56564965df-4kqpb requesting resource cpu=0m on Node k8s-g2
Dec  6 03:16:29.328: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-g1
Dec  6 03:16:29.328: INFO: Pod sonobuoy-e2e-job-9cb377fd61834674 requesting resource cpu=0m on Node k8s-g2
Dec  6 03:16:29.328: INFO: Pod sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-8vjk4 requesting resource cpu=0m on Node k8s-g1
Dec  6 03:16:29.328: INFO: Pod sonobuoy-systemd-logs-daemon-set-d4b9cdbc4a6c48b7-nl2hx requesting resource cpu=0m on Node k8s-g2
Dec  6 03:16:29.328: INFO: Pod calico-node-4mdfp requesting resource cpu=250m on Node k8s-g1
Dec  6 03:16:29.328: INFO: Pod calico-node-q6m2b requesting resource cpu=250m on Node k8s-g2
Dec  6 03:16:29.328: INFO: Pod kube-proxy-7jvxn requesting resource cpu=0m on Node k8s-g1
Dec  6 03:16:29.328: INFO: Pod kube-proxy-bvq6r requesting resource cpu=0m on Node k8s-g2
Dec  6 03:16:29.328: INFO: Pod nvidia-device-plugin-daemonset-nkqbb requesting resource cpu=0m on Node k8s-g2
Dec  6 03:16:29.328: INFO: Pod nvidia-device-plugin-daemonset-smpqz requesting resource cpu=0m on Node k8s-g1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c04572-f905-11e8-a2c6-1eb929de0ff1.156da004bca15942], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kvh9r/filler-pod-52c04572-f905-11e8-a2c6-1eb929de0ff1 to k8s-g1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c04572-f905-11e8-a2c6-1eb929de0ff1.156da005155d79b3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c04572-f905-11e8-a2c6-1eb929de0ff1.156da0052580c193], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c04572-f905-11e8-a2c6-1eb929de0ff1.156da0053a7396a6], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c9cad6-f905-11e8-a2c6-1eb929de0ff1.156da004c0b94fc0], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kvh9r/filler-pod-52c9cad6-f905-11e8-a2c6-1eb929de0ff1 to k8s-g2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c9cad6-f905-11e8-a2c6-1eb929de0ff1.156da005247b167b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c9cad6-f905-11e8-a2c6-1eb929de0ff1.156da0053421b4ca], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52c9cad6-f905-11e8-a2c6-1eb929de0ff1.156da0054a1ab880], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156da005b114eed3], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node k8s-g1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-g2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:16:34.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kvh9r" for this suite.
Dec  6 03:16:42.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:16:42.913: INFO: namespace: e2e-tests-sched-pred-kvh9r, resource: bindings, ignored listing per whitelist
Dec  6 03:16:42.966: INFO: namespace e2e-tests-sched-pred-kvh9r deletion completed in 8.238325124s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:74.101 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:16:42.966: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1206 03:17:13.942752      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  6 03:17:13.942: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:17:13.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w2rp6" for this suite.
Dec  6 03:17:22.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:17:22.063: INFO: namespace: e2e-tests-gc-w2rp6, resource: bindings, ignored listing per whitelist
Dec  6 03:17:22.215: INFO: namespace e2e-tests-gc-w2rp6 deletion completed in 8.239491018s

• [SLOW TEST:39.249 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
Dec  6 03:17:22.215: INFO: >>> kubeConfig: /tmp/kubeconfig-630354635
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-78b5l/secret-test-7273a35b-f905-11e8-a2c6-1eb929de0ff1
STEP: Creating a pod to test consume secrets
Dec  6 03:17:22.556: INFO: Waiting up to 5m0s for pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1" in namespace "e2e-tests-secrets-78b5l" to be "success or failure"
Dec  6 03:17:22.689: INFO: Pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 132.068819ms
Dec  6 03:17:24.693: INFO: Pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.136937996s
Dec  6 03:17:26.698: INFO: Pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14099835s
Dec  6 03:17:28.723: INFO: Pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166156931s
Dec  6 03:17:30.727: INFO: Pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.17019523s
STEP: Saw pod success
Dec  6 03:17:30.727: INFO: Pod "pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1" satisfied condition "success or failure"
Dec  6 03:17:30.730: INFO: Trying to get logs from node k8s-g1 pod pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1 container env-test: <nil>
STEP: delete the pod
Dec  6 03:17:30.882: INFO: Waiting for pod pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1 to disappear
Dec  6 03:17:30.886: INFO: Pod pod-configmaps-7277d320-f905-11e8-a2c6-1eb929de0ff1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
Dec  6 03:17:30.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-78b5l" for this suite.
Dec  6 03:17:36.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  6 03:17:36.935: INFO: namespace: e2e-tests-secrets-78b5l, resource: bindings, ignored listing per whitelist
Dec  6 03:17:37.048: INFO: namespace e2e-tests-secrets-78b5l deletion completed in 6.15297952s

• [SLOW TEST:14.833 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.11.3-beta.0.71+a4529464e4629c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSDec  6 03:17:37.048: INFO: Running AfterSuite actions on all node
Dec  6 03:17:37.048: INFO: Running AfterSuite actions on node 1
Dec  6 03:17:37.048: INFO: Skipping dumping logs from cluster

Ran 165 of 996 Specs in 4837.741 seconds
SUCCESS! -- 165 Passed | 0 Failed | 0 Pending | 831 Skipped PASS

Ginkgo ran 1 suite in 1h20m38.019766046s
Test Suite Passed
