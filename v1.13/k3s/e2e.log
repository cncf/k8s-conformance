I0226 02:43:03.757435      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-481393766
I0226 02:43:03.757550      18 e2e.go:224] Starting e2e run "3cbc95bc-3970-11e9-ac13-320deb251a37" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551148982 - Will randomize all specs
Will run 201 of 1946 specs

Feb 26 02:43:03.932: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 02:43:03.934: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 26 02:43:03.945: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 26 02:43:03.979: INFO: The status of Pod helm-install-traefik-svddx is Succeeded, skipping waiting
Feb 26 02:43:03.979: INFO: 3 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 26 02:43:03.979: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Feb 26 02:43:03.980: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 26 02:43:03.988: INFO: e2e test version: v1.13.0
Feb 26 02:43:03.990: INFO: kube-apiserver version: v1.13.3-k3s.6
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:43:03.990: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
Feb 26 02:43:04.255: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3da0d5fd-3970-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 02:43:04.480: INFO: Waiting up to 5m0s for pod "pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-899ml" to be "success or failure"
Feb 26 02:43:04.483: INFO: Pod "pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.712571ms
Feb 26 02:43:06.486: INFO: Pod "pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006782359s
Feb 26 02:43:08.490: INFO: Pod "pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010356995s
STEP: Saw pod success
Feb 26 02:43:08.490: INFO: Pod "pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:43:08.493: INFO: Trying to get logs from node darren-2745 pod pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 02:43:08.523: INFO: Waiting for pod pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37 to disappear
Feb 26 02:43:08.528: INFO: Pod pod-configmaps-3da3250d-3970-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:43:08.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-899ml" for this suite.
Feb 26 02:43:14.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:43:14.614: INFO: namespace: e2e-tests-configmap-899ml, resource: bindings, ignored listing per whitelist
Feb 26 02:43:14.717: INFO: namespace e2e-tests-configmap-899ml deletion completed in 6.184172166s

• [SLOW TEST:10.727 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:43:14.717: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 02:43:15.190: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 26 02:43:15.199: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8wmkm/daemonsets","resourceVersion":"476"},"items":null}

Feb 26 02:43:15.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8wmkm/pods","resourceVersion":"476"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:43:15.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8wmkm" for this suite.
Feb 26 02:43:21.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:43:21.311: INFO: namespace: e2e-tests-daemonsets-8wmkm, resource: bindings, ignored listing per whitelist
Feb 26 02:43:21.374: INFO: namespace e2e-tests-daemonsets-8wmkm deletion completed in 6.158742654s

S [SKIPPING] [6.656 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 26 02:43:15.190: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:43:21.374: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 02:43:21.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-jf9l4'
Feb 26 02:43:22.174: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 26 02:43:22.174: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 26 02:43:26.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jf9l4'
Feb 26 02:43:26.281: INFO: stderr: ""
Feb 26 02:43:26.281: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:43:26.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jf9l4" for this suite.
Feb 26 02:43:48.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:43:48.447: INFO: namespace: e2e-tests-kubectl-jf9l4, resource: bindings, ignored listing per whitelist
Feb 26 02:43:48.485: INFO: namespace e2e-tests-kubectl-jf9l4 deletion completed in 22.199199535s

• [SLOW TEST:27.111 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:43:48.485: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:43:52.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-dbxqq" for this suite.
Feb 26 02:43:58.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:43:59.007: INFO: namespace: e2e-tests-kubelet-test-dbxqq, resource: bindings, ignored listing per whitelist
Feb 26 02:43:59.103: INFO: namespace e2e-tests-kubelet-test-dbxqq deletion completed in 6.153872486s

• [SLOW TEST:10.618 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:43:59.105: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-k8bqv
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-k8bqv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-k8bqv
Feb 26 02:43:59.793: INFO: Found 0 stateful pods, waiting for 1
Feb 26 02:44:09.798: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 26 02:44:09.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:44:10.044: INFO: stderr: ""
Feb 26 02:44:10.044: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:44:10.044: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:44:10.048: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 26 02:44:20.054: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:44:20.054: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:44:20.068: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999377s
Feb 26 02:44:21.073: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994987031s
Feb 26 02:44:22.078: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99013902s
Feb 26 02:44:23.083: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985454402s
Feb 26 02:44:24.088: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980064801s
Feb 26 02:44:25.094: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975112231s
Feb 26 02:44:26.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.969417765s
Feb 26 02:44:27.104: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964476041s
Feb 26 02:44:28.108: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959080576s
Feb 26 02:44:29.113: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.784833ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-k8bqv
Feb 26 02:44:30.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:44:30.361: INFO: stderr: ""
Feb 26 02:44:30.361: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:44:30.361: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:44:30.365: INFO: Found 1 stateful pods, waiting for 3
Feb 26 02:44:40.371: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:44:40.371: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:44:40.371: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 26 02:44:40.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:44:40.838: INFO: stderr: ""
Feb 26 02:44:40.838: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:44:40.838: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:44:40.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:44:41.031: INFO: stderr: ""
Feb 26 02:44:41.031: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:44:41.031: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:44:41.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:44:41.260: INFO: stderr: ""
Feb 26 02:44:41.260: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:44:41.260: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:44:41.260: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:44:41.263: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 26 02:44:51.271: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:44:51.271: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:44:51.271: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:44:51.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999588s
Feb 26 02:44:52.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994169995s
Feb 26 02:44:53.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988486669s
Feb 26 02:44:54.301: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982397396s
Feb 26 02:44:55.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976687561s
Feb 26 02:44:56.314: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969243394s
Feb 26 02:44:57.321: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963572129s
Feb 26 02:44:58.327: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.957224331s
Feb 26 02:44:59.333: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.951450751s
Feb 26 02:45:00.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.489478ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-k8bqv
Feb 26 02:45:01.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:45:01.548: INFO: stderr: ""
Feb 26 02:45:01.548: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:45:01.548: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:45:01.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:45:01.743: INFO: stderr: ""
Feb 26 02:45:01.743: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:45:01.743: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:45:01.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-k8bqv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:45:01.970: INFO: stderr: ""
Feb 26 02:45:01.970: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:45:01.970: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:45:01.970: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 26 02:45:21.988: INFO: Deleting all statefulset in ns e2e-tests-statefulset-k8bqv
Feb 26 02:45:21.992: INFO: Scaling statefulset ss to 0
Feb 26 02:45:22.002: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:45:22.004: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:45:22.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-k8bqv" for this suite.
Feb 26 02:45:28.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:45:28.123: INFO: namespace: e2e-tests-statefulset-k8bqv, resource: bindings, ignored listing per whitelist
Feb 26 02:45:28.186: INFO: namespace e2e-tests-statefulset-k8bqv deletion completed in 6.166326049s

• [SLOW TEST:89.081 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:45:28.186: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 02:45:28.663: INFO: (0) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 13.372651ms)
Feb 26 02:45:28.666: INFO: (1) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.514764ms)
Feb 26 02:45:28.670: INFO: (2) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.506963ms)
Feb 26 02:45:28.673: INFO: (3) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.428448ms)
Feb 26 02:45:28.677: INFO: (4) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.354378ms)
Feb 26 02:45:28.680: INFO: (5) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.203004ms)
Feb 26 02:45:28.686: INFO: (6) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 6.263513ms)
Feb 26 02:45:28.698: INFO: (7) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 11.13215ms)
Feb 26 02:45:28.702: INFO: (8) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.11667ms)
Feb 26 02:45:28.705: INFO: (9) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.490271ms)
Feb 26 02:45:28.709: INFO: (10) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.848368ms)
Feb 26 02:45:28.716: INFO: (11) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 6.322243ms)
Feb 26 02:45:28.719: INFO: (12) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.189189ms)
Feb 26 02:45:28.723: INFO: (13) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.932224ms)
Feb 26 02:45:28.733: INFO: (14) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 9.751782ms)
Feb 26 02:45:28.738: INFO: (15) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.892999ms)
Feb 26 02:45:28.742: INFO: (16) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.411915ms)
Feb 26 02:45:28.747: INFO: (17) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.36257ms)
Feb 26 02:45:28.751: INFO: (18) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.198557ms)
Feb 26 02:45:28.755: INFO: (19) /api/v1/nodes/darren-16001:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.872413ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:45:28.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pzvpn" for this suite.
Feb 26 02:45:34.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:45:34.842: INFO: namespace: e2e-tests-proxy-pzvpn, resource: bindings, ignored listing per whitelist
Feb 26 02:45:34.920: INFO: namespace e2e-tests-proxy-pzvpn deletion completed in 6.161235366s

• [SLOW TEST:6.734 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:45:34.921: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-97931235-3970-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 02:45:35.380: INFO: Waiting up to 5m0s for pod "pod-secrets-979461a1-3970-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-x6nbx" to be "success or failure"
Feb 26 02:45:35.382: INFO: Pod "pod-secrets-979461a1-3970-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 1.760638ms
Feb 26 02:45:37.385: INFO: Pod "pod-secrets-979461a1-3970-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004981737s
STEP: Saw pod success
Feb 26 02:45:37.385: INFO: Pod "pod-secrets-979461a1-3970-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:45:37.387: INFO: Trying to get logs from node darren-2745 pod pod-secrets-979461a1-3970-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 02:45:37.408: INFO: Waiting for pod pod-secrets-979461a1-3970-11e9-ac13-320deb251a37 to disappear
Feb 26 02:45:37.412: INFO: Pod pod-secrets-979461a1-3970-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:45:37.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x6nbx" for this suite.
Feb 26 02:45:43.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:45:43.544: INFO: namespace: e2e-tests-secrets-x6nbx, resource: bindings, ignored listing per whitelist
Feb 26 02:45:43.579: INFO: namespace e2e-tests-secrets-x6nbx deletion completed in 6.161845736s

• [SLOW TEST:8.659 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:45:43.580: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 02:45:44.027: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:45:48.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2qcbz" for this suite.
Feb 26 02:46:38.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:46:38.292: INFO: namespace: e2e-tests-pods-2qcbz, resource: bindings, ignored listing per whitelist
Feb 26 02:46:38.317: INFO: namespace e2e-tests-pods-2qcbz deletion completed in 50.149184937s

• [SLOW TEST:54.738 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:46:38.318: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 26 02:46:38.767: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 26 02:46:38.782: INFO: Waiting for terminating namespaces to be deleted...
Feb 26 02:46:38.786: INFO: 
Logging pods the kubelet thinks is on node darren-16001 before test
Feb 26 02:46:38.792: INFO: svclb-traefik-77d498cccf-h6nlj from kube-system started at 2019-02-26 02:40:39 +0000 UTC (2 container statuses recorded)
Feb 26 02:46:38.792: INFO: 	Container http ready: true, restart count 0
Feb 26 02:46:38.792: INFO: 	Container https ready: true, restart count 1
Feb 26 02:46:38.792: INFO: sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-ts2dg from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 02:46:38.792: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 26 02:46:38.792: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 26 02:46:38.792: INFO: coredns-7748f7f6df-8kss9 from kube-system started at 2019-02-26 02:40:25 +0000 UTC (1 container statuses recorded)
Feb 26 02:46:38.792: INFO: 	Container coredns ready: true, restart count 0
Feb 26 02:46:38.792: INFO: helm-install-traefik-svddx from kube-system started at 2019-02-26 02:40:25 +0000 UTC (1 container statuses recorded)
Feb 26 02:46:38.792: INFO: 	Container helm ready: false, restart count 0
Feb 26 02:46:38.792: INFO: traefik-cd5db8d98-9t88n from kube-system started at 2019-02-26 02:40:39 +0000 UTC (1 container statuses recorded)
Feb 26 02:46:38.792: INFO: 	Container traefik ready: true, restart count 0
Feb 26 02:46:38.792: INFO: 
Logging pods the kubelet thinks is on node darren-2745 before test
Feb 26 02:46:38.798: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-26 02:42:40 +0000 UTC (1 container statuses recorded)
Feb 26 02:46:38.798: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 26 02:46:38.798: INFO: sonobuoy-e2e-job-5dae3ccfaa924d88 from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 02:46:38.798: INFO: 	Container e2e ready: true, restart count 0
Feb 26 02:46:38.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 26 02:46:38.798: INFO: sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-6cg6k from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 02:46:38.798: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 26 02:46:38.798: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1586c9fa69acab72], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:46:40.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5s6qn" for this suite.
Feb 26 02:46:46.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:46:46.095: INFO: namespace: e2e-tests-sched-pred-5s6qn, resource: bindings, ignored listing per whitelist
Feb 26 02:46:46.192: INFO: namespace e2e-tests-sched-pred-5s6qn deletion completed in 6.158981167s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.874 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:46:46.192: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 26 02:46:46.670: INFO: Waiting up to 5m0s for pod "downward-api-c212bc6f-3970-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-9kcsj" to be "success or failure"
Feb 26 02:46:46.672: INFO: Pod "downward-api-c212bc6f-3970-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100246ms
Feb 26 02:46:48.675: INFO: Pod "downward-api-c212bc6f-3970-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005269781s
Feb 26 02:46:50.678: INFO: Pod "downward-api-c212bc6f-3970-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008374854s
STEP: Saw pod success
Feb 26 02:46:50.678: INFO: Pod "downward-api-c212bc6f-3970-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:46:50.681: INFO: Trying to get logs from node darren-2745 pod downward-api-c212bc6f-3970-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 02:46:50.697: INFO: Waiting for pod downward-api-c212bc6f-3970-11e9-ac13-320deb251a37 to disappear
Feb 26 02:46:50.701: INFO: Pod downward-api-c212bc6f-3970-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:46:50.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9kcsj" for this suite.
Feb 26 02:46:56.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:46:56.860: INFO: namespace: e2e-tests-downward-api-9kcsj, resource: bindings, ignored listing per whitelist
Feb 26 02:46:56.867: INFO: namespace e2e-tests-downward-api-9kcsj deletion completed in 6.159853422s

• [SLOW TEST:10.675 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:46:56.867: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 26 02:46:57.313: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-481393766 proxy --unix-socket=/tmp/kubectl-proxy-unix398677133/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:46:57.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dfgwk" for this suite.
Feb 26 02:47:03.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:47:03.454: INFO: namespace: e2e-tests-kubectl-dfgwk, resource: bindings, ignored listing per whitelist
Feb 26 02:47:03.552: INFO: namespace e2e-tests-kubectl-dfgwk deletion completed in 6.152925357s

• [SLOW TEST:6.685 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:47:03.552: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-2mgkj/configmap-test-cc66d263-3970-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 02:47:04.008: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-2mgkj" to be "success or failure"
Feb 26 02:47:04.012: INFO: Pod "pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 4.444968ms
Feb 26 02:47:06.020: INFO: Pod "pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011972838s
STEP: Saw pod success
Feb 26 02:47:06.020: INFO: Pod "pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:47:06.024: INFO: Trying to get logs from node darren-16001 pod pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37 container env-test: <nil>
STEP: delete the pod
Feb 26 02:47:06.037: INFO: Waiting for pod pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37 to disappear
Feb 26 02:47:06.042: INFO: Pod pod-configmaps-cc68233a-3970-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:47:06.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2mgkj" for this suite.
Feb 26 02:47:12.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:47:12.163: INFO: namespace: e2e-tests-configmap-2mgkj, resource: bindings, ignored listing per whitelist
Feb 26 02:47:12.226: INFO: namespace e2e-tests-configmap-2mgkj deletion completed in 6.179544684s

• [SLOW TEST:8.674 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:47:12.226: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d19718c0-3970-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 02:47:12.713: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-scd8j" to be "success or failure"
Feb 26 02:47:12.715: INFO: Pod "pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.252198ms
Feb 26 02:47:14.719: INFO: Pod "pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005384988s
STEP: Saw pod success
Feb 26 02:47:14.719: INFO: Pod "pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:47:14.722: INFO: Trying to get logs from node darren-2745 pod pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 02:47:14.736: INFO: Waiting for pod pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37 to disappear
Feb 26 02:47:14.740: INFO: Pod pod-projected-configmaps-d1989e53-3970-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:47:14.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-scd8j" for this suite.
Feb 26 02:47:20.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:47:20.881: INFO: namespace: e2e-tests-projected-scd8j, resource: bindings, ignored listing per whitelist
Feb 26 02:47:20.956: INFO: namespace e2e-tests-projected-scd8j deletion completed in 6.211082866s

• [SLOW TEST:8.730 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:47:20.956: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-57c5v
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 26 02:47:21.439: INFO: Found 0 stateful pods, waiting for 3
Feb 26 02:47:31.445: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:47:31.445: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:47:31.445: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:47:31.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-57c5v ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:47:31.654: INFO: stderr: ""
Feb 26 02:47:31.654: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:47:31.654: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 26 02:47:41.686: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 26 02:47:51.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-57c5v ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:47:51.915: INFO: stderr: ""
Feb 26 02:47:51.915: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:47:51.915: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:48:11.936: INFO: Waiting for StatefulSet e2e-tests-statefulset-57c5v/ss2 to complete update
Feb 26 02:48:11.936: INFO: Waiting for Pod e2e-tests-statefulset-57c5v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 26 02:48:21.943: INFO: Waiting for StatefulSet e2e-tests-statefulset-57c5v/ss2 to complete update
Feb 26 02:48:21.943: INFO: Waiting for Pod e2e-tests-statefulset-57c5v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 26 02:48:31.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-57c5v ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:48:32.151: INFO: stderr: ""
Feb 26 02:48:32.151: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:48:32.151: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:48:42.184: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 26 02:48:52.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-57c5v ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:48:52.423: INFO: stderr: ""
Feb 26 02:48:52.423: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:48:52.423: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 26 02:49:12.447: INFO: Deleting all statefulset in ns e2e-tests-statefulset-57c5v
Feb 26 02:49:12.452: INFO: Scaling statefulset ss2 to 0
Feb 26 02:49:42.468: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:49:42.471: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:49:42.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-57c5v" for this suite.
Feb 26 02:49:48.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:49:48.583: INFO: namespace: e2e-tests-statefulset-57c5v, resource: bindings, ignored listing per whitelist
Feb 26 02:49:48.688: INFO: namespace e2e-tests-statefulset-57c5v deletion completed in 6.200328651s

• [SLOW TEST:147.732 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:49:48.689: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0226 02:49:59.177485      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 26 02:49:59.177: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:49:59.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gdwrx" for this suite.
Feb 26 02:50:05.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:50:05.240: INFO: namespace: e2e-tests-gc-gdwrx, resource: bindings, ignored listing per whitelist
Feb 26 02:50:05.378: INFO: namespace e2e-tests-gc-gdwrx deletion completed in 6.196290757s

• [SLOW TEST:16.689 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:50:05.378: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:50:09.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-p7k2p" for this suite.
Feb 26 02:50:15.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:50:16.045: INFO: namespace: e2e-tests-emptydir-wrapper-p7k2p, resource: bindings, ignored listing per whitelist
Feb 26 02:50:16.061: INFO: namespace e2e-tests-emptydir-wrapper-p7k2p deletion completed in 6.188912946s

• [SLOW TEST:10.683 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:50:16.061: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-h8nvt
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-h8nvt
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-h8nvt
Feb 26 02:50:16.531: INFO: Found 0 stateful pods, waiting for 1
Feb 26 02:50:26.537: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 26 02:50:26.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:50:26.743: INFO: stderr: ""
Feb 26 02:50:26.743: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:50:26.743: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:50:26.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 26 02:50:36.752: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:50:36.752: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:50:36.765: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb 26 02:50:36.765: INFO: ss-0  darren-16001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  }]
Feb 26 02:50:36.765: INFO: 
Feb 26 02:50:36.765: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 26 02:50:37.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994816053s
Feb 26 02:50:38.781: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984724634s
Feb 26 02:50:39.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978679927s
Feb 26 02:50:40.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972721415s
Feb 26 02:50:41.799: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96682413s
Feb 26 02:50:42.805: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96136567s
Feb 26 02:50:43.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9554396s
Feb 26 02:50:44.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.948885135s
Feb 26 02:50:45.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.436521ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-h8nvt
Feb 26 02:50:46.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:50:47.030: INFO: stderr: ""
Feb 26 02:50:47.031: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:50:47.032: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:50:47.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:50:47.218: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 26 02:50:47.218: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:50:47.218: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:50:47.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 26 02:50:47.439: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 26 02:50:47.439: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 26 02:50:47.439: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 26 02:50:47.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:50:47.446: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 02:50:47.446: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 26 02:50:47.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:50:47.667: INFO: stderr: ""
Feb 26 02:50:47.667: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:50:47.667: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:50:47.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:50:47.874: INFO: stderr: ""
Feb 26 02:50:47.874: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:50:47.874: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:50:47.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 exec --namespace=e2e-tests-statefulset-h8nvt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 26 02:50:48.082: INFO: stderr: ""
Feb 26 02:50:48.082: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 26 02:50:48.082: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 26 02:50:48.082: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:50:48.086: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 26 02:50:58.094: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:50:58.095: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:50:58.095: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 26 02:50:58.107: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb 26 02:50:58.107: INFO: ss-0  darren-16001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  }]
Feb 26 02:50:58.107: INFO: ss-1  darren-2745   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:50:58.108: INFO: ss-2  darren-16001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:50:58.108: INFO: 
Feb 26 02:50:58.108: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 26 02:50:59.113: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb 26 02:50:59.113: INFO: ss-0  darren-16001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  }]
Feb 26 02:50:59.113: INFO: ss-1  darren-2745   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:50:59.113: INFO: ss-2  darren-16001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:50:59.113: INFO: 
Feb 26 02:50:59.113: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 26 02:51:00.119: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb 26 02:51:00.119: INFO: ss-0  darren-16001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  }]
Feb 26 02:51:00.119: INFO: ss-1  darren-2745   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:00.119: INFO: ss-2  darren-16001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:00.119: INFO: 
Feb 26 02:51:00.119: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 26 02:51:01.124: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb 26 02:51:01.124: INFO: ss-0  darren-16001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:16 +0000 UTC  }]
Feb 26 02:51:01.124: INFO: ss-1  darren-2745   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:01.124: INFO: ss-2  darren-16001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:01.125: INFO: 
Feb 26 02:51:01.125: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 26 02:51:02.131: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Feb 26 02:51:02.131: INFO: ss-1  darren-2745   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:02.131: INFO: ss-2  darren-16001  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:02.131: INFO: 
Feb 26 02:51:02.131: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 26 02:51:03.137: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 26 02:51:03.137: INFO: ss-1  darren-2745  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:03.137: INFO: 
Feb 26 02:51:03.137: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 26 02:51:04.143: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 26 02:51:04.143: INFO: ss-1  darren-2745  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:04.143: INFO: 
Feb 26 02:51:04.143: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 26 02:51:05.148: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 26 02:51:05.148: INFO: ss-1  darren-2745  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:05.148: INFO: 
Feb 26 02:51:05.148: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 26 02:51:06.153: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 26 02:51:06.153: INFO: ss-1  darren-2745  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:06.153: INFO: 
Feb 26 02:51:06.153: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 26 02:51:07.159: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Feb 26 02:51:07.159: INFO: ss-1  darren-2745  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 02:50:36 +0000 UTC  }]
Feb 26 02:51:07.159: INFO: 
Feb 26 02:51:07.159: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-h8nvt
Feb 26 02:51:08.163: INFO: Scaling statefulset ss to 0
Feb 26 02:51:08.173: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 26 02:51:08.176: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h8nvt
Feb 26 02:51:08.179: INFO: Scaling statefulset ss to 0
Feb 26 02:51:08.194: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 02:51:08.197: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:51:08.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h8nvt" for this suite.
Feb 26 02:51:14.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:51:14.370: INFO: namespace: e2e-tests-statefulset-h8nvt, resource: bindings, ignored listing per whitelist
Feb 26 02:51:14.377: INFO: namespace e2e-tests-statefulset-h8nvt deletion completed in 6.163883279s

• [SLOW TEST:58.315 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:51:14.380: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-61ea76ef-3971-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 02:51:14.850: INFO: Waiting up to 5m0s for pod "pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-h7r9j" to be "success or failure"
Feb 26 02:51:14.852: INFO: Pod "pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010363ms
Feb 26 02:51:16.855: INFO: Pod "pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005543975s
STEP: Saw pod success
Feb 26 02:51:16.855: INFO: Pod "pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:51:16.858: INFO: Trying to get logs from node darren-2745 pod pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 02:51:16.871: INFO: Waiting for pod pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37 to disappear
Feb 26 02:51:16.877: INFO: Pod pod-secrets-61ebc824-3971-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:51:16.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h7r9j" for this suite.
Feb 26 02:51:22.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:51:23.017: INFO: namespace: e2e-tests-secrets-h7r9j, resource: bindings, ignored listing per whitelist
Feb 26 02:51:23.103: INFO: namespace e2e-tests-secrets-h7r9j deletion completed in 6.219686152s

• [SLOW TEST:8.723 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:51:23.105: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 26 02:51:25.621: INFO: Pod pod-hostip-672351b8-3971-11e9-ac13-320deb251a37 has hostIP: 134.209.63.30
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:51:25.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fj7gw" for this suite.
Feb 26 02:51:47.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:51:47.701: INFO: namespace: e2e-tests-pods-fj7gw, resource: bindings, ignored listing per whitelist
Feb 26 02:51:47.780: INFO: namespace e2e-tests-pods-fj7gw deletion completed in 22.154509072s

• [SLOW TEST:24.675 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:51:47.780: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 26 02:51:48.228: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:51:51.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jm826" for this suite.
Feb 26 02:51:57.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:51:57.746: INFO: namespace: e2e-tests-init-container-jm826, resource: bindings, ignored listing per whitelist
Feb 26 02:51:57.815: INFO: namespace e2e-tests-init-container-jm826 deletion completed in 6.171165289s

• [SLOW TEST:10.034 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:51:57.815: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7bceecdd-3971-11e9-ac13-320deb251a37
STEP: Creating secret with name s-test-opt-upd-7bceed2d-3971-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7bceecdd-3971-11e9-ac13-320deb251a37
STEP: Updating secret s-test-opt-upd-7bceed2d-3971-11e9-ac13-320deb251a37
STEP: Creating secret with name s-test-opt-create-7bceed48-3971-11e9-ac13-320deb251a37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:53:10.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rbfps" for this suite.
Feb 26 02:53:32.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:53:32.601: INFO: namespace: e2e-tests-projected-rbfps, resource: bindings, ignored listing per whitelist
Feb 26 02:53:32.689: INFO: namespace e2e-tests-projected-rbfps deletion completed in 22.146218736s

• [SLOW TEST:94.874 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:53:32.689: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 02:53:33.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-rbjk2'
Feb 26 02:53:33.453: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 26 02:53:33.453: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 26 02:53:33.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-rbjk2'
Feb 26 02:53:33.564: INFO: stderr: ""
Feb 26 02:53:33.564: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:53:33.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rbjk2" for this suite.
Feb 26 02:53:39.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:53:39.665: INFO: namespace: e2e-tests-kubectl-rbjk2, resource: bindings, ignored listing per whitelist
Feb 26 02:53:39.733: INFO: namespace e2e-tests-kubectl-rbjk2 deletion completed in 6.1645021s

• [SLOW TEST:7.044 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:53:39.733: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-dmd2v in namespace e2e-tests-proxy-bjkxh
I0226 02:53:40.200329      18 runners.go:184] Created replication controller with name: proxy-service-dmd2v, namespace: e2e-tests-proxy-bjkxh, replica count: 1
I0226 02:53:41.250889      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0226 02:53:42.251163      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0226 02:53:43.251445      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:44.251714      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:45.251976      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:46.252215      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:47.252519      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:48.252787      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:49.253132      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:50.253388      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0226 02:53:51.253665      18 runners.go:184] proxy-service-dmd2v Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 26 02:53:51.256: INFO: setup took 11.075289655s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 26 02:53:51.263: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 6.257677ms)
Feb 26 02:53:51.272: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 16.024002ms)
Feb 26 02:53:51.278: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 21.559904ms)
Feb 26 02:53:51.278: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 21.944453ms)
Feb 26 02:53:51.281: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 25.055486ms)
Feb 26 02:53:51.282: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 25.512394ms)
Feb 26 02:53:51.286: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 30.503593ms)
Feb 26 02:53:51.287: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 30.67487ms)
Feb 26 02:53:51.287: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 30.81707ms)
Feb 26 02:53:51.287: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 30.779805ms)
Feb 26 02:53:51.292: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 36.070788ms)
Feb 26 02:53:51.292: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 36.213654ms)
Feb 26 02:53:51.294: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 37.852944ms)
Feb 26 02:53:51.294: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 37.56352ms)
Feb 26 02:53:51.295: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 38.853253ms)
Feb 26 02:53:51.297: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 40.56211ms)
Feb 26 02:53:51.300: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 2.560522ms)
Feb 26 02:53:51.321: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 24.210039ms)
Feb 26 02:53:51.322: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 25.020651ms)
Feb 26 02:53:51.325: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 28.109667ms)
Feb 26 02:53:51.325: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 27.693805ms)
Feb 26 02:53:51.325: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 27.98493ms)
Feb 26 02:53:51.325: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 28.118272ms)
Feb 26 02:53:51.326: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 28.348789ms)
Feb 26 02:53:51.326: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 28.625145ms)
Feb 26 02:53:51.326: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 29.049174ms)
Feb 26 02:53:51.327: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 29.996156ms)
Feb 26 02:53:51.327: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 30.001073ms)
Feb 26 02:53:51.327: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 30.577648ms)
Feb 26 02:53:51.328: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 31.160949ms)
Feb 26 02:53:51.328: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 31.198014ms)
Feb 26 02:53:51.329: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 31.48978ms)
Feb 26 02:53:51.332: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 2.673457ms)
Feb 26 02:53:51.334: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 4.855045ms)
Feb 26 02:53:51.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 6.286328ms)
Feb 26 02:53:51.338: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 8.454439ms)
Feb 26 02:53:51.339: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 9.513969ms)
Feb 26 02:53:51.343: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 13.567551ms)
Feb 26 02:53:51.343: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 14.249482ms)
Feb 26 02:53:51.348: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 19.091489ms)
Feb 26 02:53:51.348: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 19.409338ms)
Feb 26 02:53:51.348: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 19.037209ms)
Feb 26 02:53:51.352: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 23.202815ms)
Feb 26 02:53:51.354: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 25.073891ms)
Feb 26 02:53:51.355: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 25.961161ms)
Feb 26 02:53:51.355: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 26.096224ms)
Feb 26 02:53:51.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 26.87633ms)
Feb 26 02:53:51.356: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 26.555595ms)
Feb 26 02:53:51.371: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 14.952075ms)
Feb 26 02:53:51.376: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 20.161247ms)
Feb 26 02:53:51.392: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 36.477997ms)
Feb 26 02:53:51.397: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 40.740668ms)
Feb 26 02:53:51.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 49.123623ms)
Feb 26 02:53:51.411: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 54.618177ms)
Feb 26 02:53:51.411: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 54.862795ms)
Feb 26 02:53:51.412: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 55.484671ms)
Feb 26 02:53:51.413: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 57.189861ms)
Feb 26 02:53:51.415: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 58.308132ms)
Feb 26 02:53:51.415: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 58.828022ms)
Feb 26 02:53:51.416: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 59.456801ms)
Feb 26 02:53:51.416: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 59.26781ms)
Feb 26 02:53:51.418: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 61.641518ms)
Feb 26 02:53:51.423: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 66.433955ms)
Feb 26 02:53:51.423: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 66.578035ms)
Feb 26 02:53:51.426: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 3.156378ms)
Feb 26 02:53:51.426: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 3.236795ms)
Feb 26 02:53:51.428: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 5.097366ms)
Feb 26 02:53:51.428: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 5.235395ms)
Feb 26 02:53:51.429: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 5.487672ms)
Feb 26 02:53:51.433: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 9.483192ms)
Feb 26 02:53:51.437: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 13.439329ms)
Feb 26 02:53:51.437: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 14.116615ms)
Feb 26 02:53:51.455: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 31.598749ms)
Feb 26 02:53:51.459: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 35.874487ms)
Feb 26 02:53:51.459: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 35.704705ms)
Feb 26 02:53:51.462: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 38.549571ms)
Feb 26 02:53:51.462: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 38.642875ms)
Feb 26 02:53:51.462: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 39.083804ms)
Feb 26 02:53:51.463: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 39.784768ms)
Feb 26 02:53:51.463: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 39.524448ms)
Feb 26 02:53:51.482: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 18.92377ms)
Feb 26 02:53:51.482: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 18.870719ms)
Feb 26 02:53:51.482: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 19.01853ms)
Feb 26 02:53:51.488: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 24.833963ms)
Feb 26 02:53:51.492: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 28.351484ms)
Feb 26 02:53:51.493: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 30.039541ms)
Feb 26 02:53:51.493: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 29.699472ms)
Feb 26 02:53:51.494: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 30.948688ms)
Feb 26 02:53:51.496: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 32.989784ms)
Feb 26 02:53:51.496: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 33.39127ms)
Feb 26 02:53:51.497: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 33.968713ms)
Feb 26 02:53:51.497: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 33.822734ms)
Feb 26 02:53:51.497: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 34.043552ms)
Feb 26 02:53:51.497: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 34.191766ms)
Feb 26 02:53:51.498: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 34.620494ms)
Feb 26 02:53:51.498: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 34.765888ms)
Feb 26 02:53:51.500: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 2.540025ms)
Feb 26 02:53:51.505: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 6.001304ms)
Feb 26 02:53:51.508: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 10.115534ms)
Feb 26 02:53:51.512: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 13.927242ms)
Feb 26 02:53:51.514: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 15.811908ms)
Feb 26 02:53:51.515: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 16.674897ms)
Feb 26 02:53:51.515: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 16.866516ms)
Feb 26 02:53:51.515: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 17.397562ms)
Feb 26 02:53:51.515: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 16.962596ms)
Feb 26 02:53:51.517: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 18.626544ms)
Feb 26 02:53:51.522: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 23.241297ms)
Feb 26 02:53:51.522: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 23.387141ms)
Feb 26 02:53:51.523: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 24.582892ms)
Feb 26 02:53:51.523: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 24.79213ms)
Feb 26 02:53:51.523: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 24.826612ms)
Feb 26 02:53:51.524: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 25.473959ms)
Feb 26 02:53:51.535: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 11.119073ms)
Feb 26 02:53:51.536: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 11.860253ms)
Feb 26 02:53:51.537: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 12.896929ms)
Feb 26 02:53:51.543: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 18.972193ms)
Feb 26 02:53:51.544: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 19.490993ms)
Feb 26 02:53:51.544: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 19.434362ms)
Feb 26 02:53:51.544: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 20.255032ms)
Feb 26 02:53:51.549: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 24.826395ms)
Feb 26 02:53:51.549: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 25.101087ms)
Feb 26 02:53:51.549: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 25.158367ms)
Feb 26 02:53:51.549: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 25.371166ms)
Feb 26 02:53:51.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 26.405056ms)
Feb 26 02:53:51.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 26.090116ms)
Feb 26 02:53:51.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 26.19795ms)
Feb 26 02:53:51.550: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 26.120381ms)
Feb 26 02:53:51.551: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 26.551001ms)
Feb 26 02:53:51.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 20.850004ms)
Feb 26 02:53:51.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 20.993672ms)
Feb 26 02:53:51.572: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 21.189358ms)
Feb 26 02:53:51.573: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 22.414791ms)
Feb 26 02:53:51.576: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 25.327331ms)
Feb 26 02:53:51.576: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 25.281693ms)
Feb 26 02:53:51.578: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 27.010809ms)
Feb 26 02:53:51.578: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 27.078835ms)
Feb 26 02:53:51.578: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 27.26685ms)
Feb 26 02:53:51.579: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 27.671543ms)
Feb 26 02:53:51.579: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 27.429544ms)
Feb 26 02:53:51.579: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 27.650134ms)
Feb 26 02:53:51.579: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 27.84853ms)
Feb 26 02:53:51.580: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 28.882319ms)
Feb 26 02:53:51.580: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 29.485616ms)
Feb 26 02:53:51.581: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 29.898985ms)
Feb 26 02:53:51.583: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 2.442785ms)
Feb 26 02:53:51.590: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 8.74261ms)
Feb 26 02:53:51.590: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 9.117926ms)
Feb 26 02:53:51.596: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 14.619991ms)
Feb 26 02:53:51.596: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 15.247937ms)
Feb 26 02:53:51.598: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 16.92196ms)
Feb 26 02:53:51.598: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 17.115752ms)
Feb 26 02:53:51.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 21.019209ms)
Feb 26 02:53:51.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 20.589962ms)
Feb 26 02:53:51.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 20.661345ms)
Feb 26 02:53:51.602: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 21.051632ms)
Feb 26 02:53:51.603: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 21.308731ms)
Feb 26 02:53:51.603: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 21.208121ms)
Feb 26 02:53:51.603: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 21.39667ms)
Feb 26 02:53:51.603: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 21.29867ms)
Feb 26 02:53:51.603: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 21.228279ms)
Feb 26 02:53:51.606: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 3.183472ms)
Feb 26 02:53:51.616: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 12.107793ms)
Feb 26 02:53:51.616: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 12.959045ms)
Feb 26 02:53:51.617: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 13.629783ms)
Feb 26 02:53:51.621: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 16.769706ms)
Feb 26 02:53:51.621: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 17.350934ms)
Feb 26 02:53:51.622: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 17.941749ms)
Feb 26 02:53:51.623: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 18.199995ms)
Feb 26 02:53:51.623: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 18.770258ms)
Feb 26 02:53:51.623: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 19.554207ms)
Feb 26 02:53:51.624: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 19.623778ms)
Feb 26 02:53:51.624: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 19.929448ms)
Feb 26 02:53:51.624: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 19.100098ms)
Feb 26 02:53:51.624: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 19.698582ms)
Feb 26 02:53:51.624: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 20.72706ms)
Feb 26 02:53:51.625: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 20.151156ms)
Feb 26 02:53:51.634: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 9.056807ms)
Feb 26 02:53:51.634: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 9.045821ms)
Feb 26 02:53:51.639: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 13.707013ms)
Feb 26 02:53:51.639: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 13.795614ms)
Feb 26 02:53:51.639: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 14.113957ms)
Feb 26 02:53:51.641: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 15.542843ms)
Feb 26 02:53:51.641: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 16.013051ms)
Feb 26 02:53:51.641: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 15.91508ms)
Feb 26 02:53:51.641: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 16.401403ms)
Feb 26 02:53:51.641: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 16.392882ms)
Feb 26 02:53:51.641: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 15.828658ms)
Feb 26 02:53:51.643: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 17.200248ms)
Feb 26 02:53:51.644: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 18.804108ms)
Feb 26 02:53:51.644: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 18.919198ms)
Feb 26 02:53:51.644: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 18.757446ms)
Feb 26 02:53:51.645: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 19.331493ms)
Feb 26 02:53:51.648: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 3.049229ms)
Feb 26 02:53:51.649: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 4.288068ms)
Feb 26 02:53:51.666: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 20.87623ms)
Feb 26 02:53:51.666: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 21.321062ms)
Feb 26 02:53:51.667: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 21.354576ms)
Feb 26 02:53:51.679: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 33.626939ms)
Feb 26 02:53:51.679: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 33.769731ms)
Feb 26 02:53:51.683: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 37.461545ms)
Feb 26 02:53:51.683: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 37.911368ms)
Feb 26 02:53:51.683: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 38.357567ms)
Feb 26 02:53:51.684: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 38.507905ms)
Feb 26 02:53:51.684: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 38.874376ms)
Feb 26 02:53:51.684: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 38.648327ms)
Feb 26 02:53:51.684: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 38.983111ms)
Feb 26 02:53:51.684: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 39.196568ms)
Feb 26 02:53:51.685: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 40.042936ms)
Feb 26 02:53:51.700: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 14.390703ms)
Feb 26 02:53:51.701: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 14.437307ms)
Feb 26 02:53:51.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 19.677947ms)
Feb 26 02:53:51.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 19.308355ms)
Feb 26 02:53:51.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 20.066276ms)
Feb 26 02:53:51.705: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 19.973556ms)
Feb 26 02:53:51.706: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 19.938036ms)
Feb 26 02:53:51.706: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 20.260081ms)
Feb 26 02:53:51.706: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 20.301492ms)
Feb 26 02:53:51.708: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 23.143904ms)
Feb 26 02:53:51.709: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 22.774945ms)
Feb 26 02:53:51.709: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 23.338685ms)
Feb 26 02:53:51.709: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 23.809868ms)
Feb 26 02:53:51.709: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 23.785702ms)
Feb 26 02:53:51.709: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 23.393654ms)
Feb 26 02:53:51.710: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 25.404289ms)
Feb 26 02:53:51.717: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 6.599061ms)
Feb 26 02:53:51.718: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 6.75278ms)
Feb 26 02:53:51.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 10.893685ms)
Feb 26 02:53:51.722: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 11.443175ms)
Feb 26 02:53:51.725: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 14.757259ms)
Feb 26 02:53:51.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 21.178001ms)
Feb 26 02:53:51.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 21.514044ms)
Feb 26 02:53:51.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 21.504548ms)
Feb 26 02:53:51.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 21.868625ms)
Feb 26 02:53:51.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 21.652104ms)
Feb 26 02:53:51.732: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 21.728535ms)
Feb 26 02:53:51.733: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 21.905058ms)
Feb 26 02:53:51.733: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 22.086385ms)
Feb 26 02:53:51.733: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 22.375383ms)
Feb 26 02:53:51.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 23.448832ms)
Feb 26 02:53:51.734: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 23.976816ms)
Feb 26 02:53:51.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 3.596972ms)
Feb 26 02:53:51.739: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 4.163402ms)
Feb 26 02:53:51.761: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 26.3941ms)
Feb 26 02:53:51.761: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 26.529635ms)
Feb 26 02:53:51.765: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 29.889255ms)
Feb 26 02:53:51.765: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 30.218925ms)
Feb 26 02:53:51.768: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 33.156702ms)
Feb 26 02:53:51.768: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 33.356723ms)
Feb 26 02:53:51.768: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 33.208901ms)
Feb 26 02:53:51.768: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 33.252572ms)
Feb 26 02:53:51.768: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 33.440185ms)
Feb 26 02:53:51.768: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 33.842288ms)
Feb 26 02:53:51.769: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 33.855328ms)
Feb 26 02:53:51.769: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 33.667494ms)
Feb 26 02:53:51.769: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 34.69869ms)
Feb 26 02:53:51.769: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 34.567526ms)
Feb 26 02:53:51.772: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 2.430286ms)
Feb 26 02:53:51.776: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 6.340508ms)
Feb 26 02:53:51.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 24.209752ms)
Feb 26 02:53:51.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 24.460612ms)
Feb 26 02:53:51.794: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 24.93967ms)
Feb 26 02:53:51.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 25.537419ms)
Feb 26 02:53:51.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 25.319831ms)
Feb 26 02:53:51.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 25.882018ms)
Feb 26 02:53:51.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 26.459769ms)
Feb 26 02:53:51.797: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 27.028167ms)
Feb 26 02:53:51.797: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 27.281692ms)
Feb 26 02:53:51.797: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 27.499168ms)
Feb 26 02:53:51.798: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 28.391091ms)
Feb 26 02:53:51.799: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 29.280414ms)
Feb 26 02:53:51.799: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 29.630869ms)
Feb 26 02:53:51.799: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 29.700155ms)
Feb 26 02:53:51.806: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 6.66034ms)
Feb 26 02:53:51.806: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 7.058184ms)
Feb 26 02:53:51.809: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 9.765087ms)
Feb 26 02:53:51.809: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 9.809612ms)
Feb 26 02:53:51.813: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 13.30812ms)
Feb 26 02:53:51.816: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 16.045911ms)
Feb 26 02:53:51.822: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 21.569321ms)
Feb 26 02:53:51.823: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 23.666763ms)
Feb 26 02:53:51.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 23.617361ms)
Feb 26 02:53:51.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 24.094009ms)
Feb 26 02:53:51.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 24.319933ms)
Feb 26 02:53:51.827: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 26.557759ms)
Feb 26 02:53:51.827: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 26.884048ms)
Feb 26 02:53:51.827: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 26.754213ms)
Feb 26 02:53:51.827: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 26.93076ms)
Feb 26 02:53:51.827: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 27.317895ms)
Feb 26 02:53:51.837: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 9.255449ms)
Feb 26 02:53:51.842: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 14.271625ms)
Feb 26 02:53:51.842: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 14.876007ms)
Feb 26 02:53:51.843: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 15.436926ms)
Feb 26 02:53:51.847: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 19.733548ms)
Feb 26 02:53:51.847: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 19.518706ms)
Feb 26 02:53:51.848: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 20.467567ms)
Feb 26 02:53:51.848: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 20.253503ms)
Feb 26 02:53:51.848: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 20.69753ms)
Feb 26 02:53:51.849: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 21.116647ms)
Feb 26 02:53:51.849: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 21.370492ms)
Feb 26 02:53:51.849: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 21.162704ms)
Feb 26 02:53:51.849: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 21.047576ms)
Feb 26 02:53:51.851: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 23.375309ms)
Feb 26 02:53:51.855: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 27.086176ms)
Feb 26 02:53:51.855: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 27.342311ms)
Feb 26 02:53:51.860: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname1/proxy/: foo (200; 4.360112ms)
Feb 26 02:53:51.860: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:1080/proxy/rewri... (200; 4.579005ms)
Feb 26 02:53:51.860: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:460/proxy/: tls baz (200; 4.73198ms)
Feb 26 02:53:51.860: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 5.132263ms)
Feb 26 02:53:51.871: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:1080/proxy/... (200; 15.577851ms)
Feb 26 02:53:51.871: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 15.58617ms)
Feb 26 02:53:51.871: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:160/proxy/: foo (200; 15.646903ms)
Feb 26 02:53:51.871: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/proxy-service-dmd2v-pt9bk/proxy/rewriteme"... (200; 15.884337ms)
Feb 26 02:53:51.876: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:443/proxy/... (200; 20.238858ms)
Feb 26 02:53:51.880: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname2/proxy/: bar (200; 24.886622ms)
Feb 26 02:53:51.880: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/proxy-service-dmd2v:portname2/proxy/: bar (200; 25.307887ms)
Feb 26 02:53:51.880: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/http:proxy-service-dmd2v:portname1/proxy/: foo (200; 25.169191ms)
Feb 26 02:53:51.880: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/http:proxy-service-dmd2v-pt9bk:162/proxy/: bar (200; 25.445339ms)
Feb 26 02:53:51.881: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname1/proxy/: tls baz (200; 25.377407ms)
Feb 26 02:53:51.881: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/pods/https:proxy-service-dmd2v-pt9bk:462/proxy/: tls qux (200; 25.689701ms)
Feb 26 02:53:51.881: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-bjkxh/services/https:proxy-service-dmd2v:tlsportname2/proxy/: tls qux (200; 25.767765ms)
STEP: deleting ReplicationController proxy-service-dmd2v in namespace e2e-tests-proxy-bjkxh, will wait for the garbage collector to delete the pods
Feb 26 02:53:51.937: INFO: Deleting ReplicationController proxy-service-dmd2v took: 4.45445ms
Feb 26 02:53:52.138: INFO: Terminating ReplicationController proxy-service-dmd2v pods took: 200.288215ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:54:02.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bjkxh" for this suite.
Feb 26 02:54:08.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:54:09.034: INFO: namespace: e2e-tests-proxy-bjkxh, resource: bindings, ignored listing per whitelist
Feb 26 02:54:09.109: INFO: namespace e2e-tests-proxy-bjkxh deletion completed in 6.165154258s

• [SLOW TEST:29.376 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:54:09.109: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 26 02:54:09.584: INFO: Number of nodes with available pods: 0
Feb 26 02:54:09.584: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 02:54:10.594: INFO: Number of nodes with available pods: 0
Feb 26 02:54:10.594: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 02:54:11.594: INFO: Number of nodes with available pods: 0
Feb 26 02:54:11.594: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 02:54:12.593: INFO: Number of nodes with available pods: 1
Feb 26 02:54:12.593: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 02:54:13.598: INFO: Number of nodes with available pods: 2
Feb 26 02:54:13.598: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 26 02:54:13.632: INFO: Number of nodes with available pods: 1
Feb 26 02:54:13.632: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 02:54:14.644: INFO: Number of nodes with available pods: 1
Feb 26 02:54:14.644: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 02:54:15.644: INFO: Number of nodes with available pods: 2
Feb 26 02:54:15.644: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2p86p, will wait for the garbage collector to delete the pods
Feb 26 02:54:15.714: INFO: Deleting DaemonSet.extensions daemon-set took: 10.702887ms
Feb 26 02:54:15.914: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.26323ms
Feb 26 02:54:57.719: INFO: Number of nodes with available pods: 0
Feb 26 02:54:57.719: INFO: Number of running nodes: 0, number of available pods: 0
Feb 26 02:54:57.723: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2p86p/daemonsets","resourceVersion":"1981"},"items":null}

Feb 26 02:54:57.726: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2p86p/pods","resourceVersion":"1981"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:54:57.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2p86p" for this suite.
Feb 26 02:55:03.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:55:03.862: INFO: namespace: e2e-tests-daemonsets-2p86p, resource: bindings, ignored listing per whitelist
Feb 26 02:55:03.911: INFO: namespace e2e-tests-daemonsets-2p86p deletion completed in 6.169627979s

• [SLOW TEST:54.802 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:55:03.911: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-kg56
STEP: Creating a pod to test atomic-volume-subpath
Feb 26 02:55:04.379: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-kg56" in namespace "e2e-tests-subpath-xjn6j" to be "success or failure"
Feb 26 02:55:04.381: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Pending", Reason="", readiness=false. Elapsed: 1.903764ms
Feb 26 02:55:06.385: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005480585s
Feb 26 02:55:08.388: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 4.009161568s
Feb 26 02:55:10.392: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 6.012445153s
Feb 26 02:55:12.395: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 8.016184583s
Feb 26 02:55:14.399: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 10.019723154s
Feb 26 02:55:16.402: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 12.023074696s
Feb 26 02:55:18.405: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 14.026275744s
Feb 26 02:55:20.409: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 16.029844562s
Feb 26 02:55:22.412: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 18.03304544s
Feb 26 02:55:24.416: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 20.036616628s
Feb 26 02:55:26.419: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Running", Reason="", readiness=false. Elapsed: 22.040069173s
Feb 26 02:55:28.423: INFO: Pod "pod-subpath-test-downwardapi-kg56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043596965s
STEP: Saw pod success
Feb 26 02:55:28.423: INFO: Pod "pod-subpath-test-downwardapi-kg56" satisfied condition "success or failure"
Feb 26 02:55:28.425: INFO: Trying to get logs from node darren-2745 pod pod-subpath-test-downwardapi-kg56 container test-container-subpath-downwardapi-kg56: <nil>
STEP: delete the pod
Feb 26 02:55:28.441: INFO: Waiting for pod pod-subpath-test-downwardapi-kg56 to disappear
Feb 26 02:55:28.445: INFO: Pod pod-subpath-test-downwardapi-kg56 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-kg56
Feb 26 02:55:28.445: INFO: Deleting pod "pod-subpath-test-downwardapi-kg56" in namespace "e2e-tests-subpath-xjn6j"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:55:28.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xjn6j" for this suite.
Feb 26 02:55:34.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:55:34.540: INFO: namespace: e2e-tests-subpath-xjn6j, resource: bindings, ignored listing per whitelist
Feb 26 02:55:34.610: INFO: namespace e2e-tests-subpath-xjn6j deletion completed in 6.158407702s

• [SLOW TEST:30.699 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:55:34.612: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-4l55j/secret-test-fd04e3c3-3971-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 02:55:35.071: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-4l55j" to be "success or failure"
Feb 26 02:55:35.073: INFO: Pod "pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106359ms
Feb 26 02:55:37.076: INFO: Pod "pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005285035s
Feb 26 02:55:39.079: INFO: Pod "pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00870447s
STEP: Saw pod success
Feb 26 02:55:39.079: INFO: Pod "pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:55:39.082: INFO: Trying to get logs from node darren-16001 pod pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37 container env-test: <nil>
STEP: delete the pod
Feb 26 02:55:39.095: INFO: Waiting for pod pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37 to disappear
Feb 26 02:55:39.100: INFO: Pod pod-configmaps-fd0648a4-3971-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:55:39.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4l55j" for this suite.
Feb 26 02:55:45.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:55:45.227: INFO: namespace: e2e-tests-secrets-4l55j, resource: bindings, ignored listing per whitelist
Feb 26 02:55:45.273: INFO: namespace e2e-tests-secrets-4l55j deletion completed in 6.168131926s

• [SLOW TEST:10.661 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:55:45.274: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-cb6k
STEP: Creating a pod to test atomic-volume-subpath
Feb 26 02:55:45.739: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cb6k" in namespace "e2e-tests-subpath-4d8bv" to be "success or failure"
Feb 26 02:55:45.742: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.702097ms
Feb 26 02:55:47.746: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006315772s
Feb 26 02:55:49.749: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 4.009947097s
Feb 26 02:55:51.754: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 6.014630734s
Feb 26 02:55:53.757: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 8.017823435s
Feb 26 02:55:55.761: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 10.021271087s
Feb 26 02:55:57.764: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 12.024378271s
Feb 26 02:55:59.767: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 14.02770403s
Feb 26 02:56:01.770: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 16.030960847s
Feb 26 02:56:03.774: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 18.034645375s
Feb 26 02:56:05.777: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 20.037980674s
Feb 26 02:56:07.781: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Running", Reason="", readiness=false. Elapsed: 22.041513755s
Feb 26 02:56:09.784: INFO: Pod "pod-subpath-test-configmap-cb6k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044925404s
STEP: Saw pod success
Feb 26 02:56:09.785: INFO: Pod "pod-subpath-test-configmap-cb6k" satisfied condition "success or failure"
Feb 26 02:56:09.787: INFO: Trying to get logs from node darren-2745 pod pod-subpath-test-configmap-cb6k container test-container-subpath-configmap-cb6k: <nil>
STEP: delete the pod
Feb 26 02:56:09.805: INFO: Waiting for pod pod-subpath-test-configmap-cb6k to disappear
Feb 26 02:56:09.809: INFO: Pod pod-subpath-test-configmap-cb6k no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cb6k
Feb 26 02:56:09.809: INFO: Deleting pod "pod-subpath-test-configmap-cb6k" in namespace "e2e-tests-subpath-4d8bv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:56:09.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4d8bv" for this suite.
Feb 26 02:56:15.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:56:15.903: INFO: namespace: e2e-tests-subpath-4d8bv, resource: bindings, ignored listing per whitelist
Feb 26 02:56:15.984: INFO: namespace e2e-tests-subpath-4d8bv deletion completed in 6.168003431s

• [SLOW TEST:30.710 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:56:15.984: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-cr6lg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cr6lg to expose endpoints map[]
Feb 26 02:56:16.524: INFO: Get endpoints failed (3.706287ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 26 02:56:17.527: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cr6lg exposes endpoints map[] (1.006891301s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-cr6lg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cr6lg to expose endpoints map[pod1:[80]]
Feb 26 02:56:19.557: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cr6lg exposes endpoints map[pod1:[80]] (2.020557265s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-cr6lg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cr6lg to expose endpoints map[pod1:[80] pod2:[80]]
Feb 26 02:56:21.586: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cr6lg exposes endpoints map[pod1:[80] pod2:[80]] (2.025029323s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-cr6lg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cr6lg to expose endpoints map[pod2:[80]]
Feb 26 02:56:22.604: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cr6lg exposes endpoints map[pod2:[80]] (1.010826958s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-cr6lg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cr6lg to expose endpoints map[]
Feb 26 02:56:23.613: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cr6lg exposes endpoints map[] (1.004687656s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:56:23.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-cr6lg" for this suite.
Feb 26 02:56:29.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:56:29.671: INFO: namespace: e2e-tests-services-cr6lg, resource: bindings, ignored listing per whitelist
Feb 26 02:56:29.776: INFO: namespace e2e-tests-services-cr6lg deletion completed in 6.148596325s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.792 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:56:29.778: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 26 02:56:30.232: INFO: Waiting up to 5m0s for pod "pod-1de64091-3972-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-htnn6" to be "success or failure"
Feb 26 02:56:30.234: INFO: Pod "pod-1de64091-3972-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.271549ms
Feb 26 02:56:32.238: INFO: Pod "pod-1de64091-3972-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005471921s
STEP: Saw pod success
Feb 26 02:56:32.238: INFO: Pod "pod-1de64091-3972-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 02:56:32.241: INFO: Trying to get logs from node darren-16001 pod pod-1de64091-3972-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 02:56:32.262: INFO: Waiting for pod pod-1de64091-3972-11e9-ac13-320deb251a37 to disappear
Feb 26 02:56:32.267: INFO: Pod pod-1de64091-3972-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:56:32.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-htnn6" for this suite.
Feb 26 02:56:38.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:56:38.420: INFO: namespace: e2e-tests-emptydir-htnn6, resource: bindings, ignored listing per whitelist
Feb 26 02:56:38.461: INFO: namespace e2e-tests-emptydir-htnn6 deletion completed in 6.188912983s

• [SLOW TEST:8.684 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:56:38.461: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 02:56:38.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-zk2vq'
Feb 26 02:56:39.011: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 26 02:56:39.011: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 26 02:56:39.217: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 26 02:56:39.220: INFO: scanned /root for discovery docs: <nil>
Feb 26 02:56:39.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-zk2vq'
Feb 26 02:56:55.010: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 26 02:56:55.010: INFO: stdout: "Created e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b\nScaling up e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 26 02:56:55.010: INFO: stdout: "Created e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b\nScaling up e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 26 02:56:55.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-zk2vq'
Feb 26 02:56:55.115: INFO: stderr: ""
Feb 26 02:56:55.115: INFO: stdout: "e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b-lh9gf "
Feb 26 02:56:55.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b-lh9gf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zk2vq'
Feb 26 02:56:55.207: INFO: stderr: ""
Feb 26 02:56:55.207: INFO: stdout: "true"
Feb 26 02:56:55.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b-lh9gf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zk2vq'
Feb 26 02:56:55.295: INFO: stderr: ""
Feb 26 02:56:55.295: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 26 02:56:55.295: INFO: e2e-test-nginx-rc-272d837db93c7939e9868e0a0527737b-lh9gf is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 26 02:56:55.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-zk2vq'
Feb 26 02:56:55.402: INFO: stderr: ""
Feb 26 02:56:55.402: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:56:55.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zk2vq" for this suite.
Feb 26 02:57:01.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:57:01.572: INFO: namespace: e2e-tests-kubectl-zk2vq, resource: bindings, ignored listing per whitelist
Feb 26 02:57:01.593: INFO: namespace e2e-tests-kubectl-zk2vq deletion completed in 6.181796656s

• [SLOW TEST:23.131 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:57:01.594: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 02:57:02.061: INFO: Creating ReplicaSet my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37
Feb 26 02:57:02.070: INFO: Pod name my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37: Found 0 pods out of 1
Feb 26 02:57:07.075: INFO: Pod name my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37: Found 1 pods out of 1
Feb 26 02:57:07.075: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37" is running
Feb 26 02:57:07.077: INFO: Pod "my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37-zfhvl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 02:57:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 02:57:03 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 02:57:03 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 02:57:02 +0000 UTC Reason: Message:}])
Feb 26 02:57:07.077: INFO: Trying to dial the pod
Feb 26 02:57:12.089: INFO: Controller my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37: Got expected result from replica 1 [my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37-zfhvl]: "my-hostname-basic-30e1020e-3972-11e9-ac13-320deb251a37-zfhvl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:57:12.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-xv7mm" for this suite.
Feb 26 02:57:18.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:57:18.137: INFO: namespace: e2e-tests-replicaset-xv7mm, resource: bindings, ignored listing per whitelist
Feb 26 02:57:18.259: INFO: namespace e2e-tests-replicaset-xv7mm deletion completed in 6.164402434s

• [SLOW TEST:16.665 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:57:18.260: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 26 02:57:21.242: INFO: Successfully updated pod "pod-update-3acd4cdc-3972-11e9-ac13-320deb251a37"
STEP: verifying the updated pod is in kubernetes
Feb 26 02:57:21.248: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 02:57:21.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mfkgw" for this suite.
Feb 26 02:57:43.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 02:57:43.413: INFO: namespace: e2e-tests-pods-mfkgw, resource: bindings, ignored listing per whitelist
Feb 26 02:57:43.419: INFO: namespace e2e-tests-pods-mfkgw deletion completed in 22.167124833s

• [SLOW TEST:25.159 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 02:57:43.420: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 26 02:57:44.055: INFO: Pod name wrapped-volume-race-49e62e12-3972-11e9-ac13-320deb251a37: Found 0 pods out of 5
Feb 26 02:57:49.066: INFO: Pod name wrapped-volume-race-49e62e12-3972-11e9-ac13-320deb251a37: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-49e62e12-3972-11e9-ac13-320deb251a37 in namespace e2e-tests-emptydir-wrapper-qgh77, will wait for the garbage collector to delete the pods
Feb 26 02:57:59.161: INFO: Deleting ReplicationController wrapped-volume-race-49e62e12-3972-11e9-ac13-320deb251a37 took: 22.097341ms
Feb 26 02:57:59.362: INFO: Terminating ReplicationController wrapped-volume-race-49e62e12-3972-11e9-ac13-320deb251a37 pods took: 200.24381ms
STEP: Creating RC which spawns configmap-volume pods
Feb 26 02:58:43.183: INFO: Pod name wrapped-volume-race-6d23bc70-3972-11e9-ac13-320deb251a37: Found 0 pods out of 5
Feb 26 02:58:48.193: INFO: Pod name wrapped-volume-race-6d23bc70-3972-11e9-ac13-320deb251a37: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6d23bc70-3972-11e9-ac13-320deb251a37 in namespace e2e-tests-emptydir-wrapper-qgh77, will wait for the garbage collector to delete the pods
Feb 26 02:58:58.277: INFO: Deleting ReplicationController wrapped-volume-race-6d23bc70-3972-11e9-ac13-320deb251a37 took: 10.471713ms
Feb 26 02:58:58.377: INFO: Terminating ReplicationController wrapped-volume-race-6d23bc70-3972-11e9-ac13-320deb251a37 pods took: 100.225847ms
STEP: Creating RC which spawns configmap-volume pods
Feb 26 02:59:42.909: INFO: Pod name wrapped-volume-race-90bb9c8a-3972-11e9-ac13-320deb251a37: Found 0 pods out of 5
Feb 26 02:59:47.919: INFO: Pod name wrapped-volume-race-90bb9c8a-3972-11e9-ac13-320deb251a37: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-90bb9c8a-3972-11e9-ac13-320deb251a37 in namespace e2e-tests-emptydir-wrapper-qgh77, will wait for the garbage collector to delete the pods
Feb 26 02:59:58.009: INFO: Deleting ReplicationController wrapped-volume-race-90bb9c8a-3972-11e9-ac13-320deb251a37 took: 15.840773ms
Feb 26 02:59:58.109: INFO: Terminating ReplicationController wrapped-volume-race-90bb9c8a-3972-11e9-ac13-320deb251a37 pods took: 100.253627ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:00:33.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-qgh77" for this suite.
Feb 26 03:00:39.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:00:39.746: INFO: namespace: e2e-tests-emptydir-wrapper-qgh77, resource: bindings, ignored listing per whitelist
Feb 26 03:00:39.878: INFO: namespace e2e-tests-emptydir-wrapper-qgh77 deletion completed in 6.220742984s

• [SLOW TEST:176.458 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:00:39.878: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:00:42.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-bhl6g" for this suite.
Feb 26 03:01:20.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:01:20.482: INFO: namespace: e2e-tests-kubelet-test-bhl6g, resource: bindings, ignored listing per whitelist
Feb 26 03:01:20.574: INFO: namespace e2e-tests-kubelet-test-bhl6g deletion completed in 38.18177721s

• [SLOW TEST:40.696 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:01:20.575: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:01:21.065: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-rwwl8" to be "success or failure"
Feb 26 03:01:21.068: INFO: Pod "downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 1.999752ms
Feb 26 03:01:23.071: INFO: Pod "downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005258299s
STEP: Saw pod success
Feb 26 03:01:23.071: INFO: Pod "downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:01:23.074: INFO: Trying to get logs from node darren-16001 pod downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:01:23.086: INFO: Waiting for pod downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37 to disappear
Feb 26 03:01:23.089: INFO: Pod downwardapi-volume-cb3fda4b-3972-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:01:23.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rwwl8" for this suite.
Feb 26 03:01:29.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:01:29.231: INFO: namespace: e2e-tests-projected-rwwl8, resource: bindings, ignored listing per whitelist
Feb 26 03:01:29.254: INFO: namespace e2e-tests-projected-rwwl8 deletion completed in 6.159864525s

• [SLOW TEST:8.680 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:01:29.254: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 03:01:29.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kzv9q'
Feb 26 03:01:29.830: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 26 03:01:29.831: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 26 03:01:29.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-kzv9q'
Feb 26 03:01:29.932: INFO: stderr: ""
Feb 26 03:01:29.932: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:01:29.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kzv9q" for this suite.
Feb 26 03:01:35.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:01:36.018: INFO: namespace: e2e-tests-kubectl-kzv9q, resource: bindings, ignored listing per whitelist
Feb 26 03:01:36.125: INFO: namespace e2e-tests-kubectl-kzv9q deletion completed in 6.188944209s

• [SLOW TEST:6.871 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:01:36.125: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lh5pd
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 26 03:01:36.586: INFO: Found 0 stateful pods, waiting for 3
Feb 26 03:01:46.591: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 03:01:46.591: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 03:01:46.591: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 26 03:01:46.621: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 26 03:01:56.672: INFO: Updating stateful set ss2
Feb 26 03:01:56.679: INFO: Waiting for Pod e2e-tests-statefulset-lh5pd/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 26 03:02:06.722: INFO: Found 2 stateful pods, waiting for 3
Feb 26 03:02:16.727: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 03:02:16.727: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 26 03:02:16.727: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 26 03:02:16.753: INFO: Updating stateful set ss2
Feb 26 03:02:16.758: INFO: Waiting for Pod e2e-tests-statefulset-lh5pd/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 26 03:02:26.766: INFO: Waiting for Pod e2e-tests-statefulset-lh5pd/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 26 03:02:36.788: INFO: Updating stateful set ss2
Feb 26 03:02:36.796: INFO: Waiting for StatefulSet e2e-tests-statefulset-lh5pd/ss2 to complete update
Feb 26 03:02:36.796: INFO: Waiting for Pod e2e-tests-statefulset-lh5pd/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 26 03:02:46.804: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lh5pd
Feb 26 03:02:46.811: INFO: Scaling statefulset ss2 to 0
Feb 26 03:03:16.831: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 03:03:16.834: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:03:16.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lh5pd" for this suite.
Feb 26 03:03:22.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:03:23.057: INFO: namespace: e2e-tests-statefulset-lh5pd, resource: bindings, ignored listing per whitelist
Feb 26 03:03:23.065: INFO: namespace e2e-tests-statefulset-lh5pd deletion completed in 6.197455684s

• [SLOW TEST:106.940 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:03:23.068: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-lw8v
STEP: Creating a pod to test atomic-volume-subpath
Feb 26 03:03:23.539: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-lw8v" in namespace "e2e-tests-subpath-4mq4b" to be "success or failure"
Feb 26 03:03:23.543: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Pending", Reason="", readiness=false. Elapsed: 3.789083ms
Feb 26 03:03:25.546: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007027802s
Feb 26 03:03:27.550: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 4.011142854s
Feb 26 03:03:29.553: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 6.014149689s
Feb 26 03:03:31.556: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 8.017319921s
Feb 26 03:03:33.559: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 10.020400521s
Feb 26 03:03:35.563: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 12.024080186s
Feb 26 03:03:37.567: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 14.027589194s
Feb 26 03:03:39.570: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 16.031263476s
Feb 26 03:03:41.574: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 18.03487677s
Feb 26 03:03:43.578: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 20.038540737s
Feb 26 03:03:45.581: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Running", Reason="", readiness=false. Elapsed: 22.04187004s
Feb 26 03:03:47.584: INFO: Pod "pod-subpath-test-secret-lw8v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.045490551s
STEP: Saw pod success
Feb 26 03:03:47.585: INFO: Pod "pod-subpath-test-secret-lw8v" satisfied condition "success or failure"
Feb 26 03:03:47.587: INFO: Trying to get logs from node darren-16001 pod pod-subpath-test-secret-lw8v container test-container-subpath-secret-lw8v: <nil>
STEP: delete the pod
Feb 26 03:03:47.607: INFO: Waiting for pod pod-subpath-test-secret-lw8v to disappear
Feb 26 03:03:47.611: INFO: Pod pod-subpath-test-secret-lw8v no longer exists
STEP: Deleting pod pod-subpath-test-secret-lw8v
Feb 26 03:03:47.611: INFO: Deleting pod "pod-subpath-test-secret-lw8v" in namespace "e2e-tests-subpath-4mq4b"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:03:47.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4mq4b" for this suite.
Feb 26 03:03:53.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:03:53.754: INFO: namespace: e2e-tests-subpath-4mq4b, resource: bindings, ignored listing per whitelist
Feb 26 03:03:53.767: INFO: namespace e2e-tests-subpath-4mq4b deletion completed in 6.148951786s

• [SLOW TEST:30.699 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:03:53.767: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 26 03:03:56.777: INFO: Successfully updated pod "labelsupdate2689d846-3973-11e9-ac13-320deb251a37"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:03:58.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sqnlx" for this suite.
Feb 26 03:04:20.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:04:20.922: INFO: namespace: e2e-tests-downward-api-sqnlx, resource: bindings, ignored listing per whitelist
Feb 26 03:04:20.983: INFO: namespace e2e-tests-downward-api-sqnlx deletion completed in 22.190546036s

• [SLOW TEST:27.215 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:04:20.984: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 26 03:04:21.447: INFO: Waiting up to 5m0s for pod "pod-36c3fba6-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-b66l4" to be "success or failure"
Feb 26 03:04:21.451: INFO: Pod "pod-36c3fba6-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.490765ms
Feb 26 03:04:23.458: INFO: Pod "pod-36c3fba6-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010922783s
STEP: Saw pod success
Feb 26 03:04:23.458: INFO: Pod "pod-36c3fba6-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:04:23.461: INFO: Trying to get logs from node darren-16001 pod pod-36c3fba6-3973-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:04:23.475: INFO: Waiting for pod pod-36c3fba6-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:04:23.479: INFO: Pod pod-36c3fba6-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:04:23.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b66l4" for this suite.
Feb 26 03:04:29.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:04:29.640: INFO: namespace: e2e-tests-emptydir-b66l4, resource: bindings, ignored listing per whitelist
Feb 26 03:04:29.654: INFO: namespace e2e-tests-emptydir-b66l4 deletion completed in 6.162807789s

• [SLOW TEST:8.670 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:04:29.654: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 26 03:04:30.124: INFO: Waiting up to 5m0s for pod "pod-3befbdd4-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-gwdms" to be "success or failure"
Feb 26 03:04:30.127: INFO: Pod "pod-3befbdd4-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.873267ms
Feb 26 03:04:32.130: INFO: Pod "pod-3befbdd4-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00604592s
STEP: Saw pod success
Feb 26 03:04:32.130: INFO: Pod "pod-3befbdd4-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:04:32.132: INFO: Trying to get logs from node darren-2745 pod pod-3befbdd4-3973-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:04:32.143: INFO: Waiting for pod pod-3befbdd4-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:04:32.148: INFO: Pod pod-3befbdd4-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:04:32.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gwdms" for this suite.
Feb 26 03:04:38.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:04:38.322: INFO: namespace: e2e-tests-emptydir-gwdms, resource: bindings, ignored listing per whitelist
Feb 26 03:04:38.335: INFO: namespace e2e-tests-emptydir-gwdms deletion completed in 6.181984192s

• [SLOW TEST:8.681 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:04:38.335: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 26 03:04:38.809: INFO: Waiting up to 5m0s for pod "pod-411d95fb-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-5wznr" to be "success or failure"
Feb 26 03:04:38.812: INFO: Pod "pod-411d95fb-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.542709ms
Feb 26 03:04:40.815: INFO: Pod "pod-411d95fb-3973-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005874558s
Feb 26 03:04:42.819: INFO: Pod "pod-411d95fb-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009084309s
STEP: Saw pod success
Feb 26 03:04:42.819: INFO: Pod "pod-411d95fb-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:04:42.822: INFO: Trying to get logs from node darren-16001 pod pod-411d95fb-3973-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:04:42.835: INFO: Waiting for pod pod-411d95fb-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:04:42.839: INFO: Pod pod-411d95fb-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:04:42.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5wznr" for this suite.
Feb 26 03:04:48.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:04:48.899: INFO: namespace: e2e-tests-emptydir-5wznr, resource: bindings, ignored listing per whitelist
Feb 26 03:04:48.995: INFO: namespace e2e-tests-emptydir-5wznr deletion completed in 6.151990794s

• [SLOW TEST:10.660 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:04:48.996: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4775c4a8-3973-11e9-ac13-320deb251a37
STEP: Creating secret with name secret-projected-all-test-volume-4775c48d-3973-11e9-ac13-320deb251a37
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 26 03:04:49.460: INFO: Waiting up to 5m0s for pod "projected-volume-4775c439-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-nw8nj" to be "success or failure"
Feb 26 03:04:49.463: INFO: Pod "projected-volume-4775c439-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.213508ms
Feb 26 03:04:51.466: INFO: Pod "projected-volume-4775c439-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005406491s
STEP: Saw pod success
Feb 26 03:04:51.466: INFO: Pod "projected-volume-4775c439-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:04:51.468: INFO: Trying to get logs from node darren-2745 pod projected-volume-4775c439-3973-11e9-ac13-320deb251a37 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 26 03:04:51.479: INFO: Waiting for pod projected-volume-4775c439-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:04:51.483: INFO: Pod projected-volume-4775c439-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:04:51.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nw8nj" for this suite.
Feb 26 03:04:57.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:04:57.582: INFO: namespace: e2e-tests-projected-nw8nj, resource: bindings, ignored listing per whitelist
Feb 26 03:04:57.756: INFO: namespace e2e-tests-projected-nw8nj deletion completed in 6.26824762s

• [SLOW TEST:8.761 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:04:57.757: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 26 03:04:58.220: INFO: PodSpec: initContainers in spec.initContainers
Feb 26 03:05:44.436: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4cb0fe28-3973-11e9-ac13-320deb251a37", GenerateName:"", Namespace:"e2e-tests-init-container-kv27r", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-kv27r/pods/pod-init-4cb0fe28-3973-11e9-ac13-320deb251a37", UID:"4cb3e529-3973-11e9-a404-c690ac8d27cb", ResourceVersion:"3905", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686747098, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"220093015"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7q2q6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0007911c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7q2q6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7q2q6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7q2q6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0008f5e28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"darren-16001", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0012b1b60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0008f5f80)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0008f5fa0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0008f5fa8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0008f5fac)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686747098, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686747098, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686747098, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686747098, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"134.209.63.30", PodIP:"10.42.0.51", StartTime:(*v1.Time)(0xc0018acbe0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00038a000)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00038a0e0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://ea1903fcd067d70d701aedf99d027ce992c97ff2aead66bb8f45876f49502b30"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0018acc40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0018acc00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:05:44.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kv27r" for this suite.
Feb 26 03:06:06.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:06:06.526: INFO: namespace: e2e-tests-init-container-kv27r, resource: bindings, ignored listing per whitelist
Feb 26 03:06:06.613: INFO: namespace e2e-tests-init-container-kv27r deletion completed in 22.171547201s

• [SLOW TEST:68.856 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:06:06.613: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:06:07.075: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 26 03:06:07.082: INFO: Number of nodes with available pods: 0
Feb 26 03:06:07.082: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 26 03:06:07.101: INFO: Number of nodes with available pods: 0
Feb 26 03:06:07.101: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:08.105: INFO: Number of nodes with available pods: 0
Feb 26 03:06:08.105: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:09.105: INFO: Number of nodes with available pods: 0
Feb 26 03:06:09.106: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:10.106: INFO: Number of nodes with available pods: 1
Feb 26 03:06:10.106: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 26 03:06:10.123: INFO: Number of nodes with available pods: 1
Feb 26 03:06:10.123: INFO: Number of running nodes: 0, number of available pods: 1
Feb 26 03:06:11.128: INFO: Number of nodes with available pods: 0
Feb 26 03:06:11.128: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 26 03:06:11.151: INFO: Number of nodes with available pods: 0
Feb 26 03:06:11.151: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:12.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:12.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:13.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:13.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:14.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:14.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:15.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:15.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:16.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:16.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:17.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:17.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:18.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:18.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:19.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:19.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:20.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:20.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:21.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:21.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:22.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:22.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:23.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:23.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:24.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:24.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:25.157: INFO: Number of nodes with available pods: 0
Feb 26 03:06:25.157: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:26.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:26.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:27.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:27.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:28.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:28.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:29.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:29.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:30.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:30.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:31.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:31.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:32.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:32.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:33.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:33.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:34.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:34.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:35.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:35.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:36.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:36.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:37.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:37.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:38.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:38.155: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:39.157: INFO: Number of nodes with available pods: 0
Feb 26 03:06:39.157: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:40.155: INFO: Number of nodes with available pods: 0
Feb 26 03:06:40.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:41.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:41.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:42.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:42.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:43.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:43.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:44.156: INFO: Number of nodes with available pods: 0
Feb 26 03:06:44.156: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:06:45.163: INFO: Number of nodes with available pods: 1
Feb 26 03:06:45.163: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2lfzg, will wait for the garbage collector to delete the pods
Feb 26 03:06:45.234: INFO: Deleting DaemonSet.extensions daemon-set took: 11.965946ms
Feb 26 03:06:45.435: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.263822ms
Feb 26 03:07:22.839: INFO: Number of nodes with available pods: 0
Feb 26 03:07:22.839: INFO: Number of running nodes: 0, number of available pods: 0
Feb 26 03:07:22.842: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2lfzg/daemonsets","resourceVersion":"4004"},"items":null}

Feb 26 03:07:22.854: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2lfzg/pods","resourceVersion":"4004"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:07:22.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2lfzg" for this suite.
Feb 26 03:07:28.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:07:28.926: INFO: namespace: e2e-tests-daemonsets-2lfzg, resource: bindings, ignored listing per whitelist
Feb 26 03:07:29.035: INFO: namespace e2e-tests-daemonsets-2lfzg deletion completed in 6.150766524s

• [SLOW TEST:82.422 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:07:29.038: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-sl5lz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 26 03:07:29.481: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 26 03:07:49.547: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.0.54 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sl5lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:07:49.547: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:07:50.667: INFO: Found all expected endpoints: [netserver-0]
Feb 26 03:07:50.669: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.42.1.35 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sl5lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:07:50.669: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:07:51.774: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:07:51.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-sl5lz" for this suite.
Feb 26 03:08:13.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:08:13.949: INFO: namespace: e2e-tests-pod-network-test-sl5lz, resource: bindings, ignored listing per whitelist
Feb 26 03:08:13.973: INFO: namespace e2e-tests-pod-network-test-sl5lz deletion completed in 22.193186592s

• [SLOW TEST:44.936 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:08:13.974: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 26 03:08:14.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-rdw28'
Feb 26 03:08:14.875: INFO: stderr: ""
Feb 26 03:08:14.875: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 26 03:08:15.881: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:08:15.881: INFO: Found 0 / 1
Feb 26 03:08:16.879: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:08:16.879: INFO: Found 0 / 1
Feb 26 03:08:17.880: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:08:17.880: INFO: Found 1 / 1
Feb 26 03:08:17.880: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 26 03:08:17.884: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:08:17.885: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 26 03:08:17.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 logs redis-master-7jf6q redis-master --namespace=e2e-tests-kubectl-rdw28'
Feb 26 03:08:17.992: INFO: stderr: ""
Feb 26 03:08:17.992: INFO: stdout: "1:M 26 Feb 03:08:17.318 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Feb 03:08:17.319 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Feb 03:08:17.319 # Server started, Redis version 3.2.12\n1:M 26 Feb 03:08:17.319 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Feb 03:08:17.319 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 26 03:08:17.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 log redis-master-7jf6q redis-master --namespace=e2e-tests-kubectl-rdw28 --tail=1'
Feb 26 03:08:18.099: INFO: stderr: ""
Feb 26 03:08:18.099: INFO: stdout: "1:M 26 Feb 03:08:17.319 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 26 03:08:18.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 log redis-master-7jf6q redis-master --namespace=e2e-tests-kubectl-rdw28 --limit-bytes=1'
Feb 26 03:08:18.212: INFO: stderr: ""
Feb 26 03:08:18.212: INFO: stdout: "1"
STEP: exposing timestamps
Feb 26 03:08:18.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 log redis-master-7jf6q redis-master --namespace=e2e-tests-kubectl-rdw28 --tail=1 --timestamps'
Feb 26 03:08:18.328: INFO: stderr: ""
Feb 26 03:08:18.328: INFO: stdout: "2019-02-26T03:08:17.319635235Z 1:M 26 Feb 03:08:17.319 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 26 03:08:20.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 log redis-master-7jf6q redis-master --namespace=e2e-tests-kubectl-rdw28 --since=1s'
Feb 26 03:08:20.943: INFO: stderr: ""
Feb 26 03:08:20.943: INFO: stdout: ""
Feb 26 03:08:20.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 log redis-master-7jf6q redis-master --namespace=e2e-tests-kubectl-rdw28 --since=24h'
Feb 26 03:08:21.063: INFO: stderr: ""
Feb 26 03:08:21.063: INFO: stdout: "1:M 26 Feb 03:08:17.318 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Feb 03:08:17.319 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Feb 03:08:17.319 # Server started, Redis version 3.2.12\n1:M 26 Feb 03:08:17.319 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Feb 03:08:17.319 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 26 03:08:21.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rdw28'
Feb 26 03:08:21.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 03:08:21.168: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 26 03:08:21.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-rdw28'
Feb 26 03:08:21.280: INFO: stderr: "No resources found.\n"
Feb 26 03:08:21.280: INFO: stdout: ""
Feb 26 03:08:21.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -l name=nginx --namespace=e2e-tests-kubectl-rdw28 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 26 03:08:21.381: INFO: stderr: ""
Feb 26 03:08:21.381: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:08:21.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rdw28" for this suite.
Feb 26 03:08:27.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:08:27.431: INFO: namespace: e2e-tests-kubectl-rdw28, resource: bindings, ignored listing per whitelist
Feb 26 03:08:27.563: INFO: namespace e2e-tests-kubectl-rdw28 deletion completed in 6.176298826s

• [SLOW TEST:13.589 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:08:27.563: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 26 03:08:28.437: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5t9gh,SelfLink:/api/v1/namespaces/e2e-tests-watch-5t9gh/configmaps/e2e-watch-test-label-changed,UID:c9e1bd14-3973-11e9-a404-c690ac8d27cb,ResourceVersion:4156,Generation:0,CreationTimestamp:2019-02-26 03:08:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 26 03:08:28.438: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5t9gh,SelfLink:/api/v1/namespaces/e2e-tests-watch-5t9gh/configmaps/e2e-watch-test-label-changed,UID:c9e1bd14-3973-11e9-a404-c690ac8d27cb,ResourceVersion:4157,Generation:0,CreationTimestamp:2019-02-26 03:08:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 26 03:08:28.438: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5t9gh,SelfLink:/api/v1/namespaces/e2e-tests-watch-5t9gh/configmaps/e2e-watch-test-label-changed,UID:c9e1bd14-3973-11e9-a404-c690ac8d27cb,ResourceVersion:4158,Generation:0,CreationTimestamp:2019-02-26 03:08:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 26 03:08:38.637: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5t9gh,SelfLink:/api/v1/namespaces/e2e-tests-watch-5t9gh/configmaps/e2e-watch-test-label-changed,UID:c9e1bd14-3973-11e9-a404-c690ac8d27cb,ResourceVersion:4163,Generation:0,CreationTimestamp:2019-02-26 03:08:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 26 03:08:38.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5t9gh,SelfLink:/api/v1/namespaces/e2e-tests-watch-5t9gh/configmaps/e2e-watch-test-label-changed,UID:c9e1bd14-3973-11e9-a404-c690ac8d27cb,ResourceVersion:4164,Generation:0,CreationTimestamp:2019-02-26 03:08:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 26 03:08:38.638: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5t9gh,SelfLink:/api/v1/namespaces/e2e-tests-watch-5t9gh/configmaps/e2e-watch-test-label-changed,UID:c9e1bd14-3973-11e9-a404-c690ac8d27cb,ResourceVersion:4165,Generation:0,CreationTimestamp:2019-02-26 03:08:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:08:38.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5t9gh" for this suite.
Feb 26 03:08:44.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:08:44.802: INFO: namespace: e2e-tests-watch-5t9gh, resource: bindings, ignored listing per whitelist
Feb 26 03:08:44.862: INFO: namespace e2e-tests-watch-5t9gh deletion completed in 6.218412268s

• [SLOW TEST:17.299 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:08:44.862: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d40cf414-3973-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:08:45.342: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-2gcj2" to be "success or failure"
Feb 26 03:08:45.351: INFO: Pod "pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 9.044317ms
Feb 26 03:08:47.355: INFO: Pod "pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.012387835s
Feb 26 03:08:49.358: INFO: Pod "pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016209686s
STEP: Saw pod success
Feb 26 03:08:49.358: INFO: Pod "pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:08:49.361: INFO: Trying to get logs from node darren-16001 pod pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:08:49.377: INFO: Waiting for pod pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:08:49.382: INFO: Pod pod-projected-secrets-d40f7559-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:08:49.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2gcj2" for this suite.
Feb 26 03:08:55.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:08:55.564: INFO: namespace: e2e-tests-projected-2gcj2, resource: bindings, ignored listing per whitelist
Feb 26 03:08:55.585: INFO: namespace e2e-tests-projected-2gcj2 deletion completed in 6.196902335s

• [SLOW TEST:10.723 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:08:55.587: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-kstd
STEP: Creating a pod to test atomic-volume-subpath
Feb 26 03:08:56.054: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kstd" in namespace "e2e-tests-subpath-9jczq" to be "success or failure"
Feb 26 03:08:56.064: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.337276ms
Feb 26 03:08:58.068: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014329954s
Feb 26 03:09:00.072: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 4.017659815s
Feb 26 03:09:02.076: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 6.021598548s
Feb 26 03:09:04.079: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 8.025021382s
Feb 26 03:09:06.083: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 10.028643271s
Feb 26 03:09:08.086: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 12.0324545s
Feb 26 03:09:10.090: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 14.035766973s
Feb 26 03:09:12.093: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 16.039211807s
Feb 26 03:09:14.097: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 18.042883621s
Feb 26 03:09:16.100: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 20.04625548s
Feb 26 03:09:18.103: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Running", Reason="", readiness=false. Elapsed: 22.049509742s
Feb 26 03:09:20.109: INFO: Pod "pod-subpath-test-projected-kstd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.055294113s
STEP: Saw pod success
Feb 26 03:09:20.109: INFO: Pod "pod-subpath-test-projected-kstd" satisfied condition "success or failure"
Feb 26 03:09:20.112: INFO: Trying to get logs from node darren-2745 pod pod-subpath-test-projected-kstd container test-container-subpath-projected-kstd: <nil>
STEP: delete the pod
Feb 26 03:09:20.142: INFO: Waiting for pod pod-subpath-test-projected-kstd to disappear
Feb 26 03:09:20.147: INFO: Pod pod-subpath-test-projected-kstd no longer exists
STEP: Deleting pod pod-subpath-test-projected-kstd
Feb 26 03:09:20.147: INFO: Deleting pod "pod-subpath-test-projected-kstd" in namespace "e2e-tests-subpath-9jczq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:09:20.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9jczq" for this suite.
Feb 26 03:09:26.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:09:26.219: INFO: namespace: e2e-tests-subpath-9jczq, resource: bindings, ignored listing per whitelist
Feb 26 03:09:26.320: INFO: namespace e2e-tests-subpath-9jczq deletion completed in 6.165289677s

• [SLOW TEST:30.734 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:09:26.323: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 26 03:09:26.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 --namespace=e2e-tests-kubectl-9knck run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 26 03:09:29.181: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 26 03:09:29.181: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:09:31.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9knck" for this suite.
Feb 26 03:09:37.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:09:37.308: INFO: namespace: e2e-tests-kubectl-9knck, resource: bindings, ignored listing per whitelist
Feb 26 03:09:37.343: INFO: namespace e2e-tests-kubectl-9knck deletion completed in 6.151445881s

• [SLOW TEST:11.020 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:09:37.343: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 26 03:09:37.799: INFO: Waiting up to 5m0s for pod "client-containers-f35371ba-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-containers-gxlz7" to be "success or failure"
Feb 26 03:09:37.801: INFO: Pod "client-containers-f35371ba-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077868ms
Feb 26 03:09:39.804: INFO: Pod "client-containers-f35371ba-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005028648s
Feb 26 03:09:41.808: INFO: Pod "client-containers-f35371ba-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008829419s
STEP: Saw pod success
Feb 26 03:09:41.808: INFO: Pod "client-containers-f35371ba-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:09:41.811: INFO: Trying to get logs from node darren-2745 pod client-containers-f35371ba-3973-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:09:41.823: INFO: Waiting for pod client-containers-f35371ba-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:09:41.829: INFO: Pod client-containers-f35371ba-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:09:41.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gxlz7" for this suite.
Feb 26 03:09:47.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:09:47.891: INFO: namespace: e2e-tests-containers-gxlz7, resource: bindings, ignored listing per whitelist
Feb 26 03:09:48.027: INFO: namespace e2e-tests-containers-gxlz7 deletion completed in 6.189472494s

• [SLOW TEST:10.684 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:09:48.027: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 26 03:09:48.510: INFO: Waiting up to 5m0s for pod "pod-f9b3c6ee-3973-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-8w8q4" to be "success or failure"
Feb 26 03:09:48.513: INFO: Pod "pod-f9b3c6ee-3973-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.612617ms
Feb 26 03:09:50.517: INFO: Pod "pod-f9b3c6ee-3973-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007229356s
STEP: Saw pod success
Feb 26 03:09:50.517: INFO: Pod "pod-f9b3c6ee-3973-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:09:50.520: INFO: Trying to get logs from node darren-16001 pod pod-f9b3c6ee-3973-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:09:50.537: INFO: Waiting for pod pod-f9b3c6ee-3973-11e9-ac13-320deb251a37 to disappear
Feb 26 03:09:50.542: INFO: Pod pod-f9b3c6ee-3973-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:09:50.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8w8q4" for this suite.
Feb 26 03:09:56.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:09:56.702: INFO: namespace: e2e-tests-emptydir-8w8q4, resource: bindings, ignored listing per whitelist
Feb 26 03:09:56.725: INFO: namespace e2e-tests-emptydir-8w8q4 deletion completed in 6.177145754s

• [SLOW TEST:8.698 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:09:56.725: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 26 03:10:01.233: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 26 03:10:01.239: INFO: Pod pod-with-prestop-http-hook still exists
Feb 26 03:10:03.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 26 03:10:03.249: INFO: Pod pod-with-prestop-http-hook still exists
Feb 26 03:10:05.239: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 26 03:10:05.245: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:10:05.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-z4d7x" for this suite.
Feb 26 03:10:27.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:10:27.404: INFO: namespace: e2e-tests-container-lifecycle-hook-z4d7x, resource: bindings, ignored listing per whitelist
Feb 26 03:10:27.421: INFO: namespace e2e-tests-container-lifecycle-hook-z4d7x deletion completed in 22.161161977s

• [SLOW TEST:30.696 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:10:27.421: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-112d35bc-3974-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:10:27.882: INFO: Waiting up to 5m0s for pod "pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-k22nv" to be "success or failure"
Feb 26 03:10:27.884: INFO: Pod "pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025341ms
Feb 26 03:10:29.888: INFO: Pod "pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00541229s
Feb 26 03:10:31.891: INFO: Pod "pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008613274s
STEP: Saw pod success
Feb 26 03:10:31.891: INFO: Pod "pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:10:31.895: INFO: Trying to get logs from node darren-2745 pod pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:10:31.908: INFO: Waiting for pod pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:10:31.912: INFO: Pod pod-secrets-112e8ca4-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:10:31.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-k22nv" for this suite.
Feb 26 03:10:37.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:10:38.030: INFO: namespace: e2e-tests-secrets-k22nv, resource: bindings, ignored listing per whitelist
Feb 26 03:10:38.084: INFO: namespace e2e-tests-secrets-k22nv deletion completed in 6.167335506s

• [SLOW TEST:10.662 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:10:38.084: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 26 03:10:38.546: INFO: Waiting up to 5m0s for pod "pod-17888c7b-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-9q9w6" to be "success or failure"
Feb 26 03:10:38.549: INFO: Pod "pod-17888c7b-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.255128ms
Feb 26 03:10:40.552: INFO: Pod "pod-17888c7b-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005318288s
Feb 26 03:10:42.558: INFO: Pod "pod-17888c7b-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011407391s
STEP: Saw pod success
Feb 26 03:10:42.558: INFO: Pod "pod-17888c7b-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:10:42.564: INFO: Trying to get logs from node darren-16001 pod pod-17888c7b-3974-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:10:42.582: INFO: Waiting for pod pod-17888c7b-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:10:42.586: INFO: Pod pod-17888c7b-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:10:42.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9q9w6" for this suite.
Feb 26 03:10:48.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:10:48.693: INFO: namespace: e2e-tests-emptydir-9q9w6, resource: bindings, ignored listing per whitelist
Feb 26 03:10:48.775: INFO: namespace e2e-tests-emptydir-9q9w6 deletion completed in 6.184115026s

• [SLOW TEST:10.691 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:10:48.776: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 26 03:10:49.284: INFO: Waiting up to 5m0s for pod "downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-vq92s" to be "success or failure"
Feb 26 03:10:49.286: INFO: Pod "downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.463939ms
Feb 26 03:10:51.290: INFO: Pod "downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005953276s
STEP: Saw pod success
Feb 26 03:10:51.290: INFO: Pod "downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:10:51.292: INFO: Trying to get logs from node darren-2745 pod downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 03:10:51.311: INFO: Waiting for pod downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:10:51.315: INFO: Pod downward-api-1dedd4b1-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:10:51.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vq92s" for this suite.
Feb 26 03:10:57.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:10:57.515: INFO: namespace: e2e-tests-downward-api-vq92s, resource: bindings, ignored listing per whitelist
Feb 26 03:10:57.534: INFO: namespace e2e-tests-downward-api-vq92s deletion completed in 6.203983299s

• [SLOW TEST:8.758 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:10:57.534: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2323470f-3974-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:10:58.018: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-jhbkg" to be "success or failure"
Feb 26 03:10:58.021: INFO: Pod "pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.655531ms
Feb 26 03:11:00.024: INFO: Pod "pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005866836s
Feb 26 03:11:02.027: INFO: Pod "pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009450979s
STEP: Saw pod success
Feb 26 03:11:02.027: INFO: Pod "pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:11:02.030: INFO: Trying to get logs from node darren-16001 pod pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 03:11:02.043: INFO: Waiting for pod pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:11:02.047: INFO: Pod pod-projected-configmaps-2324b43f-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:11:02.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhbkg" for this suite.
Feb 26 03:11:08.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:11:08.174: INFO: namespace: e2e-tests-projected-jhbkg, resource: bindings, ignored listing per whitelist
Feb 26 03:11:08.238: INFO: namespace e2e-tests-projected-jhbkg deletion completed in 6.185513818s

• [SLOW TEST:10.705 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:11:08.239: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:11:08.710: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 26 03:11:13.715: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 26 03:11:13.715: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 26 03:11:13.941: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-cf4hd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cf4hd/deployments/test-cleanup-deployment,UID:2ca2f9f2-3974-11e9-a404-c690ac8d27cb,ResourceVersion:4529,Generation:1,CreationTimestamp:2019-02-26 03:11:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 26 03:11:13.947: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-cf4hd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cf4hd/replicasets/test-cleanup-deployment-7dbbfcf846,UID:2ca49657-3974-11e9-a404-c690ac8d27cb,ResourceVersion:4531,Generation:1,CreationTimestamp:2019-02-26 03:11:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 2ca2f9f2-3974-11e9-a404-c690ac8d27cb 0xc001efba97 0xc001efba98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:11:13.947: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 26 03:11:13.947: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-cf4hd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cf4hd/replicasets/test-cleanup-controller,UID:2985ad81-3974-11e9-a404-c690ac8d27cb,ResourceVersion:4530,Generation:1,CreationTimestamp:2019-02-26 03:11:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 2ca2f9f2-3974-11e9-a404-c690ac8d27cb 0xc001efb9cf 0xc001efb9e0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 26 03:11:13.951: INFO: Pod "test-cleanup-controller-c8fxh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-c8fxh,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-cf4hd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cf4hd/pods/test-cleanup-controller-c8fxh,UID:29875bf4-3974-11e9-a404-c690ac8d27cb,ResourceVersion:4527,Generation:0,CreationTimestamp:2019-02-26 03:11:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 2985ad81-3974-11e9-a404-c690ac8d27cb 0xc001a4e07f 0xc001a4e090}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t5k56 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t5k56,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t5k56 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a4e100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a4e120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:11:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:11:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:11:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:11:08 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:10.42.1.43,StartTime:2019-02-26 03:11:08 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:11:09 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://596d8bc5580d955cd54b4dc863b37866ae8f393237fdfe801c6ba0c56abf2fdd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:11:13.952: INFO: Pod "test-cleanup-deployment-7dbbfcf846-jm89l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-jm89l,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-cf4hd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cf4hd/pods/test-cleanup-deployment-7dbbfcf846-jm89l,UID:2ca58043-3974-11e9-a404-c690ac8d27cb,ResourceVersion:4534,Generation:0,CreationTimestamp:2019-02-26 03:11:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 2ca49657-3974-11e9-a404-c690ac8d27cb 0xc001a4e1e7 0xc001a4e1e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t5k56 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t5k56,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-t5k56 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a4e250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a4e270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:11:13.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cf4hd" for this suite.
Feb 26 03:11:19.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:11:20.066: INFO: namespace: e2e-tests-deployment-cf4hd, resource: bindings, ignored listing per whitelist
Feb 26 03:11:20.128: INFO: namespace e2e-tests-deployment-cf4hd deletion completed in 6.170242936s

• [SLOW TEST:11.890 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:11:20.129: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:11:20.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jtbts" for this suite.
Feb 26 03:11:42.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:11:42.753: INFO: namespace: e2e-tests-pods-jtbts, resource: bindings, ignored listing per whitelist
Feb 26 03:11:42.787: INFO: namespace e2e-tests-pods-jtbts deletion completed in 22.16506759s

• [SLOW TEST:22.659 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:11:42.788: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3e196b79-3974-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:11:43.253: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-zvnfl" to be "success or failure"
Feb 26 03:11:43.260: INFO: Pod "pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 6.782081ms
Feb 26 03:11:45.264: INFO: Pod "pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.010221336s
Feb 26 03:11:47.267: INFO: Pod "pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013390267s
STEP: Saw pod success
Feb 26 03:11:47.267: INFO: Pod "pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:11:47.270: INFO: Trying to get logs from node darren-16001 pod pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 03:11:47.283: INFO: Waiting for pod pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:11:47.288: INFO: Pod pod-projected-configmaps-3e1ad24b-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:11:47.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zvnfl" for this suite.
Feb 26 03:11:53.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:11:53.382: INFO: namespace: e2e-tests-projected-zvnfl, resource: bindings, ignored listing per whitelist
Feb 26 03:11:53.463: INFO: namespace e2e-tests-projected-zvnfl deletion completed in 6.170394574s

• [SLOW TEST:10.675 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:11:53.463: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:11:53.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-t6kcn" to be "success or failure"
Feb 26 03:11:53.924: INFO: Pod "downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.130074ms
Feb 26 03:11:55.928: INFO: Pod "downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005874393s
STEP: Saw pod success
Feb 26 03:11:55.928: INFO: Pod "downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:11:55.930: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:11:55.944: INFO: Waiting for pod downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:11:55.951: INFO: Pod downwardapi-volume-4475f926-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:11:55.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t6kcn" for this suite.
Feb 26 03:12:01.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:12:02.139: INFO: namespace: e2e-tests-downward-api-t6kcn, resource: bindings, ignored listing per whitelist
Feb 26 03:12:02.202: INFO: namespace e2e-tests-downward-api-t6kcn deletion completed in 6.24478927s

• [SLOW TEST:8.739 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:12:02.202: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:12:02.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 version'
Feb 26 03:12:02.781: INFO: stderr: ""
Feb 26 03:12:02.781: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3-k3s.6\", GitCommit:\"da4e14f160174f356b1d95198f48439971cc8a85\", GitTreeState:\"clean\", BuildDate:\"2019-02-24T05:21+00:00Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:12:02.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bwrkr" for this suite.
Feb 26 03:12:08.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:12:08.934: INFO: namespace: e2e-tests-kubectl-bwrkr, resource: bindings, ignored listing per whitelist
Feb 26 03:12:08.961: INFO: namespace e2e-tests-kubectl-bwrkr deletion completed in 6.173344897s

• [SLOW TEST:6.760 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:12:08.961: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 26 03:12:09.433: INFO: Waiting up to 5m0s for pod "client-containers-4db46f28-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-containers-78tq8" to be "success or failure"
Feb 26 03:12:09.435: INFO: Pod "client-containers-4db46f28-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.585043ms
Feb 26 03:12:11.439: INFO: Pod "client-containers-4db46f28-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005754411s
Feb 26 03:12:13.442: INFO: Pod "client-containers-4db46f28-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008905285s
STEP: Saw pod success
Feb 26 03:12:13.442: INFO: Pod "client-containers-4db46f28-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:12:13.444: INFO: Trying to get logs from node darren-16001 pod client-containers-4db46f28-3974-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:12:13.455: INFO: Waiting for pod client-containers-4db46f28-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:12:13.459: INFO: Pod client-containers-4db46f28-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:12:13.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-78tq8" for this suite.
Feb 26 03:12:19.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:12:19.602: INFO: namespace: e2e-tests-containers-78tq8, resource: bindings, ignored listing per whitelist
Feb 26 03:12:19.631: INFO: namespace e2e-tests-containers-78tq8 deletion completed in 6.168014316s

• [SLOW TEST:10.670 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:12:19.636: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 26 03:12:20.130: INFO: Waiting up to 5m0s for pod "var-expansion-54140ef5-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-var-expansion-7sfs6" to be "success or failure"
Feb 26 03:12:20.132: INFO: Pod "var-expansion-54140ef5-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.529474ms
Feb 26 03:12:22.135: INFO: Pod "var-expansion-54140ef5-3974-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005687696s
Feb 26 03:12:24.139: INFO: Pod "var-expansion-54140ef5-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00882128s
STEP: Saw pod success
Feb 26 03:12:24.139: INFO: Pod "var-expansion-54140ef5-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:12:24.141: INFO: Trying to get logs from node darren-2745 pod var-expansion-54140ef5-3974-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 03:12:24.155: INFO: Waiting for pod var-expansion-54140ef5-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:12:24.159: INFO: Pod var-expansion-54140ef5-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:12:24.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-7sfs6" for this suite.
Feb 26 03:12:30.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:12:30.226: INFO: namespace: e2e-tests-var-expansion-7sfs6, resource: bindings, ignored listing per whitelist
Feb 26 03:12:30.340: INFO: namespace e2e-tests-var-expansion-7sfs6 deletion completed in 6.177631056s

• [SLOW TEST:10.706 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:12:30.341: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 26 03:12:30.794: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 26 03:12:30.809: INFO: Waiting for terminating namespaces to be deleted...
Feb 26 03:12:30.813: INFO: 
Logging pods the kubelet thinks is on node darren-16001 before test
Feb 26 03:12:30.819: INFO: sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-ts2dg from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 03:12:30.819: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 26 03:12:30.819: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 26 03:12:30.819: INFO: svclb-traefik-77d498cccf-h6nlj from kube-system started at 2019-02-26 02:40:39 +0000 UTC (2 container statuses recorded)
Feb 26 03:12:30.819: INFO: 	Container http ready: true, restart count 0
Feb 26 03:12:30.819: INFO: 	Container https ready: true, restart count 1
Feb 26 03:12:30.819: INFO: coredns-7748f7f6df-8kss9 from kube-system started at 2019-02-26 02:40:25 +0000 UTC (1 container statuses recorded)
Feb 26 03:12:30.819: INFO: 	Container coredns ready: true, restart count 0
Feb 26 03:12:30.819: INFO: helm-install-traefik-svddx from kube-system started at 2019-02-26 02:40:25 +0000 UTC (1 container statuses recorded)
Feb 26 03:12:30.819: INFO: 	Container helm ready: false, restart count 0
Feb 26 03:12:30.819: INFO: traefik-cd5db8d98-9t88n from kube-system started at 2019-02-26 02:40:39 +0000 UTC (1 container statuses recorded)
Feb 26 03:12:30.819: INFO: 	Container traefik ready: true, restart count 0
Feb 26 03:12:30.819: INFO: 
Logging pods the kubelet thinks is on node darren-2745 before test
Feb 26 03:12:30.825: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-26 02:42:40 +0000 UTC (1 container statuses recorded)
Feb 26 03:12:30.825: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 26 03:12:30.825: INFO: sonobuoy-e2e-job-5dae3ccfaa924d88 from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 03:12:30.825: INFO: 	Container e2e ready: true, restart count 0
Feb 26 03:12:30.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 26 03:12:30.825: INFO: sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-6cg6k from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 03:12:30.825: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 26 03:12:30.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node darren-16001
STEP: verifying the node has the label node darren-2745
Feb 26 03:12:30.869: INFO: Pod sonobuoy requesting resource cpu=0m on Node darren-2745
Feb 26 03:12:30.869: INFO: Pod sonobuoy-e2e-job-5dae3ccfaa924d88 requesting resource cpu=0m on Node darren-2745
Feb 26 03:12:30.869: INFO: Pod sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-6cg6k requesting resource cpu=0m on Node darren-2745
Feb 26 03:12:30.869: INFO: Pod sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-ts2dg requesting resource cpu=0m on Node darren-16001
Feb 26 03:12:30.869: INFO: Pod coredns-7748f7f6df-8kss9 requesting resource cpu=100m on Node darren-16001
Feb 26 03:12:30.869: INFO: Pod svclb-traefik-77d498cccf-h6nlj requesting resource cpu=0m on Node darren-16001
Feb 26 03:12:30.869: INFO: Pod traefik-cd5db8d98-9t88n requesting resource cpu=0m on Node darren-16001
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7ddda3-3974-11e9-ac13-320deb251a37.1586cb63bc58f937], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-m8xgc/filler-pod-5a7ddda3-3974-11e9-ac13-320deb251a37 to darren-16001]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7ddda3-3974-11e9-ac13-320deb251a37.1586cb641b21f3ce], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7ddda3-3974-11e9-ac13-320deb251a37.1586cb64219dad59], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7ddda3-3974-11e9-ac13-320deb251a37.1586cb642bd4e0f6], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7fbf61-3974-11e9-ac13-320deb251a37.1586cb63bc85fa39], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-m8xgc/filler-pod-5a7fbf61-3974-11e9-ac13-320deb251a37 to darren-2745]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7fbf61-3974-11e9-ac13-320deb251a37.1586cb63ea86ba6b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7fbf61-3974-11e9-ac13-320deb251a37.1586cb63eea16120], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a7fbf61-3974-11e9-ac13-320deb251a37.1586cb63f70e9713], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1586cb64b8c4c1a5], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node darren-16001
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node darren-2745
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:12:36.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-m8xgc" for this suite.
Feb 26 03:12:42.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:12:42.262: INFO: namespace: e2e-tests-sched-pred-m8xgc, resource: bindings, ignored listing per whitelist
Feb 26 03:12:42.339: INFO: namespace e2e-tests-sched-pred-m8xgc deletion completed in 6.180886873s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.998 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:12:42.339: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-61995f4c-3974-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:12:42.808: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-7qch9" to be "success or failure"
Feb 26 03:12:42.811: INFO: Pod "pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.514647ms
Feb 26 03:12:44.814: INFO: Pod "pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005864988s
Feb 26 03:12:46.818: INFO: Pod "pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009411465s
STEP: Saw pod success
Feb 26 03:12:46.818: INFO: Pod "pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:12:46.821: INFO: Trying to get logs from node darren-16001 pod pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:12:46.836: INFO: Waiting for pod pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:12:46.840: INFO: Pod pod-projected-secrets-619a875d-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:12:46.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7qch9" for this suite.
Feb 26 03:12:52.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:12:52.895: INFO: namespace: e2e-tests-projected-7qch9, resource: bindings, ignored listing per whitelist
Feb 26 03:12:53.001: INFO: namespace e2e-tests-projected-7qch9 deletion completed in 6.155281548s

• [SLOW TEST:10.662 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:12:53.001: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0226 03:13:03.550396      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 26 03:13:03.550: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:13:03.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hj7sf" for this suite.
Feb 26 03:13:09.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:13:09.722: INFO: namespace: e2e-tests-gc-hj7sf, resource: bindings, ignored listing per whitelist
Feb 26 03:13:09.750: INFO: namespace e2e-tests-gc-hj7sf deletion completed in 6.195313837s

• [SLOW TEST:16.749 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:13:09.751: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-71efc02f-3974-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:13:10.224: INFO: Waiting up to 5m0s for pod "pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-n5m98" to be "success or failure"
Feb 26 03:13:10.227: INFO: Pod "pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.935931ms
Feb 26 03:13:12.231: INFO: Pod "pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006288699s
STEP: Saw pod success
Feb 26 03:13:12.231: INFO: Pod "pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:13:12.233: INFO: Trying to get logs from node darren-2745 pod pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:13:12.246: INFO: Waiting for pod pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:13:12.252: INFO: Pod pod-secrets-71f1b440-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:13:12.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n5m98" for this suite.
Feb 26 03:13:18.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:13:18.377: INFO: namespace: e2e-tests-secrets-n5m98, resource: bindings, ignored listing per whitelist
Feb 26 03:13:18.429: INFO: namespace e2e-tests-secrets-n5m98 deletion completed in 6.171729318s

• [SLOW TEST:8.679 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:13:18.429: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:13:18.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 version --client'
Feb 26 03:13:18.973: INFO: stderr: ""
Feb 26 03:13:18.973: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 26 03:13:18.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-jkkjk'
Feb 26 03:13:19.161: INFO: stderr: ""
Feb 26 03:13:19.161: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 26 03:13:19.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-jkkjk'
Feb 26 03:13:19.367: INFO: stderr: ""
Feb 26 03:13:19.367: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 26 03:13:20.373: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:13:20.373: INFO: Found 0 / 1
Feb 26 03:13:21.373: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:13:21.373: INFO: Found 1 / 1
Feb 26 03:13:21.373: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 26 03:13:21.378: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:13:21.379: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 26 03:13:21.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 describe pod redis-master-pcfpr --namespace=e2e-tests-kubectl-jkkjk'
Feb 26 03:13:21.493: INFO: stderr: ""
Feb 26 03:13:21.493: INFO: stdout: "Name:               redis-master-pcfpr\nNamespace:          e2e-tests-kubectl-jkkjk\nPriority:           0\nPriorityClassName:  <none>\nNode:               darren-16001/134.209.63.30\nStart Time:         Tue, 26 Feb 2019 03:13:19 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.42.0.71\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://4c54fec25aa647344dbda75f7a328dfbbe8d27bae926b0dcc544e1b29cdddcae\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 26 Feb 2019 03:13:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-92mpv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-92mpv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-92mpv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  2s    default-scheduler      Successfully assigned e2e-tests-kubectl-jkkjk/redis-master-pcfpr to darren-16001\n  Normal  Pulled     1s    kubelet, darren-16001  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, darren-16001  Created container\n  Normal  Started    1s    kubelet, darren-16001  Started container\n"
Feb 26 03:13:21.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 describe rc redis-master --namespace=e2e-tests-kubectl-jkkjk'
Feb 26 03:13:21.612: INFO: stderr: ""
Feb 26 03:13:21.612: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-jkkjk\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-pcfpr\n"
Feb 26 03:13:21.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 describe service redis-master --namespace=e2e-tests-kubectl-jkkjk'
Feb 26 03:13:21.742: INFO: stderr: ""
Feb 26 03:13:21.742: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-jkkjk\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.166.58\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.42.0.71:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 26 03:13:21.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 describe node darren-16001'
Feb 26 03:13:21.868: INFO: stderr: ""
Feb 26 03:13:21.868: INFO: stdout: "Name:               darren-16001\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=darren-16001\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"56:73:a7:4c:60:73\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 134.209.63.30\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Feb 2019 02:40:12 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 26 Feb 2019 03:13:15 +0000   Tue, 26 Feb 2019 02:40:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 26 Feb 2019 03:13:15 +0000   Tue, 26 Feb 2019 02:40:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 26 Feb 2019 03:13:15 +0000   Tue, 26 Feb 2019 02:40:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 26 Feb 2019 03:13:15 +0000   Tue, 26 Feb 2019 02:40:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  134.209.63.30\n  Hostname:    darren-16001\nCapacity:\n cpu:                4\n ephemeral-storage:  81120644Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8167988Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  78914162422\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8167988Ki\n pods:               110\nSystem Info:\n Machine ID:                 f7b3834c6e9a42e9adefafb258455526\n System UUID:                F7B3834C-6E9A-42E9-ADEF-AFB258455526\n Boot ID:                    31d2fc22-6890-4c13-8fbe-19e304cb892e\n Kernel Version:             4.15.0-45-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.3+unknown\n Kubelet Version:            v1.13.3-k3s.6\n Kube-Proxy Version:         v1.13.3-k3s.6\nPodCIDR:                     10.42.0.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-jkkjk    redis-master-pcfpr                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-ts2dg    0 (0%)        0 (0%)      0 (0%)           0 (0%)         30m\n  kube-system                coredns-7748f7f6df-8kss9                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     32m\n  kube-system                svclb-traefik-77d498cccf-h6nlj                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                traefik-cd5db8d98-9t88n                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (2%)  0 (0%)\n  memory             70Mi (0%)  170Mi (2%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:\n  Type     Reason                   Age                From                      Message\n  ----     ------                   ----               ----                      -------\n  Normal   Starting                 33m                kubelet, darren-16001     Starting kubelet.\n  Warning  InvalidDiskCapacity      33m                kubelet, darren-16001     invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  33m (x2 over 33m)  kubelet, darren-16001     Node darren-16001 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    33m (x2 over 33m)  kubelet, darren-16001     Node darren-16001 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     33m (x2 over 33m)  kubelet, darren-16001     Node darren-16001 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  33m                kubelet, darren-16001     Updated Node Allocatable limit across pods\n  Normal   Starting                 33m                kube-proxy, darren-16001  Starting kube-proxy.\n"
Feb 26 03:13:21.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 describe namespace e2e-tests-kubectl-jkkjk'
Feb 26 03:13:21.977: INFO: stderr: ""
Feb 26 03:13:21.977: INFO: stdout: "Name:         e2e-tests-kubectl-jkkjk\nLabels:       e2e-framework=kubectl\n              e2e-run=3cbc95bc-3970-11e9-ac13-320deb251a37\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:13:21.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jkkjk" for this suite.
Feb 26 03:13:43.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:13:44.161: INFO: namespace: e2e-tests-kubectl-jkkjk, resource: bindings, ignored listing per whitelist
Feb 26 03:13:44.164: INFO: namespace e2e-tests-kubectl-jkkjk deletion completed in 22.18230729s

• [SLOW TEST:25.735 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:13:44.164: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 26 03:13:44.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 api-versions'
Feb 26 03:13:44.734: INFO: stderr: ""
Feb 26 03:13:44.734: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\nextensions/v1beta1\nk3s.cattle.io/v1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:13:44.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mhvrg" for this suite.
Feb 26 03:13:50.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:13:50.861: INFO: namespace: e2e-tests-kubectl-mhvrg, resource: bindings, ignored listing per whitelist
Feb 26 03:13:50.963: INFO: namespace e2e-tests-kubectl-mhvrg deletion completed in 6.222682154s

• [SLOW TEST:6.799 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:13:50.965: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kl87p
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-kl87p
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-kl87p
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-kl87p
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-kl87p
Feb 26 03:14:03.648: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kl87p, name: ss-0, uid: 909888ac-3974-11e9-a404-c690ac8d27cb, status phase: Pending. Waiting for statefulset controller to delete.
Feb 26 03:14:11.848: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kl87p, name: ss-0, uid: 909888ac-3974-11e9-a404-c690ac8d27cb, status phase: Failed. Waiting for statefulset controller to delete.
Feb 26 03:14:11.848: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kl87p, name: ss-0, uid: 909888ac-3974-11e9-a404-c690ac8d27cb, status phase: Failed. Waiting for statefulset controller to delete.
Feb 26 03:14:11.848: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-kl87p
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-kl87p
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-kl87p and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 26 03:14:23.875: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kl87p
Feb 26 03:14:23.879: INFO: Scaling statefulset ss to 0
Feb 26 03:14:33.896: INFO: Waiting for statefulset status.replicas updated to 0
Feb 26 03:14:33.899: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:14:33.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kl87p" for this suite.
Feb 26 03:14:39.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:14:40.050: INFO: namespace: e2e-tests-statefulset-kl87p, resource: bindings, ignored listing per whitelist
Feb 26 03:14:40.074: INFO: namespace e2e-tests-statefulset-kl87p deletion completed in 6.158825483s

• [SLOW TEST:49.109 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:14:40.074: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-rmcr9/configmap-test-a7c607ed-3974-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:14:40.539: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-rmcr9" to be "success or failure"
Feb 26 03:14:40.550: INFO: Pod "pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 10.253429ms
Feb 26 03:14:42.553: INFO: Pod "pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013549719s
STEP: Saw pod success
Feb 26 03:14:42.553: INFO: Pod "pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:14:42.555: INFO: Trying to get logs from node darren-2745 pod pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37 container env-test: <nil>
STEP: delete the pod
Feb 26 03:14:42.569: INFO: Waiting for pod pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:14:42.573: INFO: Pod pod-configmaps-a7c6b11a-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:14:42.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rmcr9" for this suite.
Feb 26 03:14:48.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:14:48.666: INFO: namespace: e2e-tests-configmap-rmcr9, resource: bindings, ignored listing per whitelist
Feb 26 03:14:48.748: INFO: namespace e2e-tests-configmap-rmcr9 deletion completed in 6.170145616s

• [SLOW TEST:8.674 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:14:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:14:49.204: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-w48t6" to be "success or failure"
Feb 26 03:14:49.207: INFO: Pod "downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.610058ms
Feb 26 03:14:51.210: INFO: Pod "downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.00573915s
Feb 26 03:14:53.213: INFO: Pod "downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008971502s
STEP: Saw pod success
Feb 26 03:14:53.213: INFO: Pod "downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:14:53.216: INFO: Trying to get logs from node darren-16001 pod downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:14:53.229: INFO: Waiting for pod downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37 to disappear
Feb 26 03:14:53.233: INFO: Pod downwardapi-volume-acf00605-3974-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:14:53.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w48t6" for this suite.
Feb 26 03:14:59.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:14:59.301: INFO: namespace: e2e-tests-downward-api-w48t6, resource: bindings, ignored listing per whitelist
Feb 26 03:14:59.475: INFO: namespace e2e-tests-downward-api-w48t6 deletion completed in 6.237718603s

• [SLOW TEST:10.727 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:14:59.475: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b3590567-3974-11e9-ac13-320deb251a37
STEP: Creating configMap with name cm-test-opt-upd-b35905b3-3974-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b3590567-3974-11e9-ac13-320deb251a37
STEP: Updating configmap cm-test-opt-upd-b35905b3-3974-11e9-ac13-320deb251a37
STEP: Creating configMap with name cm-test-opt-create-b35905d3-3974-11e9-ac13-320deb251a37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:16:12.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5z6ts" for this suite.
Feb 26 03:16:34.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:16:34.341: INFO: namespace: e2e-tests-projected-5z6ts, resource: bindings, ignored listing per whitelist
Feb 26 03:16:34.400: INFO: namespace e2e-tests-projected-5z6ts deletion completed in 22.163262832s

• [SLOW TEST:94.925 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:16:34.400: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-f5w4l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f5w4l to expose endpoints map[]
Feb 26 03:16:34.880: INFO: Get endpoints failed (3.304677ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 26 03:16:35.883: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f5w4l exposes endpoints map[] (1.006304542s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-f5w4l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f5w4l to expose endpoints map[pod1:[100]]
Feb 26 03:16:37.905: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f5w4l exposes endpoints map[pod1:[100]] (2.01471865s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-f5w4l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f5w4l to expose endpoints map[pod1:[100] pod2:[101]]
Feb 26 03:16:39.932: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f5w4l exposes endpoints map[pod1:[100] pod2:[101]] (2.023811967s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-f5w4l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f5w4l to expose endpoints map[pod2:[101]]
Feb 26 03:16:40.955: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f5w4l exposes endpoints map[pod2:[101]] (1.017896961s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-f5w4l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f5w4l to expose endpoints map[]
Feb 26 03:16:41.971: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f5w4l exposes endpoints map[] (1.005056985s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:16:41.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-f5w4l" for this suite.
Feb 26 03:17:03.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:17:04.159: INFO: namespace: e2e-tests-services-f5w4l, resource: bindings, ignored listing per whitelist
Feb 26 03:17:04.173: INFO: namespace e2e-tests-services-f5w4l deletion completed in 22.187071452s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.774 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:17:04.175: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 26 03:17:07.167: INFO: Successfully updated pod "annotationupdatefdaa1aaa-3974-11e9-ac13-320deb251a37"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:17:11.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-46nb6" for this suite.
Feb 26 03:17:33.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:17:33.354: INFO: namespace: e2e-tests-downward-api-46nb6, resource: bindings, ignored listing per whitelist
Feb 26 03:17:33.364: INFO: namespace e2e-tests-downward-api-46nb6 deletion completed in 22.175419759s

• [SLOW TEST:29.189 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:17:33.364: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 26 03:17:33.808: INFO: namespace e2e-tests-kubectl-jnnk4
Feb 26 03:17:33.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-jnnk4'
Feb 26 03:17:34.024: INFO: stderr: ""
Feb 26 03:17:34.024: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 26 03:17:35.029: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:17:35.029: INFO: Found 0 / 1
Feb 26 03:17:36.029: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:17:36.029: INFO: Found 1 / 1
Feb 26 03:17:36.029: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 26 03:17:36.033: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 03:17:36.033: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 26 03:17:36.033: INFO: wait on redis-master startup in e2e-tests-kubectl-jnnk4 
Feb 26 03:17:36.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 logs redis-master-bbjsz redis-master --namespace=e2e-tests-kubectl-jnnk4'
Feb 26 03:17:36.148: INFO: stderr: ""
Feb 26 03:17:36.148: INFO: stdout: "1:M 26 Feb 03:17:35.090 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 26 Feb 03:17:35.091 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 26 Feb 03:17:35.091 # Server started, Redis version 3.2.12\n1:M 26 Feb 03:17:35.091 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 26 Feb 03:17:35.091 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 26 03:17:36.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-jnnk4'
Feb 26 03:17:36.274: INFO: stderr: ""
Feb 26 03:17:36.274: INFO: stdout: "service/rm2 exposed\n"
Feb 26 03:17:36.277: INFO: Service rm2 in namespace e2e-tests-kubectl-jnnk4 found.
STEP: exposing service
Feb 26 03:17:38.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-jnnk4'
Feb 26 03:17:38.402: INFO: stderr: ""
Feb 26 03:17:38.402: INFO: stdout: "service/rm3 exposed\n"
Feb 26 03:17:38.406: INFO: Service rm3 in namespace e2e-tests-kubectl-jnnk4 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:17:40.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jnnk4" for this suite.
Feb 26 03:18:02.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:18:02.486: INFO: namespace: e2e-tests-kubectl-jnnk4, resource: bindings, ignored listing per whitelist
Feb 26 03:18:02.619: INFO: namespace e2e-tests-kubectl-jnnk4 deletion completed in 22.204005754s

• [SLOW TEST:29.254 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:18:02.619: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 26 03:18:03.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:03.287: INFO: stderr: ""
Feb 26 03:18:03.287: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 26 03:18:03.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:03.401: INFO: stderr: ""
Feb 26 03:18:03.401: INFO: stdout: "update-demo-nautilus-4xnr9 update-demo-nautilus-9g8ms "
Feb 26 03:18:03.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:03.503: INFO: stderr: ""
Feb 26 03:18:03.503: INFO: stdout: ""
Feb 26 03:18:03.503: INFO: update-demo-nautilus-4xnr9 is created but not running
Feb 26 03:18:08.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:08.623: INFO: stderr: ""
Feb 26 03:18:08.623: INFO: stdout: "update-demo-nautilus-4xnr9 update-demo-nautilus-9g8ms "
Feb 26 03:18:08.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:08.712: INFO: stderr: ""
Feb 26 03:18:08.712: INFO: stdout: "true"
Feb 26 03:18:08.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:08.804: INFO: stderr: ""
Feb 26 03:18:08.804: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:18:08.804: INFO: validating pod update-demo-nautilus-4xnr9
Feb 26 03:18:08.810: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:18:08.811: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:18:08.811: INFO: update-demo-nautilus-4xnr9 is verified up and running
Feb 26 03:18:08.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-9g8ms -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:08.906: INFO: stderr: ""
Feb 26 03:18:08.906: INFO: stdout: "true"
Feb 26 03:18:08.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-9g8ms -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:09.009: INFO: stderr: ""
Feb 26 03:18:09.009: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:18:09.009: INFO: validating pod update-demo-nautilus-9g8ms
Feb 26 03:18:09.014: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:18:09.014: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:18:09.014: INFO: update-demo-nautilus-9g8ms is verified up and running
STEP: scaling down the replication controller
Feb 26 03:18:09.016: INFO: scanned /root for discovery docs: <nil>
Feb 26 03:18:09.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:10.150: INFO: stderr: ""
Feb 26 03:18:10.150: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 26 03:18:10.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:10.269: INFO: stderr: ""
Feb 26 03:18:10.269: INFO: stdout: "update-demo-nautilus-4xnr9 update-demo-nautilus-9g8ms "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 26 03:18:15.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:15.556: INFO: stderr: ""
Feb 26 03:18:15.556: INFO: stdout: "update-demo-nautilus-4xnr9 "
Feb 26 03:18:15.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:15.654: INFO: stderr: ""
Feb 26 03:18:15.654: INFO: stdout: "true"
Feb 26 03:18:15.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:15.746: INFO: stderr: ""
Feb 26 03:18:15.746: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:18:15.746: INFO: validating pod update-demo-nautilus-4xnr9
Feb 26 03:18:15.757: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:18:15.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:18:15.757: INFO: update-demo-nautilus-4xnr9 is verified up and running
STEP: scaling up the replication controller
Feb 26 03:18:15.759: INFO: scanned /root for discovery docs: <nil>
Feb 26 03:18:15.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:16.874: INFO: stderr: ""
Feb 26 03:18:16.874: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 26 03:18:16.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:16.973: INFO: stderr: ""
Feb 26 03:18:16.973: INFO: stdout: "update-demo-nautilus-4xnr9 update-demo-nautilus-fz5w8 "
Feb 26 03:18:16.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:17.085: INFO: stderr: ""
Feb 26 03:18:17.085: INFO: stdout: "true"
Feb 26 03:18:17.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-4xnr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:17.174: INFO: stderr: ""
Feb 26 03:18:17.174: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:18:17.174: INFO: validating pod update-demo-nautilus-4xnr9
Feb 26 03:18:17.178: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:18:17.178: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:18:17.178: INFO: update-demo-nautilus-4xnr9 is verified up and running
Feb 26 03:18:17.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-fz5w8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:17.274: INFO: stderr: ""
Feb 26 03:18:17.274: INFO: stdout: "true"
Feb 26 03:18:17.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-fz5w8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:17.374: INFO: stderr: ""
Feb 26 03:18:17.374: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:18:17.374: INFO: validating pod update-demo-nautilus-fz5w8
Feb 26 03:18:17.378: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:18:17.378: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:18:17.378: INFO: update-demo-nautilus-fz5w8 is verified up and running
STEP: using delete to clean up resources
Feb 26 03:18:17.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:17.498: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 03:18:17.498: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 26 03:18:17.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zg4hn'
Feb 26 03:18:17.603: INFO: stderr: "No resources found.\n"
Feb 26 03:18:17.603: INFO: stdout: ""
Feb 26 03:18:17.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zg4hn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 26 03:18:17.726: INFO: stderr: ""
Feb 26 03:18:17.726: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:18:17.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zg4hn" for this suite.
Feb 26 03:18:39.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:18:39.777: INFO: namespace: e2e-tests-kubectl-zg4hn, resource: bindings, ignored listing per whitelist
Feb 26 03:18:39.893: INFO: namespace e2e-tests-kubectl-zg4hn deletion completed in 22.155213039s

• [SLOW TEST:37.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:18:39.895: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:18:40.371: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-hrdwc" to be "success or failure"
Feb 26 03:18:40.379: INFO: Pod "downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 7.721431ms
Feb 26 03:18:42.383: INFO: Pod "downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.011533359s
Feb 26 03:18:44.386: INFO: Pod "downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014726366s
STEP: Saw pod success
Feb 26 03:18:44.386: INFO: Pod "downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:18:44.389: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:18:44.401: INFO: Waiting for pod downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37 to disappear
Feb 26 03:18:44.407: INFO: Pod downwardapi-volume-36b93bbc-3975-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:18:44.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hrdwc" for this suite.
Feb 26 03:18:50.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:18:50.532: INFO: namespace: e2e-tests-projected-hrdwc, resource: bindings, ignored listing per whitelist
Feb 26 03:18:50.613: INFO: namespace e2e-tests-projected-hrdwc deletion completed in 6.20107397s

• [SLOW TEST:10.718 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:18:50.615: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-fnrjj
Feb 26 03:18:53.100: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-fnrjj
STEP: checking the pod's current state and verifying that restartCount is present
Feb 26 03:18:53.103: INFO: Initial restart count of pod liveness-exec is 0
Feb 26 03:19:41.182: INFO: Restart count of pod e2e-tests-container-probe-fnrjj/liveness-exec is now 1 (48.078520116s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:19:41.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fnrjj" for this suite.
Feb 26 03:19:47.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:19:47.291: INFO: namespace: e2e-tests-container-probe-fnrjj, resource: bindings, ignored listing per whitelist
Feb 26 03:19:47.372: INFO: namespace e2e-tests-container-probe-fnrjj deletion completed in 6.174892945s

• [SLOW TEST:56.757 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:19:47.372: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:19:47.840: INFO: (0) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.240069ms)
Feb 26 03:19:47.844: INFO: (1) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.849658ms)
Feb 26 03:19:47.854: INFO: (2) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 9.868322ms)
Feb 26 03:19:47.858: INFO: (3) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.322661ms)
Feb 26 03:19:47.862: INFO: (4) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.709657ms)
Feb 26 03:19:47.866: INFO: (5) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.608012ms)
Feb 26 03:19:47.870: INFO: (6) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.847744ms)
Feb 26 03:19:47.873: INFO: (7) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.353117ms)
Feb 26 03:19:47.878: INFO: (8) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.526548ms)
Feb 26 03:19:47.882: INFO: (9) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.861121ms)
Feb 26 03:19:47.887: INFO: (10) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.206507ms)
Feb 26 03:19:47.891: INFO: (11) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.223813ms)
Feb 26 03:19:47.895: INFO: (12) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.65337ms)
Feb 26 03:19:47.900: INFO: (13) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.263582ms)
Feb 26 03:19:47.916: INFO: (14) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 15.9598ms)
Feb 26 03:19:47.921: INFO: (15) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.697983ms)
Feb 26 03:19:47.941: INFO: (16) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 19.702893ms)
Feb 26 03:19:47.961: INFO: (17) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 20.537561ms)
Feb 26 03:19:47.965: INFO: (18) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.80857ms)
Feb 26 03:19:47.972: INFO: (19) /api/v1/nodes/darren-16001/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 6.699107ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:19:47.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bkqjj" for this suite.
Feb 26 03:19:53.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:19:54.019: INFO: namespace: e2e-tests-proxy-bkqjj, resource: bindings, ignored listing per whitelist
Feb 26 03:19:54.124: INFO: namespace e2e-tests-proxy-bkqjj deletion completed in 6.14687803s

• [SLOW TEST:6.752 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:19:54.125: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-62f5461d-3975-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:19:54.591: INFO: Waiting up to 5m0s for pod "pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-f8rlq" to be "success or failure"
Feb 26 03:19:54.608: INFO: Pod "pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 16.369198ms
Feb 26 03:19:56.611: INFO: Pod "pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.019664259s
Feb 26 03:19:58.614: INFO: Pod "pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023073788s
STEP: Saw pod success
Feb 26 03:19:58.614: INFO: Pod "pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:19:58.617: INFO: Trying to get logs from node darren-2745 pod pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 03:19:58.647: INFO: Waiting for pod pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37 to disappear
Feb 26 03:19:58.654: INFO: Pod pod-configmaps-62f6db3d-3975-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:19:58.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f8rlq" for this suite.
Feb 26 03:20:04.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:20:04.763: INFO: namespace: e2e-tests-configmap-f8rlq, resource: bindings, ignored listing per whitelist
Feb 26 03:20:04.849: INFO: namespace e2e-tests-configmap-f8rlq deletion completed in 6.188781844s

• [SLOW TEST:10.724 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:20:04.850: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:21:05.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-86ttw" for this suite.
Feb 26 03:21:27.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:21:27.397: INFO: namespace: e2e-tests-container-probe-86ttw, resource: bindings, ignored listing per whitelist
Feb 26 03:21:27.547: INFO: namespace e2e-tests-container-probe-86ttw deletion completed in 22.205291121s

• [SLOW TEST:82.698 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:21:27.548: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:21:28.012: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-5vrgp" to be "success or failure"
Feb 26 03:21:28.015: INFO: Pod "downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.716038ms
Feb 26 03:21:30.018: INFO: Pod "downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006062487s
STEP: Saw pod success
Feb 26 03:21:30.018: INFO: Pod "downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:21:30.020: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:21:30.034: INFO: Waiting for pod downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37 to disappear
Feb 26 03:21:30.040: INFO: Pod downwardapi-volume-9aa5084b-3975-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:21:30.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vrgp" for this suite.
Feb 26 03:21:36.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:21:36.192: INFO: namespace: e2e-tests-projected-5vrgp, resource: bindings, ignored listing per whitelist
Feb 26 03:21:36.206: INFO: namespace e2e-tests-projected-5vrgp deletion completed in 6.160619257s

• [SLOW TEST:8.659 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:21:36.208: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0226 03:21:37.222312      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 26 03:21:37.222: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:21:37.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2hhmn" for this suite.
Feb 26 03:21:43.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:21:43.315: INFO: namespace: e2e-tests-gc-2hhmn, resource: bindings, ignored listing per whitelist
Feb 26 03:21:43.396: INFO: namespace e2e-tests-gc-2hhmn deletion completed in 6.169208444s

• [SLOW TEST:7.188 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:21:43.396: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 26 03:21:43.856: INFO: Waiting up to 5m0s for pod "pod-a416ee4e-3975-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-89lv6" to be "success or failure"
Feb 26 03:21:43.859: INFO: Pod "pod-a416ee4e-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.710554ms
Feb 26 03:21:45.862: INFO: Pod "pod-a416ee4e-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005938877s
Feb 26 03:21:47.865: INFO: Pod "pod-a416ee4e-3975-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009239891s
STEP: Saw pod success
Feb 26 03:21:47.865: INFO: Pod "pod-a416ee4e-3975-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:21:47.868: INFO: Trying to get logs from node darren-2745 pod pod-a416ee4e-3975-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:21:47.881: INFO: Waiting for pod pod-a416ee4e-3975-11e9-ac13-320deb251a37 to disappear
Feb 26 03:21:47.886: INFO: Pod pod-a416ee4e-3975-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:21:47.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-89lv6" for this suite.
Feb 26 03:21:53.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:21:54.007: INFO: namespace: e2e-tests-emptydir-89lv6, resource: bindings, ignored listing per whitelist
Feb 26 03:21:54.082: INFO: namespace e2e-tests-emptydir-89lv6 deletion completed in 6.191492517s

• [SLOW TEST:10.687 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:21:54.083: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 26 03:21:55.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5890,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 26 03:21:55.357: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5890,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 26 03:22:05.539: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5894,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 26 03:22:05.557: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5894,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 26 03:22:15.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5898,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 26 03:22:15.757: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5898,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 26 03:22:25.940: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5902,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 26 03:22:25.957: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-a,UID:aad7d1f6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5902,Generation:0,CreationTimestamp:2019-02-26 03:21:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 26 03:22:36.149: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-b,UID:c3287dc6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5906,Generation:0,CreationTimestamp:2019-02-26 03:22:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 26 03:22:36.157: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-b,UID:c3287dc6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5906,Generation:0,CreationTimestamp:2019-02-26 03:22:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 26 03:22:46.349: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-b,UID:c3287dc6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5910,Generation:0,CreationTimestamp:2019-02-26 03:22:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 26 03:22:46.357: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fhnkh,SelfLink:/api/v1/namespaces/e2e-tests-watch-fhnkh/configmaps/e2e-watch-test-configmap-b,UID:c3287dc6-3975-11e9-a404-c690ac8d27cb,ResourceVersion:5910,Generation:0,CreationTimestamp:2019-02-26 03:22:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:22:56.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fhnkh" for this suite.
Feb 26 03:23:02.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:23:02.556: INFO: namespace: e2e-tests-watch-fhnkh, resource: bindings, ignored listing per whitelist
Feb 26 03:23:02.576: INFO: namespace e2e-tests-watch-fhnkh deletion completed in 6.213272809s

• [SLOW TEST:68.493 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:23:02.577: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:23:03.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9qwd2" for this suite.
Feb 26 03:23:09.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:23:09.148: INFO: namespace: e2e-tests-services-9qwd2, resource: bindings, ignored listing per whitelist
Feb 26 03:23:09.245: INFO: namespace e2e-tests-services-9qwd2 deletion completed in 6.185530413s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.669 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:23:09.246: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:23:09.707: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-h5qb2" to be "success or failure"
Feb 26 03:23:09.716: INFO: Pod "downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 8.740051ms
Feb 26 03:23:11.719: INFO: Pod "downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011965848s
STEP: Saw pod success
Feb 26 03:23:11.719: INFO: Pod "downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:23:11.722: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:23:11.739: INFO: Waiting for pod downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37 to disappear
Feb 26 03:23:11.742: INFO: Pod downwardapi-volume-d742224c-3975-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:23:11.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h5qb2" for this suite.
Feb 26 03:23:17.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:23:17.949: INFO: namespace: e2e-tests-projected-h5qb2, resource: bindings, ignored listing per whitelist
Feb 26 03:23:17.957: INFO: namespace e2e-tests-projected-h5qb2 deletion completed in 6.209594107s

• [SLOW TEST:8.711 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:23:17.957: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:23:20.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jxzq9" for this suite.
Feb 26 03:23:58.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:23:58.514: INFO: namespace: e2e-tests-kubelet-test-jxzq9, resource: bindings, ignored listing per whitelist
Feb 26 03:23:58.596: INFO: namespace e2e-tests-kubelet-test-jxzq9 deletion completed in 38.161604056s

• [SLOW TEST:40.639 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:23:58.597: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:23:59.073: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-v6542" to be "success or failure"
Feb 26 03:23:59.075: INFO: Pod "downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.344934ms
Feb 26 03:24:01.078: INFO: Pod "downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005830456s
Feb 26 03:24:03.082: INFO: Pod "downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008972292s
STEP: Saw pod success
Feb 26 03:24:03.082: INFO: Pod "downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:24:03.090: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:24:03.105: INFO: Waiting for pod downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37 to disappear
Feb 26 03:24:03.110: INFO: Pod downwardapi-volume-f4af504a-3975-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:24:03.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v6542" for this suite.
Feb 26 03:24:09.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:24:09.185: INFO: namespace: e2e-tests-projected-v6542, resource: bindings, ignored listing per whitelist
Feb 26 03:24:09.260: INFO: namespace e2e-tests-projected-v6542 deletion completed in 6.145885018s

• [SLOW TEST:10.663 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:24:09.261: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jfz29
Feb 26 03:24:13.723: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jfz29
STEP: checking the pod's current state and verifying that restartCount is present
Feb 26 03:24:13.725: INFO: Initial restart count of pod liveness-http is 0
Feb 26 03:24:29.753: INFO: Restart count of pod e2e-tests-container-probe-jfz29/liveness-http is now 1 (16.027796245s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:24:29.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jfz29" for this suite.
Feb 26 03:24:35.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:24:35.852: INFO: namespace: e2e-tests-container-probe-jfz29, resource: bindings, ignored listing per whitelist
Feb 26 03:24:35.938: INFO: namespace e2e-tests-container-probe-jfz29 deletion completed in 6.173700694s

• [SLOW TEST:26.677 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:24:35.939: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 26 03:24:36.406: INFO: Waiting up to 5m0s for pod "downward-api-0aef5d65-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-p6dmp" to be "success or failure"
Feb 26 03:24:36.408: INFO: Pod "downward-api-0aef5d65-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081391ms
Feb 26 03:24:38.412: INFO: Pod "downward-api-0aef5d65-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005603547s
STEP: Saw pod success
Feb 26 03:24:38.412: INFO: Pod "downward-api-0aef5d65-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:24:38.414: INFO: Trying to get logs from node darren-2745 pod downward-api-0aef5d65-3976-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 03:24:38.428: INFO: Waiting for pod downward-api-0aef5d65-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:24:38.433: INFO: Pod downward-api-0aef5d65-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:24:38.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p6dmp" for this suite.
Feb 26 03:24:44.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:24:44.592: INFO: namespace: e2e-tests-downward-api-p6dmp, resource: bindings, ignored listing per whitelist
Feb 26 03:24:44.612: INFO: namespace e2e-tests-downward-api-p6dmp deletion completed in 6.171166175s

• [SLOW TEST:8.673 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:24:44.613: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 26 03:24:45.071: INFO: Waiting up to 5m0s for pod "pod-101a0d1b-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-mkhxj" to be "success or failure"
Feb 26 03:24:45.073: INFO: Pod "pod-101a0d1b-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003051ms
Feb 26 03:24:47.076: INFO: Pod "pod-101a0d1b-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005222083s
STEP: Saw pod success
Feb 26 03:24:47.076: INFO: Pod "pod-101a0d1b-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:24:47.079: INFO: Trying to get logs from node darren-2745 pod pod-101a0d1b-3976-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:24:47.092: INFO: Waiting for pod pod-101a0d1b-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:24:47.096: INFO: Pod pod-101a0d1b-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:24:47.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mkhxj" for this suite.
Feb 26 03:24:53.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:24:53.285: INFO: namespace: e2e-tests-emptydir-mkhxj, resource: bindings, ignored listing per whitelist
Feb 26 03:24:53.292: INFO: namespace e2e-tests-emptydir-mkhxj deletion completed in 6.19055161s

• [SLOW TEST:8.680 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:24:53.293: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 26 03:24:53.751: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-481393766 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:24:53.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zs7nw" for this suite.
Feb 26 03:24:59.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:24:59.939: INFO: namespace: e2e-tests-kubectl-zs7nw, resource: bindings, ignored listing per whitelist
Feb 26 03:25:00.025: INFO: namespace e2e-tests-kubectl-zs7nw deletion completed in 6.172924221s

• [SLOW TEST:6.732 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:25:00.026: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:25:00.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-5krrv" to be "success or failure"
Feb 26 03:25:00.510: INFO: Pod "downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03579ms
Feb 26 03:25:02.513: INFO: Pod "downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005478704s
STEP: Saw pod success
Feb 26 03:25:02.513: INFO: Pod "downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:25:02.516: INFO: Trying to get logs from node darren-16001 pod downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:25:02.541: INFO: Waiting for pod downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:25:02.552: INFO: Pod downwardapi-volume-194cea44-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:25:02.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5krrv" for this suite.
Feb 26 03:25:08.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:25:08.771: INFO: namespace: e2e-tests-downward-api-5krrv, resource: bindings, ignored listing per whitelist
Feb 26 03:25:08.777: INFO: namespace e2e-tests-downward-api-5krrv deletion completed in 6.218886454s

• [SLOW TEST:8.752 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:25:08.777: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 26 03:25:16.260: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:25:17.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-cc9vv" for this suite.
Feb 26 03:25:39.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:25:39.353: INFO: namespace: e2e-tests-replicaset-cc9vv, resource: bindings, ignored listing per whitelist
Feb 26 03:25:39.449: INFO: namespace e2e-tests-replicaset-cc9vv deletion completed in 22.167239324s

• [SLOW TEST:30.671 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:25:39.449: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-30c96963-3976-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:25:39.913: INFO: Waiting up to 5m0s for pod "pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-8cm8w" to be "success or failure"
Feb 26 03:25:39.915: INFO: Pod "pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.233837ms
Feb 26 03:25:41.919: INFO: Pod "pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005961602s
STEP: Saw pod success
Feb 26 03:25:41.919: INFO: Pod "pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:25:41.922: INFO: Trying to get logs from node darren-2745 pod pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:25:41.940: INFO: Waiting for pod pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:25:41.944: INFO: Pod pod-secrets-30cb0483-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:25:41.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8cm8w" for this suite.
Feb 26 03:25:47.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:25:48.053: INFO: namespace: e2e-tests-secrets-8cm8w, resource: bindings, ignored listing per whitelist
Feb 26 03:25:48.105: INFO: namespace e2e-tests-secrets-8cm8w deletion completed in 6.156517615s

• [SLOW TEST:8.656 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:25:48.106: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:25:48.561: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-znvkt" to be "success or failure"
Feb 26 03:25:48.563: INFO: Pod "downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039019ms
Feb 26 03:25:50.566: INFO: Pod "downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005174225s
STEP: Saw pod success
Feb 26 03:25:50.566: INFO: Pod "downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:25:50.569: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:25:50.585: INFO: Waiting for pod downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:25:50.589: INFO: Pod downwardapi-volume-35f2c9d7-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:25:50.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-znvkt" for this suite.
Feb 26 03:25:56.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:25:56.675: INFO: namespace: e2e-tests-projected-znvkt, resource: bindings, ignored listing per whitelist
Feb 26 03:25:56.765: INFO: namespace e2e-tests-projected-znvkt deletion completed in 6.168365864s

• [SLOW TEST:8.659 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:25:56.765: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 26 03:25:57.244: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:26:00.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tf6f4" for this suite.
Feb 26 03:26:06.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:26:06.751: INFO: namespace: e2e-tests-init-container-tf6f4, resource: bindings, ignored listing per whitelist
Feb 26 03:26:06.823: INFO: namespace e2e-tests-init-container-tf6f4 deletion completed in 6.155173073s

• [SLOW TEST:10.058 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:26:06.823: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-411a794f-3976-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:26:07.286: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-49dcq" to be "success or failure"
Feb 26 03:26:07.288: INFO: Pod "pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.190262ms
Feb 26 03:26:09.292: INFO: Pod "pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005471593s
STEP: Saw pod success
Feb 26 03:26:09.292: INFO: Pod "pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:26:09.295: INFO: Trying to get logs from node darren-16001 pod pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:26:09.317: INFO: Waiting for pod pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:26:09.330: INFO: Pod pod-projected-secrets-411bcd8f-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:26:09.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-49dcq" for this suite.
Feb 26 03:26:15.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:26:15.448: INFO: namespace: e2e-tests-projected-49dcq, resource: bindings, ignored listing per whitelist
Feb 26 03:26:15.565: INFO: namespace e2e-tests-projected-49dcq deletion completed in 6.228900261s

• [SLOW TEST:8.742 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:26:15.566: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:26:16.070: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 26 03:26:16.092: INFO: Number of nodes with available pods: 0
Feb 26 03:26:16.092: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:26:17.106: INFO: Number of nodes with available pods: 0
Feb 26 03:26:17.106: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:26:18.103: INFO: Number of nodes with available pods: 1
Feb 26 03:26:18.103: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 03:26:19.102: INFO: Number of nodes with available pods: 2
Feb 26 03:26:19.102: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 26 03:26:19.125: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:19.125: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:20.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:20.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:21.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:21.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:22.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:22.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:23.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:23.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:24.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:24.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:25.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:25.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:26.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:26.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:27.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:27.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:28.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:28.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:29.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:29.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:30.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:30.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:31.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:31.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:32.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:32.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:33.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:33.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:34.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:34.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:35.133: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:35.133: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:36.133: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:36.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:37.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:37.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:38.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:38.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:39.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:39.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:40.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:40.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:41.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:41.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:42.136: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:42.136: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:43.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:43.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:44.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:44.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:45.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:45.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:46.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:46.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:47.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:47.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:48.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:48.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:49.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:49.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:50.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:50.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:51.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:51.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:52.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:52.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:52.135: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:53.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:53.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:53.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:54.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:54.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:54.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:55.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:55.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:55.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:56.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:56.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:56.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:57.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:57.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:57.135: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:58.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:58.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:58.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:26:59.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:59.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:26:59.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:27:00.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:00.135: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:00.135: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:27:01.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:01.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:01.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:27:02.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:02.134: INFO: Wrong image for pod: daemon-set-h6bz7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:02.134: INFO: Pod daemon-set-h6bz7 is not available
Feb 26 03:27:03.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:03.135: INFO: Pod daemon-set-8x9mp is not available
Feb 26 03:27:04.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:04.135: INFO: Pod daemon-set-8x9mp is not available
Feb 26 03:27:05.136: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:06.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:07.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:08.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:09.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:10.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:11.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:12.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:13.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:14.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:15.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:16.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:17.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:18.133: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:19.133: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:20.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:21.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:22.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:23.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:24.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:25.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:26.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:27.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:28.133: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:29.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:30.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:31.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:32.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:33.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:34.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:35.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:36.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:36.135: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:37.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:37.135: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:38.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:38.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:39.133: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:39.133: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:40.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:40.135: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:41.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:41.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:42.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:42.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:43.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:43.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:44.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:44.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:45.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:45.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:46.134: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:46.134: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:47.135: INFO: Wrong image for pod: daemon-set-2r9m4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 26 03:27:47.135: INFO: Pod daemon-set-2r9m4 is not available
Feb 26 03:27:48.134: INFO: Pod daemon-set-xq7cb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 26 03:27:48.157: INFO: Number of nodes with available pods: 1
Feb 26 03:27:48.157: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 03:27:49.166: INFO: Number of nodes with available pods: 2
Feb 26 03:27:49.166: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-8cfns, will wait for the garbage collector to delete the pods
Feb 26 03:27:49.246: INFO: Deleting DaemonSet.extensions daemon-set took: 9.493694ms
Feb 26 03:27:49.446: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.271217ms
Feb 26 03:27:57.651: INFO: Number of nodes with available pods: 0
Feb 26 03:27:57.651: INFO: Number of running nodes: 0, number of available pods: 0
Feb 26 03:27:57.655: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8cfns/daemonsets","resourceVersion":"6453"},"items":null}

Feb 26 03:27:57.658: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8cfns/pods","resourceVersion":"6453"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:27:57.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8cfns" for this suite.
Feb 26 03:28:03.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:28:03.781: INFO: namespace: e2e-tests-daemonsets-8cfns, resource: bindings, ignored listing per whitelist
Feb 26 03:28:03.916: INFO: namespace e2e-tests-daemonsets-8cfns deletion completed in 6.243216293s

• [SLOW TEST:108.351 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:28:03.918: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:28:04.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-ffgrq" to be "success or failure"
Feb 26 03:28:04.404: INFO: Pod "downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.952016ms
Feb 26 03:28:06.408: INFO: Pod "downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006332451s
STEP: Saw pod success
Feb 26 03:28:06.408: INFO: Pod "downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:28:06.411: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:28:06.430: INFO: Waiting for pod downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:28:06.435: INFO: Pod downwardapi-volume-86e99560-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:28:06.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ffgrq" for this suite.
Feb 26 03:28:12.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:28:12.584: INFO: namespace: e2e-tests-downward-api-ffgrq, resource: bindings, ignored listing per whitelist
Feb 26 03:28:12.621: INFO: namespace e2e-tests-downward-api-ffgrq deletion completed in 6.178105463s

• [SLOW TEST:8.703 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:28:12.621: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 26 03:28:13.080: INFO: Waiting up to 5m0s for pod "pod-8c15c07d-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-7xtlf" to be "success or failure"
Feb 26 03:28:13.082: INFO: Pod "pod-8c15c07d-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123775ms
Feb 26 03:28:15.085: INFO: Pod "pod-8c15c07d-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005487341s
STEP: Saw pod success
Feb 26 03:28:15.085: INFO: Pod "pod-8c15c07d-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:28:15.088: INFO: Trying to get logs from node darren-16001 pod pod-8c15c07d-3976-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:28:15.107: INFO: Waiting for pod pod-8c15c07d-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:28:15.111: INFO: Pod pod-8c15c07d-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:28:15.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7xtlf" for this suite.
Feb 26 03:28:21.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:28:21.187: INFO: namespace: e2e-tests-emptydir-7xtlf, resource: bindings, ignored listing per whitelist
Feb 26 03:28:21.279: INFO: namespace e2e-tests-emptydir-7xtlf deletion completed in 6.162807928s

• [SLOW TEST:8.658 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:28:21.279: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-hp2s6
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-hp2s6
STEP: Deleting pre-stop pod
Feb 26 03:28:32.814: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:28:32.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-hp2s6" for this suite.
Feb 26 03:29:14.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:29:14.961: INFO: namespace: e2e-tests-prestop-hp2s6, resource: bindings, ignored listing per whitelist
Feb 26 03:29:15.040: INFO: namespace e2e-tests-prestop-hp2s6 deletion completed in 42.215900945s

• [SLOW TEST:53.761 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:29:15.040: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:29:15.517: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-t2r59" to be "success or failure"
Feb 26 03:29:15.520: INFO: Pod "downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.814435ms
Feb 26 03:29:17.523: INFO: Pod "downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00603623s
STEP: Saw pod success
Feb 26 03:29:17.523: INFO: Pod "downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:29:17.527: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:29:17.547: INFO: Waiting for pod downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37 to disappear
Feb 26 03:29:17.552: INFO: Pod downwardapi-volume-b14b0556-3976-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:29:17.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t2r59" for this suite.
Feb 26 03:29:23.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:29:23.721: INFO: namespace: e2e-tests-downward-api-t2r59, resource: bindings, ignored listing per whitelist
Feb 26 03:29:23.731: INFO: namespace e2e-tests-downward-api-t2r59 deletion completed in 6.172857823s

• [SLOW TEST:8.691 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:29:23.731: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:29:24.219: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b67f0be3-3976-11e9-a404-c690ac8d27cb", Controller:(*bool)(0xc0020b75b6), BlockOwnerDeletion:(*bool)(0xc0020b75b7)}}
Feb 26 03:29:24.230: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b67e0bbf-3976-11e9-a404-c690ac8d27cb", Controller:(*bool)(0xc0024c1606), BlockOwnerDeletion:(*bool)(0xc0024c1607)}}
Feb 26 03:29:24.239: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b67e8b04-3976-11e9-a404-c690ac8d27cb", Controller:(*bool)(0xc0020b7796), BlockOwnerDeletion:(*bool)(0xc0020b7797)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:29:29.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bvs2h" for this suite.
Feb 26 03:29:35.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:29:35.391: INFO: namespace: e2e-tests-gc-bvs2h, resource: bindings, ignored listing per whitelist
Feb 26 03:29:35.440: INFO: namespace e2e-tests-gc-bvs2h deletion completed in 6.185997416s

• [SLOW TEST:11.709 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:29:35.440: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-bd767f6a-3976-11e9-ac13-320deb251a37
STEP: Creating secret with name s-test-opt-upd-bd767fb7-3976-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-bd767f6a-3976-11e9-ac13-320deb251a37
STEP: Updating secret s-test-opt-upd-bd767fb7-3976-11e9-ac13-320deb251a37
STEP: Creating secret with name s-test-opt-create-bd767fcf-3976-11e9-ac13-320deb251a37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:30:56.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b95lv" for this suite.
Feb 26 03:31:18.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:31:18.326: INFO: namespace: e2e-tests-secrets-b95lv, resource: bindings, ignored listing per whitelist
Feb 26 03:31:18.385: INFO: namespace e2e-tests-secrets-b95lv deletion completed in 22.157884747s

• [SLOW TEST:102.944 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:31:18.385: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-fad190bd-3976-11e9-ac13-320deb251a37
STEP: Creating configMap with name cm-test-opt-upd-fad1910b-3976-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fad190bd-3976-11e9-ac13-320deb251a37
STEP: Updating configmap cm-test-opt-upd-fad1910b-3976-11e9-ac13-320deb251a37
STEP: Creating configMap with name cm-test-opt-create-fad19128-3976-11e9-ac13-320deb251a37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:31:22.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dgqdf" for this suite.
Feb 26 03:31:44.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:31:45.083: INFO: namespace: e2e-tests-configmap-dgqdf, resource: bindings, ignored listing per whitelist
Feb 26 03:31:45.108: INFO: namespace e2e-tests-configmap-dgqdf deletion completed in 22.178079672s

• [SLOW TEST:26.723 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:31:45.110: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:31:45.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-jmwsz" to be "success or failure"
Feb 26 03:31:45.595: INFO: Pod "downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.266075ms
Feb 26 03:31:47.599: INFO: Pod "downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006911932s
STEP: Saw pod success
Feb 26 03:31:47.599: INFO: Pod "downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:31:47.602: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:31:47.615: INFO: Waiting for pod downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:31:47.619: INFO: Pod downwardapi-volume-0abf2a5d-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:31:47.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jmwsz" for this suite.
Feb 26 03:31:53.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:31:53.762: INFO: namespace: e2e-tests-downward-api-jmwsz, resource: bindings, ignored listing per whitelist
Feb 26 03:31:53.874: INFO: namespace e2e-tests-downward-api-jmwsz deletion completed in 6.249223878s

• [SLOW TEST:8.764 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:31:53.874: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:31:54.348: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 26 03:31:59.354: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 26 03:31:59.354: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 26 03:32:01.357: INFO: Creating deployment "test-rollover-deployment"
Feb 26 03:32:01.376: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 26 03:32:03.383: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 26 03:32:03.391: INFO: Ensure that both replica sets have 1 created replica
Feb 26 03:32:03.398: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 26 03:32:03.435: INFO: Updating deployment test-rollover-deployment
Feb 26 03:32:03.435: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 26 03:32:05.457: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 26 03:32:05.465: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 26 03:32:05.475: INFO: all replica sets need to contain the pod-template-hash label
Feb 26 03:32:05.475: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748724, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 26 03:32:07.482: INFO: all replica sets need to contain the pod-template-hash label
Feb 26 03:32:07.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748724, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 26 03:32:09.483: INFO: all replica sets need to contain the pod-template-hash label
Feb 26 03:32:09.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748724, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 26 03:32:11.483: INFO: all replica sets need to contain the pod-template-hash label
Feb 26 03:32:11.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748724, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 26 03:32:13.482: INFO: all replica sets need to contain the pod-template-hash label
Feb 26 03:32:13.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748724, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686748721, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 26 03:32:15.485: INFO: 
Feb 26 03:32:15.485: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 26 03:32:15.498: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-82tvt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-82tvt/deployments/test-rollover-deployment,UID:1429813c-3977-11e9-a404-c690ac8d27cb,ResourceVersion:6895,Generation:2,CreationTimestamp:2019-02-26 03:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-26 03:32:01 +0000 UTC 2019-02-26 03:32:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-26 03:32:15 +0000 UTC 2019-02-26 03:32:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 26 03:32:15.504: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-82tvt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-82tvt/replicasets/test-rollover-deployment-6b7f9d6597,UID:15667d79-3977-11e9-a404-c690ac8d27cb,ResourceVersion:6886,Generation:2,CreationTimestamp:2019-02-26 03:32:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1429813c-3977-11e9-a404-c690ac8d27cb 0xc000d7e6e7 0xc000d7e6e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 26 03:32:15.504: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 26 03:32:15.504: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-82tvt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-82tvt/replicasets/test-rollover-controller,UID:0ffabc64-3977-11e9-a404-c690ac8d27cb,ResourceVersion:6894,Generation:2,CreationTimestamp:2019-02-26 03:31:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1429813c-3977-11e9-a404-c690ac8d27cb 0xc000d7e4df 0xc000d7e570}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:32:15.504: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-82tvt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-82tvt/replicasets/test-rollover-deployment-6586df867b,UID:142d3f87-3977-11e9-a404-c690ac8d27cb,ResourceVersion:6867,Generation:2,CreationTimestamp:2019-02-26 03:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1429813c-3977-11e9-a404-c690ac8d27cb 0xc000d7e627 0xc000d7e628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:32:15.509: INFO: Pod "test-rollover-deployment-6b7f9d6597-k8qh4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-k8qh4,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-82tvt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-82tvt/pods/test-rollover-deployment-6b7f9d6597-k8qh4,UID:156a58f4-3977-11e9-a404-c690ac8d27cb,ResourceVersion:6880,Generation:0,CreationTimestamp:2019-02-26 03:32:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 15667d79-3977-11e9-a404-c690ac8d27cb 0xc002148167 0xc002148168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dxvvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dxvvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-dxvvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002148370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002148390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:32:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:32:03 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.91,StartTime:2019-02-26 03:32:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-26 03:32:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://e6eb8677657f876b507796da614f7a09d10b6e4fe8bae6213d0a5237d9dc355d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:32:15.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-82tvt" for this suite.
Feb 26 03:32:21.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:32:21.614: INFO: namespace: e2e-tests-deployment-82tvt, resource: bindings, ignored listing per whitelist
Feb 26 03:32:21.691: INFO: namespace e2e-tests-deployment-82tvt deletion completed in 6.177909438s

• [SLOW TEST:27.817 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:32:21.693: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-208c45f8-3977-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:32:22.164: INFO: Waiting up to 5m0s for pod "pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-4xjp4" to be "success or failure"
Feb 26 03:32:22.172: INFO: Pod "pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 7.625299ms
Feb 26 03:32:24.174: INFO: Pod "pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010079499s
STEP: Saw pod success
Feb 26 03:32:24.175: INFO: Pod "pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:32:24.177: INFO: Trying to get logs from node darren-2745 pod pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 03:32:24.215: INFO: Waiting for pod pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:32:24.219: INFO: Pod pod-configmaps-208ddaac-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:32:24.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4xjp4" for this suite.
Feb 26 03:32:30.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:32:30.369: INFO: namespace: e2e-tests-configmap-4xjp4, resource: bindings, ignored listing per whitelist
Feb 26 03:32:30.419: INFO: namespace e2e-tests-configmap-4xjp4 deletion completed in 6.194134242s

• [SLOW TEST:8.726 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:32:30.419: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 26 03:32:30.890: INFO: Waiting up to 5m0s for pod "client-containers-25c0b736-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-containers-9flqj" to be "success or failure"
Feb 26 03:32:30.893: INFO: Pod "client-containers-25c0b736-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.757445ms
Feb 26 03:32:32.896: INFO: Pod "client-containers-25c0b736-3977-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005910903s
Feb 26 03:32:34.900: INFO: Pod "client-containers-25c0b736-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009611327s
STEP: Saw pod success
Feb 26 03:32:34.900: INFO: Pod "client-containers-25c0b736-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:32:34.903: INFO: Trying to get logs from node darren-16001 pod client-containers-25c0b736-3977-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:32:34.920: INFO: Waiting for pod client-containers-25c0b736-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:32:34.924: INFO: Pod client-containers-25c0b736-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:32:34.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9flqj" for this suite.
Feb 26 03:32:40.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:32:41.108: INFO: namespace: e2e-tests-containers-9flqj, resource: bindings, ignored listing per whitelist
Feb 26 03:32:41.156: INFO: namespace e2e-tests-containers-9flqj deletion completed in 6.225964354s

• [SLOW TEST:10.736 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:32:41.156: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 26 03:32:41.622: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:32:45.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6bs7t" for this suite.
Feb 26 03:33:07.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:33:07.404: INFO: namespace: e2e-tests-init-container-6bs7t, resource: bindings, ignored listing per whitelist
Feb 26 03:33:07.472: INFO: namespace e2e-tests-init-container-6bs7t deletion completed in 22.227624489s

• [SLOW TEST:26.316 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:33:07.473: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:33:11.972: INFO: Waiting up to 5m0s for pod "client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-pods-9szrd" to be "success or failure"
Feb 26 03:33:11.974: INFO: Pod "client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.236882ms
Feb 26 03:33:13.978: INFO: Pod "client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005533035s
Feb 26 03:33:15.981: INFO: Pod "client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008860599s
STEP: Saw pod success
Feb 26 03:33:15.981: INFO: Pod "client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:33:15.983: INFO: Trying to get logs from node darren-2745 pod client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37 container env3cont: <nil>
STEP: delete the pod
Feb 26 03:33:15.996: INFO: Waiting for pod client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:33:16.004: INFO: Pod client-envvars-3e3e3d8f-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:33:16.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9szrd" for this suite.
Feb 26 03:33:54.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:33:54.067: INFO: namespace: e2e-tests-pods-9szrd, resource: bindings, ignored listing per whitelist
Feb 26 03:33:54.189: INFO: namespace e2e-tests-pods-9szrd deletion completed in 38.180058084s

• [SLOW TEST:46.716 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:33:54.190: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-57b48116-3977-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:33:56.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4rfsm" for this suite.
Feb 26 03:34:18.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:34:18.866: INFO: namespace: e2e-tests-configmap-4rfsm, resource: bindings, ignored listing per whitelist
Feb 26 03:34:18.933: INFO: namespace e2e-tests-configmap-4rfsm deletion completed in 22.208246868s

• [SLOW TEST:24.744 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:34:18.934: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:34:40.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-r9nh7" for this suite.
Feb 26 03:34:46.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:34:46.616: INFO: namespace: e2e-tests-container-runtime-r9nh7, resource: bindings, ignored listing per whitelist
Feb 26 03:34:46.750: INFO: namespace e2e-tests-container-runtime-r9nh7 deletion completed in 6.181694538s

• [SLOW TEST:27.817 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:34:46.751: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 03:34:47.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sncxc'
Feb 26 03:34:47.606: INFO: stderr: ""
Feb 26 03:34:47.607: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 26 03:34:52.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sncxc -o json'
Feb 26 03:34:52.752: INFO: stderr: ""
Feb 26 03:34:52.752: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-26T03:34:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-sncxc\",\n        \"resourceVersion\": \"7235\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-sncxc/pods/e2e-test-nginx-pod\",\n        \"uid\": \"773ea529-3977-11e9-a404-c690ac8d27cb\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mw22r\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"darren-16001\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mw22r\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mw22r\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-26T03:34:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-26T03:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-26T03:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-26T03:34:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://6e1b875f80118e59f08c6625f41adc3147f0f7ec5a8c4695097b27c38161f7c5\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-26T03:34:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"134.209.63.30\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.42.0.96\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-26T03:34:47Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 26 03:34:52.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 replace -f - --namespace=e2e-tests-kubectl-sncxc'
Feb 26 03:34:52.939: INFO: stderr: ""
Feb 26 03:34:52.939: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 26 03:34:52.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sncxc'
Feb 26 03:34:55.655: INFO: stderr: ""
Feb 26 03:34:55.655: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:34:55.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sncxc" for this suite.
Feb 26 03:35:01.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:35:01.877: INFO: namespace: e2e-tests-kubectl-sncxc, resource: bindings, ignored listing per whitelist
Feb 26 03:35:01.931: INFO: namespace e2e-tests-kubectl-sncxc deletion completed in 6.262423867s

• [SLOW TEST:15.180 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:35:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:35:04.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-r8ftq" for this suite.
Feb 26 03:35:42.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:35:42.540: INFO: namespace: e2e-tests-kubelet-test-r8ftq, resource: bindings, ignored listing per whitelist
Feb 26 03:35:42.615: INFO: namespace e2e-tests-kubelet-test-r8ftq deletion completed in 38.166267462s

• [SLOW TEST:40.683 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:35:42.616: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-984f8b4d-3977-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:35:43.095: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-gljgl" to be "success or failure"
Feb 26 03:35:43.103: INFO: Pod "pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 7.086622ms
Feb 26 03:35:45.106: INFO: Pod "pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010533809s
STEP: Saw pod success
Feb 26 03:35:45.106: INFO: Pod "pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:35:45.109: INFO: Trying to get logs from node darren-16001 pod pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 03:35:45.139: INFO: Waiting for pod pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:35:45.153: INFO: Pod pod-projected-configmaps-98511f87-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:35:45.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gljgl" for this suite.
Feb 26 03:35:51.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:35:51.309: INFO: namespace: e2e-tests-projected-gljgl, resource: bindings, ignored listing per whitelist
Feb 26 03:35:51.381: INFO: namespace e2e-tests-projected-gljgl deletion completed in 6.218443564s

• [SLOW TEST:8.766 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:35:51.385: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:35:51.843: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-z4lxk" to be "success or failure"
Feb 26 03:35:51.845: INFO: Pod "downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.377815ms
Feb 26 03:35:53.849: INFO: Pod "downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005799703s
STEP: Saw pod success
Feb 26 03:35:53.849: INFO: Pod "downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:35:53.851: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:35:53.864: INFO: Waiting for pod downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:35:53.868: INFO: Pod downwardapi-volume-9d874a6a-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:35:53.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z4lxk" for this suite.
Feb 26 03:35:59.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:36:00.092: INFO: namespace: e2e-tests-downward-api-z4lxk, resource: bindings, ignored listing per whitelist
Feb 26 03:36:00.107: INFO: namespace e2e-tests-downward-api-z4lxk deletion completed in 6.23406703s

• [SLOW TEST:8.723 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:36:00.108: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:36:00.580: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 26 03:36:00.605: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 26 03:36:04.610: INFO: Creating deployment "test-rolling-update-deployment"
Feb 26 03:36:04.614: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 26 03:36:04.630: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Feb 26 03:36:06.638: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 26 03:36:06.641: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 26 03:36:06.664: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-nxk7v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nxk7v/deployments/test-rolling-update-deployment,UID:a526e7b3-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7401,Generation:1,CreationTimestamp:2019-02-26 03:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-26 03:36:04 +0000 UTC 2019-02-26 03:36:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-26 03:36:05 +0000 UTC 2019-02-26 03:36:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 26 03:36:06.669: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-nxk7v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nxk7v/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:a52876c7-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7392,Generation:1,CreationTimestamp:2019-02-26 03:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a526e7b3-3977-11e9-a404-c690ac8d27cb 0xc0003bfbb7 0xc0003bfbb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 26 03:36:06.669: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 26 03:36:06.669: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-nxk7v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nxk7v/replicasets/test-rolling-update-controller,UID:a2c11ed0-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7400,Generation:2,CreationTimestamp:2019-02-26 03:36:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a526e7b3-3977-11e9-a404-c690ac8d27cb 0xc0003bfabf 0xc0003bfae0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:36:06.674: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-cdbcd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-cdbcd,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-nxk7v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nxk7v/pods/test-rolling-update-deployment-68b55d7bc6-cdbcd,UID:a529610d-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7391,Generation:0,CreationTimestamp:2019-02-26 03:36:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 a52876c7-3977-11e9-a404-c690ac8d27cb 0xc0003fd617 0xc0003fd618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s9hkt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s9hkt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-s9hkt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0003fd6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0003fd6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:36:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:36:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:36:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:36:04 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:10.42.1.89,StartTime:2019-02-26 03:36:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-26 03:36:05 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://654fcdd26534b743ac44a6508b4ab38e50253f4eabe99ee6ebc7a13b22de44a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:36:06.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nxk7v" for this suite.
Feb 26 03:36:12.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:36:12.888: INFO: namespace: e2e-tests-deployment-nxk7v, resource: bindings, ignored listing per whitelist
Feb 26 03:36:12.888: INFO: namespace e2e-tests-deployment-nxk7v deletion completed in 6.209130381s

• [SLOW TEST:12.780 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:36:12.888: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 26 03:36:13.357: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 26 03:36:18.362: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:36:19.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-trp2s" for this suite.
Feb 26 03:36:25.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:36:25.546: INFO: namespace: e2e-tests-replication-controller-trp2s, resource: bindings, ignored listing per whitelist
Feb 26 03:36:25.560: INFO: namespace e2e-tests-replication-controller-trp2s deletion completed in 6.180265838s

• [SLOW TEST:12.672 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:36:25.560: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b1e6b23d-3977-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 03:36:26.024: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-6pwmc" to be "success or failure"
Feb 26 03:36:26.026: INFO: Pod "pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239174ms
Feb 26 03:36:28.029: INFO: Pod "pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005581744s
Feb 26 03:36:30.033: INFO: Pod "pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009239473s
STEP: Saw pod success
Feb 26 03:36:30.033: INFO: Pod "pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:36:30.036: INFO: Trying to get logs from node darren-16001 pod pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 03:36:30.051: INFO: Waiting for pod pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:36:30.056: INFO: Pod pod-projected-configmaps-b1e7e8fc-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:36:30.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6pwmc" for this suite.
Feb 26 03:36:36.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:36:36.197: INFO: namespace: e2e-tests-projected-6pwmc, resource: bindings, ignored listing per whitelist
Feb 26 03:36:36.245: INFO: namespace e2e-tests-projected-6pwmc deletion completed in 6.184112147s

• [SLOW TEST:10.685 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:36:36.245: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 26 03:36:36.709: INFO: Waiting up to 5m0s for pod "downward-api-b8454f11-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-2hgvf" to be "success or failure"
Feb 26 03:36:36.712: INFO: Pod "downward-api-b8454f11-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.601204ms
Feb 26 03:36:38.715: INFO: Pod "downward-api-b8454f11-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005755907s
STEP: Saw pod success
Feb 26 03:36:38.715: INFO: Pod "downward-api-b8454f11-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:36:38.718: INFO: Trying to get logs from node darren-2745 pod downward-api-b8454f11-3977-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 03:36:38.738: INFO: Waiting for pod downward-api-b8454f11-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:36:38.743: INFO: Pod downward-api-b8454f11-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:36:38.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2hgvf" for this suite.
Feb 26 03:36:44.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:36:44.870: INFO: namespace: e2e-tests-downward-api-2hgvf, resource: bindings, ignored listing per whitelist
Feb 26 03:36:44.952: INFO: namespace e2e-tests-downward-api-2hgvf deletion completed in 6.201831762s

• [SLOW TEST:8.707 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:36:44.952: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:36:48.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-94dnz" for this suite.
Feb 26 03:37:10.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:37:10.600: INFO: namespace: e2e-tests-replication-controller-94dnz, resource: bindings, ignored listing per whitelist
Feb 26 03:37:10.643: INFO: namespace e2e-tests-replication-controller-94dnz deletion completed in 22.189786569s

• [SLOW TEST:25.691 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:37:10.644: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 26 03:37:11.105: INFO: Waiting up to 5m0s for pod "pod-ccc5e57a-3977-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-dwjtk" to be "success or failure"
Feb 26 03:37:11.111: INFO: Pod "pod-ccc5e57a-3977-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 6.427519ms
Feb 26 03:37:13.115: INFO: Pod "pod-ccc5e57a-3977-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010060421s
STEP: Saw pod success
Feb 26 03:37:13.115: INFO: Pod "pod-ccc5e57a-3977-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:37:13.117: INFO: Trying to get logs from node darren-2745 pod pod-ccc5e57a-3977-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:37:13.132: INFO: Waiting for pod pod-ccc5e57a-3977-11e9-ac13-320deb251a37 to disappear
Feb 26 03:37:13.135: INFO: Pod pod-ccc5e57a-3977-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:37:13.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dwjtk" for this suite.
Feb 26 03:37:19.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:37:19.278: INFO: namespace: e2e-tests-emptydir-dwjtk, resource: bindings, ignored listing per whitelist
Feb 26 03:37:19.303: INFO: namespace e2e-tests-emptydir-dwjtk deletion completed in 6.162334069s

• [SLOW TEST:8.659 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:37:19.304: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:37:19.752: INFO: Creating deployment "nginx-deployment"
Feb 26 03:37:19.762: INFO: Waiting for observed generation 1
Feb 26 03:37:21.767: INFO: Waiting for all required pods to come up
Feb 26 03:37:21.773: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 26 03:37:23.794: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 26 03:37:23.802: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 26 03:37:23.810: INFO: Updating deployment nginx-deployment
Feb 26 03:37:23.810: INFO: Waiting for observed generation 2
Feb 26 03:37:25.815: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 26 03:37:25.817: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 26 03:37:25.820: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 26 03:37:25.829: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 26 03:37:25.829: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 26 03:37:25.832: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 26 03:37:25.836: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 26 03:37:25.836: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 26 03:37:25.843: INFO: Updating deployment nginx-deployment
Feb 26 03:37:25.843: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 26 03:37:25.848: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 26 03:37:25.850: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 26 03:37:27.874: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r5wz5/deployments/nginx-deployment,UID:d1f17b88-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7895,Generation:3,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-26 03:37:25 +0000 UTC 2019-02-26 03:37:25 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-26 03:37:26 +0000 UTC 2019-02-26 03:37:19 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 26 03:37:27.888: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r5wz5/replicasets/nginx-deployment-65bbdb5f8,UID:d45c00b4-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7894,Generation:3,CreationTimestamp:2019-02-26 03:37:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment d1f17b88-3977-11e9-a404-c690ac8d27cb 0xc001c7b577 0xc001c7b578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:37:27.888: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 26 03:37:27.888: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r5wz5/replicasets/nginx-deployment-555b55d965,UID:d1f20e11-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7861,Generation:3,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment d1f17b88-3977-11e9-a404-c690ac8d27cb 0xc001c7b3f7 0xc001c7b3f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 26 03:37:27.902: INFO: Pod "nginx-deployment-555b55d965-2hjrc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2hjrc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-2hjrc,UID:d597c294-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7898,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc0022af680 0xc0022af681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022af700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022af720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.902: INFO: Pod "nginx-deployment-555b55d965-4vjtz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4vjtz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-4vjtz,UID:d59414e1-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7869,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc0022af7d7 0xc0022af7d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022af9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022af9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.902: INFO: Pod "nginx-deployment-555b55d965-5qlz4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5qlz4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-5qlz4,UID:d1f57feb-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7698,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc0022afc27 0xc0022afc28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022afca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022afcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:10.42.1.94,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://16c1ec4008ceb8ec35996054f1296ec36f015ed31d99faccf57be93c67246875}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.902: INFO: Pod "nginx-deployment-555b55d965-8vgdf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8vgdf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-8vgdf,UID:d1f855b4-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7709,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc0022afd90 0xc0022afd91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022afe00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022afe20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.106,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://be22855a86a892a01afb48cc1c95a44e69deee3f1fb2cd833933dee0172ca6a9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-9f2cm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9f2cm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-9f2cm,UID:d1f34be4-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7718,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc0022aff90 0xc0022aff91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143c000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143c150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.103,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://b571e5b34fc3bc7aa1e238993c46e16e735696346745d9ccb0eb830c1f88f7c7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-bjqgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bjqgl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-bjqgl,UID:d59520d9-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7880,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143c290 0xc00143c291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143c360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143c380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-bzc2k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bzc2k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-bzc2k,UID:d592acba-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7857,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143c687 0xc00143c688}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143c840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143c860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-cz4n8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cz4n8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-cz4n8,UID:d1f5f79e-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7690,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143c967 0xc00143c968}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143c9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143cac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:10.42.1.95,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://d4126d750f6017f4bf1ef1a5b4292d7041643c887942bee1eb9bb2e115a10383}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-fn4n6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fn4n6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-fn4n6,UID:d1f3ca97-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7711,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143cc00 0xc00143cc01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143cc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143cc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.102,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://976bfb86cf2bde2e89aff350488fd869ead55d45058599129dbbdc0bbe37a428}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-gs7kz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gs7kz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-gs7kz,UID:d59791db-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7900,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143cd50 0xc00143cd51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143ce50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143ce70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.903: INFO: Pod "nginx-deployment-555b55d965-h6jpf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h6jpf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-h6jpf,UID:d597ce1f-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7924,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143cf27 0xc00143cf28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143d020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143d040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-ht9r9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ht9r9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-ht9r9,UID:d597d716-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7883,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143d0f7 0xc00143d0f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143d2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143d2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-prwql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-prwql,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-prwql,UID:d594cb32-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7866,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143d387 0xc00143d388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143d400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143d500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-tpd5l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tpd5l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-tpd5l,UID:d1f5d521-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7705,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143d5b7 0xc00143d5b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143d700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143d720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.105,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://e1b48685eb8d2990f699ea3f1679f6bc265c670d56fe10318731c17ed1c392db}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-tr8xk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tr8xk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-tr8xk,UID:d595619d-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7877,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143d7e0 0xc00143d7e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143d850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143d8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-vs4qf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vs4qf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-vs4qf,UID:d596f24e-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7871,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143d997 0xc00143d998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143da10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143da30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-x2sj7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x2sj7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-x2sj7,UID:d5950674-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7912,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143daf7 0xc00143daf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143db70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143db90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.904: INFO: Pod "nginx-deployment-555b55d965-x6kb8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x6kb8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-x6kb8,UID:d1f59491-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7723,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143dce7 0xc00143dce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143dd60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143dd80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.104,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:21 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://ef714ba97ea7e5e6f6b5e0c48834b8b8e82de8c0b8789420eee0c0b05c3c3b32}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-555b55d965-zbfbq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zbfbq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-zbfbq,UID:d1f3efc1-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7715,Generation:0,CreationTimestamp:2019-02-26 03:37:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143de40 0xc00143de41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00143deb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00143ded0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:19 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:10.42.1.93,StartTime:2019-02-26 03:37:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-26 03:37:20 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://d9403419e01164fb0a6232619d4aa7e1b507306b671b467bcb0466ff373cb74f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-555b55d965-zg86n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zg86n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-555b55d965-zg86n,UID:d5933ffc-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7864,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d1f20e11-3977-11e9-a404-c690ac8d27cb 0xc00143df90 0xc00143df91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-5qhqk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5qhqk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-5qhqk,UID:d5a146f0-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7934,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2230 0xc001aa2231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa22c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-7jjmr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7jjmr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-7jjmr,UID:d4644e66-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7780,Generation:0,CreationTimestamp:2019-02-26 03:37:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2430 0xc001aa2431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa24b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa24d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-8cnnr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8cnnr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-8cnnr,UID:d59c9a00-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7854,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2590 0xc001aa2591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-cd5nr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cd5nr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-cd5nr,UID:d59c6e3c-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7853,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa26a0 0xc001aa26a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-fgbgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fgbgn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-fgbgn,UID:d598e2c5-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7876,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa27b0 0xc001aa27b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-kmbbt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kmbbt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-kmbbt,UID:d463c45a-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7779,Generation:0,CreationTimestamp:2019-02-26 03:37:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2910 0xc001aa2911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa29b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.905: INFO: Pod "nginx-deployment-65bbdb5f8-rjkgt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rjkgt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-rjkgt,UID:d45c6833-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7795,Generation:0,CreationTimestamp:2019-02-26 03:37:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2a70 0xc001aa2a71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:10.42.0.107,StartTime:2019-02-26 03:37:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.906: INFO: Pod "nginx-deployment-65bbdb5f8-sbwcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sbwcw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-sbwcw,UID:d59810af-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7879,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2bf0 0xc001aa2bf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.906: INFO: Pod "nginx-deployment-65bbdb5f8-t8d9x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-t8d9x,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-t8d9x,UID:d45e6d3c-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7777,Generation:0,CreationTimestamp:2019-02-26 03:37:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2d50 0xc001aa2d51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.906: INFO: Pod "nginx-deployment-65bbdb5f8-v5cgj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-v5cgj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-v5cgj,UID:d45dea10-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7778,Generation:0,CreationTimestamp:2019-02-26 03:37:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa2eb0 0xc001aa2eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa2f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa2f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:23 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.906: INFO: Pod "nginx-deployment-65bbdb5f8-vqkfg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vqkfg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-vqkfg,UID:d5975a19-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7914,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa3010 0xc001aa3011}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa3090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa30b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.906: INFO: Pod "nginx-deployment-65bbdb5f8-vsn64" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vsn64,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-vsn64,UID:d59b4979-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7926,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa3170 0xc001aa3171}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa31f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa3210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 26 03:37:27.906: INFO: Pod "nginx-deployment-65bbdb5f8-w7pbw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w7pbw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r5wz5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r5wz5/pods/nginx-deployment-65bbdb5f8-w7pbw,UID:d59c8055-3977-11e9-a404-c690ac8d27cb,ResourceVersion:7932,Generation:0,CreationTimestamp:2019-02-26 03:37:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d45c00b4-3977-11e9-a404-c690ac8d27cb 0xc001aa32d0 0xc001aa32d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9tbnd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9tbnd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9tbnd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001aa3350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001aa3370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:25 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:,StartTime:2019-02-26 03:37:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:37:27.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-r5wz5" for this suite.
Feb 26 03:37:33.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:37:33.996: INFO: namespace: e2e-tests-deployment-r5wz5, resource: bindings, ignored listing per whitelist
Feb 26 03:37:34.318: INFO: namespace e2e-tests-deployment-r5wz5 deletion completed in 6.395056139s

• [SLOW TEST:15.014 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:37:34.318: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:37:34.791: INFO: Creating deployment "test-recreate-deployment"
Feb 26 03:37:34.795: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 26 03:37:34.812: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 26 03:37:36.827: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 26 03:37:36.829: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686749054, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686749054, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686749054, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686749054, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 26 03:37:38.833: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 26 03:37:38.841: INFO: Updating deployment test-recreate-deployment
Feb 26 03:37:38.841: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 26 03:37:39.053: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-zlj87,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zlj87/deployments/test-recreate-deployment,UID:dae75ca5-3977-11e9-a404-c690ac8d27cb,ResourceVersion:8255,Generation:2,CreationTimestamp:2019-02-26 03:37:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-26 03:37:38 +0000 UTC 2019-02-26 03:37:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-26 03:37:38 +0000 UTC 2019-02-26 03:37:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 26 03:37:39.062: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-zlj87,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zlj87/replicasets/test-recreate-deployment-697fbf54bf,UID:dd589d3e-3977-11e9-a404-c690ac8d27cb,ResourceVersion:8254,Generation:1,CreationTimestamp:2019-02-26 03:37:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dae75ca5-3977-11e9-a404-c690ac8d27cb 0xc0003be927 0xc0003be928}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:37:39.062: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 26 03:37:39.062: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-zlj87,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zlj87/replicasets/test-recreate-deployment-5dfdcc846d,UID:dae7ff27-3977-11e9-a404-c690ac8d27cb,ResourceVersion:8244,Generation:2,CreationTimestamp:2019-02-26 03:37:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dae75ca5-3977-11e9-a404-c690ac8d27cb 0xc0003be817 0xc0003be818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 26 03:37:39.069: INFO: Pod "test-recreate-deployment-697fbf54bf-rvml7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-rvml7,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-zlj87,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zlj87/pods/test-recreate-deployment-697fbf54bf-rvml7,UID:dd5b3fc2-3977-11e9-a404-c690ac8d27cb,ResourceVersion:8256,Generation:0,CreationTimestamp:2019-02-26 03:37:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf dd589d3e-3977-11e9-a404-c690ac8d27cb 0xc000f0ec97 0xc000f0ec98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-x5jvr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x5jvr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-x5jvr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-16001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000f0ed30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000f0ed70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:37:38 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.30,PodIP:,StartTime:2019-02-26 03:37:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:37:39.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zlj87" for this suite.
Feb 26 03:37:45.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:37:45.195: INFO: namespace: e2e-tests-deployment-zlj87, resource: bindings, ignored listing per whitelist
Feb 26 03:37:45.405: INFO: namespace e2e-tests-deployment-zlj87 deletion completed in 6.32762053s

• [SLOW TEST:11.087 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:37:45.405: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:37:45.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-v4bgf" for this suite.
Feb 26 03:38:07.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:38:08.138: INFO: namespace: e2e-tests-kubelet-test-v4bgf, resource: bindings, ignored listing per whitelist
Feb 26 03:38:08.225: INFO: namespace e2e-tests-kubelet-test-v4bgf deletion completed in 22.314117054s

• [SLOW TEST:22.820 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:38:08.226: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 26 03:38:08.903: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-jpkxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-jpkxf/configmaps/e2e-watch-test-resource-version,UID:ef1a778f-3977-11e9-a404-c690ac8d27cb,ResourceVersion:8312,Generation:0,CreationTimestamp:2019-02-26 03:38:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 26 03:38:08.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-jpkxf,SelfLink:/api/v1/namespaces/e2e-tests-watch-jpkxf/configmaps/e2e-watch-test-resource-version,UID:ef1a778f-3977-11e9-a404-c690ac8d27cb,ResourceVersion:8313,Generation:0,CreationTimestamp:2019-02-26 03:38:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:38:08.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jpkxf" for this suite.
Feb 26 03:38:14.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:38:15.045: INFO: namespace: e2e-tests-watch-jpkxf, resource: bindings, ignored listing per whitelist
Feb 26 03:38:15.103: INFO: namespace e2e-tests-watch-jpkxf deletion completed in 6.184548259s

• [SLOW TEST:6.877 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:38:15.107: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-f33a54cb-3977-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-f33a54cb-3977-11e9-ac13-320deb251a37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:38:19.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vvd7" for this suite.
Feb 26 03:38:41.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:38:41.715: INFO: namespace: e2e-tests-projected-6vvd7, resource: bindings, ignored listing per whitelist
Feb 26 03:38:41.819: INFO: namespace e2e-tests-projected-6vvd7 deletion completed in 22.164899084s

• [SLOW TEST:26.713 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:38:41.819: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 03:38:42.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-jp9z6'
Feb 26 03:38:42.395: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 26 03:38:42.395: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 26 03:38:42.406: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-64t9q]
Feb 26 03:38:42.406: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-64t9q" in namespace "e2e-tests-kubectl-jp9z6" to be "running and ready"
Feb 26 03:38:42.409: INFO: Pod "e2e-test-nginx-rc-64t9q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614577ms
Feb 26 03:38:44.412: INFO: Pod "e2e-test-nginx-rc-64t9q": Phase="Running", Reason="", readiness=true. Elapsed: 2.005820434s
Feb 26 03:38:44.412: INFO: Pod "e2e-test-nginx-rc-64t9q" satisfied condition "running and ready"
Feb 26 03:38:44.412: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-64t9q]
Feb 26 03:38:44.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jp9z6'
Feb 26 03:38:44.546: INFO: stderr: ""
Feb 26 03:38:44.546: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 26 03:38:44.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jp9z6'
Feb 26 03:38:44.653: INFO: stderr: ""
Feb 26 03:38:44.653: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:38:44.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jp9z6" for this suite.
Feb 26 03:38:50.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:38:50.710: INFO: namespace: e2e-tests-kubectl-jp9z6, resource: bindings, ignored listing per whitelist
Feb 26 03:38:50.833: INFO: namespace e2e-tests-kubectl-jp9z6 deletion completed in 6.17513659s

• [SLOW TEST:9.014 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:38:50.833: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 26 03:38:51.303: INFO: Waiting up to 5m0s for pod "downward-api-087fc9ea-3978-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-f2crr" to be "success or failure"
Feb 26 03:38:51.311: INFO: Pod "downward-api-087fc9ea-3978-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 8.066653ms
Feb 26 03:38:53.315: INFO: Pod "downward-api-087fc9ea-3978-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011784669s
STEP: Saw pod success
Feb 26 03:38:53.315: INFO: Pod "downward-api-087fc9ea-3978-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:38:53.317: INFO: Trying to get logs from node darren-2745 pod downward-api-087fc9ea-3978-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 03:38:53.330: INFO: Waiting for pod downward-api-087fc9ea-3978-11e9-ac13-320deb251a37 to disappear
Feb 26 03:38:53.334: INFO: Pod downward-api-087fc9ea-3978-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:38:53.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f2crr" for this suite.
Feb 26 03:38:59.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:38:59.507: INFO: namespace: e2e-tests-downward-api-f2crr, resource: bindings, ignored listing per whitelist
Feb 26 03:38:59.542: INFO: namespace e2e-tests-downward-api-f2crr deletion completed in 6.203409938s

• [SLOW TEST:8.709 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:38:59.543: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bskp4;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-bskp4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-bskp4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bskp4.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 115.53.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.53.115_udp@PTR;check="$$(dig +tcp +noall +answer +search 115.53.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.53.115_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bskp4;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bskp4;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-bskp4.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-bskp4.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-bskp4.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-bskp4.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-bskp4.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 115.53.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.53.115_udp@PTR;check="$$(dig +tcp +noall +answer +search 115.53.43.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.43.53.115_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 26 03:39:10.062: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.066: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.070: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.074: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.078: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.081: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.085: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.088: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.113: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.116: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.119: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.122: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.125: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.128: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.135: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.140: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:10.161: INFO: Lookups using e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bskp4 jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc]

Feb 26 03:39:15.165: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.169: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.173: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.177: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.181: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.185: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.191: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.195: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.218: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.222: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.230: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.233: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.246: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.250: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.254: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.263: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:15.288: INFO: Lookups using e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bskp4 jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc]

Feb 26 03:39:20.165: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.169: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.175: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.179: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.183: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.187: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.190: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.211: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.237: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.241: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.244: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.250: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.254: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.257: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.265: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.269: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:20.294: INFO: Lookups using e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bskp4 jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc]

Feb 26 03:39:25.165: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.169: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.172: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.179: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.183: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.187: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.194: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.200: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.232: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.243: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.253: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.257: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.263: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.281: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.287: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.294: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:25.335: INFO: Lookups using e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bskp4 jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc]

Feb 26 03:39:30.165: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.168: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.171: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.174: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.178: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.181: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.184: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.187: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.210: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.213: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.218: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.221: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.224: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.228: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.231: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.234: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc from pod e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37: the server could not find the requested resource (get pods dns-test-0db30670-3978-11e9-ac13-320deb251a37)
Feb 26 03:39:30.255: INFO: Lookups using e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-bskp4 wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4 wheezy_udp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@dns-test-service.e2e-tests-dns-bskp4.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-bskp4 jessie_tcp@dns-test-service.e2e-tests-dns-bskp4 jessie_udp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@dns-test-service.e2e-tests-dns-bskp4.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-bskp4.svc]

Feb 26 03:39:35.285: INFO: DNS probes using e2e-tests-dns-bskp4/dns-test-0db30670-3978-11e9-ac13-320deb251a37 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:39:35.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-bskp4" for this suite.
Feb 26 03:39:41.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:39:41.485: INFO: namespace: e2e-tests-dns-bskp4, resource: bindings, ignored listing per whitelist
Feb 26 03:39:41.608: INFO: namespace e2e-tests-dns-bskp4 deletion completed in 6.24056131s

• [SLOW TEST:42.066 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:39:41.610: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:39:42.128: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-5vkhh" to be "success or failure"
Feb 26 03:39:42.132: INFO: Pod "downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009938ms
Feb 26 03:39:44.135: INFO: Pod "downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00706467s
STEP: Saw pod success
Feb 26 03:39:44.135: INFO: Pod "downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:39:44.138: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:39:44.149: INFO: Waiting for pod downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37 to disappear
Feb 26 03:39:44.154: INFO: Pod downwardapi-volume-26c9d9ef-3978-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:39:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vkhh" for this suite.
Feb 26 03:39:50.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:39:50.312: INFO: namespace: e2e-tests-projected-5vkhh, resource: bindings, ignored listing per whitelist
Feb 26 03:39:50.330: INFO: namespace e2e-tests-projected-5vkhh deletion completed in 6.172230456s

• [SLOW TEST:8.720 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:39:50.330: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:40:10.802: INFO: Container started at 2019-02-26 03:39:51 +0000 UTC, pod became ready at 2019-02-26 03:40:10 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:40:10.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fpkg2" for this suite.
Feb 26 03:40:44.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:40:44.908: INFO: namespace: e2e-tests-container-probe-fpkg2, resource: bindings, ignored listing per whitelist
Feb 26 03:40:45.012: INFO: namespace e2e-tests-container-probe-fpkg2 deletion completed in 34.205612857s

• [SLOW TEST:54.682 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:40:45.013: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 26 03:40:45.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c9gpr,SelfLink:/api/v1/namespaces/e2e-tests-watch-c9gpr/configmaps/e2e-watch-test-watch-closed,UID:4cb0e279-3978-11e9-a404-c690ac8d27cb,ResourceVersion:8562,Generation:0,CreationTimestamp:2019-02-26 03:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 26 03:40:45.889: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c9gpr,SelfLink:/api/v1/namespaces/e2e-tests-watch-c9gpr/configmaps/e2e-watch-test-watch-closed,UID:4cb0e279-3978-11e9-a404-c690ac8d27cb,ResourceVersion:8563,Generation:0,CreationTimestamp:2019-02-26 03:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 26 03:40:46.108: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c9gpr,SelfLink:/api/v1/namespaces/e2e-tests-watch-c9gpr/configmaps/e2e-watch-test-watch-closed,UID:4cb0e279-3978-11e9-a404-c690ac8d27cb,ResourceVersion:8564,Generation:0,CreationTimestamp:2019-02-26 03:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 26 03:40:46.299: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-c9gpr,SelfLink:/api/v1/namespaces/e2e-tests-watch-c9gpr/configmaps/e2e-watch-test-watch-closed,UID:4cb0e279-3978-11e9-a404-c690ac8d27cb,ResourceVersion:8565,Generation:0,CreationTimestamp:2019-02-26 03:40:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:40:46.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-c9gpr" for this suite.
Feb 26 03:40:52.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:40:52.377: INFO: namespace: e2e-tests-watch-c9gpr, resource: bindings, ignored listing per whitelist
Feb 26 03:40:52.489: INFO: namespace e2e-tests-watch-c9gpr deletion completed in 6.184384083s

• [SLOW TEST:7.476 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:40:52.489: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 26 03:40:53.466: INFO: created pod pod-service-account-defaultsa
Feb 26 03:40:53.466: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 26 03:40:53.470: INFO: created pod pod-service-account-mountsa
Feb 26 03:40:53.470: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 26 03:40:53.477: INFO: created pod pod-service-account-nomountsa
Feb 26 03:40:53.477: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 26 03:40:53.481: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 26 03:40:53.481: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 26 03:40:53.485: INFO: created pod pod-service-account-mountsa-mountspec
Feb 26 03:40:53.485: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 26 03:40:53.491: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 26 03:40:53.491: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 26 03:40:53.494: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 26 03:40:53.494: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 26 03:40:53.497: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 26 03:40:53.497: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 26 03:40:53.500: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 26 03:40:53.500: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:40:53.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-ghr9q" for this suite.
Feb 26 03:40:59.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:40:59.699: INFO: namespace: e2e-tests-svcaccounts-ghr9q, resource: bindings, ignored listing per whitelist
Feb 26 03:40:59.709: INFO: namespace e2e-tests-svcaccounts-ghr9q deletion completed in 6.204514979s

• [SLOW TEST:7.220 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:40:59.709: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-55534c4e-3978-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:41:00.207: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-ff756" to be "success or failure"
Feb 26 03:41:00.210: INFO: Pod "pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.273777ms
Feb 26 03:41:02.213: INFO: Pod "pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005790546s
STEP: Saw pod success
Feb 26 03:41:02.213: INFO: Pod "pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:41:02.216: INFO: Trying to get logs from node darren-2745 pod pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:41:02.239: INFO: Waiting for pod pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37 to disappear
Feb 26 03:41:02.251: INFO: Pod pod-projected-secrets-55550090-3978-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:41:02.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ff756" for this suite.
Feb 26 03:41:08.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:41:08.313: INFO: namespace: e2e-tests-projected-ff756, resource: bindings, ignored listing per whitelist
Feb 26 03:41:08.504: INFO: namespace e2e-tests-projected-ff756 deletion completed in 6.242087554s

• [SLOW TEST:8.795 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:41:08.505: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 26 03:41:09.517: INFO: Waiting up to 5m0s for pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq" in namespace "e2e-tests-svcaccounts-wkxxb" to be "success or failure"
Feb 26 03:41:09.519: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429226ms
Feb 26 03:41:11.524: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00700385s
Feb 26 03:41:13.527: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0100348s
STEP: Saw pod success
Feb 26 03:41:13.527: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq" satisfied condition "success or failure"
Feb 26 03:41:13.529: INFO: Trying to get logs from node darren-16001 pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq container token-test: <nil>
STEP: delete the pod
Feb 26 03:41:13.556: INFO: Waiting for pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq to disappear
Feb 26 03:41:13.560: INFO: Pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-thkqq no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 26 03:41:13.564: INFO: Waiting up to 5m0s for pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk" in namespace "e2e-tests-svcaccounts-wkxxb" to be "success or failure"
Feb 26 03:41:13.566: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429804ms
Feb 26 03:41:15.569: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk": Phase="Running", Reason="", readiness=false. Elapsed: 2.00558153s
Feb 26 03:41:17.572: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008833229s
STEP: Saw pod success
Feb 26 03:41:17.572: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk" satisfied condition "success or failure"
Feb 26 03:41:17.575: INFO: Trying to get logs from node darren-2745 pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk container root-ca-test: <nil>
STEP: delete the pod
Feb 26 03:41:17.590: INFO: Waiting for pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk to disappear
Feb 26 03:41:17.600: INFO: Pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-br4mk no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 26 03:41:17.605: INFO: Waiting up to 5m0s for pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd" in namespace "e2e-tests-svcaccounts-wkxxb" to be "success or failure"
Feb 26 03:41:17.609: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.430282ms
Feb 26 03:41:19.612: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006770389s
Feb 26 03:41:21.616: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010528035s
STEP: Saw pod success
Feb 26 03:41:21.616: INFO: Pod "pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd" satisfied condition "success or failure"
Feb 26 03:41:21.620: INFO: Trying to get logs from node darren-16001 pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd container namespace-test: <nil>
STEP: delete the pod
Feb 26 03:41:21.634: INFO: Waiting for pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd to disappear
Feb 26 03:41:21.638: INFO: Pod pod-service-account-5ae16512-3978-11e9-ac13-320deb251a37-7njnd no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:41:21.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-wkxxb" for this suite.
Feb 26 03:41:27.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:41:27.746: INFO: namespace: e2e-tests-svcaccounts-wkxxb, resource: bindings, ignored listing per whitelist
Feb 26 03:41:27.839: INFO: namespace e2e-tests-svcaccounts-wkxxb deletion completed in 6.194154007s

• [SLOW TEST:19.334 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:41:27.842: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 26 03:41:28.314: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 26 03:41:28.334: INFO: Waiting for terminating namespaces to be deleted...
Feb 26 03:41:28.337: INFO: 
Logging pods the kubelet thinks is on node darren-16001 before test
Feb 26 03:41:28.343: INFO: helm-install-traefik-svddx from kube-system started at 2019-02-26 02:40:25 +0000 UTC (1 container statuses recorded)
Feb 26 03:41:28.343: INFO: 	Container helm ready: false, restart count 0
Feb 26 03:41:28.343: INFO: traefik-cd5db8d98-9t88n from kube-system started at 2019-02-26 02:40:39 +0000 UTC (1 container statuses recorded)
Feb 26 03:41:28.343: INFO: 	Container traefik ready: true, restart count 0
Feb 26 03:41:28.343: INFO: svclb-traefik-77d498cccf-h6nlj from kube-system started at 2019-02-26 02:40:39 +0000 UTC (2 container statuses recorded)
Feb 26 03:41:28.343: INFO: 	Container http ready: true, restart count 0
Feb 26 03:41:28.343: INFO: 	Container https ready: true, restart count 1
Feb 26 03:41:28.343: INFO: coredns-7748f7f6df-8kss9 from kube-system started at 2019-02-26 02:40:25 +0000 UTC (1 container statuses recorded)
Feb 26 03:41:28.343: INFO: 	Container coredns ready: true, restart count 0
Feb 26 03:41:28.343: INFO: sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-ts2dg from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 03:41:28.343: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 26 03:41:28.343: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 26 03:41:28.343: INFO: 
Logging pods the kubelet thinks is on node darren-2745 before test
Feb 26 03:41:28.352: INFO: sonobuoy-e2e-job-5dae3ccfaa924d88 from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 03:41:28.352: INFO: 	Container e2e ready: true, restart count 0
Feb 26 03:41:28.352: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 26 03:41:28.352: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-26 02:42:40 +0000 UTC (1 container statuses recorded)
Feb 26 03:41:28.352: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 26 03:41:28.352: INFO: sonobuoy-systemd-logs-daemon-set-d99635dc61424fc0-6cg6k from heptio-sonobuoy started at 2019-02-26 02:42:45 +0000 UTC (2 container statuses recorded)
Feb 26 03:41:28.352: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 26 03:41:28.352: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6751bd35-3978-11e9-ac13-320deb251a37 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-6751bd35-3978-11e9-ac13-320deb251a37 off the node darren-2745
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6751bd35-3978-11e9-ac13-320deb251a37
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:41:32.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-pvw2c" for this suite.
Feb 26 03:41:52.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:41:52.522: INFO: namespace: e2e-tests-sched-pred-pvw2c, resource: bindings, ignored listing per whitelist
Feb 26 03:41:52.667: INFO: namespace e2e-tests-sched-pred-pvw2c deletion completed in 20.245042031s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:24.825 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:41:52.667: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 26 03:41:53.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:53.323: INFO: stderr: ""
Feb 26 03:41:53.323: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 26 03:41:53.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:53.428: INFO: stderr: ""
Feb 26 03:41:53.428: INFO: stdout: "update-demo-nautilus-hwsrf update-demo-nautilus-kqk7d "
Feb 26 03:41:53.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-hwsrf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:53.545: INFO: stderr: ""
Feb 26 03:41:53.545: INFO: stdout: ""
Feb 26 03:41:53.545: INFO: update-demo-nautilus-hwsrf is created but not running
Feb 26 03:41:58.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:58.639: INFO: stderr: ""
Feb 26 03:41:58.639: INFO: stdout: "update-demo-nautilus-hwsrf update-demo-nautilus-kqk7d "
Feb 26 03:41:58.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-hwsrf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:58.732: INFO: stderr: ""
Feb 26 03:41:58.732: INFO: stdout: "true"
Feb 26 03:41:58.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-hwsrf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:58.836: INFO: stderr: ""
Feb 26 03:41:58.836: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:41:58.836: INFO: validating pod update-demo-nautilus-hwsrf
Feb 26 03:41:58.875: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:41:58.875: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:41:58.875: INFO: update-demo-nautilus-hwsrf is verified up and running
Feb 26 03:41:58.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-kqk7d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:58.973: INFO: stderr: ""
Feb 26 03:41:58.973: INFO: stdout: "true"
Feb 26 03:41:58.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-kqk7d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:41:59.078: INFO: stderr: ""
Feb 26 03:41:59.078: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:41:59.078: INFO: validating pod update-demo-nautilus-kqk7d
Feb 26 03:41:59.084: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:41:59.084: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:41:59.084: INFO: update-demo-nautilus-kqk7d is verified up and running
STEP: rolling-update to new replication controller
Feb 26 03:41:59.085: INFO: scanned /root for discovery docs: <nil>
Feb 26 03:41:59.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:42:21.855: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 26 03:42:21.855: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 26 03:42:21.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:42:21.968: INFO: stderr: ""
Feb 26 03:42:21.968: INFO: stdout: "update-demo-kitten-7d2zn update-demo-kitten-tlcd5 "
Feb 26 03:42:21.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-kitten-7d2zn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:42:22.056: INFO: stderr: ""
Feb 26 03:42:22.056: INFO: stdout: "true"
Feb 26 03:42:22.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-kitten-7d2zn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:42:22.162: INFO: stderr: ""
Feb 26 03:42:22.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 26 03:42:22.162: INFO: validating pod update-demo-kitten-7d2zn
Feb 26 03:42:22.173: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 26 03:42:22.173: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 26 03:42:22.173: INFO: update-demo-kitten-7d2zn is verified up and running
Feb 26 03:42:22.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-kitten-tlcd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:42:22.270: INFO: stderr: ""
Feb 26 03:42:22.270: INFO: stdout: "true"
Feb 26 03:42:22.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-kitten-tlcd5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bsndb'
Feb 26 03:42:22.355: INFO: stderr: ""
Feb 26 03:42:22.355: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 26 03:42:22.355: INFO: validating pod update-demo-kitten-tlcd5
Feb 26 03:42:22.359: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 26 03:42:22.359: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 26 03:42:22.359: INFO: update-demo-kitten-tlcd5 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:42:22.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bsndb" for this suite.
Feb 26 03:42:44.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:42:44.468: INFO: namespace: e2e-tests-kubectl-bsndb, resource: bindings, ignored listing per whitelist
Feb 26 03:42:44.560: INFO: namespace e2e-tests-kubectl-bsndb deletion completed in 22.194926612s

• [SLOW TEST:51.894 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:42:44.561: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-cpd67.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-cpd67.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cpd67.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-cpd67.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-cpd67.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cpd67.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 26 03:42:57.113: INFO: DNS probes using e2e-tests-dns-cpd67/dns-test-93cec27f-3978-11e9-ac13-320deb251a37 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:42:57.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-cpd67" for this suite.
Feb 26 03:43:03.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:43:03.233: INFO: namespace: e2e-tests-dns-cpd67, resource: bindings, ignored listing per whitelist
Feb 26 03:43:03.326: INFO: namespace e2e-tests-dns-cpd67 deletion completed in 6.194801932s

• [SLOW TEST:18.765 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:43:03.326: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 26 03:43:05.822: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-9efd81d1-3978-11e9-ac13-320deb251a37,GenerateName:,Namespace:e2e-tests-events-xlbvs,SelfLink:/api/v1/namespaces/e2e-tests-events-xlbvs/pods/send-events-9efd81d1-3978-11e9-ac13-320deb251a37,UID:9f004610-3978-11e9-a404-c690ac8d27cb,ResourceVersion:9084,Generation:0,CreationTimestamp:2019-02-26 03:43:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 778355859,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jcqxm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jcqxm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-jcqxm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:darren-2745,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015eb2a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015eb2c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:43:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:43:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:43:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-26 03:43:03 +0000 UTC  }],Message:,Reason:,HostIP:134.209.63.36,PodIP:10.42.1.128,StartTime:2019-02-26 03:43:03 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-26 03:43:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://f527a5b3633d61e3b105e68652a1f886a5eb4b39f32e2124a8f96db67f55e45d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 26 03:43:07.829: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 26 03:43:09.833: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:43:09.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xlbvs" for this suite.
Feb 26 03:43:47.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:43:47.904: INFO: namespace: e2e-tests-events-xlbvs, resource: bindings, ignored listing per whitelist
Feb 26 03:43:47.998: INFO: namespace e2e-tests-events-xlbvs deletion completed in 38.153876352s

• [SLOW TEST:44.672 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:43:47.999: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-qhl8q
Feb 26 03:43:50.467: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-qhl8q
STEP: checking the pod's current state and verifying that restartCount is present
Feb 26 03:43:50.470: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:47:50.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qhl8q" for this suite.
Feb 26 03:47:56.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:47:56.988: INFO: namespace: e2e-tests-container-probe-qhl8q, resource: bindings, ignored listing per whitelist
Feb 26 03:47:57.041: INFO: namespace e2e-tests-container-probe-qhl8q deletion completed in 6.144590261s

• [SLOW TEST:249.042 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:47:57.043: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 03:47:57.487: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:47:59.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-twzbs" for this suite.
Feb 26 03:48:49.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:48:49.651: INFO: namespace: e2e-tests-pods-twzbs, resource: bindings, ignored listing per whitelist
Feb 26 03:48:49.670: INFO: namespace e2e-tests-pods-twzbs deletion completed in 50.136827473s

• [SLOW TEST:52.627 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:48:49.671: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6d6d5b3c-3979-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:48:50.140: INFO: Waiting up to 5m0s for pod "pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-6zbtk" to be "success or failure"
Feb 26 03:48:50.146: INFO: Pod "pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 6.465648ms
Feb 26 03:48:52.149: INFO: Pod "pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.009748036s
Feb 26 03:48:54.153: INFO: Pod "pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012970703s
STEP: Saw pod success
Feb 26 03:48:54.153: INFO: Pod "pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:48:54.155: INFO: Trying to get logs from node darren-16001 pod pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37 container secret-env-test: <nil>
STEP: delete the pod
Feb 26 03:48:54.166: INFO: Waiting for pod pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37 to disappear
Feb 26 03:48:54.170: INFO: Pod pod-secrets-6d6ec3ac-3979-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:48:54.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6zbtk" for this suite.
Feb 26 03:49:00.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:49:00.236: INFO: namespace: e2e-tests-secrets-6zbtk, resource: bindings, ignored listing per whitelist
Feb 26 03:49:00.334: INFO: namespace e2e-tests-secrets-6zbtk deletion completed in 6.159300784s

• [SLOW TEST:10.663 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:49:00.334: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 26 03:49:00.791: INFO: Waiting up to 5m0s for pod "var-expansion-73c8620c-3979-11e9-ac13-320deb251a37" in namespace "e2e-tests-var-expansion-v562m" to be "success or failure"
Feb 26 03:49:00.793: INFO: Pod "var-expansion-73c8620c-3979-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940645ms
Feb 26 03:49:02.796: INFO: Pod "var-expansion-73c8620c-3979-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005338506s
STEP: Saw pod success
Feb 26 03:49:02.796: INFO: Pod "var-expansion-73c8620c-3979-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:49:02.799: INFO: Trying to get logs from node darren-2745 pod var-expansion-73c8620c-3979-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 03:49:02.811: INFO: Waiting for pod var-expansion-73c8620c-3979-11e9-ac13-320deb251a37 to disappear
Feb 26 03:49:02.815: INFO: Pod var-expansion-73c8620c-3979-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:49:02.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-v562m" for this suite.
Feb 26 03:49:08.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:49:08.901: INFO: namespace: e2e-tests-var-expansion-v562m, resource: bindings, ignored listing per whitelist
Feb 26 03:49:08.959: INFO: namespace e2e-tests-var-expansion-v562m deletion completed in 6.139314868s

• [SLOW TEST:8.625 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:49:08.959: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 26 03:49:09.411: INFO: Waiting up to 5m0s for pod "pod-78eaea77-3979-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-f224k" to be "success or failure"
Feb 26 03:49:09.413: INFO: Pod "pod-78eaea77-3979-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167723ms
Feb 26 03:49:11.417: INFO: Pod "pod-78eaea77-3979-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005436798s
STEP: Saw pod success
Feb 26 03:49:11.417: INFO: Pod "pod-78eaea77-3979-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:49:11.420: INFO: Trying to get logs from node darren-16001 pod pod-78eaea77-3979-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:49:11.432: INFO: Waiting for pod pod-78eaea77-3979-11e9-ac13-320deb251a37 to disappear
Feb 26 03:49:11.437: INFO: Pod pod-78eaea77-3979-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:49:11.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f224k" for this suite.
Feb 26 03:49:17.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:49:17.492: INFO: namespace: e2e-tests-emptydir-f224k, resource: bindings, ignored listing per whitelist
Feb 26 03:49:17.600: INFO: namespace e2e-tests-emptydir-f224k deletion completed in 6.156607456s

• [SLOW TEST:8.641 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:49:17.600: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 26 03:49:20.493: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:49:44.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-z4j6m" for this suite.
Feb 26 03:49:50.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:49:50.868: INFO: namespace: e2e-tests-namespaces-z4j6m, resource: bindings, ignored listing per whitelist
Feb 26 03:49:50.881: INFO: namespace e2e-tests-namespaces-z4j6m deletion completed in 6.166759555s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vrkvk" for this suite.
Feb 26 03:49:50.888: INFO: Namespace e2e-tests-nsdeletetest-vrkvk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-dth5x" for this suite.
Feb 26 03:49:56.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:49:56.997: INFO: namespace: e2e-tests-nsdeletetest-dth5x, resource: bindings, ignored listing per whitelist
Feb 26 03:49:57.034: INFO: namespace e2e-tests-nsdeletetest-dth5x deletion completed in 6.1464507s

• [SLOW TEST:39.434 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:49:57.035: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37
Feb 26 03:49:57.496: INFO: Pod name my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37: Found 0 pods out of 1
Feb 26 03:50:02.500: INFO: Pod name my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37: Found 1 pods out of 1
Feb 26 03:50:02.500: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37" are running
Feb 26 03:50:02.503: INFO: Pod "my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37-vtp7m" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 03:49:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 03:49:59 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 03:49:59 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-26 03:49:57 +0000 UTC Reason: Message:}])
Feb 26 03:50:02.503: INFO: Trying to dial the pod
Feb 26 03:50:07.516: INFO: Controller my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37: Got expected result from replica 1 [my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37-vtp7m]: "my-hostname-basic-959352a6-3979-11e9-ac13-320deb251a37-vtp7m", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:50:07.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6gjj5" for this suite.
Feb 26 03:50:13.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:50:13.580: INFO: namespace: e2e-tests-replication-controller-6gjj5, resource: bindings, ignored listing per whitelist
Feb 26 03:50:13.681: INFO: namespace e2e-tests-replication-controller-6gjj5 deletion completed in 6.160348401s

• [SLOW TEST:16.646 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:50:13.681: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 26 03:50:20.185: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:20.190: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:22.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:22.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:24.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:24.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:26.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:26.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:28.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:28.194: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:30.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:30.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:32.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:32.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:34.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:34.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:36.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:36.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:38.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:38.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:40.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:40.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:42.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:42.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:44.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:44.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:46.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:46.195: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 26 03:50:48.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 26 03:50:48.194: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:50:48.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-59nl5" for this suite.
Feb 26 03:51:10.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:51:10.294: INFO: namespace: e2e-tests-container-lifecycle-hook-59nl5, resource: bindings, ignored listing per whitelist
Feb 26 03:51:10.352: INFO: namespace e2e-tests-container-lifecycle-hook-59nl5 deletion completed in 22.153496573s

• [SLOW TEST:56.671 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:51:10.363: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 26 03:51:10.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 cluster-info'
Feb 26 03:51:11.139: INFO: stderr: ""
Feb 26 03:51:11.139: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:51:11.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mx55g" for this suite.
Feb 26 03:51:17.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:51:17.243: INFO: namespace: e2e-tests-kubectl-mx55g, resource: bindings, ignored listing per whitelist
Feb 26 03:51:17.333: INFO: namespace e2e-tests-kubectl-mx55g deletion completed in 6.189035009s

• [SLOW TEST:6.971 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:51:17.333: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 26 03:51:17.831: INFO: Waiting up to 5m0s for pod "client-containers-c5758510-3979-11e9-ac13-320deb251a37" in namespace "e2e-tests-containers-x6bgx" to be "success or failure"
Feb 26 03:51:17.836: INFO: Pod "client-containers-c5758510-3979-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 5.447851ms
Feb 26 03:51:19.839: INFO: Pod "client-containers-c5758510-3979-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008750818s
STEP: Saw pod success
Feb 26 03:51:19.839: INFO: Pod "client-containers-c5758510-3979-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:51:19.842: INFO: Trying to get logs from node darren-16001 pod client-containers-c5758510-3979-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 03:51:19.857: INFO: Waiting for pod client-containers-c5758510-3979-11e9-ac13-320deb251a37 to disappear
Feb 26 03:51:19.861: INFO: Pod client-containers-c5758510-3979-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:51:19.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-x6bgx" for this suite.
Feb 26 03:51:25.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:51:25.983: INFO: namespace: e2e-tests-containers-x6bgx, resource: bindings, ignored listing per whitelist
Feb 26 03:51:26.008: INFO: namespace e2e-tests-containers-x6bgx deletion completed in 6.143154083s

• [SLOW TEST:8.675 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:51:26.010: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ca9b4c1d-3979-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:51:26.465: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-lcth4" to be "success or failure"
Feb 26 03:51:26.473: INFO: Pod "pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032609ms
Feb 26 03:51:28.476: INFO: Pod "pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.011227256s
Feb 26 03:51:30.479: INFO: Pod "pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014399181s
STEP: Saw pod success
Feb 26 03:51:30.479: INFO: Pod "pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:51:30.482: INFO: Trying to get logs from node darren-2745 pod pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:51:30.494: INFO: Waiting for pod pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37 to disappear
Feb 26 03:51:30.497: INFO: Pod pod-projected-secrets-ca9c8092-3979-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:51:30.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lcth4" for this suite.
Feb 26 03:51:36.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:51:36.578: INFO: namespace: e2e-tests-projected-lcth4, resource: bindings, ignored listing per whitelist
Feb 26 03:51:36.637: INFO: namespace e2e-tests-projected-lcth4 deletion completed in 6.135620573s

• [SLOW TEST:10.627 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:51:36.637: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-gk6m4
I0226 03:51:37.088079      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-gk6m4, replica count: 1
I0226 03:51:38.138675      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0226 03:51:39.139014      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 26 03:51:39.247: INFO: Created: latency-svc-hmxzq
Feb 26 03:51:39.350: INFO: Got endpoints: latency-svc-hmxzq [111.725902ms]
Feb 26 03:51:39.360: INFO: Created: latency-svc-vfrzl
Feb 26 03:51:39.373: INFO: Created: latency-svc-96f8t
Feb 26 03:51:39.386: INFO: Created: latency-svc-8hlj9
Feb 26 03:51:39.404: INFO: Created: latency-svc-mvmk4
Feb 26 03:51:39.413: INFO: Created: latency-svc-rkqh9
Feb 26 03:51:39.421: INFO: Created: latency-svc-d5n6f
Feb 26 03:51:39.428: INFO: Created: latency-svc-44l9j
Feb 26 03:51:39.438: INFO: Created: latency-svc-mxsnm
Feb 26 03:51:39.446: INFO: Created: latency-svc-lxldk
Feb 26 03:51:39.452: INFO: Created: latency-svc-mc6rz
Feb 26 03:51:39.460: INFO: Created: latency-svc-ld95h
Feb 26 03:51:39.464: INFO: Got endpoints: latency-svc-mc6rz [112.97584ms]
Feb 26 03:51:39.464: INFO: Got endpoints: latency-svc-rkqh9 [113.187803ms]
Feb 26 03:51:39.465: INFO: Got endpoints: latency-svc-d5n6f [113.485629ms]
Feb 26 03:51:39.465: INFO: Got endpoints: latency-svc-mxsnm [114.006092ms]
Feb 26 03:51:39.465: INFO: Got endpoints: latency-svc-lxldk [113.867393ms]
Feb 26 03:51:39.465: INFO: Got endpoints: latency-svc-96f8t [114.346261ms]
Feb 26 03:51:39.465: INFO: Got endpoints: latency-svc-vfrzl [114.730372ms]
Feb 26 03:51:39.466: INFO: Got endpoints: latency-svc-8hlj9 [114.503701ms]
Feb 26 03:51:39.466: INFO: Got endpoints: latency-svc-mvmk4 [114.461139ms]
Feb 26 03:51:39.465: INFO: Got endpoints: latency-svc-44l9j [114.696697ms]
Feb 26 03:51:39.474: INFO: Created: latency-svc-4f8bk
Feb 26 03:51:39.486: INFO: Created: latency-svc-r8rzx
Feb 26 03:51:39.503: INFO: Created: latency-svc-c5hfx
Feb 26 03:51:39.510: INFO: Created: latency-svc-fn9v9
Feb 26 03:51:39.520: INFO: Created: latency-svc-v5h5f
Feb 26 03:51:39.539: INFO: Created: latency-svc-4gdhq
Feb 26 03:51:39.547: INFO: Created: latency-svc-s5mjq
Feb 26 03:51:39.550: INFO: Got endpoints: latency-svc-4gdhq [86.273105ms]
Feb 26 03:51:39.551: INFO: Got endpoints: latency-svc-ld95h [199.658502ms]
Feb 26 03:51:39.551: INFO: Got endpoints: latency-svc-4f8bk [199.611113ms]
Feb 26 03:51:39.551: INFO: Got endpoints: latency-svc-r8rzx [200.143482ms]
Feb 26 03:51:39.551: INFO: Got endpoints: latency-svc-c5hfx [200.122444ms]
Feb 26 03:51:39.551: INFO: Got endpoints: latency-svc-fn9v9 [200.273798ms]
Feb 26 03:51:39.551: INFO: Got endpoints: latency-svc-v5h5f [86.645917ms]
Feb 26 03:51:39.556: INFO: Created: latency-svc-8jz9n
Feb 26 03:51:39.566: INFO: Created: latency-svc-gl2xn
Feb 26 03:51:39.577: INFO: Created: latency-svc-wm54x
Feb 26 03:51:39.589: INFO: Created: latency-svc-qb5v6
Feb 26 03:51:39.601: INFO: Created: latency-svc-pbf4b
Feb 26 03:51:39.612: INFO: Created: latency-svc-ff45l
Feb 26 03:51:39.633: INFO: Created: latency-svc-7b65m
Feb 26 03:51:39.647: INFO: Created: latency-svc-rq7tz
Feb 26 03:51:39.657: INFO: Created: latency-svc-9qq2k
Feb 26 03:51:39.667: INFO: Created: latency-svc-7kz6n
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-9qq2k [121.226857ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-rq7tz [121.669153ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-pbf4b [205.652961ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-s5mjq [206.743852ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-qb5v6 [207.616941ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-ff45l [207.043306ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-wm54x [206.35164ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-gl2xn [206.741646ms]
Feb 26 03:51:39.672: INFO: Got endpoints: latency-svc-7b65m [206.463906ms]
Feb 26 03:51:39.673: INFO: Got endpoints: latency-svc-8jz9n [207.64901ms]
Feb 26 03:51:39.679: INFO: Created: latency-svc-p6glp
Feb 26 03:51:39.691: INFO: Created: latency-svc-gtwng
Feb 26 03:51:39.707: INFO: Created: latency-svc-tj59r
Feb 26 03:51:39.721: INFO: Created: latency-svc-zpn2x
Feb 26 03:51:39.734: INFO: Created: latency-svc-mlkxc
Feb 26 03:51:39.748: INFO: Created: latency-svc-ts4fs
Feb 26 03:51:39.750: INFO: Got endpoints: latency-svc-mlkxc [77.702941ms]
Feb 26 03:51:39.750: INFO: Got endpoints: latency-svc-gtwng [199.405653ms]
Feb 26 03:51:39.750: INFO: Got endpoints: latency-svc-tj59r [199.573676ms]
Feb 26 03:51:39.751: INFO: Got endpoints: latency-svc-7kz6n [199.910686ms]
Feb 26 03:51:39.751: INFO: Got endpoints: latency-svc-p6glp [199.535764ms]
Feb 26 03:51:39.751: INFO: Got endpoints: latency-svc-zpn2x [199.525357ms]
Feb 26 03:51:39.767: INFO: Created: latency-svc-8mglx
Feb 26 03:51:39.779: INFO: Created: latency-svc-cm5nh
Feb 26 03:51:39.792: INFO: Created: latency-svc-chm7m
Feb 26 03:51:39.804: INFO: Created: latency-svc-bnv62
Feb 26 03:51:39.816: INFO: Created: latency-svc-hmczk
Feb 26 03:51:39.828: INFO: Created: latency-svc-xmhl5
Feb 26 03:51:39.838: INFO: Created: latency-svc-4gw4p
Feb 26 03:51:39.850: INFO: Created: latency-svc-4n5sc
Feb 26 03:51:39.861: INFO: Created: latency-svc-nlshp
Feb 26 03:51:39.873: INFO: Created: latency-svc-n5ccs
Feb 26 03:51:39.886: INFO: Created: latency-svc-5vn97
Feb 26 03:51:39.899: INFO: Created: latency-svc-fnhbp
Feb 26 03:51:39.912: INFO: Created: latency-svc-dqdpb
Feb 26 03:51:39.924: INFO: Created: latency-svc-q4mx7
Feb 26 03:51:39.950: INFO: Got endpoints: latency-svc-4gw4p [278.028614ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-chm7m [277.970291ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-hmczk [278.154767ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-8mglx [277.941382ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-xmhl5 [278.45247ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-bnv62 [278.623653ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-ts4fs [278.006498ms]
Feb 26 03:51:39.951: INFO: Got endpoints: latency-svc-cm5nh [278.587603ms]
Feb 26 03:51:39.969: INFO: Created: latency-svc-v87t9
Feb 26 03:51:39.986: INFO: Created: latency-svc-vjpjm
Feb 26 03:51:39.997: INFO: Created: latency-svc-jr9mh
Feb 26 03:51:40.011: INFO: Created: latency-svc-g25rj
Feb 26 03:51:40.042: INFO: Created: latency-svc-rbt64
Feb 26 03:51:40.043: INFO: Created: latency-svc-gqndm
Feb 26 03:51:40.085: INFO: Created: latency-svc-jcjwp
Feb 26 03:51:40.104: INFO: Created: latency-svc-pk4zg
Feb 26 03:51:40.150: INFO: Got endpoints: latency-svc-5vn97 [399.830941ms]
Feb 26 03:51:40.150: INFO: Got endpoints: latency-svc-4n5sc [478.368197ms]
Feb 26 03:51:40.150: INFO: Got endpoints: latency-svc-n5ccs [400.012611ms]
Feb 26 03:51:40.151: INFO: Got endpoints: latency-svc-nlshp [400.243608ms]
Feb 26 03:51:40.165: INFO: Created: latency-svc-2bmtg
Feb 26 03:51:40.181: INFO: Created: latency-svc-nblfm
Feb 26 03:51:40.196: INFO: Created: latency-svc-h8j4h
Feb 26 03:51:40.207: INFO: Created: latency-svc-v7dvf
Feb 26 03:51:40.350: INFO: Got endpoints: latency-svc-v87t9 [399.654986ms]
Feb 26 03:51:40.350: INFO: Got endpoints: latency-svc-dqdpb [599.802841ms]
Feb 26 03:51:40.350: INFO: Got endpoints: latency-svc-q4mx7 [600.069573ms]
Feb 26 03:51:40.350: INFO: Got endpoints: latency-svc-fnhbp [599.719163ms]
Feb 26 03:51:40.366: INFO: Created: latency-svc-wdvpj
Feb 26 03:51:40.381: INFO: Created: latency-svc-mdbsj
Feb 26 03:51:40.394: INFO: Created: latency-svc-66s7c
Feb 26 03:51:40.407: INFO: Created: latency-svc-746mc
Feb 26 03:51:40.550: INFO: Got endpoints: latency-svc-rbt64 [599.57685ms]
Feb 26 03:51:40.550: INFO: Got endpoints: latency-svc-g25rj [599.670218ms]
Feb 26 03:51:40.550: INFO: Got endpoints: latency-svc-vjpjm [599.553702ms]
Feb 26 03:51:40.550: INFO: Got endpoints: latency-svc-jr9mh [599.813515ms]
Feb 26 03:51:40.575: INFO: Created: latency-svc-6xlmt
Feb 26 03:51:40.590: INFO: Created: latency-svc-98vn4
Feb 26 03:51:40.604: INFO: Created: latency-svc-b9mqj
Feb 26 03:51:40.616: INFO: Created: latency-svc-kqk4q
Feb 26 03:51:40.750: INFO: Got endpoints: latency-svc-2bmtg [599.654925ms]
Feb 26 03:51:40.751: INFO: Got endpoints: latency-svc-gqndm [800.207158ms]
Feb 26 03:51:40.751: INFO: Got endpoints: latency-svc-jcjwp [800.208565ms]
Feb 26 03:51:40.751: INFO: Got endpoints: latency-svc-pk4zg [800.308041ms]
Feb 26 03:51:40.771: INFO: Created: latency-svc-dntrx
Feb 26 03:51:40.782: INFO: Created: latency-svc-8d8f7
Feb 26 03:51:40.796: INFO: Created: latency-svc-cbsbd
Feb 26 03:51:40.811: INFO: Created: latency-svc-2sn4l
Feb 26 03:51:40.950: INFO: Got endpoints: latency-svc-h8j4h [799.869182ms]
Feb 26 03:51:40.950: INFO: Got endpoints: latency-svc-wdvpj [600.040632ms]
Feb 26 03:51:40.951: INFO: Got endpoints: latency-svc-nblfm [800.270922ms]
Feb 26 03:51:40.951: INFO: Got endpoints: latency-svc-v7dvf [800.21261ms]
Feb 26 03:51:40.969: INFO: Created: latency-svc-52twg
Feb 26 03:51:40.988: INFO: Created: latency-svc-54spl
Feb 26 03:51:41.009: INFO: Created: latency-svc-vts8m
Feb 26 03:51:41.019: INFO: Created: latency-svc-28xxb
Feb 26 03:51:41.150: INFO: Got endpoints: latency-svc-6xlmt [599.950119ms]
Feb 26 03:51:41.151: INFO: Got endpoints: latency-svc-mdbsj [799.979752ms]
Feb 26 03:51:41.151: INFO: Got endpoints: latency-svc-66s7c [800.217629ms]
Feb 26 03:51:41.151: INFO: Got endpoints: latency-svc-746mc [800.346917ms]
Feb 26 03:51:41.168: INFO: Created: latency-svc-7547r
Feb 26 03:51:41.186: INFO: Created: latency-svc-frmgf
Feb 26 03:51:41.202: INFO: Created: latency-svc-hmzxg
Feb 26 03:51:41.218: INFO: Created: latency-svc-7gq8w
Feb 26 03:51:41.350: INFO: Got endpoints: latency-svc-dntrx [600.004804ms]
Feb 26 03:51:41.350: INFO: Got endpoints: latency-svc-b9mqj [800.043886ms]
Feb 26 03:51:41.351: INFO: Got endpoints: latency-svc-98vn4 [800.117426ms]
Feb 26 03:51:41.351: INFO: Got endpoints: latency-svc-kqk4q [800.107837ms]
Feb 26 03:51:41.407: INFO: Created: latency-svc-s2h55
Feb 26 03:51:41.423: INFO: Created: latency-svc-8tz95
Feb 26 03:51:41.436: INFO: Created: latency-svc-xdmz9
Feb 26 03:51:41.458: INFO: Created: latency-svc-z8tbx
Feb 26 03:51:41.550: INFO: Got endpoints: latency-svc-52twg [599.523189ms]
Feb 26 03:51:41.551: INFO: Got endpoints: latency-svc-8d8f7 [800.005528ms]
Feb 26 03:51:41.551: INFO: Got endpoints: latency-svc-cbsbd [799.986696ms]
Feb 26 03:51:41.551: INFO: Got endpoints: latency-svc-2sn4l [799.947094ms]
Feb 26 03:51:41.573: INFO: Created: latency-svc-zkdlr
Feb 26 03:51:41.591: INFO: Created: latency-svc-mvs6c
Feb 26 03:51:41.612: INFO: Created: latency-svc-pzztp
Feb 26 03:51:41.633: INFO: Created: latency-svc-gdtzr
Feb 26 03:51:41.750: INFO: Got endpoints: latency-svc-vts8m [799.680774ms]
Feb 26 03:51:41.750: INFO: Got endpoints: latency-svc-7547r [599.693237ms]
Feb 26 03:51:41.751: INFO: Got endpoints: latency-svc-54spl [800.234267ms]
Feb 26 03:51:41.751: INFO: Got endpoints: latency-svc-28xxb [800.273887ms]
Feb 26 03:51:41.770: INFO: Created: latency-svc-htkt5
Feb 26 03:51:41.785: INFO: Created: latency-svc-xk7sx
Feb 26 03:51:41.803: INFO: Created: latency-svc-v2n72
Feb 26 03:51:41.821: INFO: Created: latency-svc-sxrm4
Feb 26 03:51:41.950: INFO: Got endpoints: latency-svc-s2h55 [599.724256ms]
Feb 26 03:51:41.951: INFO: Got endpoints: latency-svc-frmgf [800.046315ms]
Feb 26 03:51:41.951: INFO: Got endpoints: latency-svc-hmzxg [799.957166ms]
Feb 26 03:51:41.951: INFO: Got endpoints: latency-svc-7gq8w [800.566791ms]
Feb 26 03:51:41.968: INFO: Created: latency-svc-d69w6
Feb 26 03:51:41.987: INFO: Created: latency-svc-m8pv5
Feb 26 03:51:42.005: INFO: Created: latency-svc-42mdk
Feb 26 03:51:42.024: INFO: Created: latency-svc-62ppt
Feb 26 03:51:42.150: INFO: Got endpoints: latency-svc-zkdlr [599.964265ms]
Feb 26 03:51:42.150: INFO: Got endpoints: latency-svc-xdmz9 [800.004446ms]
Feb 26 03:51:42.151: INFO: Got endpoints: latency-svc-8tz95 [800.103053ms]
Feb 26 03:51:42.151: INFO: Got endpoints: latency-svc-z8tbx [799.980172ms]
Feb 26 03:51:42.174: INFO: Created: latency-svc-82kgx
Feb 26 03:51:42.198: INFO: Created: latency-svc-brlrq
Feb 26 03:51:42.216: INFO: Created: latency-svc-qjbhb
Feb 26 03:51:42.238: INFO: Created: latency-svc-794dd
Feb 26 03:51:42.350: INFO: Got endpoints: latency-svc-mvs6c [799.610991ms]
Feb 26 03:51:42.350: INFO: Got endpoints: latency-svc-pzztp [799.714954ms]
Feb 26 03:51:42.351: INFO: Got endpoints: latency-svc-htkt5 [600.285067ms]
Feb 26 03:51:42.351: INFO: Got endpoints: latency-svc-gdtzr [799.956484ms]
Feb 26 03:51:42.374: INFO: Created: latency-svc-qdmlm
Feb 26 03:51:42.394: INFO: Created: latency-svc-jblgc
Feb 26 03:51:42.431: INFO: Created: latency-svc-r9fxk
Feb 26 03:51:42.476: INFO: Created: latency-svc-7hrfk
Feb 26 03:51:42.550: INFO: Got endpoints: latency-svc-d69w6 [599.64536ms]
Feb 26 03:51:42.551: INFO: Got endpoints: latency-svc-xk7sx [800.192505ms]
Feb 26 03:51:42.551: INFO: Got endpoints: latency-svc-v2n72 [800.067239ms]
Feb 26 03:51:42.551: INFO: Got endpoints: latency-svc-sxrm4 [800.186111ms]
Feb 26 03:51:42.575: INFO: Created: latency-svc-xwqwq
Feb 26 03:51:42.591: INFO: Created: latency-svc-qt27t
Feb 26 03:51:42.609: INFO: Created: latency-svc-tbqln
Feb 26 03:51:42.636: INFO: Created: latency-svc-75njh
Feb 26 03:51:42.750: INFO: Got endpoints: latency-svc-42mdk [799.537868ms]
Feb 26 03:51:42.750: INFO: Got endpoints: latency-svc-62ppt [799.444863ms]
Feb 26 03:51:42.750: INFO: Got endpoints: latency-svc-82kgx [599.836529ms]
Feb 26 03:51:42.750: INFO: Got endpoints: latency-svc-m8pv5 [799.979128ms]
Feb 26 03:51:42.779: INFO: Created: latency-svc-v2wtx
Feb 26 03:51:42.801: INFO: Created: latency-svc-2djkg
Feb 26 03:51:42.823: INFO: Created: latency-svc-8c2nv
Feb 26 03:51:42.844: INFO: Created: latency-svc-sf62s
Feb 26 03:51:42.950: INFO: Got endpoints: latency-svc-qdmlm [599.498186ms]
Feb 26 03:51:42.950: INFO: Got endpoints: latency-svc-794dd [799.692337ms]
Feb 26 03:51:42.950: INFO: Got endpoints: latency-svc-qjbhb [799.856693ms]
Feb 26 03:51:42.950: INFO: Got endpoints: latency-svc-brlrq [799.946843ms]
Feb 26 03:51:42.974: INFO: Created: latency-svc-669wh
Feb 26 03:51:42.991: INFO: Created: latency-svc-xvlsb
Feb 26 03:51:43.012: INFO: Created: latency-svc-cg5xd
Feb 26 03:51:43.030: INFO: Created: latency-svc-nvzzb
Feb 26 03:51:43.150: INFO: Got endpoints: latency-svc-jblgc [799.62827ms]
Feb 26 03:51:43.150: INFO: Got endpoints: latency-svc-r9fxk [800.005826ms]
Feb 26 03:51:43.151: INFO: Got endpoints: latency-svc-xwqwq [599.827021ms]
Feb 26 03:51:43.151: INFO: Got endpoints: latency-svc-7hrfk [800.241826ms]
Feb 26 03:51:43.174: INFO: Created: latency-svc-r6cfh
Feb 26 03:51:43.198: INFO: Created: latency-svc-s4sgc
Feb 26 03:51:43.216: INFO: Created: latency-svc-5cc9j
Feb 26 03:51:43.242: INFO: Created: latency-svc-47tq8
Feb 26 03:51:43.350: INFO: Got endpoints: latency-svc-v2wtx [599.826732ms]
Feb 26 03:51:43.350: INFO: Got endpoints: latency-svc-tbqln [799.997503ms]
Feb 26 03:51:43.350: INFO: Got endpoints: latency-svc-qt27t [799.743721ms]
Feb 26 03:51:43.351: INFO: Got endpoints: latency-svc-75njh [799.888153ms]
Feb 26 03:51:43.381: INFO: Created: latency-svc-lr99j
Feb 26 03:51:43.403: INFO: Created: latency-svc-zpjsb
Feb 26 03:51:43.426: INFO: Created: latency-svc-j4bbb
Feb 26 03:51:43.442: INFO: Created: latency-svc-pbtgx
Feb 26 03:51:43.550: INFO: Got endpoints: latency-svc-8c2nv [799.840313ms]
Feb 26 03:51:43.550: INFO: Got endpoints: latency-svc-669wh [600.002398ms]
Feb 26 03:51:43.550: INFO: Got endpoints: latency-svc-sf62s [799.709964ms]
Feb 26 03:51:43.550: INFO: Got endpoints: latency-svc-2djkg [799.633059ms]
Feb 26 03:51:43.579: INFO: Created: latency-svc-6j5bs
Feb 26 03:51:43.600: INFO: Created: latency-svc-8lhgt
Feb 26 03:51:43.618: INFO: Created: latency-svc-g7l56
Feb 26 03:51:43.645: INFO: Created: latency-svc-2d8ns
Feb 26 03:51:43.750: INFO: Got endpoints: latency-svc-r6cfh [599.897513ms]
Feb 26 03:51:43.751: INFO: Got endpoints: latency-svc-cg5xd [799.97356ms]
Feb 26 03:51:43.751: INFO: Got endpoints: latency-svc-xvlsb [799.826995ms]
Feb 26 03:51:43.751: INFO: Got endpoints: latency-svc-nvzzb [800.307972ms]
Feb 26 03:51:43.783: INFO: Created: latency-svc-gjr5h
Feb 26 03:51:43.803: INFO: Created: latency-svc-5frl2
Feb 26 03:51:43.823: INFO: Created: latency-svc-xzjdl
Feb 26 03:51:43.845: INFO: Created: latency-svc-r7s59
Feb 26 03:51:43.950: INFO: Got endpoints: latency-svc-lr99j [599.875384ms]
Feb 26 03:51:43.951: INFO: Got endpoints: latency-svc-5cc9j [800.007206ms]
Feb 26 03:51:43.951: INFO: Got endpoints: latency-svc-s4sgc [800.22604ms]
Feb 26 03:51:43.951: INFO: Got endpoints: latency-svc-47tq8 [799.996907ms]
Feb 26 03:51:43.975: INFO: Created: latency-svc-q48fd
Feb 26 03:51:43.995: INFO: Created: latency-svc-qf6bb
Feb 26 03:51:44.014: INFO: Created: latency-svc-7mfcz
Feb 26 03:51:44.038: INFO: Created: latency-svc-l47fv
Feb 26 03:51:44.150: INFO: Got endpoints: latency-svc-6j5bs [599.85322ms]
Feb 26 03:51:44.150: INFO: Got endpoints: latency-svc-zpjsb [799.925595ms]
Feb 26 03:51:44.151: INFO: Got endpoints: latency-svc-pbtgx [799.796628ms]
Feb 26 03:51:44.150: INFO: Got endpoints: latency-svc-j4bbb [799.764902ms]
Feb 26 03:51:44.176: INFO: Created: latency-svc-2b5wq
Feb 26 03:51:44.196: INFO: Created: latency-svc-h28kj
Feb 26 03:51:44.215: INFO: Created: latency-svc-lnkz4
Feb 26 03:51:44.237: INFO: Created: latency-svc-2dmwj
Feb 26 03:51:44.350: INFO: Got endpoints: latency-svc-gjr5h [599.789338ms]
Feb 26 03:51:44.351: INFO: Got endpoints: latency-svc-8lhgt [799.797176ms]
Feb 26 03:51:44.351: INFO: Got endpoints: latency-svc-g7l56 [799.980156ms]
Feb 26 03:51:44.351: INFO: Got endpoints: latency-svc-2d8ns [800.057734ms]
Feb 26 03:51:44.386: INFO: Created: latency-svc-rhrjz
Feb 26 03:51:44.412: INFO: Created: latency-svc-kfkvt
Feb 26 03:51:44.440: INFO: Created: latency-svc-kflfb
Feb 26 03:51:44.466: INFO: Created: latency-svc-t97fb
Feb 26 03:51:44.550: INFO: Got endpoints: latency-svc-q48fd [599.670646ms]
Feb 26 03:51:44.550: INFO: Got endpoints: latency-svc-xzjdl [799.948027ms]
Feb 26 03:51:44.550: INFO: Got endpoints: latency-svc-r7s59 [799.865222ms]
Feb 26 03:51:44.550: INFO: Got endpoints: latency-svc-5frl2 [799.728454ms]
Feb 26 03:51:44.574: INFO: Created: latency-svc-6dkgb
Feb 26 03:51:44.594: INFO: Created: latency-svc-pqzxc
Feb 26 03:51:44.616: INFO: Created: latency-svc-84b9z
Feb 26 03:51:44.638: INFO: Created: latency-svc-v2trs
Feb 26 03:51:44.750: INFO: Got endpoints: latency-svc-2b5wq [599.692391ms]
Feb 26 03:51:44.750: INFO: Got endpoints: latency-svc-qf6bb [799.647279ms]
Feb 26 03:51:44.750: INFO: Got endpoints: latency-svc-l47fv [799.924553ms]
Feb 26 03:51:44.750: INFO: Got endpoints: latency-svc-7mfcz [799.598852ms]
Feb 26 03:51:44.779: INFO: Created: latency-svc-5jxhc
Feb 26 03:51:44.801: INFO: Created: latency-svc-prr8v
Feb 26 03:51:44.826: INFO: Created: latency-svc-tpp6k
Feb 26 03:51:44.884: INFO: Created: latency-svc-hnc4r
Feb 26 03:51:44.950: INFO: Got endpoints: latency-svc-rhrjz [599.972259ms]
Feb 26 03:51:44.950: INFO: Got endpoints: latency-svc-h28kj [800.035841ms]
Feb 26 03:51:44.950: INFO: Got endpoints: latency-svc-2dmwj [799.782309ms]
Feb 26 03:51:44.950: INFO: Got endpoints: latency-svc-lnkz4 [800.007743ms]
Feb 26 03:51:44.977: INFO: Created: latency-svc-bgvsm
Feb 26 03:51:45.004: INFO: Created: latency-svc-btvrx
Feb 26 03:51:45.027: INFO: Created: latency-svc-8wvwh
Feb 26 03:51:45.051: INFO: Created: latency-svc-62w92
Feb 26 03:51:45.150: INFO: Got endpoints: latency-svc-kflfb [799.619131ms]
Feb 26 03:51:45.150: INFO: Got endpoints: latency-svc-t97fb [799.529794ms]
Feb 26 03:51:45.150: INFO: Got endpoints: latency-svc-6dkgb [600.023836ms]
Feb 26 03:51:45.150: INFO: Got endpoints: latency-svc-kfkvt [799.759142ms]
Feb 26 03:51:45.183: INFO: Created: latency-svc-7n9wc
Feb 26 03:51:45.207: INFO: Created: latency-svc-pvw77
Feb 26 03:51:45.231: INFO: Created: latency-svc-rjsks
Feb 26 03:51:45.262: INFO: Created: latency-svc-27szs
Feb 26 03:51:45.350: INFO: Got endpoints: latency-svc-5jxhc [599.93767ms]
Feb 26 03:51:45.350: INFO: Got endpoints: latency-svc-84b9z [800.017915ms]
Feb 26 03:51:45.350: INFO: Got endpoints: latency-svc-pqzxc [799.960096ms]
Feb 26 03:51:45.350: INFO: Got endpoints: latency-svc-v2trs [800.045333ms]
Feb 26 03:51:45.382: INFO: Created: latency-svc-25ghj
Feb 26 03:51:45.404: INFO: Created: latency-svc-lcszf
Feb 26 03:51:45.430: INFO: Created: latency-svc-rf87k
Feb 26 03:51:45.457: INFO: Created: latency-svc-pjsc6
Feb 26 03:51:45.550: INFO: Got endpoints: latency-svc-prr8v [799.937732ms]
Feb 26 03:51:45.550: INFO: Got endpoints: latency-svc-tpp6k [799.998508ms]
Feb 26 03:51:45.551: INFO: Got endpoints: latency-svc-bgvsm [600.137422ms]
Feb 26 03:51:45.551: INFO: Got endpoints: latency-svc-hnc4r [800.2224ms]
Feb 26 03:51:45.589: INFO: Created: latency-svc-p6lqh
Feb 26 03:51:45.611: INFO: Created: latency-svc-fpwm4
Feb 26 03:51:45.637: INFO: Created: latency-svc-hjw8n
Feb 26 03:51:45.664: INFO: Created: latency-svc-jdfkv
Feb 26 03:51:45.750: INFO: Got endpoints: latency-svc-btvrx [799.966425ms]
Feb 26 03:51:45.751: INFO: Got endpoints: latency-svc-8wvwh [799.993196ms]
Feb 26 03:51:45.751: INFO: Got endpoints: latency-svc-7n9wc [600.095693ms]
Feb 26 03:51:45.751: INFO: Got endpoints: latency-svc-62w92 [800.364309ms]
Feb 26 03:51:45.778: INFO: Created: latency-svc-z9kcb
Feb 26 03:51:45.801: INFO: Created: latency-svc-92tvn
Feb 26 03:51:45.826: INFO: Created: latency-svc-g7lsx
Feb 26 03:51:45.849: INFO: Created: latency-svc-xbfks
Feb 26 03:51:45.950: INFO: Got endpoints: latency-svc-25ghj [599.775737ms]
Feb 26 03:51:45.950: INFO: Got endpoints: latency-svc-rjsks [799.897836ms]
Feb 26 03:51:45.950: INFO: Got endpoints: latency-svc-27szs [799.958011ms]
Feb 26 03:51:45.951: INFO: Got endpoints: latency-svc-pvw77 [799.923381ms]
Feb 26 03:51:45.988: INFO: Created: latency-svc-vtd2n
Feb 26 03:51:46.023: INFO: Created: latency-svc-sq8vs
Feb 26 03:51:46.055: INFO: Created: latency-svc-wv8v2
Feb 26 03:51:46.081: INFO: Created: latency-svc-hzpzh
Feb 26 03:51:46.150: INFO: Got endpoints: latency-svc-p6lqh [599.919218ms]
Feb 26 03:51:46.150: INFO: Got endpoints: latency-svc-rf87k [799.817861ms]
Feb 26 03:51:46.150: INFO: Got endpoints: latency-svc-pjsc6 [799.817498ms]
Feb 26 03:51:46.151: INFO: Got endpoints: latency-svc-lcszf [800.069235ms]
Feb 26 03:51:46.180: INFO: Created: latency-svc-jg2q8
Feb 26 03:51:46.211: INFO: Created: latency-svc-5dgf6
Feb 26 03:51:46.233: INFO: Created: latency-svc-d887h
Feb 26 03:51:46.257: INFO: Created: latency-svc-zpv7l
Feb 26 03:51:46.350: INFO: Got endpoints: latency-svc-z9kcb [599.890197ms]
Feb 26 03:51:46.350: INFO: Got endpoints: latency-svc-hjw8n [799.773886ms]
Feb 26 03:51:46.350: INFO: Got endpoints: latency-svc-jdfkv [800.012689ms]
Feb 26 03:51:46.351: INFO: Got endpoints: latency-svc-fpwm4 [799.78332ms]
Feb 26 03:51:46.382: INFO: Created: latency-svc-hlg5j
Feb 26 03:51:46.407: INFO: Created: latency-svc-4pkl4
Feb 26 03:51:46.435: INFO: Created: latency-svc-4j5qg
Feb 26 03:51:46.462: INFO: Created: latency-svc-pwvbv
Feb 26 03:51:46.550: INFO: Got endpoints: latency-svc-g7lsx [799.832421ms]
Feb 26 03:51:46.550: INFO: Got endpoints: latency-svc-xbfks [799.595676ms]
Feb 26 03:51:46.550: INFO: Got endpoints: latency-svc-92tvn [799.505158ms]
Feb 26 03:51:46.550: INFO: Got endpoints: latency-svc-vtd2n [599.96566ms]
Feb 26 03:51:46.582: INFO: Created: latency-svc-rt8zv
Feb 26 03:51:46.606: INFO: Created: latency-svc-sxfnr
Feb 26 03:51:46.629: INFO: Created: latency-svc-2qdpj
Feb 26 03:51:46.654: INFO: Created: latency-svc-rgs4f
Feb 26 03:51:46.750: INFO: Got endpoints: latency-svc-jg2q8 [599.958103ms]
Feb 26 03:51:46.750: INFO: Got endpoints: latency-svc-sq8vs [799.92341ms]
Feb 26 03:51:46.750: INFO: Got endpoints: latency-svc-wv8v2 [799.931629ms]
Feb 26 03:51:46.751: INFO: Got endpoints: latency-svc-hzpzh [800.111577ms]
Feb 26 03:51:46.784: INFO: Created: latency-svc-rw89p
Feb 26 03:51:46.809: INFO: Created: latency-svc-cpw4k
Feb 26 03:51:46.834: INFO: Created: latency-svc-mhgf4
Feb 26 03:51:46.858: INFO: Created: latency-svc-s4dcl
Feb 26 03:51:46.950: INFO: Got endpoints: latency-svc-hlg5j [600.005155ms]
Feb 26 03:51:46.950: INFO: Got endpoints: latency-svc-d887h [799.88493ms]
Feb 26 03:51:46.951: INFO: Got endpoints: latency-svc-zpv7l [800.103087ms]
Feb 26 03:51:46.951: INFO: Got endpoints: latency-svc-5dgf6 [800.301139ms]
Feb 26 03:51:46.981: INFO: Created: latency-svc-pjpdk
Feb 26 03:51:47.003: INFO: Created: latency-svc-8xt6m
Feb 26 03:51:47.027: INFO: Created: latency-svc-b9nsr
Feb 26 03:51:47.049: INFO: Created: latency-svc-hzrj7
Feb 26 03:51:47.150: INFO: Got endpoints: latency-svc-rt8zv [599.890456ms]
Feb 26 03:51:47.151: INFO: Got endpoints: latency-svc-4pkl4 [800.156787ms]
Feb 26 03:51:47.151: INFO: Got endpoints: latency-svc-4j5qg [800.310784ms]
Feb 26 03:51:47.151: INFO: Got endpoints: latency-svc-pwvbv [800.520567ms]
Feb 26 03:51:47.183: INFO: Created: latency-svc-dvc8k
Feb 26 03:51:47.211: INFO: Created: latency-svc-bvbkb
Feb 26 03:51:47.239: INFO: Created: latency-svc-x7596
Feb 26 03:51:47.267: INFO: Created: latency-svc-mnm79
Feb 26 03:51:47.350: INFO: Got endpoints: latency-svc-rw89p [599.814777ms]
Feb 26 03:51:47.350: INFO: Got endpoints: latency-svc-sxfnr [799.918676ms]
Feb 26 03:51:47.350: INFO: Got endpoints: latency-svc-2qdpj [799.659872ms]
Feb 26 03:51:47.350: INFO: Got endpoints: latency-svc-rgs4f [799.597542ms]
Feb 26 03:51:47.550: INFO: Got endpoints: latency-svc-pjpdk [599.810777ms]
Feb 26 03:51:47.550: INFO: Got endpoints: latency-svc-cpw4k [799.896054ms]
Feb 26 03:51:47.550: INFO: Got endpoints: latency-svc-mhgf4 [799.907657ms]
Feb 26 03:51:47.550: INFO: Got endpoints: latency-svc-s4dcl [799.844772ms]
Feb 26 03:51:47.750: INFO: Got endpoints: latency-svc-dvc8k [599.675223ms]
Feb 26 03:51:47.750: INFO: Got endpoints: latency-svc-8xt6m [799.96759ms]
Feb 26 03:51:47.750: INFO: Got endpoints: latency-svc-b9nsr [799.934892ms]
Feb 26 03:51:47.750: INFO: Got endpoints: latency-svc-hzrj7 [799.714589ms]
Feb 26 03:51:47.950: INFO: Got endpoints: latency-svc-mnm79 [799.517661ms]
Feb 26 03:51:47.950: INFO: Got endpoints: latency-svc-bvbkb [799.98921ms]
Feb 26 03:51:47.950: INFO: Got endpoints: latency-svc-x7596 [799.447473ms]
Feb 26 03:51:47.950: INFO: Latencies: [77.702941ms 86.273105ms 86.645917ms 112.97584ms 113.187803ms 113.485629ms 113.867393ms 114.006092ms 114.346261ms 114.461139ms 114.503701ms 114.696697ms 114.730372ms 121.226857ms 121.669153ms 199.405653ms 199.525357ms 199.535764ms 199.573676ms 199.611113ms 199.658502ms 199.910686ms 200.122444ms 200.143482ms 200.273798ms 205.652961ms 206.35164ms 206.463906ms 206.741646ms 206.743852ms 207.043306ms 207.616941ms 207.64901ms 277.941382ms 277.970291ms 278.006498ms 278.028614ms 278.154767ms 278.45247ms 278.587603ms 278.623653ms 399.654986ms 399.830941ms 400.012611ms 400.243608ms 478.368197ms 599.498186ms 599.523189ms 599.553702ms 599.57685ms 599.64536ms 599.654925ms 599.670218ms 599.670646ms 599.675223ms 599.692391ms 599.693237ms 599.719163ms 599.724256ms 599.775737ms 599.789338ms 599.802841ms 599.810777ms 599.813515ms 599.814777ms 599.826732ms 599.827021ms 599.836529ms 599.85322ms 599.875384ms 599.890197ms 599.890456ms 599.897513ms 599.919218ms 599.93767ms 599.950119ms 599.958103ms 599.964265ms 599.96566ms 599.972259ms 600.002398ms 600.004804ms 600.005155ms 600.023836ms 600.040632ms 600.069573ms 600.095693ms 600.137422ms 600.285067ms 799.444863ms 799.447473ms 799.505158ms 799.517661ms 799.529794ms 799.537868ms 799.595676ms 799.597542ms 799.598852ms 799.610991ms 799.619131ms 799.62827ms 799.633059ms 799.647279ms 799.659872ms 799.680774ms 799.692337ms 799.709964ms 799.714589ms 799.714954ms 799.728454ms 799.743721ms 799.759142ms 799.764902ms 799.773886ms 799.782309ms 799.78332ms 799.796628ms 799.797176ms 799.817498ms 799.817861ms 799.826995ms 799.832421ms 799.840313ms 799.844772ms 799.856693ms 799.865222ms 799.869182ms 799.88493ms 799.888153ms 799.896054ms 799.897836ms 799.907657ms 799.918676ms 799.923381ms 799.92341ms 799.924553ms 799.925595ms 799.931629ms 799.934892ms 799.937732ms 799.946843ms 799.947094ms 799.948027ms 799.956484ms 799.957166ms 799.958011ms 799.960096ms 799.966425ms 799.96759ms 799.97356ms 799.979128ms 799.979752ms 799.980156ms 799.980172ms 799.986696ms 799.98921ms 799.993196ms 799.996907ms 799.997503ms 799.998508ms 800.004446ms 800.005528ms 800.005826ms 800.007206ms 800.007743ms 800.012689ms 800.017915ms 800.035841ms 800.043886ms 800.045333ms 800.046315ms 800.057734ms 800.067239ms 800.069235ms 800.103053ms 800.103087ms 800.107837ms 800.111577ms 800.117426ms 800.156787ms 800.186111ms 800.192505ms 800.207158ms 800.208565ms 800.21261ms 800.217629ms 800.2224ms 800.22604ms 800.234267ms 800.241826ms 800.270922ms 800.273887ms 800.301139ms 800.307972ms 800.308041ms 800.310784ms 800.346917ms 800.364309ms 800.520567ms 800.566791ms]
Feb 26 03:51:47.951: INFO: 50 %ile: 799.62827ms
Feb 26 03:51:47.951: INFO: 90 %ile: 800.186111ms
Feb 26 03:51:47.951: INFO: 99 %ile: 800.520567ms
Feb 26 03:51:47.951: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:51:47.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-gk6m4" for this suite.
Feb 26 03:52:03.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:52:04.073: INFO: namespace: e2e-tests-svc-latency-gk6m4, resource: bindings, ignored listing per whitelist
Feb 26 03:52:04.387: INFO: namespace e2e-tests-svc-latency-gk6m4 deletion completed in 16.427154935s

• [SLOW TEST:27.749 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:52:04.387: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 03:52:04.860: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-rzfmg" to be "success or failure"
Feb 26 03:52:04.863: INFO: Pod "downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.011794ms
Feb 26 03:52:06.867: INFO: Pod "downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006300202s
STEP: Saw pod success
Feb 26 03:52:06.867: INFO: Pod "downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:52:06.869: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 03:52:06.891: INFO: Waiting for pod downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37 to disappear
Feb 26 03:52:06.905: INFO: Pod downwardapi-volume-e17c6bf2-3979-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:52:06.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rzfmg" for this suite.
Feb 26 03:52:12.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:52:13.056: INFO: namespace: e2e-tests-projected-rzfmg, resource: bindings, ignored listing per whitelist
Feb 26 03:52:13.079: INFO: namespace e2e-tests-projected-rzfmg deletion completed in 6.15978848s

• [SLOW TEST:8.692 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:52:13.079: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 26 03:52:13.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:13.753: INFO: stderr: ""
Feb 26 03:52:13.753: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 26 03:52:13.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:13.871: INFO: stderr: ""
Feb 26 03:52:13.871: INFO: stdout: "update-demo-nautilus-hq59h update-demo-nautilus-s5g84 "
Feb 26 03:52:13.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-hq59h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:13.959: INFO: stderr: ""
Feb 26 03:52:13.959: INFO: stdout: ""
Feb 26 03:52:13.959: INFO: update-demo-nautilus-hq59h is created but not running
Feb 26 03:52:18.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.074: INFO: stderr: ""
Feb 26 03:52:19.074: INFO: stdout: "update-demo-nautilus-hq59h update-demo-nautilus-s5g84 "
Feb 26 03:52:19.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-hq59h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.182: INFO: stderr: ""
Feb 26 03:52:19.182: INFO: stdout: "true"
Feb 26 03:52:19.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-hq59h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.273: INFO: stderr: ""
Feb 26 03:52:19.273: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:52:19.273: INFO: validating pod update-demo-nautilus-hq59h
Feb 26 03:52:19.276: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:52:19.276: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:52:19.276: INFO: update-demo-nautilus-hq59h is verified up and running
Feb 26 03:52:19.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-s5g84 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.375: INFO: stderr: ""
Feb 26 03:52:19.375: INFO: stdout: "true"
Feb 26 03:52:19.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods update-demo-nautilus-s5g84 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.484: INFO: stderr: ""
Feb 26 03:52:19.484: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 26 03:52:19.484: INFO: validating pod update-demo-nautilus-s5g84
Feb 26 03:52:19.490: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 26 03:52:19.490: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 26 03:52:19.490: INFO: update-demo-nautilus-s5g84 is verified up and running
STEP: using delete to clean up resources
Feb 26 03:52:19.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.599: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 03:52:19.599: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 26 03:52:19.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zzt79'
Feb 26 03:52:19.713: INFO: stderr: "No resources found.\n"
Feb 26 03:52:19.713: INFO: stdout: ""
Feb 26 03:52:19.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zzt79 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 26 03:52:19.830: INFO: stderr: ""
Feb 26 03:52:19.830: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:52:19.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zzt79" for this suite.
Feb 26 03:52:41.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:52:41.959: INFO: namespace: e2e-tests-kubectl-zzt79, resource: bindings, ignored listing per whitelist
Feb 26 03:52:41.970: INFO: namespace e2e-tests-kubectl-zzt79 deletion completed in 22.135065011s

• [SLOW TEST:28.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:52:41.970: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-fhqpm
Feb 26 03:52:46.431: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-fhqpm
STEP: checking the pod's current state and verifying that restartCount is present
Feb 26 03:52:46.433: INFO: Initial restart count of pod liveness-http is 0
Feb 26 03:53:06.469: INFO: Restart count of pod e2e-tests-container-probe-fhqpm/liveness-http is now 1 (20.035563768s elapsed)
Feb 26 03:53:24.498: INFO: Restart count of pod e2e-tests-container-probe-fhqpm/liveness-http is now 2 (38.064540123s elapsed)
Feb 26 03:53:44.529: INFO: Restart count of pod e2e-tests-container-probe-fhqpm/liveness-http is now 3 (58.095455919s elapsed)
Feb 26 03:54:04.561: INFO: Restart count of pod e2e-tests-container-probe-fhqpm/liveness-http is now 4 (1m18.127365736s elapsed)
Feb 26 03:55:06.662: INFO: Restart count of pod e2e-tests-container-probe-fhqpm/liveness-http is now 5 (2m20.228369491s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:55:06.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fhqpm" for this suite.
Feb 26 03:55:12.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:55:12.743: INFO: namespace: e2e-tests-container-probe-fhqpm, resource: bindings, ignored listing per whitelist
Feb 26 03:55:12.876: INFO: namespace e2e-tests-container-probe-fhqpm deletion completed in 6.203125405s

• [SLOW TEST:150.906 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:55:12.879: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0226 03:55:19.384786      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 26 03:55:19.384: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:55:19.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pdjdd" for this suite.
Feb 26 03:55:25.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:55:25.471: INFO: namespace: e2e-tests-gc-pdjdd, resource: bindings, ignored listing per whitelist
Feb 26 03:55:25.576: INFO: namespace e2e-tests-gc-pdjdd deletion completed in 6.187196864s

• [SLOW TEST:12.697 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:55:25.576: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-5967f2ed-397a-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 03:55:26.056: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-8v8qq" to be "success or failure"
Feb 26 03:55:26.058: INFO: Pod "pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.247054ms
Feb 26 03:55:28.061: INFO: Pod "pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00523233s
STEP: Saw pod success
Feb 26 03:55:28.061: INFO: Pod "pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 03:55:28.064: INFO: Trying to get logs from node darren-2745 pod pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 26 03:55:28.076: INFO: Waiting for pod pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37 to disappear
Feb 26 03:55:28.083: INFO: Pod pod-projected-secrets-596996cb-397a-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:55:28.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8v8qq" for this suite.
Feb 26 03:55:34.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:55:34.194: INFO: namespace: e2e-tests-projected-8v8qq, resource: bindings, ignored listing per whitelist
Feb 26 03:55:34.293: INFO: namespace e2e-tests-projected-8v8qq deletion completed in 6.202010978s

• [SLOW TEST:8.717 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:55:34.293: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-78zc6
Feb 26 03:55:36.762: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-78zc6
STEP: checking the pod's current state and verifying that restartCount is present
Feb 26 03:55:36.765: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:59:37.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-78zc6" for this suite.
Feb 26 03:59:43.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 03:59:43.324: INFO: namespace: e2e-tests-container-probe-78zc6, resource: bindings, ignored listing per whitelist
Feb 26 03:59:43.327: INFO: namespace e2e-tests-container-probe-78zc6 deletion completed in 6.143531787s

• [SLOW TEST:249.035 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 03:59:43.329: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 26 03:59:47.810: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:47.810: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:47.914: INFO: Exec stderr: ""
Feb 26 03:59:47.914: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:47.914: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.025: INFO: Exec stderr: ""
Feb 26 03:59:48.025: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.025: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.123: INFO: Exec stderr: ""
Feb 26 03:59:48.123: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.123: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.217: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 26 03:59:48.217: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.217: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.329: INFO: Exec stderr: ""
Feb 26 03:59:48.329: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.329: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.444: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 26 03:59:48.444: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.444: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.584: INFO: Exec stderr: ""
Feb 26 03:59:48.584: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.584: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.690: INFO: Exec stderr: ""
Feb 26 03:59:48.690: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.690: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.836: INFO: Exec stderr: ""
Feb 26 03:59:48.836: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-t9p28 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 03:59:48.836: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 03:59:48.940: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 03:59:48.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-t9p28" for this suite.
Feb 26 04:00:38.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:00:39.104: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-t9p28, resource: bindings, ignored listing per whitelist
Feb 26 04:00:39.111: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-t9p28 deletion completed in 50.166995338s

• [SLOW TEST:55.782 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:00:39.111: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v7xzr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 26 04:00:39.578: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 26 04:00:57.649: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.145:8080/dial?request=hostName&protocol=http&host=10.42.0.146&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-v7xzr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 04:00:57.650: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 04:00:57.821: INFO: Waiting for endpoints: map[]
Feb 26 04:00:57.823: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.1.145:8080/dial?request=hostName&protocol=http&host=10.42.1.144&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-v7xzr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 04:00:57.823: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 04:00:57.946: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:00:57.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v7xzr" for this suite.
Feb 26 04:01:19.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:01:20.002: INFO: namespace: e2e-tests-pod-network-test-v7xzr, resource: bindings, ignored listing per whitelist
Feb 26 04:01:20.095: INFO: namespace e2e-tests-pod-network-test-v7xzr deletion completed in 22.14371472s

• [SLOW TEST:40.984 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:01:20.095: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0226 04:01:51.099508      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 26 04:01:51.099: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:01:51.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-74pnp" for this suite.
Feb 26 04:01:57.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:01:57.193: INFO: namespace: e2e-tests-gc-74pnp, resource: bindings, ignored listing per whitelist
Feb 26 04:01:57.296: INFO: namespace e2e-tests-gc-74pnp deletion completed in 6.193315912s

• [SLOW TEST:37.202 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:01:57.297: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 26 04:01:57.774: INFO: Waiting up to 5m0s for pod "pod-42e5c1c8-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-8vz64" to be "success or failure"
Feb 26 04:01:57.776: INFO: Pod "pod-42e5c1c8-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.196589ms
Feb 26 04:01:59.779: INFO: Pod "pod-42e5c1c8-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005175047s
STEP: Saw pod success
Feb 26 04:01:59.779: INFO: Pod "pod-42e5c1c8-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:01:59.782: INFO: Trying to get logs from node darren-2745 pod pod-42e5c1c8-397b-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 04:01:59.803: INFO: Waiting for pod pod-42e5c1c8-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:01:59.808: INFO: Pod pod-42e5c1c8-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:01:59.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8vz64" for this suite.
Feb 26 04:02:05.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:02:06.030: INFO: namespace: e2e-tests-emptydir-8vz64, resource: bindings, ignored listing per whitelist
Feb 26 04:02:06.085: INFO: namespace e2e-tests-emptydir-8vz64 deletion completed in 6.270973806s

• [SLOW TEST:8.788 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:02:06.085: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 04:02:06.575: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-vz4f7" to be "success or failure"
Feb 26 04:02:06.578: INFO: Pod "downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.543659ms
Feb 26 04:02:08.581: INFO: Pod "downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.00587357s
Feb 26 04:02:10.585: INFO: Pod "downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009902351s
STEP: Saw pod success
Feb 26 04:02:10.585: INFO: Pod "downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:02:10.588: INFO: Trying to get logs from node darren-16001 pod downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 04:02:10.612: INFO: Waiting for pod downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:02:10.616: INFO: Pod downwardapi-volume-4824459d-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:02:10.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vz4f7" for this suite.
Feb 26 04:02:16.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:02:16.745: INFO: namespace: e2e-tests-projected-vz4f7, resource: bindings, ignored listing per whitelist
Feb 26 04:02:16.780: INFO: namespace e2e-tests-projected-vz4f7 deletion completed in 6.159132517s

• [SLOW TEST:10.695 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:02:16.780: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 26 04:02:17.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-2zmpk'
Feb 26 04:02:17.684: INFO: stderr: ""
Feb 26 04:02:17.684: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 26 04:02:18.689: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 04:02:18.689: INFO: Found 0 / 1
Feb 26 04:02:19.689: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 04:02:19.689: INFO: Found 1 / 1
Feb 26 04:02:19.689: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 26 04:02:19.693: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 04:02:19.693: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 26 04:02:19.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 patch pod redis-master-mm7zs --namespace=e2e-tests-kubectl-2zmpk -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 26 04:02:19.812: INFO: stderr: ""
Feb 26 04:02:19.812: INFO: stdout: "pod/redis-master-mm7zs patched\n"
STEP: checking annotations
Feb 26 04:02:19.817: INFO: Selector matched 1 pods for map[app:redis]
Feb 26 04:02:19.817: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:02:19.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2zmpk" for this suite.
Feb 26 04:02:41.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:02:41.910: INFO: namespace: e2e-tests-kubectl-2zmpk, resource: bindings, ignored listing per whitelist
Feb 26 04:02:41.966: INFO: namespace e2e-tests-kubectl-2zmpk deletion completed in 22.143965446s

• [SLOW TEST:25.186 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:02:41.966: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 26 04:02:42.430: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 26 04:02:42.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:42.639: INFO: stderr: ""
Feb 26 04:02:42.639: INFO: stdout: "service/redis-slave created\n"
Feb 26 04:02:42.639: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 26 04:02:42.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:42.862: INFO: stderr: ""
Feb 26 04:02:42.862: INFO: stdout: "service/redis-master created\n"
Feb 26 04:02:42.862: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 26 04:02:42.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:43.057: INFO: stderr: ""
Feb 26 04:02:43.057: INFO: stdout: "service/frontend created\n"
Feb 26 04:02:43.057: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 26 04:02:43.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:43.246: INFO: stderr: ""
Feb 26 04:02:43.246: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 26 04:02:43.246: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 26 04:02:43.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:43.442: INFO: stderr: ""
Feb 26 04:02:43.442: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 26 04:02:43.443: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 26 04:02:43.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:43.656: INFO: stderr: ""
Feb 26 04:02:43.656: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 26 04:02:43.656: INFO: Waiting for all frontend pods to be Running.
Feb 26 04:02:58.708: INFO: Waiting for frontend to serve content.
Feb 26 04:02:58.722: INFO: Trying to add a new entry to the guestbook.
Feb 26 04:02:58.739: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 26 04:02:58.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:58.868: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:02:58.868: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 26 04:02:58.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:58.976: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:02:58.976: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 26 04:02:58.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:59.087: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:02:59.087: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 26 04:02:59.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:59.199: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:02:59.199: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 26 04:02:59.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:59.315: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:02:59.315: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 26 04:02:59.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qfm5s'
Feb 26 04:02:59.454: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:02:59.454: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:02:59.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qfm5s" for this suite.
Feb 26 04:03:37.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:03:37.555: INFO: namespace: e2e-tests-kubectl-qfm5s, resource: bindings, ignored listing per whitelist
Feb 26 04:03:37.622: INFO: namespace e2e-tests-kubectl-qfm5s deletion completed in 38.16214849s

• [SLOW TEST:55.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:03:37.622: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 04:03:38.092: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-tlzw9" to be "success or failure"
Feb 26 04:03:38.095: INFO: Pod "downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.829743ms
Feb 26 04:03:40.098: INFO: Pod "downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006039569s
Feb 26 04:03:42.102: INFO: Pod "downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009411057s
STEP: Saw pod success
Feb 26 04:03:42.102: INFO: Pod "downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:03:42.105: INFO: Trying to get logs from node darren-16001 pod downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 04:03:42.123: INFO: Waiting for pod downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:03:42.127: INFO: Pod downwardapi-volume-7eafbae3-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:03:42.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tlzw9" for this suite.
Feb 26 04:03:48.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:03:48.177: INFO: namespace: e2e-tests-downward-api-tlzw9, resource: bindings, ignored listing per whitelist
Feb 26 04:03:48.269: INFO: namespace e2e-tests-downward-api-tlzw9 deletion completed in 6.138153025s

• [SLOW TEST:10.647 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:03:48.269: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 26 04:03:48.730: INFO: Waiting up to 5m0s for pod "pod-8507d69c-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-ds9bn" to be "success or failure"
Feb 26 04:03:48.733: INFO: Pod "pod-8507d69c-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.63408ms
Feb 26 04:03:50.736: INFO: Pod "pod-8507d69c-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005902354s
STEP: Saw pod success
Feb 26 04:03:50.736: INFO: Pod "pod-8507d69c-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:03:50.739: INFO: Trying to get logs from node darren-2745 pod pod-8507d69c-397b-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 04:03:50.752: INFO: Waiting for pod pod-8507d69c-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:03:50.756: INFO: Pod pod-8507d69c-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:03:50.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ds9bn" for this suite.
Feb 26 04:03:56.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:03:56.873: INFO: namespace: e2e-tests-emptydir-ds9bn, resource: bindings, ignored listing per whitelist
Feb 26 04:03:56.947: INFO: namespace e2e-tests-emptydir-ds9bn deletion completed in 6.186019494s

• [SLOW TEST:8.678 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:03:56.947: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 04:03:57.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-downward-api-4p2rg" to be "success or failure"
Feb 26 04:03:57.411: INFO: Pod "downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.368938ms
Feb 26 04:03:59.414: INFO: Pod "downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006171617s
STEP: Saw pod success
Feb 26 04:03:59.415: INFO: Pod "downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:03:59.422: INFO: Trying to get logs from node darren-2745 pod downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37 container client-container: <nil>
STEP: delete the pod
Feb 26 04:03:59.438: INFO: Waiting for pod downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:03:59.443: INFO: Pod downwardapi-volume-8a34617b-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:03:59.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4p2rg" for this suite.
Feb 26 04:04:05.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:04:05.528: INFO: namespace: e2e-tests-downward-api-4p2rg, resource: bindings, ignored listing per whitelist
Feb 26 04:04:05.618: INFO: namespace e2e-tests-downward-api-4p2rg deletion completed in 6.168405454s

• [SLOW TEST:8.671 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:04:05.619: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-8f616b00-397b-11e9-ac13-320deb251a37
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-8f616b00-397b-11e9-ac13-320deb251a37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:04:10.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cxz8q" for this suite.
Feb 26 04:04:32.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:04:32.274: INFO: namespace: e2e-tests-configmap-cxz8q, resource: bindings, ignored listing per whitelist
Feb 26 04:04:32.302: INFO: namespace e2e-tests-configmap-cxz8q deletion completed in 22.174331172s

• [SLOW TEST:26.683 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:04:32.302: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 26 04:04:32.770: INFO: Waiting up to 5m0s for pod "pod-9f4834df-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-emptydir-hcdxj" to be "success or failure"
Feb 26 04:04:32.772: INFO: Pod "pod-9f4834df-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.292635ms
Feb 26 04:04:34.782: INFO: Pod "pod-9f4834df-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012246188s
STEP: Saw pod success
Feb 26 04:04:34.783: INFO: Pod "pod-9f4834df-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:04:34.786: INFO: Trying to get logs from node darren-16001 pod pod-9f4834df-397b-11e9-ac13-320deb251a37 container test-container: <nil>
STEP: delete the pod
Feb 26 04:04:34.802: INFO: Waiting for pod pod-9f4834df-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:04:34.805: INFO: Pod pod-9f4834df-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:04:34.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hcdxj" for this suite.
Feb 26 04:04:40.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:04:40.882: INFO: namespace: e2e-tests-emptydir-hcdxj, resource: bindings, ignored listing per whitelist
Feb 26 04:04:40.950: INFO: namespace e2e-tests-emptydir-hcdxj deletion completed in 6.140837242s

• [SLOW TEST:8.648 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:04:40.950: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-a46e501d-397b-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 04:04:41.413: INFO: Waiting up to 5m0s for pod "pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-b2fbt" to be "success or failure"
Feb 26 04:04:41.415: INFO: Pod "pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.5516ms
Feb 26 04:04:43.418: INFO: Pod "pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005792478s
STEP: Saw pod success
Feb 26 04:04:43.418: INFO: Pod "pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:04:43.421: INFO: Trying to get logs from node darren-2745 pod pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 04:04:43.440: INFO: Waiting for pod pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:04:43.446: INFO: Pod pod-secrets-a46fc21f-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:04:43.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-b2fbt" for this suite.
Feb 26 04:04:49.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:04:49.573: INFO: namespace: e2e-tests-secrets-b2fbt, resource: bindings, ignored listing per whitelist
Feb 26 04:04:49.608: INFO: namespace e2e-tests-secrets-b2fbt deletion completed in 6.157132787s

• [SLOW TEST:8.658 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:04:49.608: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-6ltn
STEP: Creating a pod to test atomic-volume-subpath
Feb 26 04:04:50.080: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6ltn" in namespace "e2e-tests-subpath-hgghj" to be "success or failure"
Feb 26 04:04:50.082: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.53116ms
Feb 26 04:04:52.086: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005889743s
Feb 26 04:04:54.089: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 4.009286236s
Feb 26 04:04:56.093: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 6.012809768s
Feb 26 04:04:58.096: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 8.016260029s
Feb 26 04:05:00.099: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 10.019497166s
Feb 26 04:05:02.103: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 12.022924217s
Feb 26 04:05:04.106: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 14.026221065s
Feb 26 04:05:06.110: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 16.029769388s
Feb 26 04:05:08.113: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 18.033305506s
Feb 26 04:05:10.117: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 20.036816216s
Feb 26 04:05:12.120: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Running", Reason="", readiness=false. Elapsed: 22.040204034s
Feb 26 04:05:14.123: INFO: Pod "pod-subpath-test-configmap-6ltn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043672938s
STEP: Saw pod success
Feb 26 04:05:14.123: INFO: Pod "pod-subpath-test-configmap-6ltn" satisfied condition "success or failure"
Feb 26 04:05:14.126: INFO: Trying to get logs from node darren-16001 pod pod-subpath-test-configmap-6ltn container test-container-subpath-configmap-6ltn: <nil>
STEP: delete the pod
Feb 26 04:05:14.144: INFO: Waiting for pod pod-subpath-test-configmap-6ltn to disappear
Feb 26 04:05:14.148: INFO: Pod pod-subpath-test-configmap-6ltn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6ltn
Feb 26 04:05:14.148: INFO: Deleting pod "pod-subpath-test-configmap-6ltn" in namespace "e2e-tests-subpath-hgghj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:05:14.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hgghj" for this suite.
Feb 26 04:05:20.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:05:20.248: INFO: namespace: e2e-tests-subpath-hgghj, resource: bindings, ignored listing per whitelist
Feb 26 04:05:20.285: INFO: namespace e2e-tests-subpath-hgghj deletion completed in 6.130371989s

• [SLOW TEST:30.676 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:05:20.285: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:05:27.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-vmz4z" for this suite.
Feb 26 04:05:33.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:05:33.494: INFO: namespace: e2e-tests-namespaces-vmz4z, resource: bindings, ignored listing per whitelist
Feb 26 04:05:33.589: INFO: namespace e2e-tests-namespaces-vmz4z deletion completed in 6.203358317s
STEP: Destroying namespace "e2e-tests-nsdeletetest-68cvs" for this suite.
Feb 26 04:05:33.591: INFO: Namespace e2e-tests-nsdeletetest-68cvs was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2sb66" for this suite.
Feb 26 04:05:39.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:05:39.721: INFO: namespace: e2e-tests-nsdeletetest-2sb66, resource: bindings, ignored listing per whitelist
Feb 26 04:05:39.724: INFO: namespace e2e-tests-nsdeletetest-2sb66 deletion completed in 6.133218794s

• [SLOW TEST:19.440 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:05:39.729: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 26 04:05:40.184: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-zdd2d" to be "success or failure"
Feb 26 04:05:40.186: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.778357ms
Feb 26 04:05:42.193: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.008861874s
Feb 26 04:05:44.196: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012063062s
STEP: Saw pod success
Feb 26 04:05:44.196: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 26 04:05:44.198: INFO: Trying to get logs from node darren-2745 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 26 04:05:44.214: INFO: Waiting for pod pod-host-path-test to disappear
Feb 26 04:05:44.218: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:05:44.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-zdd2d" for this suite.
Feb 26 04:05:50.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:05:50.272: INFO: namespace: e2e-tests-hostpath-zdd2d, resource: bindings, ignored listing per whitelist
Feb 26 04:05:50.376: INFO: namespace e2e-tests-hostpath-zdd2d deletion completed in 6.152975676s

• [SLOW TEST:10.648 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:05:50.376: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cdd29103-397b-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume secrets
Feb 26 04:05:51.074: INFO: Waiting up to 5m0s for pod "pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37" in namespace "e2e-tests-secrets-9rtzq" to be "success or failure"
Feb 26 04:05:51.077: INFO: Pod "pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.464302ms
Feb 26 04:05:53.080: INFO: Pod "pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006048464s
STEP: Saw pod success
Feb 26 04:05:53.080: INFO: Pod "pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:05:53.083: INFO: Trying to get logs from node darren-16001 pod pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37 container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 04:05:53.098: INFO: Waiting for pod pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37 to disappear
Feb 26 04:05:53.102: INFO: Pod pod-secrets-cdf51b67-397b-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:05:53.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9rtzq" for this suite.
Feb 26 04:05:59.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:05:59.172: INFO: namespace: e2e-tests-secrets-9rtzq, resource: bindings, ignored listing per whitelist
Feb 26 04:05:59.277: INFO: namespace e2e-tests-secrets-9rtzq deletion completed in 6.168826529s
STEP: Destroying namespace "e2e-tests-secret-namespace-xctsl" for this suite.
Feb 26 04:06:05.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:06:05.383: INFO: namespace: e2e-tests-secret-namespace-xctsl, resource: bindings, ignored listing per whitelist
Feb 26 04:06:05.447: INFO: namespace e2e-tests-secret-namespace-xctsl deletion completed in 6.169846241s

• [SLOW TEST:15.071 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:06:05.448: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0226 04:06:45.981538      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 26 04:06:45.981: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:06:45.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rph78" for this suite.
Feb 26 04:06:51.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:06:52.101: INFO: namespace: e2e-tests-gc-rph78, resource: bindings, ignored listing per whitelist
Feb 26 04:06:52.150: INFO: namespace e2e-tests-gc-rph78 deletion completed in 6.164381809s

• [SLOW TEST:46.702 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:06:52.150: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 26 04:06:55.134: INFO: Successfully updated pod "labelsupdatef2a2b699-397b-11e9-ac13-320deb251a37"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:06:59.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v7z5g" for this suite.
Feb 26 04:07:21.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:07:21.203: INFO: namespace: e2e-tests-projected-v7z5g, resource: bindings, ignored listing per whitelist
Feb 26 04:07:21.300: INFO: namespace e2e-tests-projected-v7z5g deletion completed in 22.143570693s

• [SLOW TEST:29.150 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:07:21.300: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0401a0ce-397c-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 04:07:21.758: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-sd6pd" to be "success or failure"
Feb 26 04:07:21.760: INFO: Pod "pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 1.93858ms
Feb 26 04:07:23.763: INFO: Pod "pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.004962356s
Feb 26 04:07:25.767: INFO: Pod "pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008423692s
STEP: Saw pod success
Feb 26 04:07:25.767: INFO: Pod "pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:07:25.769: INFO: Trying to get logs from node darren-16001 pod pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 04:07:25.786: INFO: Waiting for pod pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:07:25.790: INFO: Pod pod-projected-configmaps-0402ced1-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:07:25.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sd6pd" for this suite.
Feb 26 04:07:31.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:07:31.834: INFO: namespace: e2e-tests-projected-sd6pd, resource: bindings, ignored listing per whitelist
Feb 26 04:07:31.936: INFO: namespace e2e-tests-projected-sd6pd deletion completed in 6.142436998s

• [SLOW TEST:10.636 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:07:31.936: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 26 04:07:36.420: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 26 04:07:36.425: INFO: Pod pod-with-poststart-http-hook still exists
Feb 26 04:07:38.425: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 26 04:07:38.430: INFO: Pod pod-with-poststart-http-hook still exists
Feb 26 04:07:40.425: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 26 04:07:40.430: INFO: Pod pod-with-poststart-http-hook still exists
Feb 26 04:07:42.425: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 26 04:07:42.430: INFO: Pod pod-with-poststart-http-hook still exists
Feb 26 04:07:44.425: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 26 04:07:44.429: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:07:44.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-45ps6" for this suite.
Feb 26 04:08:06.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:08:06.570: INFO: namespace: e2e-tests-container-lifecycle-hook-45ps6, resource: bindings, ignored listing per whitelist
Feb 26 04:08:06.581: INFO: namespace e2e-tests-container-lifecycle-hook-45ps6 deletion completed in 22.147409498s

• [SLOW TEST:34.645 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:08:06.582: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 26 04:08:07.062: INFO: Number of nodes with available pods: 0
Feb 26 04:08:07.062: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 04:08:08.072: INFO: Number of nodes with available pods: 0
Feb 26 04:08:08.072: INFO: Node darren-16001 is running more than one daemon pod
Feb 26 04:08:09.072: INFO: Number of nodes with available pods: 2
Feb 26 04:08:09.072: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 26 04:08:09.092: INFO: Number of nodes with available pods: 1
Feb 26 04:08:09.092: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:10.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:10.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:11.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:11.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:12.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:12.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:13.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:13.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:14.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:14.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:15.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:15.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:16.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:16.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:17.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:17.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:18.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:18.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:19.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:19.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:20.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:20.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:21.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:21.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:22.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:22.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:23.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:23.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:24.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:24.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:25.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:25.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:26.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:26.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:27.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:27.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:28.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:28.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:29.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:29.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:30.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:30.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:31.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:31.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:32.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:32.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:33.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:33.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:34.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:34.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:35.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:35.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:36.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:36.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:37.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:37.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:38.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:38.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:39.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:39.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:40.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:40.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:41.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:41.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:42.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:42.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:43.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:43.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:44.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:44.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:45.100: INFO: Number of nodes with available pods: 1
Feb 26 04:08:45.100: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:46.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:46.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:47.102: INFO: Number of nodes with available pods: 1
Feb 26 04:08:47.102: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:48.101: INFO: Number of nodes with available pods: 1
Feb 26 04:08:48.101: INFO: Node darren-2745 is running more than one daemon pod
Feb 26 04:08:49.101: INFO: Number of nodes with available pods: 2
Feb 26 04:08:49.101: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-c96bv, will wait for the garbage collector to delete the pods
Feb 26 04:08:49.166: INFO: Deleting DaemonSet.extensions daemon-set took: 9.069694ms
Feb 26 04:08:49.367: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.411558ms
Feb 26 04:09:27.771: INFO: Number of nodes with available pods: 0
Feb 26 04:09:27.771: INFO: Number of running nodes: 0, number of available pods: 0
Feb 26 04:09:27.775: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-c96bv/daemonsets","resourceVersion":"12663"},"items":null}

Feb 26 04:09:27.780: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-c96bv/pods","resourceVersion":"12663"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:09:27.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-c96bv" for this suite.
Feb 26 04:09:33.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:09:33.837: INFO: namespace: e2e-tests-daemonsets-c96bv, resource: bindings, ignored listing per whitelist
Feb 26 04:09:33.924: INFO: namespace e2e-tests-daemonsets-c96bv deletion completed in 6.13002432s

• [SLOW TEST:87.342 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:09:33.924: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-530e174e-397c-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 04:09:34.382: INFO: Waiting up to 5m0s for pod "pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-czv8k" to be "success or failure"
Feb 26 04:09:34.386: INFO: Pod "pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.992821ms
Feb 26 04:09:36.389: INFO: Pod "pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007340234s
STEP: Saw pod success
Feb 26 04:09:36.389: INFO: Pod "pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:09:36.391: INFO: Trying to get logs from node darren-2745 pod pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 04:09:36.405: INFO: Waiting for pod pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:09:36.421: INFO: Pod pod-configmaps-530f6c17-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:09:36.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-czv8k" for this suite.
Feb 26 04:09:42.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:09:42.532: INFO: namespace: e2e-tests-configmap-czv8k, resource: bindings, ignored listing per whitelist
Feb 26 04:09:42.578: INFO: namespace e2e-tests-configmap-czv8k deletion completed in 6.151504407s

• [SLOW TEST:8.653 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:09:42.579: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 26 04:09:45.562: INFO: Successfully updated pod "annotationupdate5837056d-397c-11e9-ac13-320deb251a37"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:09:49.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ljvkr" for this suite.
Feb 26 04:10:11.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:10:11.694: INFO: namespace: e2e-tests-projected-ljvkr, resource: bindings, ignored listing per whitelist
Feb 26 04:10:11.747: INFO: namespace e2e-tests-projected-ljvkr deletion completed in 22.164213581s

• [SLOW TEST:29.168 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:10:11.747: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 26 04:10:12.194: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:10:13.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-qfz9r" for this suite.
Feb 26 04:10:19.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:10:19.467: INFO: namespace: e2e-tests-custom-resource-definition-qfz9r, resource: bindings, ignored listing per whitelist
Feb 26 04:10:19.565: INFO: namespace e2e-tests-custom-resource-definition-qfz9r deletion completed in 6.131515344s

• [SLOW TEST:7.818 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:10:19.565: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6e43923d-397c-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 04:10:20.025: INFO: Waiting up to 5m0s for pod "pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-6mj45" to be "success or failure"
Feb 26 04:10:20.027: INFO: Pod "pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 1.963426ms
Feb 26 04:10:22.031: INFO: Pod "pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005605783s
STEP: Saw pod success
Feb 26 04:10:22.031: INFO: Pod "pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:10:22.033: INFO: Trying to get logs from node darren-16001 pod pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 04:10:22.046: INFO: Waiting for pod pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:10:22.049: INFO: Pod pod-configmaps-6e4415cd-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:10:22.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6mj45" for this suite.
Feb 26 04:10:28.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:10:28.188: INFO: namespace: e2e-tests-configmap-6mj45, resource: bindings, ignored listing per whitelist
Feb 26 04:10:28.219: INFO: namespace e2e-tests-configmap-6mj45 deletion completed in 6.164754373s

• [SLOW TEST:8.654 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:10:28.220: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-736bb5b7-397c-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 04:10:28.686: INFO: Waiting up to 5m0s for pod "pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-fctrr" to be "success or failure"
Feb 26 04:10:28.688: INFO: Pod "pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.108729ms
Feb 26 04:10:30.691: INFO: Pod "pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005208598s
STEP: Saw pod success
Feb 26 04:10:30.691: INFO: Pod "pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:10:30.694: INFO: Trying to get logs from node darren-16001 pod pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 04:10:30.705: INFO: Waiting for pod pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:10:30.709: INFO: Pod pod-configmaps-736d1cff-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:10:30.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fctrr" for this suite.
Feb 26 04:10:36.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:10:36.782: INFO: namespace: e2e-tests-configmap-fctrr, resource: bindings, ignored listing per whitelist
Feb 26 04:10:36.874: INFO: namespace e2e-tests-configmap-fctrr deletion completed in 6.16041166s

• [SLOW TEST:8.655 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:10:36.874: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 26 04:10:37.360: INFO: Waiting up to 5m0s for pod "var-expansion-7894e65a-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-var-expansion-gk8qw" to be "success or failure"
Feb 26 04:10:37.363: INFO: Pod "var-expansion-7894e65a-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.999564ms
Feb 26 04:10:39.367: INFO: Pod "var-expansion-7894e65a-397c-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.006303933s
Feb 26 04:10:41.370: INFO: Pod "var-expansion-7894e65a-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009993003s
STEP: Saw pod success
Feb 26 04:10:41.371: INFO: Pod "var-expansion-7894e65a-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:10:41.373: INFO: Trying to get logs from node darren-16001 pod var-expansion-7894e65a-397c-11e9-ac13-320deb251a37 container dapi-container: <nil>
STEP: delete the pod
Feb 26 04:10:41.387: INFO: Waiting for pod var-expansion-7894e65a-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:10:41.390: INFO: Pod var-expansion-7894e65a-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:10:41.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gk8qw" for this suite.
Feb 26 04:10:47.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:10:47.503: INFO: namespace: e2e-tests-var-expansion-gk8qw, resource: bindings, ignored listing per whitelist
Feb 26 04:10:47.620: INFO: namespace e2e-tests-var-expansion-gk8qw deletion completed in 6.225672413s

• [SLOW TEST:10.746 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:10:47.620: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 04:10:48.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zcjgv'
Feb 26 04:10:48.170: INFO: stderr: ""
Feb 26 04:10:48.170: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 26 04:10:48.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-zcjgv'
Feb 26 04:10:52.863: INFO: stderr: ""
Feb 26 04:10:52.863: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:10:52.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zcjgv" for this suite.
Feb 26 04:10:58.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:10:58.991: INFO: namespace: e2e-tests-kubectl-zcjgv, resource: bindings, ignored listing per whitelist
Feb 26 04:10:59.049: INFO: namespace e2e-tests-kubectl-zcjgv deletion completed in 6.180750856s

• [SLOW TEST:11.429 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:10:59.049: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 26 04:11:02.031: INFO: Successfully updated pod "pod-update-activedeadlineseconds-85cba595-397c-11e9-ac13-320deb251a37"
Feb 26 04:11:02.031: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-85cba595-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-pods-qwj96" to be "terminated due to deadline exceeded"
Feb 26 04:11:02.034: INFO: Pod "pod-update-activedeadlineseconds-85cba595-397c-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.884255ms
Feb 26 04:11:04.037: INFO: Pod "pod-update-activedeadlineseconds-85cba595-397c-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.005893763s
Feb 26 04:11:06.040: INFO: Pod "pod-update-activedeadlineseconds-85cba595-397c-11e9-ac13-320deb251a37": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009080078s
Feb 26 04:11:06.040: INFO: Pod "pod-update-activedeadlineseconds-85cba595-397c-11e9-ac13-320deb251a37" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:11:06.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qwj96" for this suite.
Feb 26 04:11:12.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:11:12.163: INFO: namespace: e2e-tests-pods-qwj96, resource: bindings, ignored listing per whitelist
Feb 26 04:11:12.227: INFO: namespace e2e-tests-pods-qwj96 deletion completed in 6.182199045s

• [SLOW TEST:13.178 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:11:12.227: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 26 04:11:15.132: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-8dabf811-397c-11e9-ac13-320deb251a37", GenerateName:"", Namespace:"e2e-tests-pods-b7pxx", SelfLink:"/api/v1/namespaces/e2e-tests-pods-b7pxx/pods/pod-submit-remove-8dabf811-397c-11e9-ac13-320deb251a37", UID:"8dd21e26-397c-11e9-a404-c690ac8d27cb", ResourceVersion:"12960", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686751072, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"709639723"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fqfsh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00269cc40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fqfsh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0028221e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"darren-16001", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020ddc80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002822230)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002822250)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002822258), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00282225c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686751072, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686751074, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686751074, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686751072, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"134.209.63.30", PodIP:"10.42.0.169", StartTime:(*v1.Time)(0xc00280e8a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00280e8c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"containerd://7fc3205748740f2ebd4de4f9a55a29bfaefc2b7aa4299fb1899c18895970765d"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:11:22.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b7pxx" for this suite.
Feb 26 04:11:28.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:11:29.057: INFO: namespace: e2e-tests-pods-b7pxx, resource: bindings, ignored listing per whitelist
Feb 26 04:11:29.095: INFO: namespace e2e-tests-pods-b7pxx deletion completed in 6.162495878s

• [SLOW TEST:16.868 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:11:29.095: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9fzwz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 26 04:11:29.545: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 26 04:11:47.633: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.0.170:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9fzwz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 04:11:47.633: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 04:11:47.757: INFO: Found all expected endpoints: [netserver-0]
Feb 26 04:11:47.760: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.42.1.168:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9fzwz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 04:11:47.760: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 04:11:47.893: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:11:47.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9fzwz" for this suite.
Feb 26 04:12:09.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:12:10.013: INFO: namespace: e2e-tests-pod-network-test-9fzwz, resource: bindings, ignored listing per whitelist
Feb 26 04:12:10.084: INFO: namespace e2e-tests-pod-network-test-9fzwz deletion completed in 22.184039734s

• [SLOW TEST:40.988 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:12:10.084: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 26 04:12:10.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 create -f - --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:10.745: INFO: stderr: ""
Feb 26 04:12:10.745: INFO: stdout: "pod/pause created\n"
Feb 26 04:12:10.745: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 26 04:12:10.745: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-lpvcx" to be "running and ready"
Feb 26 04:12:10.748: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.897935ms
Feb 26 04:12:12.751: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005733747s
Feb 26 04:12:12.751: INFO: Pod "pause" satisfied condition "running and ready"
Feb 26 04:12:12.751: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 26 04:12:12.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:12.840: INFO: stderr: ""
Feb 26 04:12:12.840: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 26 04:12:12.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pod pause -L testing-label --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:12.927: INFO: stderr: ""
Feb 26 04:12:12.927: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 26 04:12:12.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 label pods pause testing-label- --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:13.037: INFO: stderr: ""
Feb 26 04:12:13.037: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 26 04:12:13.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pod pause -L testing-label --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:13.139: INFO: stderr: ""
Feb 26 04:12:13.139: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 26 04:12:13.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:13.227: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 26 04:12:13.227: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 26 04:12:13.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-lpvcx'
Feb 26 04:12:13.326: INFO: stderr: "No resources found.\n"
Feb 26 04:12:13.326: INFO: stdout: ""
Feb 26 04:12:13.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-481393766 get pods -l name=pause --namespace=e2e-tests-kubectl-lpvcx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 26 04:12:13.427: INFO: stderr: ""
Feb 26 04:12:13.427: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:12:13.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lpvcx" for this suite.
Feb 26 04:12:19.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:12:19.501: INFO: namespace: e2e-tests-kubectl-lpvcx, resource: bindings, ignored listing per whitelist
Feb 26 04:12:19.558: INFO: namespace e2e-tests-kubectl-lpvcx deletion completed in 6.125896567s

• [SLOW TEST:9.474 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:12:19.558: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 26 04:12:24.033: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:24.037: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:26.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:26.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:28.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:28.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:30.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:30.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:32.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:32.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:34.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:34.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:36.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:36.043: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:38.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:38.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:40.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:40.043: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:42.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:42.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:44.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:44.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:46.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:46.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:48.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:48.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:50.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:50.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:52.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:52.042: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 26 04:12:54.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 26 04:12:54.042: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:12:54.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-66jkv" for this suite.
Feb 26 04:13:16.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:13:16.191: INFO: namespace: e2e-tests-container-lifecycle-hook-66jkv, resource: bindings, ignored listing per whitelist
Feb 26 04:13:16.197: INFO: namespace e2e-tests-container-lifecycle-hook-66jkv deletion completed in 22.145715808s

• [SLOW TEST:56.640 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:13:16.198: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-h56lg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 26 04:13:16.642: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 26 04:13:34.715: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.177:8080/dial?request=hostName&protocol=udp&host=10.42.1.169&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-h56lg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 04:13:34.715: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 04:13:34.815: INFO: Waiting for endpoints: map[]
Feb 26 04:13:34.818: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.42.0.177:8080/dial?request=hostName&protocol=udp&host=10.42.0.176&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-h56lg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 04:13:34.818: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
Feb 26 04:13:34.918: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:13:34.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-h56lg" for this suite.
Feb 26 04:13:56.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:13:57.030: INFO: namespace: e2e-tests-pod-network-test-h56lg, resource: bindings, ignored listing per whitelist
Feb 26 04:13:57.082: INFO: namespace e2e-tests-pod-network-test-h56lg deletion completed in 22.157999443s

• [SLOW TEST:40.885 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:13:57.083: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-efeb441a-397c-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 04:13:57.552: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-projected-5pztg" to be "success or failure"
Feb 26 04:13:57.554: INFO: Pod "pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.153726ms
Feb 26 04:13:59.557: INFO: Pod "pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005393162s
STEP: Saw pod success
Feb 26 04:13:59.557: INFO: Pod "pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:13:59.559: INFO: Trying to get logs from node darren-16001 pod pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 04:13:59.577: INFO: Waiting for pod pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:13:59.581: INFO: Pod pod-projected-configmaps-efebc556-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:13:59.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5pztg" for this suite.
Feb 26 04:14:05.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:14:05.674: INFO: namespace: e2e-tests-projected-5pztg, resource: bindings, ignored listing per whitelist
Feb 26 04:14:05.792: INFO: namespace e2e-tests-projected-5pztg deletion completed in 6.206174549s

• [SLOW TEST:8.709 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 04:14:05.793: INFO: >>> kubeConfig: /tmp/kubeconfig-481393766
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f51e8217-397c-11e9-ac13-320deb251a37
STEP: Creating a pod to test consume configMaps
Feb 26 04:14:06.289: INFO: Waiting up to 5m0s for pod "pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37" in namespace "e2e-tests-configmap-f76qd" to be "success or failure"
Feb 26 04:14:06.293: INFO: Pod "pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37": Phase="Pending", Reason="", readiness=false. Elapsed: 3.243066ms
Feb 26 04:14:08.296: INFO: Pod "pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37": Phase="Running", Reason="", readiness=true. Elapsed: 2.006295643s
Feb 26 04:14:10.299: INFO: Pod "pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009806041s
STEP: Saw pod success
Feb 26 04:14:10.299: INFO: Pod "pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37" satisfied condition "success or failure"
Feb 26 04:14:10.302: INFO: Trying to get logs from node darren-16001 pod pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 26 04:14:10.317: INFO: Waiting for pod pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37 to disappear
Feb 26 04:14:10.322: INFO: Pod pod-configmaps-f5206496-397c-11e9-ac13-320deb251a37 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 04:14:10.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f76qd" for this suite.
Feb 26 04:14:16.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 04:14:16.430: INFO: namespace: e2e-tests-configmap-f76qd, resource: bindings, ignored listing per whitelist
Feb 26 04:14:16.460: INFO: namespace e2e-tests-configmap-f76qd deletion completed in 6.13345777s

• [SLOW TEST:10.667 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSFeb 26 04:14:16.461: INFO: Running AfterSuite actions on all nodes
Feb 26 04:14:16.461: INFO: Running AfterSuite actions on node 1
Feb 26 04:14:16.461: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5472.530 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h31m13.593766899s
Test Suite Passed
