I0218 03:08:51.579453      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-647419003
I0218 03:08:51.579782      17 e2e.go:224] Starting e2e run "83afc1ef-332a-11e9-94e0-0a580af401c1" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1550459330 - Will randomize all specs
Will run 201 of 1946 specs

Feb 18 03:08:51.945: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 03:08:51.949: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 18 03:08:51.970: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 18 03:08:52.018: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 18 03:08:52.018: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Feb 18 03:08:52.018: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 18 03:08:52.034: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Feb 18 03:08:52.034: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Feb 18 03:08:52.034: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Feb 18 03:08:52.034: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Feb 18 03:08:52.034: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Feb 18 03:08:52.034: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 18 03:08:52.034: INFO: e2e test version: v1.13.0
Feb 18 03:08:52.035: INFO: kube-apiserver version: v1.13.3
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:08:52.036: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
Feb 18 03:08:52.132: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 18 03:08:52.134: INFO: namespace e2e-tests-kubectl-45kkr
Feb 18 03:08:52.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-45kkr'
Feb 18 03:08:52.700: INFO: stderr: ""
Feb 18 03:08:52.700: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 18 03:08:53.967: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:08:53.967: INFO: Found 0 / 1
Feb 18 03:08:54.711: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:08:54.711: INFO: Found 1 / 1
Feb 18 03:08:54.711: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 18 03:08:54.716: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:08:54.716: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 18 03:08:54.716: INFO: wait on redis-master startup in e2e-tests-kubectl-45kkr 
Feb 18 03:08:54.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 logs redis-master-2xr5x redis-master --namespace=e2e-tests-kubectl-45kkr'
Feb 18 03:08:54.913: INFO: stderr: ""
Feb 18 03:08:54.913: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Feb 03:08:53.954 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Feb 03:08:53.954 # Server started, Redis version 3.2.12\n1:M 18 Feb 03:08:53.954 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Feb 03:08:53.955 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 18 03:08:54.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-45kkr'
Feb 18 03:08:55.167: INFO: stderr: ""
Feb 18 03:08:55.167: INFO: stdout: "service/rm2 exposed\n"
Feb 18 03:08:55.340: INFO: Service rm2 in namespace e2e-tests-kubectl-45kkr found.
STEP: exposing service
Feb 18 03:08:57.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-45kkr'
Feb 18 03:08:57.543: INFO: stderr: ""
Feb 18 03:08:57.543: INFO: stdout: "service/rm3 exposed\n"
Feb 18 03:08:57.551: INFO: Service rm3 in namespace e2e-tests-kubectl-45kkr found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:08:59.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-45kkr" for this suite.
Feb 18 03:09:21.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:09:21.632: INFO: namespace: e2e-tests-kubectl-45kkr, resource: bindings, ignored listing per whitelist
Feb 18 03:09:21.708: INFO: namespace e2e-tests-kubectl-45kkr deletion completed in 22.140675917s

• [SLOW TEST:29.672 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:09:21.708: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:09:50.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-z99dd" for this suite.
Feb 18 03:09:56.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:09:56.126: INFO: namespace: e2e-tests-container-runtime-z99dd, resource: bindings, ignored listing per whitelist
Feb 18 03:09:56.244: INFO: namespace e2e-tests-container-runtime-z99dd deletion completed in 6.156776861s

• [SLOW TEST:34.536 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:09:56.245: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 18 03:09:56.366: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9zv6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-9zv6f/configmaps/e2e-watch-test-label-changed,UID:ab162623-332a-11e9-9a73-8a88965a7424,ResourceVersion:329439,Generation:0,CreationTimestamp:2019-02-18 03:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 03:09:56.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9zv6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-9zv6f/configmaps/e2e-watch-test-label-changed,UID:ab162623-332a-11e9-9a73-8a88965a7424,ResourceVersion:329440,Generation:0,CreationTimestamp:2019-02-18 03:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 18 03:09:56.366: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9zv6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-9zv6f/configmaps/e2e-watch-test-label-changed,UID:ab162623-332a-11e9-9a73-8a88965a7424,ResourceVersion:329441,Generation:0,CreationTimestamp:2019-02-18 03:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 18 03:10:06.400: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9zv6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-9zv6f/configmaps/e2e-watch-test-label-changed,UID:ab162623-332a-11e9-9a73-8a88965a7424,ResourceVersion:329456,Generation:0,CreationTimestamp:2019-02-18 03:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 03:10:06.400: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9zv6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-9zv6f/configmaps/e2e-watch-test-label-changed,UID:ab162623-332a-11e9-9a73-8a88965a7424,ResourceVersion:329457,Generation:0,CreationTimestamp:2019-02-18 03:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 18 03:10:06.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9zv6f,SelfLink:/api/v1/namespaces/e2e-tests-watch-9zv6f/configmaps/e2e-watch-test-label-changed,UID:ab162623-332a-11e9-9a73-8a88965a7424,ResourceVersion:329458,Generation:0,CreationTimestamp:2019-02-18 03:09:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:10:06.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9zv6f" for this suite.
Feb 18 03:10:12.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:10:12.497: INFO: namespace: e2e-tests-watch-9zv6f, resource: bindings, ignored listing per whitelist
Feb 18 03:10:12.535: INFO: namespace e2e-tests-watch-9zv6f deletion completed in 6.130180848s

• [SLOW TEST:16.291 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:10:12.536: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 03:10:12.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9wwp8'
Feb 18 03:10:12.809: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 03:10:12.809: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 18 03:10:12.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-9wwp8'
Feb 18 03:10:13.010: INFO: stderr: ""
Feb 18 03:10:13.010: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:10:13.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9wwp8" for this suite.
Feb 18 03:10:19.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:10:19.099: INFO: namespace: e2e-tests-kubectl-9wwp8, resource: bindings, ignored listing per whitelist
Feb 18 03:10:19.148: INFO: namespace e2e-tests-kubectl-9wwp8 deletion completed in 6.130990468s

• [SLOW TEST:6.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:10:19.149: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:10:21.286: INFO: Waiting up to 5m0s for pod "client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1" in namespace "e2e-tests-pods-nz5zm" to be "success or failure"
Feb 18 03:10:21.293: INFO: Pod "client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.288314ms
Feb 18 03:10:23.298: INFO: Pod "client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011925309s
STEP: Saw pod success
Feb 18 03:10:23.298: INFO: Pod "client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:10:23.302: INFO: Trying to get logs from node xen16-168.ebaotech.com pod client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1 container env3cont: <nil>
STEP: delete the pod
Feb 18 03:10:23.323: INFO: Waiting for pod client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:10:23.327: INFO: Pod client-envvars-b9f1f959-332a-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:10:23.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nz5zm" for this suite.
Feb 18 03:11:09.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:11:09.462: INFO: namespace: e2e-tests-pods-nz5zm, resource: bindings, ignored listing per whitelist
Feb 18 03:11:09.464: INFO: namespace e2e-tests-pods-nz5zm deletion completed in 46.131285598s

• [SLOW TEST:50.315 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:11:09.464: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 18 03:11:10.284: INFO: Waiting up to 5m0s for pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx" in namespace "e2e-tests-svcaccounts-rscws" to be "success or failure"
Feb 18 03:11:10.382: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx": Phase="Pending", Reason="", readiness=false. Elapsed: 97.9404ms
Feb 18 03:11:12.388: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103974224s
Feb 18 03:11:14.394: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109722559s
STEP: Saw pod success
Feb 18 03:11:14.394: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx" satisfied condition "success or failure"
Feb 18 03:11:14.398: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx container token-test: <nil>
STEP: delete the pod
Feb 18 03:11:14.423: INFO: Waiting for pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx to disappear
Feb 18 03:11:14.427: INFO: Pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-bx5rx no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 18 03:11:14.432: INFO: Waiting up to 5m0s for pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h" in namespace "e2e-tests-svcaccounts-rscws" to be "success or failure"
Feb 18 03:11:14.436: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h": Phase="Pending", Reason="", readiness=false. Elapsed: 3.941344ms
Feb 18 03:11:16.441: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009466201s
Feb 18 03:11:18.447: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0151577s
STEP: Saw pod success
Feb 18 03:11:18.447: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h" satisfied condition "success or failure"
Feb 18 03:11:18.450: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h container root-ca-test: <nil>
STEP: delete the pod
Feb 18 03:11:18.476: INFO: Waiting for pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h to disappear
Feb 18 03:11:18.479: INFO: Pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-8zp5h no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 18 03:11:18.484: INFO: Waiting up to 5m0s for pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5" in namespace "e2e-tests-svcaccounts-rscws" to be "success or failure"
Feb 18 03:11:18.488: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.9705ms
Feb 18 03:11:20.494: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009750689s
Feb 18 03:11:22.500: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016028202s
STEP: Saw pod success
Feb 18 03:11:22.500: INFO: Pod "pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5" satisfied condition "success or failure"
Feb 18 03:11:22.504: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5 container namespace-test: <nil>
STEP: delete the pod
Feb 18 03:11:22.526: INFO: Waiting for pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5 to disappear
Feb 18 03:11:22.530: INFO: Pod pod-service-account-d72655e4-332a-11e9-94e0-0a580af401c1-dlff5 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:11:22.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-rscws" for this suite.
Feb 18 03:11:28.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:11:28.654: INFO: namespace: e2e-tests-svcaccounts-rscws, resource: bindings, ignored listing per whitelist
Feb 18 03:11:28.671: INFO: namespace e2e-tests-svcaccounts-rscws deletion completed in 6.135764324s

• [SLOW TEST:19.208 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:11:28.672: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 03:11:28.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-jmkjn" to be "success or failure"
Feb 18 03:11:28.780: INFO: Pod "downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.499263ms
Feb 18 03:11:30.785: INFO: Pod "downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010582122s
STEP: Saw pod success
Feb 18 03:11:30.785: INFO: Pod "downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:11:30.790: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 03:11:30.817: INFO: Waiting for pod downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:11:30.822: INFO: Pod downwardapi-volume-e22b8fb7-332a-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:11:30.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jmkjn" for this suite.
Feb 18 03:11:36.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:11:36.946: INFO: namespace: e2e-tests-projected-jmkjn, resource: bindings, ignored listing per whitelist
Feb 18 03:11:36.963: INFO: namespace e2e-tests-projected-jmkjn deletion completed in 6.1367477s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:11:36.964: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vvrtc
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 18 03:11:37.076: INFO: Found 0 stateful pods, waiting for 3
Feb 18 03:11:47.082: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:11:47.083: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:11:47.083: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 18 03:11:47.116: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 18 03:11:57.154: INFO: Updating stateful set ss2
Feb 18 03:11:57.164: INFO: Waiting for Pod e2e-tests-statefulset-vvrtc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 18 03:12:07.243: INFO: Found 1 stateful pods, waiting for 3
Feb 18 03:12:17.250: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:12:17.250: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:12:17.250: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 18 03:12:17.281: INFO: Updating stateful set ss2
Feb 18 03:12:17.291: INFO: Waiting for Pod e2e-tests-statefulset-vvrtc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 18 03:12:27.321: INFO: Updating stateful set ss2
Feb 18 03:12:27.329: INFO: Waiting for StatefulSet e2e-tests-statefulset-vvrtc/ss2 to complete update
Feb 18 03:12:27.329: INFO: Waiting for Pod e2e-tests-statefulset-vvrtc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 03:12:37.340: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vvrtc
Feb 18 03:12:37.345: INFO: Scaling statefulset ss2 to 0
Feb 18 03:12:57.362: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 03:12:57.366: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:12:57.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vvrtc" for this suite.
Feb 18 03:13:03.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:13:03.701: INFO: namespace: e2e-tests-statefulset-vvrtc, resource: bindings, ignored listing per whitelist
Feb 18 03:13:03.752: INFO: namespace e2e-tests-statefulset-vvrtc deletion completed in 6.305721836s

• [SLOW TEST:86.789 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:13:03.753: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1adda40e-332b-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 03:13:03.897: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-qpltc" to be "success or failure"
Feb 18 03:13:04.016: INFO: Pod "pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 119.128289ms
Feb 18 03:13:06.021: INFO: Pod "pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.123939409s
STEP: Saw pod success
Feb 18 03:13:06.021: INFO: Pod "pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:13:06.025: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 03:13:06.049: INFO: Waiting for pod pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:13:06.065: INFO: Pod pod-projected-secrets-1ade487f-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:13:06.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qpltc" for this suite.
Feb 18 03:13:12.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:13:12.163: INFO: namespace: e2e-tests-projected-qpltc, resource: bindings, ignored listing per whitelist
Feb 18 03:13:12.203: INFO: namespace e2e-tests-projected-qpltc deletion completed in 6.133184215s

• [SLOW TEST:8.451 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:13:12.204: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1fe64102-332b-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 03:13:12.344: INFO: Waiting up to 5m0s for pod "pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-m4qvg" to be "success or failure"
Feb 18 03:13:12.348: INFO: Pod "pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.836403ms
Feb 18 03:13:14.354: INFO: Pod "pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00979655s
STEP: Saw pod success
Feb 18 03:13:14.354: INFO: Pod "pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:13:14.359: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 03:13:14.381: INFO: Waiting for pod pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:13:14.385: INFO: Pod pod-secrets-1fe70146-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:13:14.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m4qvg" for this suite.
Feb 18 03:13:20.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:13:20.416: INFO: namespace: e2e-tests-secrets-m4qvg, resource: bindings, ignored listing per whitelist
Feb 18 03:13:20.522: INFO: namespace e2e-tests-secrets-m4qvg deletion completed in 6.131099382s

• [SLOW TEST:8.318 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:13:20.522: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:13:20.624: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:13:22.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-md8hx" for this suite.
Feb 18 03:14:01.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:01.095: INFO: namespace: e2e-tests-pods-md8hx, resource: bindings, ignored listing per whitelist
Feb 18 03:14:01.157: INFO: namespace e2e-tests-pods-md8hx deletion completed in 38.168363893s

• [SLOW TEST:40.635 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:01.157: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 03:14:01.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-nqww8" to be "success or failure"
Feb 18 03:14:01.262: INFO: Pod "downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.151821ms
Feb 18 03:14:03.306: INFO: Pod "downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047660984s
STEP: Saw pod success
Feb 18 03:14:03.306: INFO: Pod "downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:14:03.310: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 03:14:03.338: INFO: Waiting for pod downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:14:03.342: INFO: Pod downwardapi-volume-3d0ead01-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:14:03.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nqww8" for this suite.
Feb 18 03:14:09.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:09.403: INFO: namespace: e2e-tests-projected-nqww8, resource: bindings, ignored listing per whitelist
Feb 18 03:14:09.464: INFO: namespace e2e-tests-projected-nqww8 deletion completed in 6.116989828s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:09.465: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:14:09.568: INFO: (0) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.751702ms)
Feb 18 03:14:09.574: INFO: (1) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.000448ms)
Feb 18 03:14:09.580: INFO: (2) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.821392ms)
Feb 18 03:14:09.586: INFO: (3) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.328616ms)
Feb 18 03:14:09.592: INFO: (4) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.645456ms)
Feb 18 03:14:09.598: INFO: (5) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.684109ms)
Feb 18 03:14:09.604: INFO: (6) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.273746ms)
Feb 18 03:14:09.610: INFO: (7) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.104607ms)
Feb 18 03:14:09.617: INFO: (8) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.746518ms)
Feb 18 03:14:09.623: INFO: (9) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.322619ms)
Feb 18 03:14:09.629: INFO: (10) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.440043ms)
Feb 18 03:14:09.635: INFO: (11) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.820322ms)
Feb 18 03:14:09.640: INFO: (12) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.425863ms)
Feb 18 03:14:09.645: INFO: (13) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.183116ms)
Feb 18 03:14:09.651: INFO: (14) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.261471ms)
Feb 18 03:14:09.656: INFO: (15) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.312237ms)
Feb 18 03:14:09.661: INFO: (16) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.522155ms)
Feb 18 03:14:09.667: INFO: (17) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.451302ms)
Feb 18 03:14:09.672: INFO: (18) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.143809ms)
Feb 18 03:14:09.678: INFO: (19) /api/v1/nodes/xen16-168.ebaotech.com/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.635545ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:14:09.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zdtcq" for this suite.
Feb 18 03:14:15.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:15.801: INFO: namespace: e2e-tests-proxy-zdtcq, resource: bindings, ignored listing per whitelist
Feb 18 03:14:15.810: INFO: namespace e2e-tests-proxy-zdtcq deletion completed in 6.127242117s

• [SLOW TEST:6.345 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:15.810: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 03:14:15.924: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-8lljt" to be "success or failure"
Feb 18 03:14:15.929: INFO: Pod "downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.561579ms
Feb 18 03:14:17.935: INFO: Pod "downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011187409s
STEP: Saw pod success
Feb 18 03:14:17.935: INFO: Pod "downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:14:17.938: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 03:14:18.124: INFO: Waiting for pod downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:14:18.130: INFO: Pod downwardapi-volume-45cc65ef-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:14:18.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8lljt" for this suite.
Feb 18 03:14:24.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:24.334: INFO: namespace: e2e-tests-projected-8lljt, resource: bindings, ignored listing per whitelist
Feb 18 03:14:24.340: INFO: namespace e2e-tests-projected-8lljt deletion completed in 6.203307594s

• [SLOW TEST:8.530 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:24.340: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 18 03:14:24.435: INFO: Waiting up to 5m0s for pod "pod-4adf420b-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-stqnw" to be "success or failure"
Feb 18 03:14:24.438: INFO: Pod "pod-4adf420b-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371882ms
Feb 18 03:14:26.443: INFO: Pod "pod-4adf420b-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008656491s
STEP: Saw pod success
Feb 18 03:14:26.443: INFO: Pod "pod-4adf420b-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:14:26.447: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-4adf420b-332b-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:14:26.473: INFO: Waiting for pod pod-4adf420b-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:14:26.477: INFO: Pod pod-4adf420b-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:14:26.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-stqnw" for this suite.
Feb 18 03:14:32.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:32.542: INFO: namespace: e2e-tests-emptydir-stqnw, resource: bindings, ignored listing per whitelist
Feb 18 03:14:32.614: INFO: namespace e2e-tests-emptydir-stqnw deletion completed in 6.131690936s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:32.614: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4fcf19c6-332b-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 03:14:32.758: INFO: Waiting up to 5m0s for pod "pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-zzfhs" to be "success or failure"
Feb 18 03:14:32.765: INFO: Pod "pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.187879ms
Feb 18 03:14:34.771: INFO: Pod "pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013172965s
STEP: Saw pod success
Feb 18 03:14:34.771: INFO: Pod "pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:14:34.775: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 03:14:34.798: INFO: Waiting for pod pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:14:34.801: INFO: Pod pod-secrets-4fd54f61-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:14:34.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zzfhs" for this suite.
Feb 18 03:14:40.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:40.942: INFO: namespace: e2e-tests-secrets-zzfhs, resource: bindings, ignored listing per whitelist
Feb 18 03:14:40.952: INFO: namespace e2e-tests-secrets-zzfhs deletion completed in 6.145105492s
STEP: Destroying namespace "e2e-tests-secret-namespace-cfct5" for this suite.
Feb 18 03:14:46.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:47.025: INFO: namespace: e2e-tests-secret-namespace-cfct5, resource: bindings, ignored listing per whitelist
Feb 18 03:14:47.092: INFO: namespace e2e-tests-secret-namespace-cfct5 deletion completed in 6.139602331s

• [SLOW TEST:14.478 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:47.092: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 03:14:47.195: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-lxm7r" to be "success or failure"
Feb 18 03:14:47.199: INFO: Pod "downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.875066ms
Feb 18 03:14:49.203: INFO: Pod "downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008359218s
STEP: Saw pod success
Feb 18 03:14:49.204: INFO: Pod "downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:14:49.208: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 03:14:49.235: INFO: Waiting for pod downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:14:49.238: INFO: Pod downwardapi-volume-58704fea-332b-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:14:49.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lxm7r" for this suite.
Feb 18 03:14:55.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:14:55.329: INFO: namespace: e2e-tests-downward-api-lxm7r, resource: bindings, ignored listing per whitelist
Feb 18 03:14:55.385: INFO: namespace e2e-tests-downward-api-lxm7r deletion completed in 6.140669175s

• [SLOW TEST:8.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:14:55.385: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0218 03:15:26.024623      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 03:15:26.024: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:15:26.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6vw7l" for this suite.
Feb 18 03:15:32.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:15:32.142: INFO: namespace: e2e-tests-gc-6vw7l, resource: bindings, ignored listing per whitelist
Feb 18 03:15:32.178: INFO: namespace e2e-tests-gc-6vw7l deletion completed in 6.149177485s

• [SLOW TEST:36.793 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:15:32.178: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:15:32.270: INFO: Creating ReplicaSet my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1
Feb 18 03:15:32.279: INFO: Pod name my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1: Found 0 pods out of 1
Feb 18 03:15:37.285: INFO: Pod name my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1: Found 1 pods out of 1
Feb 18 03:15:37.285: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1" is running
Feb 18 03:15:37.289: INFO: Pod "my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1-66jl8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 03:15:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 03:15:34 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 03:15:34 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 03:15:32 +0000 UTC Reason: Message:}])
Feb 18 03:15:37.289: INFO: Trying to dial the pod
Feb 18 03:15:42.306: INFO: Controller my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1: Got expected result from replica 1 [my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1-66jl8]: "my-hostname-basic-734f7745-332b-11e9-94e0-0a580af401c1-66jl8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:15:42.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-kl5xm" for this suite.
Feb 18 03:15:48.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:15:48.427: INFO: namespace: e2e-tests-replicaset-kl5xm, resource: bindings, ignored listing per whitelist
Feb 18 03:15:48.518: INFO: namespace e2e-tests-replicaset-kl5xm deletion completed in 6.206226901s

• [SLOW TEST:16.341 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:15:48.519: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zwf2c
Feb 18 03:15:50.832: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zwf2c
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 03:15:50.836: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:19:51.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zwf2c" for this suite.
Feb 18 03:19:57.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:19:57.574: INFO: namespace: e2e-tests-container-probe-zwf2c, resource: bindings, ignored listing per whitelist
Feb 18 03:19:57.635: INFO: namespace e2e-tests-container-probe-zwf2c deletion completed in 6.130308757s

• [SLOW TEST:249.117 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:19:57.636: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-118cfdd7-332c-11e9-94e0-0a580af401c1
STEP: Creating secret with name secret-projected-all-test-volume-118cfdac-332c-11e9-94e0-0a580af401c1
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 18 03:19:57.773: INFO: Waiting up to 5m0s for pod "projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-45pbb" to be "success or failure"
Feb 18 03:19:57.781: INFO: Pod "projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.78049ms
Feb 18 03:19:59.786: INFO: Pod "projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012718748s
STEP: Saw pod success
Feb 18 03:19:59.786: INFO: Pod "projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:19:59.789: INFO: Trying to get logs from node xen16-168.ebaotech.com pod projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 18 03:19:59.815: INFO: Waiting for pod projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:19:59.818: INFO: Pod projected-volume-118cfd30-332c-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:19:59.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-45pbb" for this suite.
Feb 18 03:20:05.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:20:05.882: INFO: namespace: e2e-tests-projected-45pbb, resource: bindings, ignored listing per whitelist
Feb 18 03:20:05.958: INFO: namespace e2e-tests-projected-45pbb deletion completed in 6.132464961s

• [SLOW TEST:8.323 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:20:05.958: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-167e52bc-332c-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 03:20:06.058: INFO: Waiting up to 5m0s for pod "pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-dml5r" to be "success or failure"
Feb 18 03:20:06.264: INFO: Pod "pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 205.49965ms
Feb 18 03:20:08.269: INFO: Pod "pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.211175158s
STEP: Saw pod success
Feb 18 03:20:08.269: INFO: Pod "pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:20:08.274: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 03:20:08.299: INFO: Waiting for pod pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:20:08.302: INFO: Pod pod-secrets-167ef5b4-332c-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:20:08.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dml5r" for this suite.
Feb 18 03:20:14.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:20:14.455: INFO: namespace: e2e-tests-secrets-dml5r, resource: bindings, ignored listing per whitelist
Feb 18 03:20:14.508: INFO: namespace e2e-tests-secrets-dml5r deletion completed in 6.137285484s

• [SLOW TEST:8.550 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:20:14.508: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 18 03:20:14.610: INFO: Waiting up to 5m0s for pod "downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-dtksn" to be "success or failure"
Feb 18 03:20:14.614: INFO: Pod "downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.92189ms
Feb 18 03:20:16.619: INFO: Pod "downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009150976s
STEP: Saw pod success
Feb 18 03:20:16.619: INFO: Pod "downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:20:16.623: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 03:20:16.650: INFO: Waiting for pod downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:20:16.653: INFO: Pod downward-api-1b97f27d-332c-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:20:16.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dtksn" for this suite.
Feb 18 03:20:22.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:20:22.706: INFO: namespace: e2e-tests-downward-api-dtksn, resource: bindings, ignored listing per whitelist
Feb 18 03:20:22.789: INFO: namespace e2e-tests-downward-api-dtksn deletion completed in 6.130749349s

• [SLOW TEST:8.280 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:20:22.789: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:20:22.936: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 18 03:20:27.943: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 18 03:20:27.943: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 18 03:20:29.948: INFO: Creating deployment "test-rollover-deployment"
Feb 18 03:20:29.956: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 18 03:20:31.965: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 18 03:20:31.974: INFO: Ensure that both replica sets have 1 created replica
Feb 18 03:20:31.982: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 18 03:20:31.989: INFO: Updating deployment test-rollover-deployment
Feb 18 03:20:31.989: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 18 03:20:33.997: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 18 03:20:34.007: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 18 03:20:34.015: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 03:20:34.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056832, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:20:36.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 03:20:36.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056834, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:20:38.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 03:20:38.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056834, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:20:40.026: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 03:20:40.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056834, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:20:42.026: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 03:20:42.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056834, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:20:44.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 03:20:44.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056834, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686056829, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:20:46.026: INFO: 
Feb 18 03:20:46.026: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 03:20:46.038: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-2tzzd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2tzzd/deployments/test-rollover-deployment,UID:24bc9e60-332c-11e9-9a73-8a88965a7424,ResourceVersion:331212,Generation:2,CreationTimestamp:2019-02-18 03:20:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-18 03:20:29 +0000 UTC 2019-02-18 03:20:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-18 03:20:44 +0000 UTC 2019-02-18 03:20:29 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 18 03:20:46.043: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-2tzzd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2tzzd/replicasets/test-rollover-deployment-6b7f9d6597,UID:25f404c9-332c-11e9-9a73-8a88965a7424,ResourceVersion:331202,Generation:2,CreationTimestamp:2019-02-18 03:20:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 24bc9e60-332c-11e9-9a73-8a88965a7424 0xc001b97a27 0xc001b97a28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 18 03:20:46.043: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 18 03:20:46.043: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-2tzzd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2tzzd/replicasets/test-rollover-controller,UID:208db692-332c-11e9-9a73-8a88965a7424,ResourceVersion:331211,Generation:2,CreationTimestamp:2019-02-18 03:20:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 24bc9e60-332c-11e9-9a73-8a88965a7424 0xc001b97897 0xc001b97898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 03:20:46.043: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-2tzzd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2tzzd/replicasets/test-rollover-deployment-6586df867b,UID:24bfc56a-332c-11e9-9a73-8a88965a7424,ResourceVersion:331173,Generation:2,CreationTimestamp:2019-02-18 03:20:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 24bc9e60-332c-11e9-9a73-8a88965a7424 0xc001b97957 0xc001b97958}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 03:20:46.049: INFO: Pod "test-rollover-deployment-6b7f9d6597-w496r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-w496r,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-2tzzd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2tzzd/pods/test-rollover-deployment-6b7f9d6597-w496r,UID:25f95566-332c-11e9-9a73-8a88965a7424,ResourceVersion:331185,Generation:0,CreationTimestamp:2019-02-18 03:20:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 25f404c9-332c-11e9-9a73-8a88965a7424 0xc002042577 0xc002042578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbrj8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbrj8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gbrj8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020425e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002042600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:32 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.230,StartTime:2019-02-18 03:20:32 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-18 03:20:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://56892ec0a45280f9febb12a1fd9bcdd8a7ca957ef15b9cd084b2ff8a59e55029}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:20:46.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2tzzd" for this suite.
Feb 18 03:20:52.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:20:52.115: INFO: namespace: e2e-tests-deployment-2tzzd, resource: bindings, ignored listing per whitelist
Feb 18 03:20:52.197: INFO: namespace e2e-tests-deployment-2tzzd deletion completed in 6.14237953s

• [SLOW TEST:29.408 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:20:52.197: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vwcp6
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vwcp6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vwcp6
Feb 18 03:20:52.314: INFO: Found 0 stateful pods, waiting for 1
Feb 18 03:21:02.321: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 18 03:21:02.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 03:21:02.824: INFO: stderr: ""
Feb 18 03:21:02.824: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 03:21:02.824: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 03:21:02.829: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 18 03:21:12.835: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 03:21:12.835: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 03:21:12.854: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:12.854: INFO: ss-0  xen16-168.ebaotech.com  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:12.854: INFO: 
Feb 18 03:21:12.854: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 18 03:21:13.865: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995675455s
Feb 18 03:21:14.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984750205s
Feb 18 03:21:15.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977985269s
Feb 18 03:21:16.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971886281s
Feb 18 03:21:17.891: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.964799408s
Feb 18 03:21:18.897: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.958420496s
Feb 18 03:21:19.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.952180869s
Feb 18 03:21:20.911: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.94591023s
Feb 18 03:21:21.918: INFO: Verifying statefulset ss doesn't scale past 3 for another 938.234389ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vwcp6
Feb 18 03:21:22.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:21:23.406: INFO: stderr: ""
Feb 18 03:21:23.406: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 03:21:23.406: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 03:21:23.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:21:23.894: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 18 03:21:23.894: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 03:21:23.894: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 03:21:23.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:21:24.400: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 18 03:21:24.400: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 03:21:24.400: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 03:21:24.406: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:21:24.406: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:21:24.406: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 18 03:21:24.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 03:21:24.915: INFO: stderr: ""
Feb 18 03:21:24.915: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 03:21:24.915: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 03:21:24.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 03:21:25.405: INFO: stderr: ""
Feb 18 03:21:25.405: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 03:21:25.405: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 03:21:25.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 03:21:25.899: INFO: stderr: ""
Feb 18 03:21:25.899: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 03:21:25.899: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 03:21:25.899: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 03:21:25.904: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 18 03:21:35.914: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 03:21:35.914: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 03:21:35.914: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 03:21:35.930: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:35.930: INFO: ss-0  xen16-168.ebaotech.com  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:35.930: INFO: ss-1  xen16-168.ebaotech.com  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  }]
Feb 18 03:21:35.930: INFO: ss-2  xen16-168.ebaotech.com  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  }]
Feb 18 03:21:35.930: INFO: 
Feb 18 03:21:35.930: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 03:21:36.937: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:36.937: INFO: ss-0  xen16-168.ebaotech.com  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:36.937: INFO: ss-1  xen16-168.ebaotech.com  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  }]
Feb 18 03:21:36.937: INFO: ss-2  xen16-168.ebaotech.com  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:12 +0000 UTC  }]
Feb 18 03:21:36.937: INFO: 
Feb 18 03:21:36.937: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 03:21:37.943: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:37.943: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:37.943: INFO: 
Feb 18 03:21:37.943: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:38.949: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:38.949: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:38.949: INFO: 
Feb 18 03:21:38.949: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:39.954: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:39.954: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:39.954: INFO: 
Feb 18 03:21:39.954: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:40.961: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:40.961: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:40.961: INFO: 
Feb 18 03:21:40.961: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:41.967: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:41.967: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:41.967: INFO: 
Feb 18 03:21:41.967: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:42.974: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:42.974: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:42.974: INFO: 
Feb 18 03:21:42.974: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:43.980: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:43.980: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:43.980: INFO: 
Feb 18 03:21:43.980: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 18 03:21:44.986: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
Feb 18 03:21:44.986: INFO: ss-0  xen16-168.ebaotech.com  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:21:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:20:52 +0000 UTC  }]
Feb 18 03:21:44.986: INFO: 
Feb 18 03:21:44.986: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vwcp6
Feb 18 03:21:45.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:21:46.215: INFO: rc: 1
Feb 18 03:21:46.216: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0017212c0 exit status 1 <nil> <nil> true [0xc001dcc468 0xc001dcc480 0xc001dcc498] [0xc001dcc468 0xc001dcc480 0xc001dcc498] [0xc001dcc478 0xc001dcc490] [0x92f8e0 0x92f8e0] 0xc001b6dec0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb 18 03:21:56.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:21:56.374: INFO: rc: 1
Feb 18 03:21:56.374: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017217a0 exit status 1 <nil> <nil> true [0xc001dcc4a0 0xc001dcc4b8 0xc001dcc4d0] [0xc001dcc4a0 0xc001dcc4b8 0xc001dcc4d0] [0xc001dcc4b0 0xc001dcc4c8] [0x92f8e0 0x92f8e0] 0xc001970360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:22:06.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:22:06.524: INFO: rc: 1
Feb 18 03:22:06.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001844d80 exit status 1 <nil> <nil> true [0xc001dc4560 0xc001dc4578 0xc001dc4590] [0xc001dc4560 0xc001dc4578 0xc001dc4590] [0xc001dc4570 0xc001dc4588] [0x92f8e0 0x92f8e0] 0xc001b0d860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:22:16.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:22:16.671: INFO: rc: 1
Feb 18 03:22:16.671: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001721b90 exit status 1 <nil> <nil> true [0xc001dcc4d8 0xc001dcc4f0 0xc001dcc508] [0xc001dcc4d8 0xc001dcc4f0 0xc001dcc508] [0xc001dcc4e8 0xc001dcc500] [0x92f8e0 0x92f8e0] 0xc001970960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:22:26.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:22:26.825: INFO: rc: 1
Feb 18 03:22:26.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001721f20 exit status 1 <nil> <nil> true [0xc001dcc510 0xc001dcc528 0xc001dcc540] [0xc001dcc510 0xc001dcc528 0xc001dcc540] [0xc001dcc520 0xc001dcc538] [0x92f8e0 0x92f8e0] 0xc001970fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:22:36.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:22:36.971: INFO: rc: 1
Feb 18 03:22:36.971: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001845170 exit status 1 <nil> <nil> true [0xc001dc4598 0xc001dc45b0 0xc001dc45c8] [0xc001dc4598 0xc001dc45b0 0xc001dc45c8] [0xc001dc45a8 0xc001dc45c0] [0x92f8e0 0x92f8e0] 0xc001b0db60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:22:46.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:22:47.135: INFO: rc: 1
Feb 18 03:22:47.135: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000fbc660 exit status 1 <nil> <nil> true [0xc001dcc548 0xc001dcc560 0xc001dcc578] [0xc001dcc548 0xc001dcc560 0xc001dcc578] [0xc001dcc558 0xc001dcc570] [0x92f8e0 0x92f8e0] 0xc001971380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:22:57.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:22:57.293: INFO: rc: 1
Feb 18 03:22:57.293: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000678a20 exit status 1 <nil> <nil> true [0xc00035b270 0xc00035b410 0xc00035b5d0] [0xc00035b270 0xc00035b410 0xc00035b5d0] [0xc00035b330 0xc00035b558] [0x92f8e0 0x92f8e0] 0xc0015e1440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:23:07.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:23:07.450: INFO: rc: 1
Feb 18 03:23:07.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000679380 exit status 1 <nil> <nil> true [0xc00035b5f0 0xc00035b640 0xc00035b718] [0xc00035b5f0 0xc00035b640 0xc00035b718] [0xc00035b618 0xc00035b6f0] [0x92f8e0 0x92f8e0] 0xc001b6c120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:23:17.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:23:17.600: INFO: rc: 1
Feb 18 03:23:17.600: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001720390 exit status 1 <nil> <nil> true [0xc0001601b8 0xc0001602f0 0xc000160858] [0xc0001601b8 0xc0001602f0 0xc000160858] [0xc000160298 0xc0001605d0] [0x92f8e0 0x92f8e0] 0xc00137a420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:23:27.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:23:27.755: INFO: rc: 1
Feb 18 03:23:27.756: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2c390 exit status 1 <nil> <nil> true [0xc000696320 0xc000696398 0xc0006964b0] [0xc000696320 0xc000696398 0xc0006964b0] [0xc000696330 0xc000696480] [0x92f8e0 0x92f8e0] 0xc0017a05a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:23:37.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:23:37.910: INFO: rc: 1
Feb 18 03:23:37.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2c720 exit status 1 <nil> <nil> true [0xc0006964d0 0xc0006966e0 0xc000696c68] [0xc0006964d0 0xc0006966e0 0xc000696c68] [0xc000696650 0xc000696c10] [0x92f8e0 0x92f8e0] 0xc0017a0c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:23:47.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:23:48.064: INFO: rc: 1
Feb 18 03:23:48.064: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2cb40 exit status 1 <nil> <nil> true [0xc000696ca8 0xc000696e00 0xc000696f00] [0xc000696ca8 0xc000696e00 0xc000696f00] [0xc000696d98 0xc000696ed8] [0x92f8e0 0x92f8e0] 0xc0017a1140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:23:58.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:23:58.221: INFO: rc: 1
Feb 18 03:23:58.221: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001720750 exit status 1 <nil> <nil> true [0xc0001608d0 0xc000160aa0 0xc000160c48] [0xc0001608d0 0xc000160aa0 0xc000160c48] [0xc0001609f8 0xc000160bc0] [0x92f8e0 0x92f8e0] 0xc00137a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:24:08.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:24:08.377: INFO: rc: 1
Feb 18 03:24:08.377: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001720ba0 exit status 1 <nil> <nil> true [0xc000160c90 0xc000160f30 0xc000161018] [0xc000160c90 0xc000160f30 0xc000161018] [0xc000160e28 0xc000160fc0] [0x92f8e0 0x92f8e0] 0xc00137aba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:24:18.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:24:18.528: INFO: rc: 1
Feb 18 03:24:18.529: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0006799b0 exit status 1 <nil> <nil> true [0xc00035b750 0xc00035b798 0xc00035b7d0] [0xc00035b750 0xc00035b798 0xc00035b7d0] [0xc00035b790 0xc00035b7b0] [0x92f8e0 0x92f8e0] 0xc001b6c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:24:28.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:24:28.682: INFO: rc: 1
Feb 18 03:24:28.682: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000679da0 exit status 1 <nil> <nil> true [0xc00035b818 0xc00035b8d0 0xc00035b948] [0xc00035b818 0xc00035b8d0 0xc00035b948] [0xc00035b8b8 0xc00035b918] [0x92f8e0 0x92f8e0] 0xc001b6c8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:24:38.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:24:38.833: INFO: rc: 1
Feb 18 03:24:38.833: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2cff0 exit status 1 <nil> <nil> true [0xc000696f90 0xc000697030 0xc000697128] [0xc000696f90 0xc000697030 0xc000697128] [0xc000696fd8 0xc0006970c8] [0x92f8e0 0x92f8e0] 0xc0017a16e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:24:48.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:24:48.981: INFO: rc: 1
Feb 18 03:24:48.981: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a22150 exit status 1 <nil> <nil> true [0xc00035b988 0xc00035ba50 0xc00035bb30] [0xc00035b988 0xc00035ba50 0xc00035bb30] [0xc00035ba18 0xc00035ba90] [0x92f8e0 0x92f8e0] 0xc001b6cc00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:24:58.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:24:59.134: INFO: rc: 1
Feb 18 03:24:59.135: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001720c30 exit status 1 <nil> <nil> true [0xc000697168 0xc000697238 0xc0006972d8] [0xc000697168 0xc000697238 0xc0006972d8] [0xc0006971f0 0xc0006972c0] [0x92f8e0 0x92f8e0] 0xc00137acc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:25:09.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:25:09.285: INFO: rc: 1
Feb 18 03:25:09.285: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000678a50 exit status 1 <nil> <nil> true [0xc0001601b8 0xc0001602f0 0xc000160858] [0xc0001601b8 0xc0001602f0 0xc000160858] [0xc000160298 0xc0001605d0] [0x92f8e0 0x92f8e0] 0xc0015e1440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:25:19.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:25:19.434: INFO: rc: 1
Feb 18 03:25:19.434: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a223c0 exit status 1 <nil> <nil> true [0xc00035b270 0xc00035b410 0xc00035b5d0] [0xc00035b270 0xc00035b410 0xc00035b5d0] [0xc00035b330 0xc00035b558] [0x92f8e0 0x92f8e0] 0xc001b6c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:25:29.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:25:29.581: INFO: rc: 1
Feb 18 03:25:29.581: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2c3c0 exit status 1 <nil> <nil> true [0xc000696320 0xc000696398 0xc0006964b0] [0xc000696320 0xc000696398 0xc0006964b0] [0xc000696330 0xc000696480] [0x92f8e0 0x92f8e0] 0xc00137a420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:25:39.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:25:39.743: INFO: rc: 1
Feb 18 03:25:39.743: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2c7b0 exit status 1 <nil> <nil> true [0xc0006964d0 0xc0006966e0 0xc000696c68] [0xc0006964d0 0xc0006966e0 0xc000696c68] [0xc000696650 0xc000696c10] [0x92f8e0 0x92f8e0] 0xc00137a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:25:49.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:25:49.889: INFO: rc: 1
Feb 18 03:25:49.889: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2cc00 exit status 1 <nil> <nil> true [0xc000696ca8 0xc000696e00 0xc000696f00] [0xc000696ca8 0xc000696e00 0xc000696f00] [0xc000696d98 0xc000696ed8] [0x92f8e0 0x92f8e0] 0xc00137aba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:25:59.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:26:00.038: INFO: rc: 1
Feb 18 03:26:00.038: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2d080 exit status 1 <nil> <nil> true [0xc000696f90 0xc000697030 0xc000697128] [0xc000696f90 0xc000697030 0xc000697128] [0xc000696fd8 0xc0006970c8] [0x92f8e0 0x92f8e0] 0xc00137b3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:26:10.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:26:10.177: INFO: rc: 1
Feb 18 03:26:10.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2da70 exit status 1 <nil> <nil> true [0xc000697190 0xc000697360 0xc000697430] [0xc000697190 0xc000697360 0xc000697430] [0xc0006972e8 0xc0006973c8] [0x92f8e0 0x92f8e0] 0xc00137be60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:26:20.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:26:20.335: INFO: rc: 1
Feb 18 03:26:20.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000679470 exit status 1 <nil> <nil> true [0xc0001608d0 0xc000160aa0 0xc000160c48] [0xc0001608d0 0xc000160aa0 0xc000160c48] [0xc0001609f8 0xc000160bc0] [0x92f8e0 0x92f8e0] 0xc0017a0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:26:30.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:26:30.491: INFO: rc: 1
Feb 18 03:26:30.491: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0017203f0 exit status 1 <nil> <nil> true [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc010 0xc001dcc028] [0x92f8e0 0x92f8e0] 0xc0018d6300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:26:40.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:26:40.647: INFO: rc: 1
Feb 18 03:26:40.647: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000e2def0 exit status 1 <nil> <nil> true [0xc000697440 0xc000697468 0xc000697530] [0xc000697440 0xc000697468 0xc000697530] [0xc000697460 0xc0006974d0] [0x92f8e0 0x92f8e0] 0xc0016f8cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Feb 18 03:26:50.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-vwcp6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:26:50.805: INFO: rc: 1
Feb 18 03:26:50.805: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Feb 18 03:26:50.805: INFO: Scaling statefulset ss to 0
Feb 18 03:26:50.817: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 03:26:50.821: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vwcp6
Feb 18 03:26:50.824: INFO: Scaling statefulset ss to 0
Feb 18 03:26:50.835: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 03:26:50.839: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:26:50.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vwcp6" for this suite.
Feb 18 03:26:56.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:26:56.963: INFO: namespace: e2e-tests-statefulset-vwcp6, resource: bindings, ignored listing per whitelist
Feb 18 03:26:56.989: INFO: namespace e2e-tests-statefulset-vwcp6 deletion completed in 6.130548793s

• [SLOW TEST:364.792 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:26:56.990: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-w9svr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-w9svr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-w9svr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-w9svr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-w9svr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-w9svr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 18 03:27:01.215: INFO: DNS probes using e2e-tests-dns-w9svr/dns-test-0b7f2318-332d-11e9-94e0-0a580af401c1 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:27:01.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-w9svr" for this suite.
Feb 18 03:27:07.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:27:07.322: INFO: namespace: e2e-tests-dns-w9svr, resource: bindings, ignored listing per whitelist
Feb 18 03:27:07.371: INFO: namespace e2e-tests-dns-w9svr deletion completed in 6.138087382s

• [SLOW TEST:10.381 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:27:07.371: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 03:27:07.485: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-9drjn" to be "success or failure"
Feb 18 03:27:07.492: INFO: Pod "downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.416008ms
Feb 18 03:27:09.497: INFO: Pod "downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012058939s
STEP: Saw pod success
Feb 18 03:27:09.497: INFO: Pod "downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:27:09.502: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 03:27:09.619: INFO: Waiting for pod downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:27:09.623: INFO: Pod downwardapi-volume-11af5d93-332d-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:27:09.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9drjn" for this suite.
Feb 18 03:27:15.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:27:15.696: INFO: namespace: e2e-tests-projected-9drjn, resource: bindings, ignored listing per whitelist
Feb 18 03:27:15.764: INFO: namespace e2e-tests-projected-9drjn deletion completed in 6.134219353s

• [SLOW TEST:8.393 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:27:15.764: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 03:27:15.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6dmlp'
Feb 18 03:27:16.185: INFO: stderr: ""
Feb 18 03:27:16.185: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 18 03:27:21.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6dmlp -o json'
Feb 18 03:27:21.397: INFO: stderr: ""
Feb 18 03:27:21.397: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-18T03:27:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-6dmlp\",\n        \"resourceVersion\": \"331997\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-6dmlp/pods/e2e-test-nginx-pod\",\n        \"uid\": \"16dc43da-332d-11e9-9a73-8a88965a7424\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-r75nr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"xen16-168.ebaotech.com\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-r75nr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-r75nr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-18T03:27:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-18T03:27:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-18T03:27:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-18T03:27:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://02e0f7c6cef47bab24c1092c2694874ffb2e7e33d1b85f4714d4df591a50de64\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-18T03:27:17Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.25.16.168\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.236\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-18T03:27:16Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 18 03:27:21.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 replace -f - --namespace=e2e-tests-kubectl-6dmlp'
Feb 18 03:27:21.705: INFO: stderr: ""
Feb 18 03:27:21.705: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 18 03:27:21.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6dmlp'
Feb 18 03:27:27.449: INFO: stderr: ""
Feb 18 03:27:27.449: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:27:27.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6dmlp" for this suite.
Feb 18 03:27:33.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:27:33.551: INFO: namespace: e2e-tests-kubectl-6dmlp, resource: bindings, ignored listing per whitelist
Feb 18 03:27:33.590: INFO: namespace e2e-tests-kubectl-6dmlp deletion completed in 6.134976738s

• [SLOW TEST:17.826 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:27:33.590: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 18 03:27:33.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 api-versions'
Feb 18 03:27:33.907: INFO: stderr: ""
Feb 18 03:27:33.907: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:27:33.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8brjw" for this suite.
Feb 18 03:27:40.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:27:40.087: INFO: namespace: e2e-tests-kubectl-8brjw, resource: bindings, ignored listing per whitelist
Feb 18 03:27:40.131: INFO: namespace e2e-tests-kubectl-8brjw deletion completed in 6.217847043s

• [SLOW TEST:6.541 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:27:40.131: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-2rbz
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 03:27:40.245: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2rbz" in namespace "e2e-tests-subpath-cvkqn" to be "success or failure"
Feb 18 03:27:40.249: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.303366ms
Feb 18 03:27:42.253: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008616276s
Feb 18 03:27:44.259: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 4.014814978s
Feb 18 03:27:46.265: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 6.020644939s
Feb 18 03:27:48.271: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 8.026163044s
Feb 18 03:27:50.277: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 10.032033477s
Feb 18 03:27:52.282: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 12.037654962s
Feb 18 03:27:54.288: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 14.043303116s
Feb 18 03:27:56.294: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 16.049645949s
Feb 18 03:27:58.300: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 18.05565891s
Feb 18 03:28:00.306: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 20.061362497s
Feb 18 03:28:02.315: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Running", Reason="", readiness=false. Elapsed: 22.07008363s
Feb 18 03:28:04.321: INFO: Pod "pod-subpath-test-configmap-2rbz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.076043356s
STEP: Saw pod success
Feb 18 03:28:04.321: INFO: Pod "pod-subpath-test-configmap-2rbz" satisfied condition "success or failure"
Feb 18 03:28:04.325: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-subpath-test-configmap-2rbz container test-container-subpath-configmap-2rbz: <nil>
STEP: delete the pod
Feb 18 03:28:04.350: INFO: Waiting for pod pod-subpath-test-configmap-2rbz to disappear
Feb 18 03:28:04.354: INFO: Pod pod-subpath-test-configmap-2rbz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2rbz
Feb 18 03:28:04.354: INFO: Deleting pod "pod-subpath-test-configmap-2rbz" in namespace "e2e-tests-subpath-cvkqn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:28:04.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cvkqn" for this suite.
Feb 18 03:28:10.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:28:10.399: INFO: namespace: e2e-tests-subpath-cvkqn, resource: bindings, ignored listing per whitelist
Feb 18 03:28:10.492: INFO: namespace e2e-tests-subpath-cvkqn deletion completed in 6.127778213s

• [SLOW TEST:30.360 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:28:10.492: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-stdpc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 03:28:10.611: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 03:28:32.675: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.1.238 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-stdpc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 03:28:32.675: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 03:28:34.017: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:28:34.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-stdpc" for this suite.
Feb 18 03:28:56.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:28:56.162: INFO: namespace: e2e-tests-pod-network-test-stdpc, resource: bindings, ignored listing per whitelist
Feb 18 03:28:56.202: INFO: namespace e2e-tests-pod-network-test-stdpc deletion completed in 22.177472601s

• [SLOW TEST:45.710 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:28:56.202: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:28:56.342: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 18 03:28:56.353: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:28:56.356: INFO: Number of nodes with available pods: 0
Feb 18 03:28:56.356: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:28:57.362: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:28:57.367: INFO: Number of nodes with available pods: 0
Feb 18 03:28:57.367: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:28:58.362: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:28:58.366: INFO: Number of nodes with available pods: 1
Feb 18 03:28:58.366: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 18 03:28:58.397: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:28:58.408: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:28:59.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:28:59.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:00.452: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:00.458: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:01.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:01.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:02.445: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:02.451: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:03.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:03.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:04.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:04.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:05.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:05.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:06.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:06.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:07.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:07.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:08.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:08.428: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:09.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:09.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:10.415: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:10.421: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:11.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:11.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:12.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:12.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:13.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:13.581: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:14.446: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:14.452: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:15.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:15.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:16.412: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:16.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:17.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:17.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:18.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:18.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:19.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:19.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:20.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:20.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:21.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:21.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:22.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:22.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:23.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:23.421: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:24.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:24.421: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:25.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:25.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:26.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:26.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:27.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:27.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:28.415: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:28.421: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:29.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:29.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:30.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:30.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:31.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:31.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:32.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:32.414: INFO: Pod daemon-set-bqqvw is not available
Feb 18 03:29:32.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:33.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:33.414: INFO: Pod daemon-set-bqqvw is not available
Feb 18 03:29:33.422: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:34.415: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:34.415: INFO: Pod daemon-set-bqqvw is not available
Feb 18 03:29:34.421: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:35.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:35.414: INFO: Pod daemon-set-bqqvw is not available
Feb 18 03:29:35.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:36.413: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:36.413: INFO: Pod daemon-set-bqqvw is not available
Feb 18 03:29:36.418: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:37.414: INFO: Wrong image for pod: daemon-set-bqqvw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 18 03:29:37.414: INFO: Pod daemon-set-bqqvw is not available
Feb 18 03:29:37.419: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:38.414: INFO: Pod daemon-set-frtg6 is not available
Feb 18 03:29:38.420: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 18 03:29:38.425: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:38.429: INFO: Number of nodes with available pods: 0
Feb 18 03:29:38.429: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:29:39.435: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:29:39.439: INFO: Number of nodes with available pods: 1
Feb 18 03:29:39.439: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2xbs9, will wait for the garbage collector to delete the pods
Feb 18 03:29:39.524: INFO: Deleting DaemonSet.extensions daemon-set took: 10.114697ms
Feb 18 03:29:39.624: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.363701ms
Feb 18 03:29:43.529: INFO: Number of nodes with available pods: 0
Feb 18 03:29:43.529: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 03:29:43.533: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2xbs9/daemonsets","resourceVersion":"332358"},"items":null}

Feb 18 03:29:43.537: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2xbs9/pods","resourceVersion":"332358"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:29:43.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2xbs9" for this suite.
Feb 18 03:29:49.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:29:49.613: INFO: namespace: e2e-tests-daemonsets-2xbs9, resource: bindings, ignored listing per whitelist
Feb 18 03:29:49.686: INFO: namespace e2e-tests-daemonsets-2xbs9 deletion completed in 6.133977361s

• [SLOW TEST:53.484 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:29:49.686: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 18 03:29:49.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:50.095: INFO: stderr: ""
Feb 18 03:29:50.095: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 03:29:50.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:50.257: INFO: stderr: ""
Feb 18 03:29:50.257: INFO: stdout: "update-demo-nautilus-wsrcq update-demo-nautilus-x9nwf "
Feb 18 03:29:50.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-wsrcq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:50.426: INFO: stderr: ""
Feb 18 03:29:50.427: INFO: stdout: ""
Feb 18 03:29:50.427: INFO: update-demo-nautilus-wsrcq is created but not running
Feb 18 03:29:55.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:55.603: INFO: stderr: ""
Feb 18 03:29:55.603: INFO: stdout: "update-demo-nautilus-wsrcq update-demo-nautilus-x9nwf "
Feb 18 03:29:55.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-wsrcq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:55.774: INFO: stderr: ""
Feb 18 03:29:55.774: INFO: stdout: "true"
Feb 18 03:29:55.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-wsrcq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:55.944: INFO: stderr: ""
Feb 18 03:29:55.944: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 03:29:55.944: INFO: validating pod update-demo-nautilus-wsrcq
Feb 18 03:29:55.953: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 03:29:55.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 03:29:55.953: INFO: update-demo-nautilus-wsrcq is verified up and running
Feb 18 03:29:55.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-x9nwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:56.126: INFO: stderr: ""
Feb 18 03:29:56.126: INFO: stdout: "true"
Feb 18 03:29:56.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-x9nwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:56.289: INFO: stderr: ""
Feb 18 03:29:56.290: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 03:29:56.290: INFO: validating pod update-demo-nautilus-x9nwf
Feb 18 03:29:56.296: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 03:29:56.296: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 03:29:56.296: INFO: update-demo-nautilus-x9nwf is verified up and running
STEP: scaling down the replication controller
Feb 18 03:29:56.298: INFO: scanned /root for discovery docs: <nil>
Feb 18 03:29:56.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:57.516: INFO: stderr: ""
Feb 18 03:29:57.516: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 03:29:57.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:29:57.709: INFO: stderr: ""
Feb 18 03:29:57.710: INFO: stdout: "update-demo-nautilus-wsrcq update-demo-nautilus-x9nwf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 18 03:30:02.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:02.884: INFO: stderr: ""
Feb 18 03:30:02.884: INFO: stdout: "update-demo-nautilus-x9nwf "
Feb 18 03:30:02.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-x9nwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:03.055: INFO: stderr: ""
Feb 18 03:30:03.055: INFO: stdout: "true"
Feb 18 03:30:03.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-x9nwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:03.208: INFO: stderr: ""
Feb 18 03:30:03.208: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 03:30:03.208: INFO: validating pod update-demo-nautilus-x9nwf
Feb 18 03:30:03.214: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 03:30:03.214: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 03:30:03.214: INFO: update-demo-nautilus-x9nwf is verified up and running
STEP: scaling up the replication controller
Feb 18 03:30:03.216: INFO: scanned /root for discovery docs: <nil>
Feb 18 03:30:03.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:04.508: INFO: stderr: ""
Feb 18 03:30:04.508: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 03:30:04.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:04.688: INFO: stderr: ""
Feb 18 03:30:04.688: INFO: stdout: "update-demo-nautilus-hjsjt update-demo-nautilus-x9nwf "
Feb 18 03:30:04.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-hjsjt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:04.857: INFO: stderr: ""
Feb 18 03:30:04.858: INFO: stdout: ""
Feb 18 03:30:04.858: INFO: update-demo-nautilus-hjsjt is created but not running
Feb 18 03:30:09.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:10.033: INFO: stderr: ""
Feb 18 03:30:10.033: INFO: stdout: "update-demo-nautilus-hjsjt update-demo-nautilus-x9nwf "
Feb 18 03:30:10.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-hjsjt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:10.190: INFO: stderr: ""
Feb 18 03:30:10.190: INFO: stdout: "true"
Feb 18 03:30:10.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-hjsjt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:10.354: INFO: stderr: ""
Feb 18 03:30:10.354: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 03:30:10.354: INFO: validating pod update-demo-nautilus-hjsjt
Feb 18 03:30:10.362: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 03:30:10.362: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 03:30:10.362: INFO: update-demo-nautilus-hjsjt is verified up and running
Feb 18 03:30:10.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-x9nwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:10.522: INFO: stderr: ""
Feb 18 03:30:10.522: INFO: stdout: "true"
Feb 18 03:30:10.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-x9nwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:10.691: INFO: stderr: ""
Feb 18 03:30:10.691: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 03:30:10.691: INFO: validating pod update-demo-nautilus-x9nwf
Feb 18 03:30:10.698: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 03:30:10.698: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 03:30:10.698: INFO: update-demo-nautilus-x9nwf is verified up and running
STEP: using delete to clean up resources
Feb 18 03:30:10.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:10.857: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 03:30:10.857: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 18 03:30:10.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-rz6b8'
Feb 18 03:30:11.032: INFO: stderr: "No resources found.\n"
Feb 18 03:30:11.032: INFO: stdout: ""
Feb 18 03:30:11.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -l name=update-demo --namespace=e2e-tests-kubectl-rz6b8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 03:30:11.208: INFO: stderr: ""
Feb 18 03:30:11.208: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:30:11.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rz6b8" for this suite.
Feb 18 03:30:33.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:30:33.272: INFO: namespace: e2e-tests-kubectl-rz6b8, resource: bindings, ignored listing per whitelist
Feb 18 03:30:33.343: INFO: namespace e2e-tests-kubectl-rz6b8 deletion completed in 22.129239959s

• [SLOW TEST:43.657 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:30:33.344: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 18 03:30:33.512: INFO: Waiting up to 5m0s for pod "client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1" in namespace "e2e-tests-containers-6kxt8" to be "success or failure"
Feb 18 03:30:33.521: INFO: Pod "client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.176039ms
Feb 18 03:30:35.526: INFO: Pod "client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013368453s
STEP: Saw pod success
Feb 18 03:30:35.526: INFO: Pod "client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:30:35.531: INFO: Trying to get logs from node xen16-168.ebaotech.com pod client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:30:35.556: INFO: Waiting for pod client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:30:35.560: INFO: Pod client-containers-8c7ce341-332d-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:30:35.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6kxt8" for this suite.
Feb 18 03:30:41.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:30:41.596: INFO: namespace: e2e-tests-containers-6kxt8, resource: bindings, ignored listing per whitelist
Feb 18 03:30:41.691: INFO: namespace e2e-tests-containers-6kxt8 deletion completed in 6.125363219s

• [SLOW TEST:8.347 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:30:41.691: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 18 03:30:41.786: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 18 03:30:41.796: INFO: Waiting for terminating namespaces to be deleted...
Feb 18 03:30:41.799: INFO: 
Logging pods the kubelet thinks is on node xen16-168.ebaotech.com before test
Feb 18 03:30:41.809: INFO: kube-flannel-ds-amd64-2ll58 from kube-system started at 2019-02-15 09:27:27 +0000 UTC (1 container statuses recorded)
Feb 18 03:30:41.809: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 18 03:30:41.809: INFO: kube-proxy-9c526 from kube-system started at 2019-02-15 09:27:27 +0000 UTC (1 container statuses recorded)
Feb 18 03:30:41.809: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 03:30:41.809: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-18 03:08:34 +0000 UTC (1 container statuses recorded)
Feb 18 03:30:41.809: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 18 03:30:41.809: INFO: sonobuoy-systemd-logs-daemon-set-4510b99ad8934c9d-dqlfh from heptio-sonobuoy started at 2019-02-18 03:08:41 +0000 UTC (2 container statuses recorded)
Feb 18 03:30:41.809: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 18 03:30:41.809: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 03:30:41.809: INFO: sonobuoy-e2e-job-25438afdb0174082 from heptio-sonobuoy started at 2019-02-18 03:08:41 +0000 UTC (2 container statuses recorded)
Feb 18 03:30:41.809: INFO: 	Container e2e ready: true, restart count 0
Feb 18 03:30:41.809: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158457bd31f15e1c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:30:42.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-whtr6" for this suite.
Feb 18 03:30:48.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:30:48.934: INFO: namespace: e2e-tests-sched-pred-whtr6, resource: bindings, ignored listing per whitelist
Feb 18 03:30:48.992: INFO: namespace e2e-tests-sched-pred-whtr6 deletion completed in 6.148539199s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.301 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:30:48.992: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0218 03:31:29.247870      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 03:31:29.247: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:31:29.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wdmqm" for this suite.
Feb 18 03:31:35.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:31:35.473: INFO: namespace: e2e-tests-gc-wdmqm, resource: bindings, ignored listing per whitelist
Feb 18 03:31:35.477: INFO: namespace e2e-tests-gc-wdmqm deletion completed in 6.225695107s

• [SLOW TEST:46.485 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:31:35.478: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:32:03.597: INFO: Container started at 2019-02-18 03:31:37 +0000 UTC, pod became ready at 2019-02-18 03:32:01 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:32:03.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hprfj" for this suite.
Feb 18 03:32:25.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:32:25.681: INFO: namespace: e2e-tests-container-probe-hprfj, resource: bindings, ignored listing per whitelist
Feb 18 03:32:25.733: INFO: namespace e2e-tests-container-probe-hprfj deletion completed in 22.130091762s

• [SLOW TEST:50.255 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:32:25.733: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 18 03:32:36.865: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:32:37.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-vv5zz" for this suite.
Feb 18 03:32:59.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:32:59.970: INFO: namespace: e2e-tests-replicaset-vv5zz, resource: bindings, ignored listing per whitelist
Feb 18 03:33:00.020: INFO: namespace e2e-tests-replicaset-vv5zz deletion completed in 22.12789023s

• [SLOW TEST:34.287 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:33:00.020: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-e3e05e6b-332d-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:33:04.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kqnl4" for this suite.
Feb 18 03:33:26.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:33:26.366: INFO: namespace: e2e-tests-configmap-kqnl4, resource: bindings, ignored listing per whitelist
Feb 18 03:33:26.369: INFO: namespace e2e-tests-configmap-kqnl4 deletion completed in 22.187455257s

• [SLOW TEST:26.349 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:33:26.370: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 18 03:33:26.469: INFO: Waiting up to 5m0s for pod "pod-f39415e1-332d-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-j2d54" to be "success or failure"
Feb 18 03:33:26.473: INFO: Pod "pod-f39415e1-332d-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.606218ms
Feb 18 03:33:28.478: INFO: Pod "pod-f39415e1-332d-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008707009s
STEP: Saw pod success
Feb 18 03:33:28.478: INFO: Pod "pod-f39415e1-332d-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:33:28.482: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-f39415e1-332d-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:33:28.506: INFO: Waiting for pod pod-f39415e1-332d-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:33:28.509: INFO: Pod pod-f39415e1-332d-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:33:28.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j2d54" for this suite.
Feb 18 03:33:34.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:33:34.558: INFO: namespace: e2e-tests-emptydir-j2d54, resource: bindings, ignored listing per whitelist
Feb 18 03:33:34.644: INFO: namespace e2e-tests-emptydir-j2d54 deletion completed in 6.129986294s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:33:34.644: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 18 03:33:37.284: INFO: Successfully updated pod "annotationupdatef881e4d6-332d-11e9-94e0-0a580af401c1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:33:39.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cptbw" for this suite.
Feb 18 03:34:01.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:34:01.392: INFO: namespace: e2e-tests-projected-cptbw, resource: bindings, ignored listing per whitelist
Feb 18 03:34:01.449: INFO: namespace e2e-tests-projected-cptbw deletion completed in 22.134434993s

• [SLOW TEST:26.805 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:34:01.449: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 18 03:34:01.557: INFO: Waiting up to 5m0s for pod "var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1" in namespace "e2e-tests-var-expansion-vv5cc" to be "success or failure"
Feb 18 03:34:01.561: INFO: Pod "var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.360895ms
Feb 18 03:34:03.566: INFO: Pod "var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009282915s
STEP: Saw pod success
Feb 18 03:34:03.566: INFO: Pod "var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:34:03.570: INFO: Trying to get logs from node xen16-168.ebaotech.com pod var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 03:34:03.595: INFO: Waiting for pod var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:34:03.599: INFO: Pod var-expansion-087dedcc-332e-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:34:03.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vv5cc" for this suite.
Feb 18 03:34:09.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:34:09.867: INFO: namespace: e2e-tests-var-expansion-vv5cc, resource: bindings, ignored listing per whitelist
Feb 18 03:34:09.939: INFO: namespace e2e-tests-var-expansion-vv5cc deletion completed in 6.33516063s

• [SLOW TEST:8.490 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:34:09.939: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mvtv7
Feb 18 03:34:12.043: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mvtv7
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 03:34:12.047: INFO: Initial restart count of pod liveness-http is 0
Feb 18 03:34:30.100: INFO: Restart count of pod e2e-tests-container-probe-mvtv7/liveness-http is now 1 (18.053473433s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:34:30.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mvtv7" for this suite.
Feb 18 03:34:36.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:34:36.239: INFO: namespace: e2e-tests-container-probe-mvtv7, resource: bindings, ignored listing per whitelist
Feb 18 03:34:36.249: INFO: namespace e2e-tests-container-probe-mvtv7 deletion completed in 6.133227798s

• [SLOW TEST:26.310 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:34:36.250: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1d3c2b21-332e-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 03:34:36.362: INFO: Waiting up to 5m0s for pod "pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-vtc6k" to be "success or failure"
Feb 18 03:34:36.366: INFO: Pod "pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.140458ms
Feb 18 03:34:38.417: INFO: Pod "pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054779379s
Feb 18 03:34:40.422: INFO: Pod "pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059751432s
Feb 18 03:34:42.427: INFO: Pod "pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065162298s
STEP: Saw pod success
Feb 18 03:34:42.427: INFO: Pod "pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:34:42.431: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 03:34:42.454: INFO: Waiting for pod pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:34:42.458: INFO: Pod pod-configmaps-1d3ccc85-332e-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:34:42.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vtc6k" for this suite.
Feb 18 03:34:48.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:34:48.511: INFO: namespace: e2e-tests-configmap-vtc6k, resource: bindings, ignored listing per whitelist
Feb 18 03:34:48.586: INFO: namespace e2e-tests-configmap-vtc6k deletion completed in 6.12234284s

• [SLOW TEST:12.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:34:48.586: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 18 03:34:52.753: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-249b9bda-332e-11e9-94e0-0a580af401c1", GenerateName:"", Namespace:"e2e-tests-pods-dn8fv", SelfLink:"/api/v1/namespaces/e2e-tests-pods-dn8fv/pods/pod-submit-remove-249b9bda-332e-11e9-94e0-0a580af401c1", UID:"249b47cb-332e-11e9-9a73-8a88965a7424", ResourceVersion:"333347", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686057688, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"720083326"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4gtzt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000a43d40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4gtzt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001a773b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"xen16-168.ebaotech.com", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0018d6fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a773f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a774c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001a774c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001a774cc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686057688, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686057690, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686057690, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686057688, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.25.16.168", PodIP:"10.244.1.12", StartTime:(*v1.Time)(0xc000876940), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000876960), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://f8e5cf4d8e059609b794360056566c388c67d4c9dc6eb910758a7b68553f73ad"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 18 03:34:57.774: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:34:57.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dn8fv" for this suite.
Feb 18 03:35:03.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:35:03.867: INFO: namespace: e2e-tests-pods-dn8fv, resource: bindings, ignored listing per whitelist
Feb 18 03:35:03.918: INFO: namespace e2e-tests-pods-dn8fv deletion completed in 6.132145578s

• [SLOW TEST:15.333 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:35:03.919: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 18 03:35:04.021: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333385,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 03:35:04.021: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333385,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 18 03:35:14.031: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333399,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 18 03:35:14.032: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333399,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 18 03:35:24.042: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333413,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 03:35:24.042: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333413,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 18 03:35:34.051: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333427,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 03:35:34.051: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-a,UID:2db81ac2-332e-11e9-9a73-8a88965a7424,ResourceVersion:333427,Generation:0,CreationTimestamp:2019-02-18 03:35:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 18 03:35:44.062: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-b,UID:45957211-332e-11e9-9a73-8a88965a7424,ResourceVersion:333441,Generation:0,CreationTimestamp:2019-02-18 03:35:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 03:35:44.062: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-b,UID:45957211-332e-11e9-9a73-8a88965a7424,ResourceVersion:333441,Generation:0,CreationTimestamp:2019-02-18 03:35:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 18 03:35:54.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-b,UID:45957211-332e-11e9-9a73-8a88965a7424,ResourceVersion:333455,Generation:0,CreationTimestamp:2019-02-18 03:35:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 03:35:54.189: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-hppgt,SelfLink:/api/v1/namespaces/e2e-tests-watch-hppgt/configmaps/e2e-watch-test-configmap-b,UID:45957211-332e-11e9-9a73-8a88965a7424,ResourceVersion:333455,Generation:0,CreationTimestamp:2019-02-18 03:35:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:36:04.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hppgt" for this suite.
Feb 18 03:36:10.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:36:10.279: INFO: namespace: e2e-tests-watch-hppgt, resource: bindings, ignored listing per whitelist
Feb 18 03:36:10.337: INFO: namespace e2e-tests-watch-hppgt deletion completed in 6.140624251s

• [SLOW TEST:66.418 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:36:10.337: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:36:10.536: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:36:14.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-98sqd" for this suite.
Feb 18 03:36:52.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:36:52.657: INFO: namespace: e2e-tests-pods-98sqd, resource: bindings, ignored listing per whitelist
Feb 18 03:36:52.722: INFO: namespace e2e-tests-pods-98sqd deletion completed in 38.131121278s

• [SLOW TEST:42.385 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:36:52.722: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 03:36:52.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jmrv5'
Feb 18 03:36:53.013: INFO: stderr: ""
Feb 18 03:36:53.013: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 18 03:36:53.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-jmrv5'
Feb 18 03:36:57.449: INFO: stderr: ""
Feb 18 03:36:57.449: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:36:57.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jmrv5" for this suite.
Feb 18 03:37:03.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:37:03.520: INFO: namespace: e2e-tests-kubectl-jmrv5, resource: bindings, ignored listing per whitelist
Feb 18 03:37:03.588: INFO: namespace e2e-tests-kubectl-jmrv5 deletion completed in 6.133100394s

• [SLOW TEST:10.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:37:03.588: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 03:37:03.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hmjjq'
Feb 18 03:37:04.045: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 03:37:04.045: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 18 03:37:06.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hmjjq'
Feb 18 03:37:06.233: INFO: stderr: ""
Feb 18 03:37:06.233: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:37:06.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hmjjq" for this suite.
Feb 18 03:38:28.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:38:28.296: INFO: namespace: e2e-tests-kubectl-hmjjq, resource: bindings, ignored listing per whitelist
Feb 18 03:38:28.377: INFO: namespace e2e-tests-kubectl-hmjjq deletion completed in 1m22.137974607s

• [SLOW TEST:84.789 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:38:28.378: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-ln2m
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 03:38:28.490: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ln2m" in namespace "e2e-tests-subpath-m7gmh" to be "success or failure"
Feb 18 03:38:28.499: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Pending", Reason="", readiness=false. Elapsed: 8.851257ms
Feb 18 03:38:30.504: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014344438s
Feb 18 03:38:32.510: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019657216s
Feb 18 03:38:34.515: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025026982s
Feb 18 03:38:36.520: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 8.030093018s
Feb 18 03:38:38.526: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 10.035593819s
Feb 18 03:38:40.531: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 12.041500029s
Feb 18 03:38:42.537: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 14.047173725s
Feb 18 03:38:44.542: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 16.05237217s
Feb 18 03:38:46.548: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 18.058129089s
Feb 18 03:38:48.553: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 20.063523255s
Feb 18 03:38:50.560: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 22.069806534s
Feb 18 03:38:52.565: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 24.075347841s
Feb 18 03:38:54.571: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Running", Reason="", readiness=false. Elapsed: 26.080886199s
Feb 18 03:38:56.576: INFO: Pod "pod-subpath-test-projected-ln2m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.08631737s
STEP: Saw pod success
Feb 18 03:38:56.576: INFO: Pod "pod-subpath-test-projected-ln2m" satisfied condition "success or failure"
Feb 18 03:38:56.580: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-subpath-test-projected-ln2m container test-container-subpath-projected-ln2m: <nil>
STEP: delete the pod
Feb 18 03:38:56.608: INFO: Waiting for pod pod-subpath-test-projected-ln2m to disappear
Feb 18 03:38:56.611: INFO: Pod pod-subpath-test-projected-ln2m no longer exists
STEP: Deleting pod pod-subpath-test-projected-ln2m
Feb 18 03:38:56.612: INFO: Deleting pod "pod-subpath-test-projected-ln2m" in namespace "e2e-tests-subpath-m7gmh"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:38:56.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-m7gmh" for this suite.
Feb 18 03:39:02.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:39:02.654: INFO: namespace: e2e-tests-subpath-m7gmh, resource: bindings, ignored listing per whitelist
Feb 18 03:39:02.755: INFO: namespace e2e-tests-subpath-m7gmh deletion completed in 6.135286103s

• [SLOW TEST:34.378 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:39:02.755: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 18 03:39:06.877: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-bc14f91a-332e-11e9-94e0-0a580af401c1,GenerateName:,Namespace:e2e-tests-events-m7sb5,SelfLink:/api/v1/namespaces/e2e-tests-events-m7sb5/pods/send-events-bc14f91a-332e-11e9-94e0-0a580af401c1,UID:bc158520-332e-11e9-9a73-8a88965a7424,ResourceVersion:333843,Generation:0,CreationTimestamp:2019-02-18 03:39:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 851419777,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xll52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xll52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-xll52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c50650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c50670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:39:02 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:39:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:39:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:39:02 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.17,StartTime:2019-02-18 03:39:02 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-18 03:39:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ec6df9fd185e5243bf357db105a6c86c8303e469a9b0990391fc4222b1979216}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 18 03:39:08.883: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 18 03:39:10.890: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:39:10.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-m7sb5" for this suite.
Feb 18 03:39:48.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:39:48.971: INFO: namespace: e2e-tests-events-m7sb5, resource: bindings, ignored listing per whitelist
Feb 18 03:39:49.033: INFO: namespace e2e-tests-events-m7sb5 deletion completed in 38.130580547s

• [SLOW TEST:46.277 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:39:49.033: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 18 03:39:49.139: INFO: Waiting up to 5m0s for pod "pod-d7aaa932-332e-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-kd95q" to be "success or failure"
Feb 18 03:39:49.143: INFO: Pod "pod-d7aaa932-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42004ms
Feb 18 03:39:51.148: INFO: Pod "pod-d7aaa932-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00954069s
Feb 18 03:39:53.169: INFO: Pod "pod-d7aaa932-332e-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030270898s
Feb 18 03:39:55.174: INFO: Pod "pod-d7aaa932-332e-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035391694s
STEP: Saw pod success
Feb 18 03:39:55.174: INFO: Pod "pod-d7aaa932-332e-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:39:55.178: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-d7aaa932-332e-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:39:55.202: INFO: Waiting for pod pod-d7aaa932-332e-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:39:55.205: INFO: Pod pod-d7aaa932-332e-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:39:55.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kd95q" for this suite.
Feb 18 03:40:01.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:40:01.273: INFO: namespace: e2e-tests-emptydir-kd95q, resource: bindings, ignored listing per whitelist
Feb 18 03:40:01.397: INFO: namespace e2e-tests-emptydir-kd95q deletion completed in 6.186582216s

• [SLOW TEST:12.364 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:40:01.397: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:40:01.515: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 18 03:40:01.526: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 18 03:40:06.532: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 18 03:40:06.532: INFO: Creating deployment "test-rolling-update-deployment"
Feb 18 03:40:06.540: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 18 03:40:06.548: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 18 03:40:08.558: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 18 03:40:08.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058006, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058006, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058006, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058006, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 03:40:10.568: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 03:40:10.581: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-4lvxs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4lvxs/deployments/test-rolling-update-deployment,UID:e20a9283-332e-11e9-9a73-8a88965a7424,ResourceVersion:334008,Generation:1,CreationTimestamp:2019-02-18 03:40:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-18 03:40:06 +0000 UTC 2019-02-18 03:40:06 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-18 03:40:09 +0000 UTC 2019-02-18 03:40:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 18 03:40:10.587: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-4lvxs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4lvxs/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:e20e3ae0-332e-11e9-9a73-8a88965a7424,ResourceVersion:333999,Generation:1,CreationTimestamp:2019-02-18 03:40:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e20a9283-332e-11e9-9a73-8a88965a7424 0xc001976dd7 0xc001976dd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 18 03:40:10.587: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 18 03:40:10.587: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-4lvxs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4lvxs/replicasets/test-rolling-update-controller,UID:df0cf9e5-332e-11e9-9a73-8a88965a7424,ResourceVersion:334007,Generation:2,CreationTimestamp:2019-02-18 03:40:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment e20a9283-332e-11e9-9a73-8a88965a7424 0xc001976bf7 0xc001976bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 03:40:10.592: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-qc4tf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-qc4tf,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-4lvxs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4lvxs/pods/test-rolling-update-deployment-68b55d7bc6-qc4tf,UID:e20f24ae-332e-11e9-9a73-8a88965a7424,ResourceVersion:333998,Generation:0,CreationTimestamp:2019-02-18 03:40:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 e20e3ae0-332e-11e9-9a73-8a88965a7424 0xc0019777a7 0xc0019777a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tzvwd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tzvwd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tzvwd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001977810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001977830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:40:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:40:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:40:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 03:40:06 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.20,StartTime:2019-02-18 03:40:06 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-18 03:40:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9908786fd880f1fe1ca16fe28ffdcdcf8e9e9dd96e4f2b2c9f097198801b651d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:40:10.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4lvxs" for this suite.
Feb 18 03:40:16.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:40:16.654: INFO: namespace: e2e-tests-deployment-4lvxs, resource: bindings, ignored listing per whitelist
Feb 18 03:40:16.731: INFO: namespace e2e-tests-deployment-4lvxs deletion completed in 6.134496065s

• [SLOW TEST:15.334 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:40:16.731: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 18 03:40:21.365: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e82cd962-332e-11e9-94e0-0a580af401c1"
Feb 18 03:40:21.365: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e82cd962-332e-11e9-94e0-0a580af401c1" in namespace "e2e-tests-pods-s2wrx" to be "terminated due to deadline exceeded"
Feb 18 03:40:21.370: INFO: Pod "pod-update-activedeadlineseconds-e82cd962-332e-11e9-94e0-0a580af401c1": Phase="Running", Reason="", readiness=true. Elapsed: 4.888976ms
Feb 18 03:40:23.376: INFO: Pod "pod-update-activedeadlineseconds-e82cd962-332e-11e9-94e0-0a580af401c1": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.01008753s
Feb 18 03:40:23.376: INFO: Pod "pod-update-activedeadlineseconds-e82cd962-332e-11e9-94e0-0a580af401c1" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:40:23.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-s2wrx" for this suite.
Feb 18 03:40:29.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:40:29.469: INFO: namespace: e2e-tests-pods-s2wrx, resource: bindings, ignored listing per whitelist
Feb 18 03:40:29.522: INFO: namespace e2e-tests-pods-s2wrx deletion completed in 6.139261395s

• [SLOW TEST:12.791 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:40:29.522: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 18 03:40:29.648: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:29.651: INFO: Number of nodes with available pods: 0
Feb 18 03:40:29.651: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:40:30.659: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:30.664: INFO: Number of nodes with available pods: 0
Feb 18 03:40:30.665: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:40:31.659: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:31.664: INFO: Number of nodes with available pods: 0
Feb 18 03:40:31.664: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:40:32.679: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:32.684: INFO: Number of nodes with available pods: 1
Feb 18 03:40:32.684: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 18 03:40:32.796: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:32.801: INFO: Number of nodes with available pods: 0
Feb 18 03:40:32.801: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:40:33.807: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:33.812: INFO: Number of nodes with available pods: 0
Feb 18 03:40:33.812: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:40:34.807: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:34.811: INFO: Number of nodes with available pods: 0
Feb 18 03:40:34.811: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:40:35.808: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 03:40:35.812: INFO: Number of nodes with available pods: 1
Feb 18 03:40:35.812: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hm9sb, will wait for the garbage collector to delete the pods
Feb 18 03:40:35.882: INFO: Deleting DaemonSet.extensions daemon-set took: 9.544493ms
Feb 18 03:40:35.982: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.332946ms
Feb 18 03:41:17.488: INFO: Number of nodes with available pods: 0
Feb 18 03:41:17.488: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 03:41:17.491: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hm9sb/daemonsets","resourceVersion":"334207"},"items":null}

Feb 18 03:41:17.494: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hm9sb/pods","resourceVersion":"334207"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:41:17.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hm9sb" for this suite.
Feb 18 03:41:23.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:41:23.604: INFO: namespace: e2e-tests-daemonsets-hm9sb, resource: bindings, ignored listing per whitelist
Feb 18 03:41:23.642: INFO: namespace e2e-tests-daemonsets-hm9sb deletion completed in 6.133342652s

• [SLOW TEST:54.120 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:41:23.642: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-vhf98/configmap-test-100ef69c-332f-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 03:41:23.752: INFO: Waiting up to 5m0s for pod "pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-vhf98" to be "success or failure"
Feb 18 03:41:23.757: INFO: Pod "pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.577208ms
Feb 18 03:41:25.762: INFO: Pod "pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009941746s
Feb 18 03:41:27.769: INFO: Pod "pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017068824s
STEP: Saw pod success
Feb 18 03:41:27.769: INFO: Pod "pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:41:27.773: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1 container env-test: <nil>
STEP: delete the pod
Feb 18 03:41:27.800: INFO: Waiting for pod pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:41:27.803: INFO: Pod pod-configmaps-100fa124-332f-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:41:27.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vhf98" for this suite.
Feb 18 03:41:33.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:41:33.926: INFO: namespace: e2e-tests-configmap-vhf98, resource: bindings, ignored listing per whitelist
Feb 18 03:41:33.950: INFO: namespace e2e-tests-configmap-vhf98 deletion completed in 6.141660309s

• [SLOW TEST:10.307 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:41:33.950: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 18 03:41:34.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-cjb8h'
Feb 18 03:41:34.540: INFO: stderr: ""
Feb 18 03:41:34.540: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 18 03:41:35.546: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:41:35.546: INFO: Found 0 / 1
Feb 18 03:41:36.545: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:41:36.545: INFO: Found 0 / 1
Feb 18 03:41:37.546: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:41:37.546: INFO: Found 1 / 1
Feb 18 03:41:37.546: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 18 03:41:37.551: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:41:37.551: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 18 03:41:37.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 patch pod redis-master-b6qtd --namespace=e2e-tests-kubectl-cjb8h -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 18 03:41:37.726: INFO: stderr: ""
Feb 18 03:41:37.726: INFO: stdout: "pod/redis-master-b6qtd patched\n"
STEP: checking annotations
Feb 18 03:41:37.732: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:41:37.732: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:41:37.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cjb8h" for this suite.
Feb 18 03:41:59.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:41:59.802: INFO: namespace: e2e-tests-kubectl-cjb8h, resource: bindings, ignored listing per whitelist
Feb 18 03:41:59.869: INFO: namespace e2e-tests-kubectl-cjb8h deletion completed in 22.131579155s

• [SLOW TEST:25.919 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:41:59.869: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:42:04.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-rkmbl" for this suite.
Feb 18 03:42:42.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:42:42.291: INFO: namespace: e2e-tests-kubelet-test-rkmbl, resource: bindings, ignored listing per whitelist
Feb 18 03:42:42.304: INFO: namespace e2e-tests-kubelet-test-rkmbl deletion completed in 38.296962981s

• [SLOW TEST:42.436 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:42:42.305: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3ef263c6-332f-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3ef263c6-332f-11e9-94e0-0a580af401c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:42:46.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p2nqq" for this suite.
Feb 18 03:43:08.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:43:08.591: INFO: namespace: e2e-tests-configmap-p2nqq, resource: bindings, ignored listing per whitelist
Feb 18 03:43:08.668: INFO: namespace e2e-tests-configmap-p2nqq deletion completed in 22.139294467s

• [SLOW TEST:26.364 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:43:08.668: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 03:43:08.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-rv8x6" to be "success or failure"
Feb 18 03:43:08.788: INFO: Pod "downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.579203ms
Feb 18 03:43:10.887: INFO: Pod "downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.111550039s
STEP: Saw pod success
Feb 18 03:43:10.887: INFO: Pod "downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:43:10.891: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 03:43:10.992: INFO: Waiting for pod downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:43:10.996: INFO: Pod downwardapi-volume-4ea87d1c-332f-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:43:10.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rv8x6" for this suite.
Feb 18 03:43:17.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:43:17.149: INFO: namespace: e2e-tests-projected-rv8x6, resource: bindings, ignored listing per whitelist
Feb 18 03:43:17.244: INFO: namespace e2e-tests-projected-rv8x6 deletion completed in 6.242503637s

• [SLOW TEST:8.576 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:43:17.244: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 18 03:43:17.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 cluster-info'
Feb 18 03:43:17.528: INFO: stderr: ""
Feb 18 03:43:17.528: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:43:17.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bht7x" for this suite.
Feb 18 03:43:23.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:43:23.570: INFO: namespace: e2e-tests-kubectl-bht7x, resource: bindings, ignored listing per whitelist
Feb 18 03:43:23.670: INFO: namespace e2e-tests-kubectl-bht7x deletion completed in 6.136167926s

• [SLOW TEST:6.426 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:43:23.670: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-fnlqj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fnlqj to expose endpoints map[]
Feb 18 03:43:23.789: INFO: Get endpoints failed (4.531241ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 18 03:43:24.794: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fnlqj exposes endpoints map[] (1.009654429s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-fnlqj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fnlqj to expose endpoints map[pod1:[80]]
Feb 18 03:43:27.966: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fnlqj exposes endpoints map[pod1:[80]] (3.159627741s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-fnlqj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fnlqj to expose endpoints map[pod1:[80] pod2:[80]]
Feb 18 03:43:31.035: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fnlqj exposes endpoints map[pod2:[80] pod1:[80]] (3.064059825s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-fnlqj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fnlqj to expose endpoints map[pod2:[80]]
Feb 18 03:43:32.060: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fnlqj exposes endpoints map[pod2:[80]] (1.017681987s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-fnlqj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fnlqj to expose endpoints map[]
Feb 18 03:43:33.074: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fnlqj exposes endpoints map[] (1.008680063s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:43:33.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fnlqj" for this suite.
Feb 18 03:43:39.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:43:39.449: INFO: namespace: e2e-tests-services-fnlqj, resource: bindings, ignored listing per whitelist
Feb 18 03:43:39.587: INFO: namespace e2e-tests-services-fnlqj deletion completed in 6.235181094s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:15.917 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:43:39.588: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:43:39.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 version --client'
Feb 18 03:43:39.816: INFO: stderr: ""
Feb 18 03:43:39.816: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 18 03:43:39.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-5f94f'
Feb 18 03:43:40.111: INFO: stderr: ""
Feb 18 03:43:40.111: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 18 03:43:40.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-5f94f'
Feb 18 03:43:40.413: INFO: stderr: ""
Feb 18 03:43:40.413: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 18 03:43:41.419: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:43:41.419: INFO: Found 0 / 1
Feb 18 03:43:42.419: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:43:42.419: INFO: Found 1 / 1
Feb 18 03:43:42.419: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 18 03:43:42.423: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 03:43:42.423: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 18 03:43:42.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 describe pod redis-master-dxmdm --namespace=e2e-tests-kubectl-5f94f'
Feb 18 03:43:42.627: INFO: stderr: ""
Feb 18 03:43:42.627: INFO: stdout: "Name:               redis-master-dxmdm\nNamespace:          e2e-tests-kubectl-5f94f\nPriority:           0\nPriorityClassName:  <none>\nNode:               xen16-168.ebaotech.com/172.25.16.168\nStart Time:         Mon, 18 Feb 2019 03:43:40 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.33\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://076fb00e84cb4a7bd8df1ee7648077a77c044ad9e220e95d4be055da58ce0ff1\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 18 Feb 2019 03:43:41 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-xjbl6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-xjbl6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-xjbl6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                             Message\n  ----    ------     ----  ----                             -------\n  Normal  Scheduled  2s    default-scheduler                Successfully assigned e2e-tests-kubectl-5f94f/redis-master-dxmdm to xen16-168.ebaotech.com\n  Normal  Pulled     1s    kubelet, xen16-168.ebaotech.com  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, xen16-168.ebaotech.com  Created container\n  Normal  Started    1s    kubelet, xen16-168.ebaotech.com  Started container\n"
Feb 18 03:43:42.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 describe rc redis-master --namespace=e2e-tests-kubectl-5f94f'
Feb 18 03:43:42.845: INFO: stderr: ""
Feb 18 03:43:42.845: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-5f94f\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-dxmdm\n"
Feb 18 03:43:42.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 describe service redis-master --namespace=e2e-tests-kubectl-5f94f'
Feb 18 03:43:43.033: INFO: stderr: ""
Feb 18 03:43:43.033: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-5f94f\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.101.173.89\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.33:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 18 03:43:43.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 describe node xen16-121.ebaotech.com'
Feb 18 03:43:43.245: INFO: stderr: ""
Feb 18 03:43:43.245: INFO: stdout: "Name:               xen16-121.ebaotech.com\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=xen16-121.ebaotech.com\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"32:f9:fa:37:3e:94\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.25.16.121\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 15 Feb 2019 09:24:16 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 18 Feb 2019 03:43:34 +0000   Fri, 15 Feb 2019 09:24:16 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 18 Feb 2019 03:43:34 +0000   Fri, 15 Feb 2019 09:24:16 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 18 Feb 2019 03:43:34 +0000   Fri, 15 Feb 2019 09:24:16 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 18 Feb 2019 03:43:34 +0000   Fri, 15 Feb 2019 09:26:27 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.25.16.121\n  Hostname:    xen16-121.ebaotech.com\nCapacity:\n cpu:                4\n ephemeral-storage:  37067076Ki\n hugepages-2Mi:      0\n memory:             3618516Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  34161017186\n hugepages-2Mi:      0\n memory:             3516116Ki\n pods:               110\nSystem Info:\n Machine ID:                 998d46b86ab0414d9af268aa4516b989\n System UUID:                5CCE3F5D-771C-1F45-7B11-7447AA4D039C\n Boot ID:                    3941c529-e033-457f-841e-1046328e7f97\n Kernel Version:             3.10.0-514.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-4510b99ad8934c9d-8zjhz    0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\n  kube-system                coredns-86c58d9df4-2tb58                                   100m (2%)     0 (0%)      70Mi (2%)        170Mi (4%)     2d18h\n  kube-system                coredns-86c58d9df4-qvtlf                                   100m (2%)     0 (0%)      70Mi (2%)        170Mi (4%)     2d18h\n  kube-system                etcd-xen16-121.ebaotech.com                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d18h\n  kube-system                kube-apiserver-xen16-121.ebaotech.com                      250m (6%)     0 (0%)      0 (0%)           0 (0%)         2d18h\n  kube-system                kube-controller-manager-xen16-121.ebaotech.com             200m (5%)     0 (0%)      0 (0%)           0 (0%)         2d18h\n  kube-system                kube-flannel-ds-amd64-vjk75                                100m (2%)     100m (2%)   50Mi (1%)        50Mi (1%)      2d18h\n  kube-system                kube-proxy-jrmtc                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d18h\n  kube-system                kube-scheduler-xen16-121.ebaotech.com                      100m (2%)     0 (0%)      0 (0%)           0 (0%)         2d18h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (21%)  100m (2%)\n  memory             190Mi (5%)  390Mi (11%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Feb 18 03:43:43.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 describe namespace e2e-tests-kubectl-5f94f'
Feb 18 03:43:43.426: INFO: stderr: ""
Feb 18 03:43:43.426: INFO: stdout: "Name:         e2e-tests-kubectl-5f94f\nLabels:       e2e-framework=kubectl\n              e2e-run=83afc1ef-332a-11e9-94e0-0a580af401c1\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:43:43.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5f94f" for this suite.
Feb 18 03:44:05.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:44:05.571: INFO: namespace: e2e-tests-kubectl-5f94f, resource: bindings, ignored listing per whitelist
Feb 18 03:44:05.571: INFO: namespace e2e-tests-kubectl-5f94f deletion completed in 22.139708612s

• [SLOW TEST:25.983 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:44:05.571: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:44:11.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-4ndzr" for this suite.
Feb 18 03:44:17.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:44:17.849: INFO: namespace: e2e-tests-namespaces-4ndzr, resource: bindings, ignored listing per whitelist
Feb 18 03:44:17.923: INFO: namespace e2e-tests-namespaces-4ndzr deletion completed in 6.152773806s
STEP: Destroying namespace "e2e-tests-nsdeletetest-tk65m" for this suite.
Feb 18 03:44:17.927: INFO: Namespace e2e-tests-nsdeletetest-tk65m was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-m25r7" for this suite.
Feb 18 03:44:23.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:44:23.972: INFO: namespace: e2e-tests-nsdeletetest-m25r7, resource: bindings, ignored listing per whitelist
Feb 18 03:44:24.058: INFO: namespace e2e-tests-nsdeletetest-m25r7 deletion completed in 6.131402796s

• [SLOW TEST:18.487 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:44:24.058: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 18 03:44:26.699: INFO: Successfully updated pod "labelsupdate7b97e259-332f-11e9-94e0-0a580af401c1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:44:28.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5k7s2" for this suite.
Feb 18 03:44:50.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:44:50.870: INFO: namespace: e2e-tests-projected-5k7s2, resource: bindings, ignored listing per whitelist
Feb 18 03:44:50.889: INFO: namespace e2e-tests-projected-5k7s2 deletion completed in 22.154435958s

• [SLOW TEST:26.830 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:44:50.889: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 18 03:44:51.056: INFO: Waiting up to 5m0s for pod "pod-8b9fa75b-332f-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-7jm2x" to be "success or failure"
Feb 18 03:44:51.060: INFO: Pod "pod-8b9fa75b-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.916964ms
Feb 18 03:44:53.064: INFO: Pod "pod-8b9fa75b-332f-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008570788s
STEP: Saw pod success
Feb 18 03:44:53.065: INFO: Pod "pod-8b9fa75b-332f-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:44:53.068: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-8b9fa75b-332f-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:44:53.092: INFO: Waiting for pod pod-8b9fa75b-332f-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:44:53.096: INFO: Pod pod-8b9fa75b-332f-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:44:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7jm2x" for this suite.
Feb 18 03:44:59.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:44:59.241: INFO: namespace: e2e-tests-emptydir-7jm2x, resource: bindings, ignored listing per whitelist
Feb 18 03:44:59.244: INFO: namespace e2e-tests-emptydir-7jm2x deletion completed in 6.142806415s

• [SLOW TEST:8.355 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:44:59.244: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:44:59.353: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 18 03:44:59.365: INFO: Number of nodes with available pods: 0
Feb 18 03:44:59.365: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 18 03:44:59.395: INFO: Number of nodes with available pods: 0
Feb 18 03:44:59.395: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:00.401: INFO: Number of nodes with available pods: 0
Feb 18 03:45:00.401: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:01.401: INFO: Number of nodes with available pods: 1
Feb 18 03:45:01.401: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 18 03:45:01.424: INFO: Number of nodes with available pods: 1
Feb 18 03:45:01.424: INFO: Number of running nodes: 0, number of available pods: 1
Feb 18 03:45:02.430: INFO: Number of nodes with available pods: 0
Feb 18 03:45:02.430: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 18 03:45:02.442: INFO: Number of nodes with available pods: 0
Feb 18 03:45:02.442: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:03.447: INFO: Number of nodes with available pods: 0
Feb 18 03:45:03.447: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:04.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:04.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:05.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:05.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:06.447: INFO: Number of nodes with available pods: 0
Feb 18 03:45:06.447: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:07.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:07.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:08.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:08.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:09.449: INFO: Number of nodes with available pods: 0
Feb 18 03:45:09.449: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:10.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:10.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:11.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:11.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:12.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:12.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:13.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:13.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:14.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:14.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:15.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:15.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:16.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:16.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:17.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:17.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:18.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:18.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:19.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:19.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:20.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:20.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:21.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:21.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:22.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:22.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:23.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:23.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:24.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:24.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:25.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:25.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:26.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:26.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:27.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:27.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:28.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:28.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:29.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:29.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:30.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:30.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:31.449: INFO: Number of nodes with available pods: 0
Feb 18 03:45:31.449: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:32.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:32.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:33.447: INFO: Number of nodes with available pods: 0
Feb 18 03:45:33.447: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:34.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:34.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:35.447: INFO: Number of nodes with available pods: 0
Feb 18 03:45:35.447: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:36.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:36.448: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:37.448: INFO: Number of nodes with available pods: 0
Feb 18 03:45:37.449: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 03:45:38.448: INFO: Number of nodes with available pods: 1
Feb 18 03:45:38.448: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cfkps, will wait for the garbage collector to delete the pods
Feb 18 03:45:38.522: INFO: Deleting DaemonSet.extensions daemon-set took: 12.931377ms
Feb 18 03:45:38.623: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.364661ms
Feb 18 03:46:17.529: INFO: Number of nodes with available pods: 0
Feb 18 03:46:17.529: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 03:46:17.533: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cfkps/daemonsets","resourceVersion":"334991"},"items":null}

Feb 18 03:46:17.536: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cfkps/pods","resourceVersion":"334991"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:46:17.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cfkps" for this suite.
Feb 18 03:46:23.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:46:23.626: INFO: namespace: e2e-tests-daemonsets-cfkps, resource: bindings, ignored listing per whitelist
Feb 18 03:46:23.690: INFO: namespace e2e-tests-daemonsets-cfkps deletion completed in 6.127786927s

• [SLOW TEST:84.446 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:46:23.690: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 18 03:46:23.796: INFO: Waiting up to 5m0s for pod "pod-c2e69603-332f-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-zh8x4" to be "success or failure"
Feb 18 03:46:23.802: INFO: Pod "pod-c2e69603-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.59684ms
Feb 18 03:46:25.808: INFO: Pod "pod-c2e69603-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01120265s
Feb 18 03:46:27.813: INFO: Pod "pod-c2e69603-332f-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016229049s
STEP: Saw pod success
Feb 18 03:46:27.813: INFO: Pod "pod-c2e69603-332f-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:46:27.816: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-c2e69603-332f-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:46:27.854: INFO: Waiting for pod pod-c2e69603-332f-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:46:27.858: INFO: Pod pod-c2e69603-332f-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:46:27.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zh8x4" for this suite.
Feb 18 03:46:33.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:46:33.963: INFO: namespace: e2e-tests-emptydir-zh8x4, resource: bindings, ignored listing per whitelist
Feb 18 03:46:33.988: INFO: namespace e2e-tests-emptydir-zh8x4 deletion completed in 6.124061985s

• [SLOW TEST:10.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:46:33.988: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 18 03:46:34.098: INFO: Waiting up to 5m0s for pod "pod-c90a852b-332f-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-4g6f2" to be "success or failure"
Feb 18 03:46:34.101: INFO: Pod "pod-c90a852b-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.374495ms
Feb 18 03:46:36.106: INFO: Pod "pod-c90a852b-332f-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008362229s
Feb 18 03:46:38.112: INFO: Pod "pod-c90a852b-332f-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013641345s
STEP: Saw pod success
Feb 18 03:46:38.112: INFO: Pod "pod-c90a852b-332f-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:46:38.115: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-c90a852b-332f-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:46:38.143: INFO: Waiting for pod pod-c90a852b-332f-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:46:38.147: INFO: Pod pod-c90a852b-332f-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:46:38.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4g6f2" for this suite.
Feb 18 03:46:44.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:46:44.283: INFO: namespace: e2e-tests-emptydir-4g6f2, resource: bindings, ignored listing per whitelist
Feb 18 03:46:44.286: INFO: namespace e2e-tests-emptydir-4g6f2 deletion completed in 6.132882072s

• [SLOW TEST:10.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:46:44.286: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 18 03:46:49.037: INFO: Successfully updated pod "annotationupdatecf3ce81a-332f-11e9-94e0-0a580af401c1"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:46:51.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pjkkr" for this suite.
Feb 18 03:47:13.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:47:13.254: INFO: namespace: e2e-tests-downward-api-pjkkr, resource: bindings, ignored listing per whitelist
Feb 18 03:47:13.278: INFO: namespace e2e-tests-downward-api-pjkkr deletion completed in 22.139444732s

• [SLOW TEST:28.992 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:47:13.278: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-9cv2v
Feb 18 03:47:15.434: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-9cv2v
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 03:47:15.438: INFO: Initial restart count of pod liveness-exec is 0
Feb 18 03:48:03.568: INFO: Restart count of pod e2e-tests-container-probe-9cv2v/liveness-exec is now 1 (48.130182315s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:48:03.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9cv2v" for this suite.
Feb 18 03:48:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:48:09.665: INFO: namespace: e2e-tests-container-probe-9cv2v, resource: bindings, ignored listing per whitelist
Feb 18 03:48:09.715: INFO: namespace e2e-tests-container-probe-9cv2v deletion completed in 6.12970585s

• [SLOW TEST:56.437 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:48:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0218368b-3330-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 03:48:09.822: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-k7smw" to be "success or failure"
Feb 18 03:48:09.826: INFO: Pod "pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.799641ms
Feb 18 03:48:11.831: INFO: Pod "pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008599168s
STEP: Saw pod success
Feb 18 03:48:11.831: INFO: Pod "pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:48:11.835: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 03:48:11.861: INFO: Waiting for pod pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:48:11.865: INFO: Pod pod-projected-configmaps-0218edf7-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:48:11.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7smw" for this suite.
Feb 18 03:48:17.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:48:17.981: INFO: namespace: e2e-tests-projected-k7smw, resource: bindings, ignored listing per whitelist
Feb 18 03:48:18.008: INFO: namespace e2e-tests-projected-k7smw deletion completed in 6.137311368s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:48:18.008: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 18 03:48:18.165: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-647419003 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:48:18.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4ttt6" for this suite.
Feb 18 03:48:24.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:48:24.418: INFO: namespace: e2e-tests-kubectl-4ttt6, resource: bindings, ignored listing per whitelist
Feb 18 03:48:24.457: INFO: namespace e2e-tests-kubectl-4ttt6 deletion completed in 6.130763288s

• [SLOW TEST:6.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:48:24.457: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 18 03:48:24.553: INFO: Waiting up to 5m0s for pod "downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-knxqz" to be "success or failure"
Feb 18 03:48:24.557: INFO: Pod "downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.436851ms
Feb 18 03:48:26.563: INFO: Pod "downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00940143s
STEP: Saw pod success
Feb 18 03:48:26.563: INFO: Pod "downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:48:26.567: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 03:48:26.592: INFO: Waiting for pod downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:48:26.596: INFO: Pod downward-api-0ae10b8e-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:48:26.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-knxqz" for this suite.
Feb 18 03:48:32.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:48:32.668: INFO: namespace: e2e-tests-downward-api-knxqz, resource: bindings, ignored listing per whitelist
Feb 18 03:48:32.742: INFO: namespace e2e-tests-downward-api-knxqz deletion completed in 6.141154974s

• [SLOW TEST:8.284 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:48:32.742: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7hckv
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 18 03:48:32.847: INFO: Found 0 stateful pods, waiting for 3
Feb 18 03:48:42.854: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:48:42.854: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:48:42.855: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 03:48:42.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-7hckv ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 03:48:43.385: INFO: stderr: ""
Feb 18 03:48:43.385: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 03:48:43.385: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 18 03:48:53.427: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 18 03:49:03.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-7hckv ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:49:03.946: INFO: stderr: ""
Feb 18 03:49:03.946: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 03:49:03.946: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 03:49:23.974: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hckv/ss2 to complete update
Feb 18 03:49:23.975: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 18 03:49:33.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-7hckv ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 03:49:34.468: INFO: stderr: ""
Feb 18 03:49:34.468: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 03:49:34.468: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 03:49:44.509: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 18 03:49:54.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-7hckv ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 03:49:55.038: INFO: stderr: ""
Feb 18 03:49:55.038: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 03:49:55.038: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 03:50:05.066: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hckv/ss2 to complete update
Feb 18 03:50:05.066: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 18 03:50:05.066: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 18 03:50:05.066: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 18 03:50:15.076: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hckv/ss2 to complete update
Feb 18 03:50:15.076: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 18 03:50:15.076: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb 18 03:50:25.077: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hckv/ss2 to complete update
Feb 18 03:50:25.077: INFO: Waiting for Pod e2e-tests-statefulset-7hckv/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 03:50:35.075: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7hckv
Feb 18 03:50:35.079: INFO: Scaling statefulset ss2 to 0
Feb 18 03:50:55.097: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 03:50:55.101: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:50:55.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7hckv" for this suite.
Feb 18 03:51:01.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:51:01.181: INFO: namespace: e2e-tests-statefulset-7hckv, resource: bindings, ignored listing per whitelist
Feb 18 03:51:01.273: INFO: namespace e2e-tests-statefulset-7hckv deletion completed in 6.147846573s

• [SLOW TEST:148.531 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:51:01.273: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 18 03:51:05.407: INFO: Pod pod-hostip-685c14ff-3330-11e9-94e0-0a580af401c1 has hostIP: 172.25.16.168
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:51:05.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p7rn9" for this suite.
Feb 18 03:51:27.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:51:27.446: INFO: namespace: e2e-tests-pods-p7rn9, resource: bindings, ignored listing per whitelist
Feb 18 03:51:27.536: INFO: namespace e2e-tests-pods-p7rn9 deletion completed in 22.124190013s

• [SLOW TEST:26.263 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:51:27.536: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 18 03:51:27.646: INFO: Waiting up to 5m0s for pod "pod-78027ca8-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-g9zm5" to be "success or failure"
Feb 18 03:51:27.649: INFO: Pod "pod-78027ca8-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.120314ms
Feb 18 03:51:29.688: INFO: Pod "pod-78027ca8-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042329173s
STEP: Saw pod success
Feb 18 03:51:29.688: INFO: Pod "pod-78027ca8-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:51:29.692: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-78027ca8-3330-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:51:29.719: INFO: Waiting for pod pod-78027ca8-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:51:29.722: INFO: Pod pod-78027ca8-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:51:29.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g9zm5" for this suite.
Feb 18 03:51:35.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:51:35.934: INFO: namespace: e2e-tests-emptydir-g9zm5, resource: bindings, ignored listing per whitelist
Feb 18 03:51:35.948: INFO: namespace e2e-tests-emptydir-g9zm5 deletion completed in 6.221289053s

• [SLOW TEST:8.412 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:51:35.949: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 18 03:51:36.050: INFO: Waiting up to 5m0s for pod "downward-api-7d04d409-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-6rb7r" to be "success or failure"
Feb 18 03:51:36.054: INFO: Pod "downward-api-7d04d409-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850502ms
Feb 18 03:51:38.060: INFO: Pod "downward-api-7d04d409-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009742811s
Feb 18 03:51:40.065: INFO: Pod "downward-api-7d04d409-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015395354s
STEP: Saw pod success
Feb 18 03:51:40.065: INFO: Pod "downward-api-7d04d409-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:51:40.069: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downward-api-7d04d409-3330-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 03:51:40.132: INFO: Waiting for pod downward-api-7d04d409-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:51:40.136: INFO: Pod downward-api-7d04d409-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:51:40.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6rb7r" for this suite.
Feb 18 03:51:46.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:51:46.312: INFO: namespace: e2e-tests-downward-api-6rb7r, resource: bindings, ignored listing per whitelist
Feb 18 03:51:46.365: INFO: namespace e2e-tests-downward-api-6rb7r deletion completed in 6.222894072s

• [SLOW TEST:10.416 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:51:46.365: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:51:48.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-69rm4" for this suite.
Feb 18 03:51:54.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:51:54.709: INFO: namespace: e2e-tests-emptydir-wrapper-69rm4, resource: bindings, ignored listing per whitelist
Feb 18 03:51:54.726: INFO: namespace e2e-tests-emptydir-wrapper-69rm4 deletion completed in 6.197952232s

• [SLOW TEST:8.361 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:51:54.727: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 18 03:51:54.901: INFO: PodSpec: initContainers in spec.initContainers
Feb 18 03:52:43.298: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8842847c-3330-11e9-94e0-0a580af401c1", GenerateName:"", Namespace:"e2e-tests-init-container-t8pn4", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-t8pn4/pods/pod-init-8842847c-3330-11e9-94e0-0a580af401c1", UID:"884071cb-3330-11e9-9a73-8a88965a7424", ResourceVersion:"336153", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686058714, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"901832904"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6n8tt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001f7e140), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6n8tt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6n8tt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6n8tt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001cd2ca8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"xen16-168.ebaotech.com", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d6c960), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001cd2d20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001cd2d40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001cd2d48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001cd2d4c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058714, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058714, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058714, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686058714, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.25.16.168", PodIP:"10.244.1.58", StartTime:(*v1.Time)(0xc0017b1f40), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002196a80)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002196af0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://6ebdec0f2d518f5deecac305ead076c53b0e9991ec4c826f1761523f015a9b1a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0017b1f80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0017b1f60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:52:43.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-t8pn4" for this suite.
Feb 18 03:53:05.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:53:05.441: INFO: namespace: e2e-tests-init-container-t8pn4, resource: bindings, ignored listing per whitelist
Feb 18 03:53:05.459: INFO: namespace e2e-tests-init-container-t8pn4 deletion completed in 22.153941065s

• [SLOW TEST:70.733 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:53:05.459: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 18 03:53:05.566: INFO: Waiting up to 5m0s for pod "client-containers-b25f9204-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-containers-2cnr2" to be "success or failure"
Feb 18 03:53:05.570: INFO: Pod "client-containers-b25f9204-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.596465ms
Feb 18 03:53:07.575: INFO: Pod "client-containers-b25f9204-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008477321s
Feb 18 03:53:09.579: INFO: Pod "client-containers-b25f9204-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012840506s
STEP: Saw pod success
Feb 18 03:53:09.579: INFO: Pod "client-containers-b25f9204-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:53:09.583: INFO: Trying to get logs from node xen16-168.ebaotech.com pod client-containers-b25f9204-3330-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:53:09.610: INFO: Waiting for pod client-containers-b25f9204-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:53:09.613: INFO: Pod client-containers-b25f9204-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:53:09.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2cnr2" for this suite.
Feb 18 03:53:15.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:53:15.716: INFO: namespace: e2e-tests-containers-2cnr2, resource: bindings, ignored listing per whitelist
Feb 18 03:53:15.747: INFO: namespace e2e-tests-containers-2cnr2 deletion completed in 6.128359484s

• [SLOW TEST:10.287 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:53:15.747: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-ttd4
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 03:53:15.855: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-ttd4" in namespace "e2e-tests-subpath-6cwz5" to be "success or failure"
Feb 18 03:53:15.860: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137228ms
Feb 18 03:53:17.866: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010154277s
Feb 18 03:53:19.871: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 4.015122464s
Feb 18 03:53:21.875: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 6.019648343s
Feb 18 03:53:23.880: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 8.02482131s
Feb 18 03:53:25.885: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 10.029771412s
Feb 18 03:53:27.890: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 12.0349523s
Feb 18 03:53:29.895: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 14.040040522s
Feb 18 03:53:31.900: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 16.044901696s
Feb 18 03:53:33.906: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 18.050864366s
Feb 18 03:53:35.912: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 20.056509829s
Feb 18 03:53:37.917: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Running", Reason="", readiness=false. Elapsed: 22.061482696s
Feb 18 03:53:39.922: INFO: Pod "pod-subpath-test-secret-ttd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.066553893s
STEP: Saw pod success
Feb 18 03:53:39.922: INFO: Pod "pod-subpath-test-secret-ttd4" satisfied condition "success or failure"
Feb 18 03:53:39.925: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-subpath-test-secret-ttd4 container test-container-subpath-secret-ttd4: <nil>
STEP: delete the pod
Feb 18 03:53:39.948: INFO: Waiting for pod pod-subpath-test-secret-ttd4 to disappear
Feb 18 03:53:39.952: INFO: Pod pod-subpath-test-secret-ttd4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-ttd4
Feb 18 03:53:39.952: INFO: Deleting pod "pod-subpath-test-secret-ttd4" in namespace "e2e-tests-subpath-6cwz5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:53:39.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6cwz5" for this suite.
Feb 18 03:53:45.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:53:46.052: INFO: namespace: e2e-tests-subpath-6cwz5, resource: bindings, ignored listing per whitelist
Feb 18 03:53:46.097: INFO: namespace e2e-tests-subpath-6cwz5 deletion completed in 6.136842097s

• [SLOW TEST:30.350 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:53:46.097: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 18 03:53:46.231: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:53:50.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2jhbl" for this suite.
Feb 18 03:53:56.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:53:56.312: INFO: namespace: e2e-tests-init-container-2jhbl, resource: bindings, ignored listing per whitelist
Feb 18 03:53:56.380: INFO: namespace e2e-tests-init-container-2jhbl deletion completed in 6.138495937s

• [SLOW TEST:10.283 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:53:56.381: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d0ba509e-3330-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 03:53:56.499: INFO: Waiting up to 5m0s for pod "pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-h7mnm" to be "success or failure"
Feb 18 03:53:56.505: INFO: Pod "pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.335163ms
Feb 18 03:53:58.510: INFO: Pod "pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010490738s
STEP: Saw pod success
Feb 18 03:53:58.510: INFO: Pod "pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:53:58.513: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 03:53:58.538: INFO: Waiting for pod pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:53:58.541: INFO: Pod pod-configmaps-d0bb1818-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:53:58.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h7mnm" for this suite.
Feb 18 03:54:04.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:54:04.628: INFO: namespace: e2e-tests-configmap-h7mnm, resource: bindings, ignored listing per whitelist
Feb 18 03:54:04.688: INFO: namespace e2e-tests-configmap-h7mnm deletion completed in 6.13359999s

• [SLOW TEST:8.307 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:54:04.688: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d5abaa16-3330-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 03:54:04.788: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-ls9fn" to be "success or failure"
Feb 18 03:54:04.791: INFO: Pod "pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.242482ms
Feb 18 03:54:06.797: INFO: Pod "pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008484305s
STEP: Saw pod success
Feb 18 03:54:06.797: INFO: Pod "pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:54:06.801: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 03:54:06.827: INFO: Waiting for pod pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:54:06.831: INFO: Pod pod-configmaps-d5ac6caf-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:54:06.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ls9fn" for this suite.
Feb 18 03:54:12.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:54:12.934: INFO: namespace: e2e-tests-configmap-ls9fn, resource: bindings, ignored listing per whitelist
Feb 18 03:54:12.967: INFO: namespace e2e-tests-configmap-ls9fn deletion completed in 6.132205269s

• [SLOW TEST:8.279 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:54:12.967: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 18 03:54:13.065: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 18 03:54:13.075: INFO: Waiting for terminating namespaces to be deleted...
Feb 18 03:54:13.079: INFO: 
Logging pods the kubelet thinks is on node xen16-168.ebaotech.com before test
Feb 18 03:54:13.091: INFO: sonobuoy-systemd-logs-daemon-set-4510b99ad8934c9d-dqlfh from heptio-sonobuoy started at 2019-02-18 03:08:41 +0000 UTC (2 container statuses recorded)
Feb 18 03:54:13.091: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 18 03:54:13.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 03:54:13.091: INFO: sonobuoy-e2e-job-25438afdb0174082 from heptio-sonobuoy started at 2019-02-18 03:08:41 +0000 UTC (2 container statuses recorded)
Feb 18 03:54:13.091: INFO: 	Container e2e ready: true, restart count 0
Feb 18 03:54:13.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 03:54:13.091: INFO: kube-flannel-ds-amd64-2ll58 from kube-system started at 2019-02-15 09:27:27 +0000 UTC (1 container statuses recorded)
Feb 18 03:54:13.091: INFO: 	Container kube-flannel ready: true, restart count 0
Feb 18 03:54:13.091: INFO: kube-proxy-9c526 from kube-system started at 2019-02-15 09:27:27 +0000 UTC (1 container statuses recorded)
Feb 18 03:54:13.091: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 03:54:13.091: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-18 03:08:34 +0000 UTC (1 container statuses recorded)
Feb 18 03:54:13.091: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dbd613a7-3330-11e9-94e0-0a580af401c1 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dbd613a7-3330-11e9-94e0-0a580af401c1 off the node xen16-168.ebaotech.com
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dbd613a7-3330-11e9-94e0-0a580af401c1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:54:19.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-q8x8p" for this suite.
Feb 18 03:54:27.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:54:27.320: INFO: namespace: e2e-tests-sched-pred-q8x8p, resource: bindings, ignored listing per whitelist
Feb 18 03:54:27.324: INFO: namespace e2e-tests-sched-pred-q8x8p deletion completed in 8.14198569s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.357 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:54:27.324: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 18 03:54:33.472: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 03:54:33.476: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 03:54:35.476: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 03:54:35.482: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 03:54:37.477: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 03:54:37.482: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:54:37.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rmmzv" for this suite.
Feb 18 03:54:59.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:54:59.657: INFO: namespace: e2e-tests-container-lifecycle-hook-rmmzv, resource: bindings, ignored listing per whitelist
Feb 18 03:54:59.675: INFO: namespace e2e-tests-container-lifecycle-hook-rmmzv deletion completed in 22.174544617s

• [SLOW TEST:32.351 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:54:59.675: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 18 03:54:59.771: INFO: Waiting up to 5m0s for pod "var-expansion-f6724598-3330-11e9-94e0-0a580af401c1" in namespace "e2e-tests-var-expansion-6x5lr" to be "success or failure"
Feb 18 03:54:59.775: INFO: Pod "var-expansion-f6724598-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.999304ms
Feb 18 03:55:01.781: INFO: Pod "var-expansion-f6724598-3330-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010230751s
Feb 18 03:55:03.787: INFO: Pod "var-expansion-f6724598-3330-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016187722s
STEP: Saw pod success
Feb 18 03:55:03.787: INFO: Pod "var-expansion-f6724598-3330-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:55:03.791: INFO: Trying to get logs from node xen16-168.ebaotech.com pod var-expansion-f6724598-3330-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 03:55:03.816: INFO: Waiting for pod var-expansion-f6724598-3330-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:55:03.819: INFO: Pod var-expansion-f6724598-3330-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:03.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6x5lr" for this suite.
Feb 18 03:55:09.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:55:09.893: INFO: namespace: e2e-tests-var-expansion-6x5lr, resource: bindings, ignored listing per whitelist
Feb 18 03:55:09.958: INFO: namespace e2e-tests-var-expansion-6x5lr deletion completed in 6.132208628s

• [SLOW TEST:10.283 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:55:09.958: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:55:10.056: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:11.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-76qpr" for this suite.
Feb 18 03:55:17.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:55:17.311: INFO: namespace: e2e-tests-custom-resource-definition-76qpr, resource: bindings, ignored listing per whitelist
Feb 18 03:55:17.396: INFO: namespace e2e-tests-custom-resource-definition-76qpr deletion completed in 6.179060556s

• [SLOW TEST:7.438 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:55:17.396: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 18 03:55:17.488: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 18 03:55:17.497: INFO: Waiting for terminating namespaces to be deleted...
Feb 18 03:55:17.501: INFO: 
Logging pods the kubelet thinks is on node xen16-168.ebaotech.com before test
Feb 18 03:55:17.512: INFO: kube-proxy-9c526 from kube-system started at 2019-02-15 09:27:27 +0000 UTC (1 container statuses recorded)
Feb 18 03:55:17.512: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 03:55:17.512: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-18 03:08:34 +0000 UTC (1 container statuses recorded)
Feb 18 03:55:17.512: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 18 03:55:17.512: INFO: sonobuoy-systemd-logs-daemon-set-4510b99ad8934c9d-dqlfh from heptio-sonobuoy started at 2019-02-18 03:08:41 +0000 UTC (2 container statuses recorded)
Feb 18 03:55:17.512: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 18 03:55:17.512: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 03:55:17.512: INFO: sonobuoy-e2e-job-25438afdb0174082 from heptio-sonobuoy started at 2019-02-18 03:08:41 +0000 UTC (2 container statuses recorded)
Feb 18 03:55:17.512: INFO: 	Container e2e ready: true, restart count 0
Feb 18 03:55:17.513: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 03:55:17.513: INFO: kube-flannel-ds-amd64-2ll58 from kube-system started at 2019-02-15 09:27:27 +0000 UTC (1 container statuses recorded)
Feb 18 03:55:17.513: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node xen16-168.ebaotech.com
Feb 18 03:55:17.544: INFO: Pod sonobuoy requesting resource cpu=0m on Node xen16-168.ebaotech.com
Feb 18 03:55:17.544: INFO: Pod sonobuoy-e2e-job-25438afdb0174082 requesting resource cpu=0m on Node xen16-168.ebaotech.com
Feb 18 03:55:17.544: INFO: Pod sonobuoy-systemd-logs-daemon-set-4510b99ad8934c9d-dqlfh requesting resource cpu=0m on Node xen16-168.ebaotech.com
Feb 18 03:55:17.544: INFO: Pod kube-flannel-ds-amd64-2ll58 requesting resource cpu=100m on Node xen16-168.ebaotech.com
Feb 18 03:55:17.544: INFO: Pod kube-proxy-9c526 requesting resource cpu=0m on Node xen16-168.ebaotech.com
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-010b4d3d-3331-11e9-94e0-0a580af401c1.15845914ca25b58f], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-lzqtc/filler-pod-010b4d3d-3331-11e9-94e0-0a580af401c1 to xen16-168.ebaotech.com]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-010b4d3d-3331-11e9-94e0-0a580af401c1.15845915015ec56d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-010b4d3d-3331-11e9-94e0-0a580af401c1.1584591502e02963], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-010b4d3d-3331-11e9-94e0-0a580af401c1.15845915150fb862], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15845915424c9658], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node xen16-168.ebaotech.com
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:20.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lzqtc" for this suite.
Feb 18 03:55:26.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:55:26.693: INFO: namespace: e2e-tests-sched-pred-lzqtc, resource: bindings, ignored listing per whitelist
Feb 18 03:55:26.738: INFO: namespace e2e-tests-sched-pred-lzqtc deletion completed in 6.132388977s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.342 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:55:26.739: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0694f02b-3331-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 03:55:26.848: INFO: Waiting up to 5m0s for pod "pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-lhv6t" to be "success or failure"
Feb 18 03:55:26.852: INFO: Pod "pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.945369ms
Feb 18 03:55:28.858: INFO: Pod "pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009716967s
STEP: Saw pod success
Feb 18 03:55:28.858: INFO: Pod "pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:55:28.867: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 03:55:28.945: INFO: Waiting for pod pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:55:28.949: INFO: Pod pod-configmaps-0695af01-3331-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:28.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lhv6t" for this suite.
Feb 18 03:55:35.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:55:35.077: INFO: namespace: e2e-tests-configmap-lhv6t, resource: bindings, ignored listing per whitelist
Feb 18 03:55:35.162: INFO: namespace e2e-tests-configmap-lhv6t deletion completed in 6.206809049s

• [SLOW TEST:8.424 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:55:35.162: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 03:55:35.271: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 18 03:55:35.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wwhqd/daemonsets","resourceVersion":"336739"},"items":null}

Feb 18 03:55:35.283: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wwhqd/pods","resourceVersion":"336739"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:35.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wwhqd" for this suite.
Feb 18 03:55:41.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:55:41.321: INFO: namespace: e2e-tests-daemonsets-wwhqd, resource: bindings, ignored listing per whitelist
Feb 18 03:55:41.427: INFO: namespace e2e-tests-daemonsets-wwhqd deletion completed in 6.131526721s

S [SKIPPING] [6.265 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 18 03:55:35.271: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:55:41.427: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 18 03:55:41.598: INFO: Waiting up to 5m0s for pod "pod-0f602bc7-3331-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-qjznm" to be "success or failure"
Feb 18 03:55:41.602: INFO: Pod "pod-0f602bc7-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.164465ms
Feb 18 03:55:43.609: INFO: Pod "pod-0f602bc7-3331-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011108597s
STEP: Saw pod success
Feb 18 03:55:43.609: INFO: Pod "pod-0f602bc7-3331-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:55:43.613: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-0f602bc7-3331-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 03:55:43.638: INFO: Waiting for pod pod-0f602bc7-3331-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:55:43.642: INFO: Pod pod-0f602bc7-3331-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:43.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qjznm" for this suite.
Feb 18 03:55:49.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:55:49.681: INFO: namespace: e2e-tests-emptydir-qjznm, resource: bindings, ignored listing per whitelist
Feb 18 03:55:49.785: INFO: namespace e2e-tests-emptydir-qjznm deletion completed in 6.136364s

• [SLOW TEST:8.358 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:55:49.785: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:55:52.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-4d6nf" for this suite.
Feb 18 03:56:44.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:56:44.058: INFO: namespace: e2e-tests-kubelet-test-4d6nf, resource: bindings, ignored listing per whitelist
Feb 18 03:56:44.163: INFO: namespace e2e-tests-kubelet-test-4d6nf deletion completed in 52.138190178s

• [SLOW TEST:54.378 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:56:44.164: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-34c64571-3331-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-34c64571-3331-11e9-94e0-0a580af401c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:56:48.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t7xfx" for this suite.
Feb 18 03:57:10.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:57:10.593: INFO: namespace: e2e-tests-projected-t7xfx, resource: bindings, ignored listing per whitelist
Feb 18 03:57:10.650: INFO: namespace e2e-tests-projected-t7xfx deletion completed in 22.129053591s

• [SLOW TEST:26.486 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:57:10.651: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-k4nnz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k4nnz to expose endpoints map[]
Feb 18 03:57:10.764: INFO: Get endpoints failed (3.453579ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 18 03:57:11.769: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k4nnz exposes endpoints map[] (1.008458847s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-k4nnz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k4nnz to expose endpoints map[pod1:[100]]
Feb 18 03:57:13.808: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k4nnz exposes endpoints map[pod1:[100]] (2.028671202s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-k4nnz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k4nnz to expose endpoints map[pod2:[101] pod1:[100]]
Feb 18 03:57:15.853: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k4nnz exposes endpoints map[pod1:[100] pod2:[101]] (2.038953391s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-k4nnz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k4nnz to expose endpoints map[pod2:[101]]
Feb 18 03:57:16.879: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k4nnz exposes endpoints map[pod2:[101]] (1.018924439s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-k4nnz
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k4nnz to expose endpoints map[]
Feb 18 03:57:17.897: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k4nnz exposes endpoints map[] (1.010987708s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:57:17.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-k4nnz" for this suite.
Feb 18 03:57:23.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:57:24.011: INFO: namespace: e2e-tests-services-k4nnz, resource: bindings, ignored listing per whitelist
Feb 18 03:57:24.129: INFO: namespace e2e-tests-services-k4nnz deletion completed in 6.1865103s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.479 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:57:24.129: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0218 03:57:34.274555      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 03:57:34.274: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:57:34.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5drzw" for this suite.
Feb 18 03:57:40.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:57:40.306: INFO: namespace: e2e-tests-gc-5drzw, resource: bindings, ignored listing per whitelist
Feb 18 03:57:40.412: INFO: namespace e2e-tests-gc-5drzw deletion completed in 6.132952651s

• [SLOW TEST:16.283 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:57:40.412: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 18 03:57:40.514: INFO: Waiting up to 5m0s for pod "var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1" in namespace "e2e-tests-var-expansion-f5dpq" to be "success or failure"
Feb 18 03:57:40.520: INFO: Pod "var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.136566ms
Feb 18 03:57:42.526: INFO: Pod "var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011564551s
Feb 18 03:57:44.531: INFO: Pod "var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017115268s
STEP: Saw pod success
Feb 18 03:57:44.531: INFO: Pod "var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 03:57:44.536: INFO: Trying to get logs from node xen16-168.ebaotech.com pod var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 03:57:44.562: INFO: Waiting for pod var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1 to disappear
Feb 18 03:57:44.565: INFO: Pod var-expansion-5641d11f-3331-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:57:44.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-f5dpq" for this suite.
Feb 18 03:57:50.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:57:50.688: INFO: namespace: e2e-tests-var-expansion-f5dpq, resource: bindings, ignored listing per whitelist
Feb 18 03:57:50.701: INFO: namespace e2e-tests-var-expansion-f5dpq deletion completed in 6.131082399s

• [SLOW TEST:10.289 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:57:50.702: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 18 03:57:50.803: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:57:56.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-n8nld" for this suite.
Feb 18 03:58:18.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:58:18.646: INFO: namespace: e2e-tests-init-container-n8nld, resource: bindings, ignored listing per whitelist
Feb 18 03:58:18.735: INFO: namespace e2e-tests-init-container-n8nld deletion completed in 22.200097149s

• [SLOW TEST:28.033 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:58:18.735: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 18 03:58:18.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 --namespace=e2e-tests-kubectl-56z8d run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 18 03:58:21.530: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 18 03:58:21.530: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:58:23.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-56z8d" for this suite.
Feb 18 03:58:29.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:58:29.587: INFO: namespace: e2e-tests-kubectl-56z8d, resource: bindings, ignored listing per whitelist
Feb 18 03:58:29.680: INFO: namespace e2e-tests-kubectl-56z8d deletion completed in 6.13585183s

• [SLOW TEST:10.945 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:58:29.680: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:58:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zngwx" for this suite.
Feb 18 03:58:35.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 03:58:35.899: INFO: namespace: e2e-tests-kubelet-test-zngwx, resource: bindings, ignored listing per whitelist
Feb 18 03:58:35.954: INFO: namespace e2e-tests-kubelet-test-zngwx deletion completed in 6.139322838s

• [SLOW TEST:6.274 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 03:58:35.954: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-775da017-3331-11e9-94e0-0a580af401c1
STEP: Creating configMap with name cm-test-opt-upd-775da097-3331-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-775da017-3331-11e9-94e0-0a580af401c1
STEP: Updating configmap cm-test-opt-upd-775da097-3331-11e9-94e0-0a580af401c1
STEP: Creating configMap with name cm-test-opt-create-775da0cb-3331-11e9-94e0-0a580af401c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 03:59:48.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zbgdf" for this suite.
Feb 18 04:00:10.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:00:10.914: INFO: namespace: e2e-tests-projected-zbgdf, resource: bindings, ignored listing per whitelist
Feb 18 04:00:10.914: INFO: namespace e2e-tests-projected-zbgdf deletion completed in 22.169908892s

• [SLOW TEST:94.960 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:00:10.915: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:00:11.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-2w47p" for this suite.
Feb 18 04:00:17.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:00:17.154: INFO: namespace: e2e-tests-services-2w47p, resource: bindings, ignored listing per whitelist
Feb 18 04:00:17.256: INFO: namespace e2e-tests-services-2w47p deletion completed in 6.130680238s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.341 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:00:17.256: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:00:17.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-z8f6t" to be "success or failure"
Feb 18 04:00:17.493: INFO: Pod "downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.290629ms
Feb 18 04:00:19.498: INFO: Pod "downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010151908s
STEP: Saw pod success
Feb 18 04:00:19.499: INFO: Pod "downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:00:19.503: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:00:19.529: INFO: Waiting for pod downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:00:19.532: INFO: Pod downwardapi-volume-b3d20a17-3331-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:00:19.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z8f6t" for this suite.
Feb 18 04:00:25.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:00:25.594: INFO: namespace: e2e-tests-downward-api-z8f6t, resource: bindings, ignored listing per whitelist
Feb 18 04:00:25.676: INFO: namespace e2e-tests-downward-api-z8f6t deletion completed in 6.138642395s

• [SLOW TEST:8.420 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:00:25.676: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 18 04:00:25.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-8b2mk'
Feb 18 04:00:26.145: INFO: stderr: ""
Feb 18 04:00:26.145: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 18 04:00:27.151: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 04:00:27.151: INFO: Found 0 / 1
Feb 18 04:00:28.152: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 04:00:28.152: INFO: Found 1 / 1
Feb 18 04:00:28.152: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 18 04:00:28.156: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 04:00:28.156: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 18 04:00:28.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 logs redis-master-7fnjl redis-master --namespace=e2e-tests-kubectl-8b2mk'
Feb 18 04:00:28.337: INFO: stderr: ""
Feb 18 04:00:28.337: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Feb 04:00:27.479 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Feb 04:00:27.479 # Server started, Redis version 3.2.12\n1:M 18 Feb 04:00:27.479 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Feb 04:00:27.480 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 18 04:00:28.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 log redis-master-7fnjl redis-master --namespace=e2e-tests-kubectl-8b2mk --tail=1'
Feb 18 04:00:28.508: INFO: stderr: ""
Feb 18 04:00:28.508: INFO: stdout: "1:M 18 Feb 04:00:27.480 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 18 04:00:28.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 log redis-master-7fnjl redis-master --namespace=e2e-tests-kubectl-8b2mk --limit-bytes=1'
Feb 18 04:00:28.697: INFO: stderr: ""
Feb 18 04:00:28.697: INFO: stdout: " "
STEP: exposing timestamps
Feb 18 04:00:28.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 log redis-master-7fnjl redis-master --namespace=e2e-tests-kubectl-8b2mk --tail=1 --timestamps'
Feb 18 04:00:28.880: INFO: stderr: ""
Feb 18 04:00:28.880: INFO: stdout: "2019-02-18T04:00:27.480652451Z 1:M 18 Feb 04:00:27.480 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 18 04:00:31.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 log redis-master-7fnjl redis-master --namespace=e2e-tests-kubectl-8b2mk --since=1s'
Feb 18 04:00:31.567: INFO: stderr: ""
Feb 18 04:00:31.567: INFO: stdout: ""
Feb 18 04:00:31.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 log redis-master-7fnjl redis-master --namespace=e2e-tests-kubectl-8b2mk --since=24h'
Feb 18 04:00:31.761: INFO: stderr: ""
Feb 18 04:00:31.761: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Feb 04:00:27.479 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Feb 04:00:27.479 # Server started, Redis version 3.2.12\n1:M 18 Feb 04:00:27.479 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Feb 04:00:27.480 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 18 04:00:31.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8b2mk'
Feb 18 04:00:31.929: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:00:31.929: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 18 04:00:31.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-8b2mk'
Feb 18 04:00:32.185: INFO: stderr: "No resources found.\n"
Feb 18 04:00:32.186: INFO: stdout: ""
Feb 18 04:00:32.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -l name=nginx --namespace=e2e-tests-kubectl-8b2mk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 04:00:32.374: INFO: stderr: ""
Feb 18 04:00:32.375: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:00:32.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8b2mk" for this suite.
Feb 18 04:00:38.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:00:38.473: INFO: namespace: e2e-tests-kubectl-8b2mk, resource: bindings, ignored listing per whitelist
Feb 18 04:00:38.625: INFO: namespace e2e-tests-kubectl-8b2mk deletion completed in 6.243987571s

• [SLOW TEST:12.949 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:00:38.626: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 18 04:00:38.730: INFO: Waiting up to 5m0s for pod "pod-c07b143f-3331-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-z9b58" to be "success or failure"
Feb 18 04:00:38.735: INFO: Pod "pod-c07b143f-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.604176ms
Feb 18 04:00:40.740: INFO: Pod "pod-c07b143f-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010779997s
Feb 18 04:00:42.746: INFO: Pod "pod-c07b143f-3331-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01633656s
STEP: Saw pod success
Feb 18 04:00:42.746: INFO: Pod "pod-c07b143f-3331-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:00:42.750: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-c07b143f-3331-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:00:42.788: INFO: Waiting for pod pod-c07b143f-3331-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:00:42.792: INFO: Pod pod-c07b143f-3331-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:00:42.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z9b58" for this suite.
Feb 18 04:00:48.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:00:48.894: INFO: namespace: e2e-tests-emptydir-z9b58, resource: bindings, ignored listing per whitelist
Feb 18 04:00:48.930: INFO: namespace e2e-tests-emptydir-z9b58 deletion completed in 6.132076296s

• [SLOW TEST:10.304 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:00:48.930: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-fkvkk;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-fkvkk;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fkvkk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 154.142.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.142.154_udp@PTR;check="$$(dig +tcp +noall +answer +search 154.142.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.142.154_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-fkvkk;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fkvkk.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-fkvkk.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fkvkk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 154.142.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.142.154_udp@PTR;check="$$(dig +tcp +noall +answer +search 154.142.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.142.154_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 18 04:00:53.098: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.146: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.165: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.170: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.174: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.178: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.183: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.188: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.193: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.199: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:53.228: INFO: Lookups using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 failed for: [wheezy_udp@dns-test-service wheezy_udp@PodARecord jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fkvkk jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc]

Feb 18 04:00:58.236: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.321: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.327: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.332: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.337: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.342: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.346: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.351: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.355: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:00:58.385: INFO: Lookups using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fkvkk jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc]

Feb 18 04:01:03.236: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.317: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.322: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.328: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.333: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.339: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.345: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.351: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.356: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:03.395: INFO: Lookups using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fkvkk jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc]

Feb 18 04:01:08.236: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.314: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.319: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.324: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.328: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.333: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.338: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.343: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.349: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:08.380: INFO: Lookups using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fkvkk jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc]

Feb 18 04:01:13.235: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.300: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.304: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.308: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.313: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.317: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.321: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.326: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.331: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:13.387: INFO: Lookups using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fkvkk jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc]

Feb 18 04:01:18.236: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.330: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.335: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.339: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.344: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.347: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.352: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.356: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.362: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc from pod e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1: the server could not find the requested resource (get pods dns-test-c6a55536-3331-11e9-94e0-0a580af401c1)
Feb 18 04:01:18.393: INFO: Lookups using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fkvkk jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk jessie_udp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@dns-test-service.e2e-tests-dns-fkvkk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fkvkk.svc]

Feb 18 04:01:23.375: INFO: DNS probes using e2e-tests-dns-fkvkk/dns-test-c6a55536-3331-11e9-94e0-0a580af401c1 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:01:23.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-fkvkk" for this suite.
Feb 18 04:01:29.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:01:29.704: INFO: namespace: e2e-tests-dns-fkvkk, resource: bindings, ignored listing per whitelist
Feb 18 04:01:29.727: INFO: namespace e2e-tests-dns-fkvkk deletion completed in 6.189527676s

• [SLOW TEST:40.797 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:01:29.728: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-f8k8n
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 04:01:29.822: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 04:01:55.891: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.90:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-f8k8n PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:01:55.891: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:01:56.234: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:01:56.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-f8k8n" for this suite.
Feb 18 04:02:18.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:02:18.424: INFO: namespace: e2e-tests-pod-network-test-f8k8n, resource: bindings, ignored listing per whitelist
Feb 18 04:02:18.433: INFO: namespace e2e-tests-pod-network-test-f8k8n deletion completed in 22.185464613s

• [SLOW TEST:48.706 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:02:18.434: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fbf91a85-3331-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:02:18.545: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-dp9bg" to be "success or failure"
Feb 18 04:02:18.594: INFO: Pod "pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 48.469622ms
Feb 18 04:02:20.599: INFO: Pod "pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053626887s
STEP: Saw pod success
Feb 18 04:02:20.599: INFO: Pod "pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:02:20.603: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:02:20.631: INFO: Waiting for pod pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:02:20.635: INFO: Pod pod-projected-configmaps-fbf9d363-3331-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:02:20.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dp9bg" for this suite.
Feb 18 04:02:26.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:02:26.740: INFO: namespace: e2e-tests-projected-dp9bg, resource: bindings, ignored listing per whitelist
Feb 18 04:02:26.795: INFO: namespace e2e-tests-projected-dp9bg deletion completed in 6.155063921s

• [SLOW TEST:8.361 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:02:26.796: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:02:26.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4vfx6" for this suite.
Feb 18 04:02:48.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:02:48.959: INFO: namespace: e2e-tests-pods-4vfx6, resource: bindings, ignored listing per whitelist
Feb 18 04:02:49.048: INFO: namespace e2e-tests-pods-4vfx6 deletion completed in 22.138586359s

• [SLOW TEST:22.252 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:02:49.048: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 18 04:02:49.244: INFO: Waiting up to 5m0s for pod "pod-0e462dcb-3332-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-phjmd" to be "success or failure"
Feb 18 04:02:49.251: INFO: Pod "pod-0e462dcb-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.475769ms
Feb 18 04:02:51.255: INFO: Pod "pod-0e462dcb-3332-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010830223s
STEP: Saw pod success
Feb 18 04:02:51.255: INFO: Pod "pod-0e462dcb-3332-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:02:51.258: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-0e462dcb-3332-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:02:51.282: INFO: Waiting for pod pod-0e462dcb-3332-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:02:51.286: INFO: Pod pod-0e462dcb-3332-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:02:51.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-phjmd" for this suite.
Feb 18 04:02:57.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:02:57.337: INFO: namespace: e2e-tests-emptydir-phjmd, resource: bindings, ignored listing per whitelist
Feb 18 04:02:57.441: INFO: namespace e2e-tests-emptydir-phjmd deletion completed in 6.1500863s

• [SLOW TEST:8.393 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:02:57.441: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1337de7a-3332-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:02:57.544: INFO: Waiting up to 5m0s for pod "pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-ssw94" to be "success or failure"
Feb 18 04:02:57.548: INFO: Pod "pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.73588ms
Feb 18 04:02:59.577: INFO: Pod "pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03297722s
STEP: Saw pod success
Feb 18 04:02:59.577: INFO: Pod "pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:02:59.581: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:02:59.609: INFO: Waiting for pod pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:02:59.613: INFO: Pod pod-secrets-1338a6d7-3332-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:02:59.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ssw94" for this suite.
Feb 18 04:03:05.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:03:05.732: INFO: namespace: e2e-tests-secrets-ssw94, resource: bindings, ignored listing per whitelist
Feb 18 04:03:05.764: INFO: namespace e2e-tests-secrets-ssw94 deletion completed in 6.145631381s

• [SLOW TEST:8.322 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:03:05.764: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 18 04:03:09.922: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 04:03:09.926: INFO: Pod pod-with-poststart-http-hook still exists
Feb 18 04:03:11.926: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 04:03:11.931: INFO: Pod pod-with-poststart-http-hook still exists
Feb 18 04:03:13.926: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 04:03:13.932: INFO: Pod pod-with-poststart-http-hook still exists
Feb 18 04:03:15.926: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 04:03:15.931: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:03:15.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-d6jkh" for this suite.
Feb 18 04:03:37.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:03:38.034: INFO: namespace: e2e-tests-container-lifecycle-hook-d6jkh, resource: bindings, ignored listing per whitelist
Feb 18 04:03:38.081: INFO: namespace e2e-tests-container-lifecycle-hook-d6jkh deletion completed in 22.144936886s

• [SLOW TEST:32.317 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:03:38.082: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 18 04:03:40.465: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:04:04.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-xwkjr" for this suite.
Feb 18 04:04:10.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:04:10.649: INFO: namespace: e2e-tests-namespaces-xwkjr, resource: bindings, ignored listing per whitelist
Feb 18 04:04:10.659: INFO: namespace e2e-tests-namespaces-xwkjr deletion completed in 6.131745015s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gcdwd" for this suite.
Feb 18 04:04:10.662: INFO: Namespace e2e-tests-nsdeletetest-gcdwd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-cvlzm" for this suite.
Feb 18 04:04:16.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:04:16.750: INFO: namespace: e2e-tests-nsdeletetest-cvlzm, resource: bindings, ignored listing per whitelist
Feb 18 04:04:16.793: INFO: namespace e2e-tests-nsdeletetest-cvlzm deletion completed in 6.130747798s

• [SLOW TEST:38.711 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:04:16.793: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-42844f46-3332-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:04:16.897: INFO: Waiting up to 5m0s for pod "pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-zfj6f" to be "success or failure"
Feb 18 04:04:16.900: INFO: Pod "pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.354941ms
Feb 18 04:04:18.906: INFO: Pod "pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009014938s
Feb 18 04:04:20.911: INFO: Pod "pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014265082s
STEP: Saw pod success
Feb 18 04:04:20.911: INFO: Pod "pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:04:20.915: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:04:20.941: INFO: Waiting for pod pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:04:20.945: INFO: Pod pod-secrets-4284e1a6-3332-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:04:20.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zfj6f" for this suite.
Feb 18 04:04:26.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:04:27.037: INFO: namespace: e2e-tests-secrets-zfj6f, resource: bindings, ignored listing per whitelist
Feb 18 04:04:27.078: INFO: namespace e2e-tests-secrets-zfj6f deletion completed in 6.127491724s

• [SLOW TEST:10.285 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:04:27.078: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-48a5b246-3332-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:04:27.181: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-fsp6f" to be "success or failure"
Feb 18 04:04:27.184: INFO: Pod "pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.094367ms
Feb 18 04:04:29.190: INFO: Pod "pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00845318s
Feb 18 04:04:31.196: INFO: Pod "pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014208153s
STEP: Saw pod success
Feb 18 04:04:31.196: INFO: Pod "pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:04:31.199: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:04:31.233: INFO: Waiting for pod pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:04:31.237: INFO: Pod pod-projected-secrets-48a64f01-3332-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:04:31.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsp6f" for this suite.
Feb 18 04:04:37.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:04:37.339: INFO: namespace: e2e-tests-projected-fsp6f, resource: bindings, ignored listing per whitelist
Feb 18 04:04:37.374: INFO: namespace e2e-tests-projected-fsp6f deletion completed in 6.132459182s

• [SLOW TEST:10.296 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:04:37.375: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 18 04:04:43.531: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:43.535: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:45.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:45.541: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:47.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:47.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:49.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:49.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:51.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:51.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:53.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:53.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:55.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:55.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:57.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:57.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:04:59.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:04:59.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:05:01.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:05:01.540: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 04:05:03.535: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 04:05:03.541: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:05:03.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-p6xhx" for this suite.
Feb 18 04:05:25.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:05:25.651: INFO: namespace: e2e-tests-container-lifecycle-hook-p6xhx, resource: bindings, ignored listing per whitelist
Feb 18 04:05:25.693: INFO: namespace e2e-tests-container-lifecycle-hook-p6xhx deletion completed in 22.130855469s

• [SLOW TEST:48.318 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:05:25.693: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 18 04:05:25.788: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:05:30.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8n9sq" for this suite.
Feb 18 04:05:36.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:05:36.701: INFO: namespace: e2e-tests-init-container-8n9sq, resource: bindings, ignored listing per whitelist
Feb 18 04:05:36.762: INFO: namespace e2e-tests-init-container-8n9sq deletion completed in 6.131017165s

• [SLOW TEST:11.069 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:05:36.763: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 18 04:05:36.863: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-647419003 proxy --unix-socket=/tmp/kubectl-proxy-unix389135262/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:05:36.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2bdkw" for this suite.
Feb 18 04:05:43.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:05:43.031: INFO: namespace: e2e-tests-kubectl-2bdkw, resource: bindings, ignored listing per whitelist
Feb 18 04:05:43.120: INFO: namespace e2e-tests-kubectl-2bdkw deletion completed in 6.131723506s

• [SLOW TEST:6.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:05:43.120: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:05:43.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-dt5k4" to be "success or failure"
Feb 18 04:05:43.268: INFO: Pod "downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.07392ms
Feb 18 04:05:45.273: INFO: Pod "downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010227506s
STEP: Saw pod success
Feb 18 04:05:45.273: INFO: Pod "downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:05:45.277: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:05:45.303: INFO: Waiting for pod downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:05:45.307: INFO: Pod downwardapi-volume-75ff0427-3332-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:05:45.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dt5k4" for this suite.
Feb 18 04:05:51.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:05:51.375: INFO: namespace: e2e-tests-projected-dt5k4, resource: bindings, ignored listing per whitelist
Feb 18 04:05:51.448: INFO: namespace e2e-tests-projected-dt5k4 deletion completed in 6.135311595s

• [SLOW TEST:8.328 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:05:51.448: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zxpf6
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-zxpf6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-zxpf6
Feb 18 04:05:51.553: INFO: Found 0 stateful pods, waiting for 1
Feb 18 04:06:01.558: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 18 04:06:01.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 04:06:02.074: INFO: stderr: ""
Feb 18 04:06:02.074: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 04:06:02.074: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 04:06:02.081: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 18 04:06:12.087: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 04:06:12.087: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 04:06:12.105: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998902s
Feb 18 04:06:13.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995749974s
Feb 18 04:06:14.118: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988899002s
Feb 18 04:06:15.124: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983268166s
Feb 18 04:06:16.130: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977318806s
Feb 18 04:06:17.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97141403s
Feb 18 04:06:18.142: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.965517854s
Feb 18 04:06:19.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.95871825s
Feb 18 04:06:20.155: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.952437762s
Feb 18 04:06:21.161: INFO: Verifying statefulset ss doesn't scale past 1 for another 945.77588ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-zxpf6
Feb 18 04:06:22.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:06:22.644: INFO: stderr: ""
Feb 18 04:06:22.644: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 04:06:22.644: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 04:06:22.650: INFO: Found 2 stateful pods, waiting for 3
Feb 18 04:06:32.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 04:06:32.659: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 04:06:32.659: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 18 04:06:32.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 04:06:33.147: INFO: stderr: ""
Feb 18 04:06:33.147: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 04:06:33.147: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 04:06:33.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 04:06:33.657: INFO: stderr: ""
Feb 18 04:06:33.657: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 04:06:33.657: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 04:06:33.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 04:06:34.155: INFO: stderr: ""
Feb 18 04:06:34.156: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 04:06:34.156: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 04:06:34.156: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 04:06:34.161: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 18 04:06:44.172: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 04:06:44.172: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 04:06:44.172: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 04:06:44.189: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998855s
Feb 18 04:06:45.196: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99194719s
Feb 18 04:06:46.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985707556s
Feb 18 04:06:47.208: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978693296s
Feb 18 04:06:48.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972876125s
Feb 18 04:06:49.223: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965429009s
Feb 18 04:06:50.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.958666563s
Feb 18 04:06:51.236: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.952097944s
Feb 18 04:06:52.242: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.945522556s
Feb 18 04:06:53.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 939.388699ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-zxpf6
Feb 18 04:06:54.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:06:54.757: INFO: stderr: ""
Feb 18 04:06:54.757: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 04:06:54.757: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 04:06:54.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:06:55.277: INFO: stderr: ""
Feb 18 04:06:55.277: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 04:06:55.277: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 04:06:55.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:06:55.770: INFO: rc: 137
Feb 18 04:06:55.770: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  command terminated with exit code 137
 [] <nil> 0xc0013fbf20 exit status 137 <nil> <nil> true [0xc001cb64e8 0xc001cb6500 0xc001cb6520] [0xc001cb64e8 0xc001cb6500 0xc001cb6520] [0xc001cb64f8 0xc001cb6510] [0x92f8e0 0x92f8e0] 0xc002023860 <nil>}:
Command stdout:

stderr:
command terminated with exit code 137

error:
exit status 137

Feb 18 04:07:05.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:07:05.924: INFO: rc: 1
Feb 18 04:07:05.924: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae15f0 exit status 1 <nil> <nil> true [0xc001dc4608 0xc001dc4620 0xc001dc4638] [0xc001dc4608 0xc001dc4620 0xc001dc4638] [0xc001dc4618 0xc001dc4630] [0x92f8e0 0x92f8e0] 0xc0022ffa40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:07:15.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:07:16.058: INFO: rc: 1
Feb 18 04:07:16.058: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257c4e0 exit status 1 <nil> <nil> true [0xc00000e030 0xc00000e068 0xc00000e0f0] [0xc00000e030 0xc00000e068 0xc00000e0f0] [0xc00000e050 0xc00000e0b0] [0x92f8e0 0x92f8e0] 0xc001dd8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:07:26.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:07:26.210: INFO: rc: 1
Feb 18 04:07:26.210: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027803c0 exit status 1 <nil> <nil> true [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc010 0xc001dcc028] [0x92f8e0 0x92f8e0] 0xc0020a03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:07:36.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:07:36.362: INFO: rc: 1
Feb 18 04:07:36.362: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257c8d0 exit status 1 <nil> <nil> true [0xc00000e118 0xc00000e178 0xc00000e198] [0xc00000e118 0xc00000e178 0xc00000e198] [0xc00000e160 0xc00000e190] [0x92f8e0 0x92f8e0] 0xc001dd8de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:07:46.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:07:46.511: INFO: rc: 1
Feb 18 04:07:46.511: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257cc90 exit status 1 <nil> <nil> true [0xc00000e1a8 0xc00000e1c8 0xc00000e1e8] [0xc00000e1a8 0xc00000e1c8 0xc00000e1e8] [0xc00000e1c0 0xc00000e1e0] [0x92f8e0 0x92f8e0] 0xc001dd9500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:07:56.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:07:56.674: INFO: rc: 1
Feb 18 04:07:56.674: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257d1d0 exit status 1 <nil> <nil> true [0xc00000e1f8 0xc00000e218 0xc00000e270] [0xc00000e1f8 0xc00000e218 0xc00000e270] [0xc00000e208 0xc00000e250] [0x92f8e0 0x92f8e0] 0xc001dd9e00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:08:06.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:08:06.837: INFO: rc: 1
Feb 18 04:08:06.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002780780 exit status 1 <nil> <nil> true [0xc001dcc038 0xc001dcc050 0xc001dcc068] [0xc001dcc038 0xc001dcc050 0xc001dcc068] [0xc001dcc048 0xc001dcc060] [0x92f8e0 0x92f8e0] 0xc0020a0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:08:16.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:08:17.011: INFO: rc: 1
Feb 18 04:08:17.011: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257d560 exit status 1 <nil> <nil> true [0xc00000e2a0 0xc00000e2d8 0xc00000e2f0] [0xc00000e2a0 0xc00000e2d8 0xc00000e2f0] [0xc00000e2d0 0xc00000e2e8] [0x92f8e0 0x92f8e0] 0xc002064480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:08:27.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:08:27.165: INFO: rc: 1
Feb 18 04:08:27.165: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002780b10 exit status 1 <nil> <nil> true [0xc001dcc070 0xc001dcc088 0xc001dcc0a0] [0xc001dcc070 0xc001dcc088 0xc001dcc0a0] [0xc001dcc080 0xc001dcc098] [0x92f8e0 0x92f8e0] 0xc0020a1380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:08:37.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:08:37.328: INFO: rc: 1
Feb 18 04:08:37.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257d980 exit status 1 <nil> <nil> true [0xc00000e2f8 0xc00000e310 0xc00000e3c0] [0xc00000e2f8 0xc00000e310 0xc00000e3c0] [0xc00000e308 0xc00000e3a0] [0x92f8e0 0x92f8e0] 0xc002064900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:08:47.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:08:47.484: INFO: rc: 1
Feb 18 04:08:47.484: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257dd10 exit status 1 <nil> <nil> true [0xc00000e3c8 0xc00000e468 0xc00000e4d0] [0xc00000e3c8 0xc00000e468 0xc00000e4d0] [0xc00000e448 0xc00000e4a8] [0x92f8e0 0x92f8e0] 0xc002064d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:08:57.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:08:57.643: INFO: rc: 1
Feb 18 04:08:57.643: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a4120 exit status 1 <nil> <nil> true [0xc00000e4e8 0xc00000e518 0xc00000e540] [0xc00000e4e8 0xc00000e518 0xc00000e540] [0xc00000e510 0xc00000e530] [0x92f8e0 0x92f8e0] 0xc002065200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:09:07.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:09:07.806: INFO: rc: 1
Feb 18 04:09:07.806: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002780f00 exit status 1 <nil> <nil> true [0xc001dcc0a8 0xc001dcc0c0 0xc001dcc0e0] [0xc001dcc0a8 0xc001dcc0c0 0xc001dcc0e0] [0xc001dcc0b8 0xc001dcc0d8] [0x92f8e0 0x92f8e0] 0xc0020a1c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:09:17.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:09:17.966: INFO: rc: 1
Feb 18 04:09:17.966: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257c4b0 exit status 1 <nil> <nil> true [0xc00000e030 0xc00000e068 0xc00000e0f0] [0xc00000e030 0xc00000e068 0xc00000e0f0] [0xc00000e050 0xc00000e0b0] [0x92f8e0 0x92f8e0] 0xc001dd8540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:09:27.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:09:28.112: INFO: rc: 1
Feb 18 04:09:28.112: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a4420 exit status 1 <nil> <nil> true [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc010 0xc001dcc028] [0x92f8e0 0x92f8e0] 0xc002064480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:09:38.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:09:38.269: INFO: rc: 1
Feb 18 04:09:38.269: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257c870 exit status 1 <nil> <nil> true [0xc00000e118 0xc00000e178 0xc00000e198] [0xc00000e118 0xc00000e178 0xc00000e198] [0xc00000e160 0xc00000e190] [0x92f8e0 0x92f8e0] 0xc001dd8de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:09:48.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:09:48.408: INFO: rc: 1
Feb 18 04:09:48.408: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002780390 exit status 1 <nil> <nil> true [0xc00035b260 0xc00035b330 0xc00035b558] [0xc00035b260 0xc00035b330 0xc00035b558] [0xc00035b2f8 0xc00035b4c0] [0x92f8e0 0x92f8e0] 0xc0020a03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:09:58.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:09:58.571: INFO: rc: 1
Feb 18 04:09:58.571: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002652510 exit status 1 <nil> <nil> true [0xc0001601b8 0xc0001602f0 0xc000160858] [0xc0001601b8 0xc0001602f0 0xc000160858] [0xc000160298 0xc0001605d0] [0x92f8e0 0x92f8e0] 0xc001e2a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:10:08.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:10:08.718: INFO: rc: 1
Feb 18 04:10:08.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0027807b0 exit status 1 <nil> <nil> true [0xc00035b5d0 0xc00035b618 0xc00035b6f0] [0xc00035b5d0 0xc00035b618 0xc00035b6f0] [0xc00035b608 0xc00035b6a8] [0x92f8e0 0x92f8e0] 0xc0020a0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:10:18.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:10:18.870: INFO: rc: 1
Feb 18 04:10:18.870: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002652ab0 exit status 1 <nil> <nil> true [0xc0001608d0 0xc000160aa0 0xc000160c48] [0xc0001608d0 0xc000160aa0 0xc000160c48] [0xc0001609f8 0xc000160bc0] [0x92f8e0 0x92f8e0] 0xc001e2a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:10:28.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:10:29.012: INFO: rc: 1
Feb 18 04:10:29.012: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a49f0 exit status 1 <nil> <nil> true [0xc001dcc038 0xc001dcc050 0xc001dcc068] [0xc001dcc038 0xc001dcc050 0xc001dcc068] [0xc001dcc048 0xc001dcc060] [0x92f8e0 0x92f8e0] 0xc002064900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:10:39.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:10:39.174: INFO: rc: 1
Feb 18 04:10:39.175: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a4f90 exit status 1 <nil> <nil> true [0xc001dcc070 0xc001dcc088 0xc001dcc0a0] [0xc001dcc070 0xc001dcc088 0xc001dcc0a0] [0xc001dcc080 0xc001dcc098] [0x92f8e0 0x92f8e0] 0xc002064d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:10:49.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:10:49.323: INFO: rc: 1
Feb 18 04:10:49.323: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002780bd0 exit status 1 <nil> <nil> true [0xc00035b718 0xc00035b790 0xc00035b7b0] [0xc00035b718 0xc00035b790 0xc00035b7b0] [0xc00035b760 0xc00035b7a8] [0x92f8e0 0x92f8e0] 0xc0020a1380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:10:59.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:10:59.468: INFO: rc: 1
Feb 18 04:10:59.468: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a53e0 exit status 1 <nil> <nil> true [0xc001dcc0a8 0xc001dcc0c0 0xc001dcc0e0] [0xc001dcc0a8 0xc001dcc0c0 0xc001dcc0e0] [0xc001dcc0b8 0xc001dcc0d8] [0x92f8e0 0x92f8e0] 0xc002065200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:11:09.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:11:09.639: INFO: rc: 1
Feb 18 04:11:09.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002652f60 exit status 1 <nil> <nil> true [0xc000160c90 0xc000160f30 0xc000161018] [0xc000160c90 0xc000160f30 0xc000161018] [0xc000160e28 0xc000160fc0] [0x92f8e0 0x92f8e0] 0xc001e2a9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:11:19.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:11:19.797: INFO: rc: 1
Feb 18 04:11:19.797: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257cbd0 exit status 1 <nil> <nil> true [0xc00000e1a8 0xc00000e1c8 0xc00000e1e8] [0xc00000e1a8 0xc00000e1c8 0xc00000e1e8] [0xc00000e1c0 0xc00000e1e0] [0x92f8e0 0x92f8e0] 0xc001dd94a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:11:29.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:11:29.948: INFO: rc: 1
Feb 18 04:11:29.948: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a43f0 exit status 1 <nil> <nil> true [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc000 0xc001dcc018 0xc001dcc030] [0xc001dcc010 0xc001dcc028] [0x92f8e0 0x92f8e0] 0xc0020a03c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:11:39.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:11:40.124: INFO: rc: 1
Feb 18 04:11:40.124: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0022a4a20 exit status 1 <nil> <nil> true [0xc001dcc038 0xc001dcc050 0xc001dcc068] [0xc001dcc038 0xc001dcc050 0xc001dcc068] [0xc001dcc048 0xc001dcc060] [0x92f8e0 0x92f8e0] 0xc0020a0960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:11:50.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:11:50.270: INFO: rc: 1
Feb 18 04:11:50.271: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00257c4e0 exit status 1 <nil> <nil> true [0xc00000e028 0xc00000e050 0xc00000e0b0] [0xc00000e028 0xc00000e050 0xc00000e0b0] [0xc00000e048 0xc00000e080] [0x92f8e0 0x92f8e0] 0xc002064480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb 18 04:12:00.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 exec --namespace=e2e-tests-statefulset-zxpf6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 04:12:00.416: INFO: rc: 1
Feb 18 04:12:00.416: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb 18 04:12:00.416: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 04:12:00.432: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zxpf6
Feb 18 04:12:00.436: INFO: Scaling statefulset ss to 0
Feb 18 04:12:00.448: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 04:12:00.453: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:12:00.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zxpf6" for this suite.
Feb 18 04:12:06.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:12:06.604: INFO: namespace: e2e-tests-statefulset-zxpf6, resource: bindings, ignored listing per whitelist
Feb 18 04:12:06.610: INFO: namespace e2e-tests-statefulset-zxpf6 deletion completed in 6.1335631s

• [SLOW TEST:375.162 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:12:06.610: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:13:06.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ctx99" for this suite.
Feb 18 04:13:28.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:13:28.899: INFO: namespace: e2e-tests-container-probe-ctx99, resource: bindings, ignored listing per whitelist
Feb 18 04:13:28.903: INFO: namespace e2e-tests-container-probe-ctx99 deletion completed in 22.174616216s

• [SLOW TEST:82.293 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:13:28.903: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-8b9b1209-3333-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:13:29.017: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-vglw7" to be "success or failure"
Feb 18 04:13:29.021: INFO: Pod "pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.984151ms
Feb 18 04:13:31.026: INFO: Pod "pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008927252s
Feb 18 04:13:33.032: INFO: Pod "pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014308953s
STEP: Saw pod success
Feb 18 04:13:33.032: INFO: Pod "pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:13:33.036: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:13:33.149: INFO: Waiting for pod pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:13:33.154: INFO: Pod pod-projected-secrets-8b9bbf24-3333-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:13:33.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vglw7" for this suite.
Feb 18 04:13:39.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:13:39.291: INFO: namespace: e2e-tests-projected-vglw7, resource: bindings, ignored listing per whitelist
Feb 18 04:13:39.294: INFO: namespace e2e-tests-projected-vglw7 deletion completed in 6.135668261s

• [SLOW TEST:10.391 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:13:39.295: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:13:39.500: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-m8vwt" to be "success or failure"
Feb 18 04:13:39.504: INFO: Pod "downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211534ms
Feb 18 04:13:41.509: INFO: Pod "downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009350341s
STEP: Saw pod success
Feb 18 04:13:41.510: INFO: Pod "downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:13:41.513: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:13:41.538: INFO: Waiting for pod downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:13:41.541: INFO: Pod downwardapi-volume-91db3246-3333-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:13:41.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m8vwt" for this suite.
Feb 18 04:13:47.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:13:47.676: INFO: namespace: e2e-tests-downward-api-m8vwt, resource: bindings, ignored listing per whitelist
Feb 18 04:13:47.690: INFO: namespace e2e-tests-downward-api-m8vwt deletion completed in 6.14419506s

• [SLOW TEST:8.396 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:13:47.691: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:13:47.797: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-fzfmr" to be "success or failure"
Feb 18 04:13:47.801: INFO: Pod "downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020007ms
Feb 18 04:13:49.807: INFO: Pod "downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009084188s
STEP: Saw pod success
Feb 18 04:13:49.807: INFO: Pod "downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:13:49.810: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:13:49.835: INFO: Waiting for pod downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:13:49.839: INFO: Pod downwardapi-volume-96cd2ffa-3333-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:13:49.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fzfmr" for this suite.
Feb 18 04:13:55.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:13:55.918: INFO: namespace: e2e-tests-downward-api-fzfmr, resource: bindings, ignored listing per whitelist
Feb 18 04:13:55.983: INFO: namespace e2e-tests-downward-api-fzfmr deletion completed in 6.138476425s

• [SLOW TEST:8.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:13:55.983: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 18 04:13:56.083: INFO: Waiting up to 5m0s for pod "client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1" in namespace "e2e-tests-containers-rqq8h" to be "success or failure"
Feb 18 04:13:56.086: INFO: Pod "client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.280996ms
Feb 18 04:13:58.093: INFO: Pod "client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010247236s
STEP: Saw pod success
Feb 18 04:13:58.094: INFO: Pod "client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:13:58.098: INFO: Trying to get logs from node xen16-168.ebaotech.com pod client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:13:58.121: INFO: Waiting for pod client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:13:58.124: INFO: Pod client-containers-9bbdb74a-3333-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:13:58.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rqq8h" for this suite.
Feb 18 04:14:04.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:14:04.184: INFO: namespace: e2e-tests-containers-rqq8h, resource: bindings, ignored listing per whitelist
Feb 18 04:14:04.267: INFO: namespace e2e-tests-containers-rqq8h deletion completed in 6.136462422s

• [SLOW TEST:8.284 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:14:04.268: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-n5ttz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 04:14:04.356: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 04:14:24.420: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.115:8080/dial?request=hostName&protocol=http&host=10.244.1.114&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-n5ttz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:14:24.421: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:14:24.777: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:14:24.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-n5ttz" for this suite.
Feb 18 04:14:46.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:14:46.886: INFO: namespace: e2e-tests-pod-network-test-n5ttz, resource: bindings, ignored listing per whitelist
Feb 18 04:14:46.915: INFO: namespace e2e-tests-pod-network-test-n5ttz deletion completed in 22.131244423s

• [SLOW TEST:42.647 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:14:46.915: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 18 04:14:47.052: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:47.055: INFO: Number of nodes with available pods: 0
Feb 18 04:14:47.055: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:48.105: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:48.110: INFO: Number of nodes with available pods: 0
Feb 18 04:14:48.110: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:49.063: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:49.067: INFO: Number of nodes with available pods: 0
Feb 18 04:14:49.067: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:50.063: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:50.068: INFO: Number of nodes with available pods: 1
Feb 18 04:14:50.068: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 18 04:14:50.087: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:50.090: INFO: Number of nodes with available pods: 0
Feb 18 04:14:50.090: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:51.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:51.103: INFO: Number of nodes with available pods: 0
Feb 18 04:14:51.103: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:52.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:52.103: INFO: Number of nodes with available pods: 0
Feb 18 04:14:52.104: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:53.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:53.102: INFO: Number of nodes with available pods: 0
Feb 18 04:14:53.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:54.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:54.102: INFO: Number of nodes with available pods: 0
Feb 18 04:14:54.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:55.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:55.102: INFO: Number of nodes with available pods: 0
Feb 18 04:14:55.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:56.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:56.102: INFO: Number of nodes with available pods: 0
Feb 18 04:14:56.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:57.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:57.102: INFO: Number of nodes with available pods: 0
Feb 18 04:14:57.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:58.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:58.102: INFO: Number of nodes with available pods: 0
Feb 18 04:14:58.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:14:59.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:14:59.101: INFO: Number of nodes with available pods: 0
Feb 18 04:14:59.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:00.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:00.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:00.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:01.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:01.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:01.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:02.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:02.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:02.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:03.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:03.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:03.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:04.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:04.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:04.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:05.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:05.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:05.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:06.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:06.103: INFO: Number of nodes with available pods: 0
Feb 18 04:15:06.103: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:07.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:07.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:07.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:08.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:08.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:08.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:09.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:09.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:09.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:10.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:10.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:10.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:11.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:11.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:11.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:12.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:12.103: INFO: Number of nodes with available pods: 0
Feb 18 04:15:12.103: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:13.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:13.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:13.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:14.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:14.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:14.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:15.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:15.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:15.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:16.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:16.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:16.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:17.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:17.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:17.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:18.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:18.103: INFO: Number of nodes with available pods: 0
Feb 18 04:15:18.103: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:19.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:19.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:19.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:20.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:20.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:20.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:21.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:21.102: INFO: Number of nodes with available pods: 0
Feb 18 04:15:21.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:22.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:22.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:22.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:23.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:23.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:23.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:24.194: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:24.198: INFO: Number of nodes with available pods: 0
Feb 18 04:15:24.198: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:25.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:25.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:25.101: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:26.098: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:26.101: INFO: Number of nodes with available pods: 0
Feb 18 04:15:26.102: INFO: Node xen16-168.ebaotech.com is running more than one daemon pod
Feb 18 04:15:27.097: INFO: DaemonSet pods can't tolerate node xen16-121.ebaotech.com with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 04:15:27.100: INFO: Number of nodes with available pods: 1
Feb 18 04:15:27.100: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nnm5b, will wait for the garbage collector to delete the pods
Feb 18 04:15:27.165: INFO: Deleting DaemonSet.extensions daemon-set took: 8.313298ms
Feb 18 04:15:27.265: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.305457ms
Feb 18 04:16:07.470: INFO: Number of nodes with available pods: 0
Feb 18 04:16:07.470: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 04:16:07.474: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nnm5b/daemonsets","resourceVersion":"339678"},"items":null}

Feb 18 04:16:07.477: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nnm5b/pods","resourceVersion":"339678"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:16:07.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nnm5b" for this suite.
Feb 18 04:16:13.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:16:13.616: INFO: namespace: e2e-tests-daemonsets-nnm5b, resource: bindings, ignored listing per whitelist
Feb 18 04:16:13.628: INFO: namespace e2e-tests-daemonsets-nnm5b deletion completed in 6.13526771s

• [SLOW TEST:86.713 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:16:13.628: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0218 04:16:24.092879      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 04:16:24.093: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:16:24.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vfh7l" for this suite.
Feb 18 04:16:30.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:16:30.197: INFO: namespace: e2e-tests-gc-vfh7l, resource: bindings, ignored listing per whitelist
Feb 18 04:16:30.237: INFO: namespace e2e-tests-gc-vfh7l deletion completed in 6.138517136s

• [SLOW TEST:16.609 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:16:30.237: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 04:16:30.332: INFO: Creating deployment "nginx-deployment"
Feb 18 04:16:30.337: INFO: Waiting for observed generation 1
Feb 18 04:16:32.432: INFO: Waiting for all required pods to come up
Feb 18 04:16:32.439: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 18 04:16:38.452: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 18 04:16:38.460: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 18 04:16:38.469: INFO: Updating deployment nginx-deployment
Feb 18 04:16:38.469: INFO: Waiting for observed generation 2
Feb 18 04:16:40.479: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 18 04:16:40.483: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 18 04:16:40.486: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 18 04:16:40.498: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 18 04:16:40.498: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 18 04:16:40.501: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 18 04:16:40.507: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 18 04:16:40.507: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 18 04:16:40.516: INFO: Updating deployment nginx-deployment
Feb 18 04:16:40.516: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 18 04:16:40.548: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 18 04:16:42.558: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 04:16:42.566: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c9xlw/deployments/nginx-deployment,UID:f7ae9c24-3333-11e9-9a73-8a88965a7424,ResourceVersion:340202,Generation:3,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-18 04:16:40 +0000 UTC 2019-02-18 04:16:40 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-18 04:16:40 +0000 UTC 2019-02-18 04:16:30 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 18 04:16:42.571: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c9xlw/replicasets/nginx-deployment-65bbdb5f8,UID:fc884844-3333-11e9-9a73-8a88965a7424,ResourceVersion:340195,Generation:3,CreationTimestamp:2019-02-18 04:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f7ae9c24-3333-11e9-9a73-8a88965a7424 0xc0019a3fb7 0xc0019a3fb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 04:16:42.571: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 18 04:16:42.572: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c9xlw/replicasets/nginx-deployment-555b55d965,UID:f7b0834b-3333-11e9-9a73-8a88965a7424,ResourceVersion:340196,Generation:3,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f7ae9c24-3333-11e9-9a73-8a88965a7424 0xc0019a3e07 0xc0019a3e08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 18 04:16:42.581: INFO: Pod "nginx-deployment-555b55d965-5q6rw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5q6rw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-5q6rw,UID:f7bcea5d-3333-11e9-9a73-8a88965a7424,ResourceVersion:340047,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001e73f07 0xc001e73f08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e73f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e73f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.136,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://e9582c9e16cd3149d5e2f622c71b2c140776fd69972eaf7aab62934b0299da12}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.581: INFO: Pod "nginx-deployment-555b55d965-5rm75" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5rm75,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-5rm75,UID:fdd3cd59-3333-11e9-9a73-8a88965a7424,ResourceVersion:340186,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bac477 0xc001bac478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bac4e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bac500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.582: INFO: Pod "nginx-deployment-555b55d965-79wsx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-79wsx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-79wsx,UID:f7bcfea9-3333-11e9-9a73-8a88965a7424,ResourceVersion:340052,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bac870 0xc001bac871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bac8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bac8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.135,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://e6a19e253e49e9c69097e05d4a2817aa485d65b761c99463a2b9645c8e22e7b7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.582: INFO: Pod "nginx-deployment-555b55d965-7fvwd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7fvwd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-7fvwd,UID:fdcbe307-3333-11e9-9a73-8a88965a7424,ResourceVersion:340233,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bac9b7 0xc001bac9b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001baca20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001baca50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.582: INFO: Pod "nginx-deployment-555b55d965-8lbbs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8lbbs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-8lbbs,UID:f7b6c8b6-3333-11e9-9a73-8a88965a7424,ResourceVersion:340035,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bacb47 0xc001bacb48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bacbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bacbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.137,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1097fd3aa52ba292d1d8d495e687f4d7e0d0036f18e5042df2201bfd2ba38531}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.583: INFO: Pod "nginx-deployment-555b55d965-96fz9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-96fz9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-96fz9,UID:fdc810c1-3333-11e9-9a73-8a88965a7424,ResourceVersion:340161,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001baccc7 0xc001baccc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bacd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bacd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.583: INFO: Pod "nginx-deployment-555b55d965-9rf89" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9rf89,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-9rf89,UID:f7b6ca3d-3333-11e9-9a73-8a88965a7424,ResourceVersion:340029,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bace87 0xc001bace88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bacef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bacf10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.138,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7131346a1acb83c5d96842e2069c0065d0073926afabd218937cc7e41cc629bb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.583: INFO: Pod "nginx-deployment-555b55d965-kdpqf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kdpqf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-kdpqf,UID:fdcbc5d3-3333-11e9-9a73-8a88965a7424,ResourceVersion:340174,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bacfd7 0xc001bacfd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.583: INFO: Pod "nginx-deployment-555b55d965-kh7jt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kh7jt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-kh7jt,UID:fdca148b-3333-11e9-9a73-8a88965a7424,ResourceVersion:340220,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bad150 0xc001bad151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.584: INFO: Pod "nginx-deployment-555b55d965-mc6q2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mc6q2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-mc6q2,UID:fdd3b588-3333-11e9-9a73-8a88965a7424,ResourceVersion:340190,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bad2a7 0xc001bad2a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.584: INFO: Pod "nginx-deployment-555b55d965-n5pjm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n5pjm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-n5pjm,UID:f7b6d3d9-3333-11e9-9a73-8a88965a7424,ResourceVersion:340019,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bad460 0xc001bad461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad4c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad4e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.132,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6f70cd9626d5126a954a4b841977b1b6f6a8a3e7d71cb26dcdd5341199681098}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.584: INFO: Pod "nginx-deployment-555b55d965-p58vq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p58vq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-p58vq,UID:fdc9d3e2-3333-11e9-9a73-8a88965a7424,ResourceVersion:340200,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bad5a7 0xc001bad5a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.584: INFO: Pod "nginx-deployment-555b55d965-rgfkv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rgfkv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-rgfkv,UID:f7b6ea1b-3333-11e9-9a73-8a88965a7424,ResourceVersion:340058,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bad6f7 0xc001bad6f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.134,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://066703927e4786c6e04ead8f0cbbe7515a8dd9dcf905700c5f5effefd1e8d88a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.584: INFO: Pod "nginx-deployment-555b55d965-rtg5k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rtg5k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-rtg5k,UID:fdcbef58-3333-11e9-9a73-8a88965a7424,ResourceVersion:340169,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bad857 0xc001bad858}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bad940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bad990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.585: INFO: Pod "nginx-deployment-555b55d965-rwcrd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rwcrd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-rwcrd,UID:fdd31588-3333-11e9-9a73-8a88965a7424,ResourceVersion:340187,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001bada00 0xc001bada01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bada60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bada80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.585: INFO: Pod "nginx-deployment-555b55d965-rzmsp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rzmsp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-rzmsp,UID:fdcc032b-3333-11e9-9a73-8a88965a7424,ResourceVersion:340237,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001badaf0 0xc001badaf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001badb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001badb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.586: INFO: Pod "nginx-deployment-555b55d965-s6n8m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s6n8m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-s6n8m,UID:f7b36d21-3333-11e9-9a73-8a88965a7424,ResourceVersion:340069,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001badc27 0xc001badc28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001badcb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001badcd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.129,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:32 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://136bccd969240b70482a963546061157d1381192b3285f114c1047b58bda930a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.586: INFO: Pod "nginx-deployment-555b55d965-wp2bq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wp2bq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-wp2bq,UID:f7bd183c-3333-11e9-9a73-8a88965a7424,ResourceVersion:340041,Generation:0,CreationTimestamp:2019-02-18 04:16:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001badec7 0xc001badec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001badf30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001badf50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:30 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:10.244.1.133,StartTime:2019-02-18 04:16:30 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-18 04:16:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://f56b82c8b8f105a87a2c11087bd8ac7f1814cc50b56c5ff6603920a56fa11083}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.586: INFO: Pod "nginx-deployment-555b55d965-x9c7r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x9c7r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-x9c7r,UID:fdd34ae4-3333-11e9-9a73-8a88965a7424,ResourceVersion:340188,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001cd2047 0xc001cd2048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd20b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd20e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.586: INFO: Pod "nginx-deployment-555b55d965-xwrlm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xwrlm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-555b55d965-xwrlm,UID:fdd47182-3333-11e9-9a73-8a88965a7424,ResourceVersion:340191,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f7b0834b-3333-11e9-9a73-8a88965a7424 0xc001cd21d0 0xc001cd21d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.587: INFO: Pod "nginx-deployment-65bbdb5f8-bgvzd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bgvzd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-bgvzd,UID:fdce3166-3333-11e9-9a73-8a88965a7424,ResourceVersion:340171,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd22c0 0xc001cd22c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.587: INFO: Pod "nginx-deployment-65bbdb5f8-c9r7x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c9r7x,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-c9r7x,UID:fc8c3da8-3333-11e9-9a73-8a88965a7424,ResourceVersion:340116,Generation:0,CreationTimestamp:2019-02-18 04:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd2420 0xc001cd2421}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd24b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.587: INFO: Pod "nginx-deployment-65bbdb5f8-dnrll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dnrll,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-dnrll,UID:fdce4c2f-3333-11e9-9a73-8a88965a7424,ResourceVersion:340173,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd2570 0xc001cd2571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.587: INFO: Pod "nginx-deployment-65bbdb5f8-hsqft" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hsqft,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-hsqft,UID:fdcdf71e-3333-11e9-9a73-8a88965a7424,ResourceVersion:340176,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd26c0 0xc001cd26c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.587: INFO: Pod "nginx-deployment-65bbdb5f8-kxtfz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kxtfz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-kxtfz,UID:fdcdc5d6-3333-11e9-9a73-8a88965a7424,ResourceVersion:340172,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd27f0 0xc001cd27f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd28a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd28c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.588: INFO: Pod "nginx-deployment-65bbdb5f8-l65gm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-l65gm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-l65gm,UID:fc93ba82-3333-11e9-9a73-8a88965a7424,ResourceVersion:340126,Generation:0,CreationTimestamp:2019-02-18 04:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd2930 0xc001cd2931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.588: INFO: Pod "nginx-deployment-65bbdb5f8-mgm74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mgm74,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-mgm74,UID:fdcb8654-3333-11e9-9a73-8a88965a7424,ResourceVersion:340230,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd2b30 0xc001cd2b31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.588: INFO: Pod "nginx-deployment-65bbdb5f8-ml6rn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ml6rn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-ml6rn,UID:fc89c96d-3333-11e9-9a73-8a88965a7424,ResourceVersion:340099,Generation:0,CreationTimestamp:2019-02-18 04:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd2d20 0xc001cd2d21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd2fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd2fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.588: INFO: Pod "nginx-deployment-65bbdb5f8-qdf5n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qdf5n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-qdf5n,UID:fc928066-3333-11e9-9a73-8a88965a7424,ResourceVersion:340123,Generation:0,CreationTimestamp:2019-02-18 04:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd3160 0xc001cd3161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd3260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd3280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.589: INFO: Pod "nginx-deployment-65bbdb5f8-rmd8c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rmd8c,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-rmd8c,UID:fdd36505-3333-11e9-9a73-8a88965a7424,ResourceVersion:340189,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd3340 0xc001cd3341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd33b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd33d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.589: INFO: Pod "nginx-deployment-65bbdb5f8-sgsnh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sgsnh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-sgsnh,UID:fc8bfa37-3333-11e9-9a73-8a88965a7424,ResourceVersion:340118,Generation:0,CreationTimestamp:2019-02-18 04:16:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd3440 0xc001cd3441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd34b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd34d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:38 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.589: INFO: Pod "nginx-deployment-65bbdb5f8-vmx7b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vmx7b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-vmx7b,UID:fdca228d-3333-11e9-9a73-8a88965a7424,ResourceVersion:340185,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd3590 0xc001cd3591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd3600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd3620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 04:16:42.589: INFO: Pod "nginx-deployment-65bbdb5f8-wxddj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wxddj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-c9xlw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c9xlw/pods/nginx-deployment-65bbdb5f8-wxddj,UID:fdcbc683-3333-11e9-9a73-8a88965a7424,ResourceVersion:340235,Generation:0,CreationTimestamp:2019-02-18 04:16:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 fc884844-3333-11e9-9a73-8a88965a7424 0xc001cd36e0 0xc001cd36e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jn4wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jn4wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-jn4wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cd3750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cd3770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:16:40 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:16:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:16:42.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-c9xlw" for this suite.
Feb 18 04:16:50.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:16:50.694: INFO: namespace: e2e-tests-deployment-c9xlw, resource: bindings, ignored listing per whitelist
Feb 18 04:16:50.729: INFO: namespace e2e-tests-deployment-c9xlw deletion completed in 8.134925781s

• [SLOW TEST:20.492 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:16:50.730: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0218 04:16:56.879673      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 04:16:56.879: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:16:56.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mt8m2" for this suite.
Feb 18 04:17:02.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:17:02.972: INFO: namespace: e2e-tests-gc-mt8m2, resource: bindings, ignored listing per whitelist
Feb 18 04:17:03.022: INFO: namespace e2e-tests-gc-mt8m2 deletion completed in 6.138747317s

• [SLOW TEST:12.293 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:17:03.023: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0b53f544-3334-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:17:03.303: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-5bmcw" to be "success or failure"
Feb 18 04:17:03.307: INFO: Pod "pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.77613ms
Feb 18 04:17:05.311: INFO: Pod "pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007946222s
STEP: Saw pod success
Feb 18 04:17:05.311: INFO: Pod "pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:17:05.315: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:17:05.337: INFO: Waiting for pod pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:17:05.341: INFO: Pod pod-projected-configmaps-0b54aa84-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:17:05.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5bmcw" for this suite.
Feb 18 04:17:11.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:17:11.378: INFO: namespace: e2e-tests-projected-5bmcw, resource: bindings, ignored listing per whitelist
Feb 18 04:17:11.480: INFO: namespace e2e-tests-projected-5bmcw deletion completed in 6.132474426s

• [SLOW TEST:8.458 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:17:11.480: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-1043b3ee-3334-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:17:11.581: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-crgmb" to be "success or failure"
Feb 18 04:17:11.587: INFO: Pod "pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.332219ms
Feb 18 04:17:13.592: INFO: Pod "pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010165038s
STEP: Saw pod success
Feb 18 04:17:13.592: INFO: Pod "pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:17:13.596: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:17:13.620: INFO: Waiting for pod pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:17:13.624: INFO: Pod pod-projected-secrets-10445513-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:17:13.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-crgmb" for this suite.
Feb 18 04:17:19.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:17:19.681: INFO: namespace: e2e-tests-projected-crgmb, resource: bindings, ignored listing per whitelist
Feb 18 04:17:19.760: INFO: namespace e2e-tests-projected-crgmb deletion completed in 6.130551308s

• [SLOW TEST:8.280 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:17:19.760: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 04:17:19.869: INFO: (0) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.537723ms)
Feb 18 04:17:19.875: INFO: (1) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.949546ms)
Feb 18 04:17:19.881: INFO: (2) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.905308ms)
Feb 18 04:17:19.887: INFO: (3) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.05708ms)
Feb 18 04:17:19.893: INFO: (4) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.974055ms)
Feb 18 04:17:19.898: INFO: (5) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.157324ms)
Feb 18 04:17:19.904: INFO: (6) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.51616ms)
Feb 18 04:17:19.909: INFO: (7) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.499794ms)
Feb 18 04:17:19.915: INFO: (8) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.290237ms)
Feb 18 04:17:19.921: INFO: (9) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.97816ms)
Feb 18 04:17:19.926: INFO: (10) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.651821ms)
Feb 18 04:17:19.932: INFO: (11) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.556069ms)
Feb 18 04:17:19.938: INFO: (12) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.146464ms)
Feb 18 04:17:19.945: INFO: (13) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.360942ms)
Feb 18 04:17:19.950: INFO: (14) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.566914ms)
Feb 18 04:17:19.956: INFO: (15) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.876525ms)
Feb 18 04:17:19.962: INFO: (16) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.923253ms)
Feb 18 04:17:19.968: INFO: (17) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.967565ms)
Feb 18 04:17:19.974: INFO: (18) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.601714ms)
Feb 18 04:17:19.980: INFO: (19) /api/v1/nodes/xen16-168.ebaotech.com:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.197017ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:17:19.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5mps6" for this suite.
Feb 18 04:17:25.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:17:26.038: INFO: namespace: e2e-tests-proxy-5mps6, resource: bindings, ignored listing per whitelist
Feb 18 04:17:26.121: INFO: namespace e2e-tests-proxy-5mps6 deletion completed in 6.135429161s

• [SLOW TEST:6.360 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:17:26.121: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 04:17:26.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-kjjgn'
Feb 18 04:17:26.529: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 04:17:26.529: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Feb 18 04:17:26.542: INFO: scanned /root for discovery docs: <nil>
Feb 18 04:17:26.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-kjjgn'
Feb 18 04:17:42.441: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 18 04:17:42.441: INFO: stdout: "Created e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f\nScaling up e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 18 04:17:42.441: INFO: stdout: "Created e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f\nScaling up e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 18 04:17:42.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-kjjgn'
Feb 18 04:17:42.611: INFO: stderr: ""
Feb 18 04:17:42.611: INFO: stdout: "e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f-zkwhm "
Feb 18 04:17:42.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f-zkwhm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kjjgn'
Feb 18 04:17:42.786: INFO: stderr: ""
Feb 18 04:17:42.786: INFO: stdout: "true"
Feb 18 04:17:42.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f-zkwhm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kjjgn'
Feb 18 04:17:42.946: INFO: stderr: ""
Feb 18 04:17:42.946: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 18 04:17:42.946: INFO: e2e-test-nginx-rc-9514d82eb44e01e551bfe1d88e34a62f-zkwhm is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 18 04:17:42.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-kjjgn'
Feb 18 04:17:43.118: INFO: stderr: ""
Feb 18 04:17:43.118: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:17:43.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kjjgn" for this suite.
Feb 18 04:17:49.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:17:49.194: INFO: namespace: e2e-tests-kubectl-kjjgn, resource: bindings, ignored listing per whitelist
Feb 18 04:17:49.260: INFO: namespace e2e-tests-kubectl-kjjgn deletion completed in 6.135242408s

• [SLOW TEST:23.139 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:17:49.260: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 04:17:49.353: INFO: Creating deployment "test-recreate-deployment"
Feb 18 04:17:49.361: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 18 04:17:49.373: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 18 04:17:51.383: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 18 04:17:51.387: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 18 04:17:51.395: INFO: Updating deployment test-recreate-deployment
Feb 18 04:17:51.395: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 04:17:51.484: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-jtmrd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jtmrd/deployments/test-recreate-deployment,UID:26c8defd-3334-11e9-9a73-8a88965a7424,ResourceVersion:340805,Generation:2,CreationTimestamp:2019-02-18 04:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-18 04:17:51 +0000 UTC 2019-02-18 04:17:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-18 04:17:51 +0000 UTC 2019-02-18 04:17:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 18 04:17:51.489: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-jtmrd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jtmrd/replicasets/test-recreate-deployment-697fbf54bf,UID:28071177-3334-11e9-9a73-8a88965a7424,ResourceVersion:340804,Generation:1,CreationTimestamp:2019-02-18 04:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 26c8defd-3334-11e9-9a73-8a88965a7424 0xc00255b857 0xc00255b858}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 04:17:51.489: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 18 04:17:51.489: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-jtmrd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jtmrd/replicasets/test-recreate-deployment-5dfdcc846d,UID:26caa8ea-3334-11e9-9a73-8a88965a7424,ResourceVersion:340794,Generation:2,CreationTimestamp:2019-02-18 04:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 26c8defd-3334-11e9-9a73-8a88965a7424 0xc00255b797 0xc00255b798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 04:17:51.494: INFO: Pod "test-recreate-deployment-697fbf54bf-pcjgx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-pcjgx,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-jtmrd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jtmrd/pods/test-recreate-deployment-697fbf54bf-pcjgx,UID:2807b1d3-3334-11e9-9a73-8a88965a7424,ResourceVersion:340806,Generation:0,CreationTimestamp:2019-02-18 04:17:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 28071177-3334-11e9-9a73-8a88965a7424 0xc002501197 0xc002501198}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-v9bgc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v9bgc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-v9bgc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:xen16-168.ebaotech.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002501200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002501220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:17:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:17:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:17:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-18 04:17:51 +0000 UTC  }],Message:,Reason:,HostIP:172.25.16.168,PodIP:,StartTime:2019-02-18 04:17:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:17:51.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jtmrd" for this suite.
Feb 18 04:17:57.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:17:57.547: INFO: namespace: e2e-tests-deployment-jtmrd, resource: bindings, ignored listing per whitelist
Feb 18 04:17:57.626: INFO: namespace e2e-tests-deployment-jtmrd deletion completed in 6.127255445s

• [SLOW TEST:8.366 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:17:57.626: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2bc7d89d-3334-11e9-94e0-0a580af401c1
STEP: Creating secret with name s-test-opt-upd-2bc7d92b-3334-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2bc7d89d-3334-11e9-94e0-0a580af401c1
STEP: Updating secret s-test-opt-upd-2bc7d92b-3334-11e9-94e0-0a580af401c1
STEP: Creating secret with name s-test-opt-create-2bc7d95f-3334-11e9-94e0-0a580af401c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:19:32.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vnbss" for this suite.
Feb 18 04:19:54.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:19:54.620: INFO: namespace: e2e-tests-secrets-vnbss, resource: bindings, ignored listing per whitelist
Feb 18 04:19:54.683: INFO: namespace e2e-tests-secrets-vnbss deletion completed in 22.132570228s

• [SLOW TEST:117.056 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:19:54.683: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 04:19:54.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ssl4b'
Feb 18 04:19:54.959: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 04:19:54.959: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 18 04:19:57.059: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-fv7m2]
Feb 18 04:19:57.059: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-fv7m2" in namespace "e2e-tests-kubectl-ssl4b" to be "running and ready"
Feb 18 04:19:57.066: INFO: Pod "e2e-test-nginx-rc-fv7m2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.402196ms
Feb 18 04:19:59.071: INFO: Pod "e2e-test-nginx-rc-fv7m2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012815528s
Feb 18 04:19:59.072: INFO: Pod "e2e-test-nginx-rc-fv7m2" satisfied condition "running and ready"
Feb 18 04:19:59.072: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-fv7m2]
Feb 18 04:19:59.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ssl4b'
Feb 18 04:19:59.280: INFO: stderr: ""
Feb 18 04:19:59.280: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 18 04:19:59.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ssl4b'
Feb 18 04:19:59.576: INFO: stderr: ""
Feb 18 04:19:59.576: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:19:59.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ssl4b" for this suite.
Feb 18 04:20:05.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:20:05.624: INFO: namespace: e2e-tests-kubectl-ssl4b, resource: bindings, ignored listing per whitelist
Feb 18 04:20:05.715: INFO: namespace e2e-tests-kubectl-ssl4b deletion completed in 6.133444078s

• [SLOW TEST:11.032 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:20:05.716: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:20:05.818: INFO: Waiting up to 5m0s for pod "downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-ffkvf" to be "success or failure"
Feb 18 04:20:05.822: INFO: Pod "downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551871ms
Feb 18 04:20:07.828: INFO: Pod "downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009804105s
STEP: Saw pod success
Feb 18 04:20:07.828: INFO: Pod "downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:20:07.833: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:20:07.859: INFO: Waiting for pod downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:20:07.863: INFO: Pod downwardapi-volume-781e94c9-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:20:07.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ffkvf" for this suite.
Feb 18 04:20:13.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:20:13.986: INFO: namespace: e2e-tests-downward-api-ffkvf, resource: bindings, ignored listing per whitelist
Feb 18 04:20:14.009: INFO: namespace e2e-tests-downward-api-ffkvf deletion completed in 6.140540887s

• [SLOW TEST:8.293 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:20:14.009: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:20:14.220: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-wp269" to be "success or failure"
Feb 18 04:20:14.224: INFO: Pod "downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.280003ms
Feb 18 04:20:16.230: INFO: Pod "downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010544869s
STEP: Saw pod success
Feb 18 04:20:16.230: INFO: Pod "downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:20:16.234: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:20:16.264: INFO: Waiting for pod downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:20:16.268: INFO: Pod downwardapi-volume-7d208421-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:20:16.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wp269" for this suite.
Feb 18 04:20:22.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:20:22.364: INFO: namespace: e2e-tests-projected-wp269, resource: bindings, ignored listing per whitelist
Feb 18 04:20:22.409: INFO: namespace e2e-tests-projected-wp269 deletion completed in 6.135630085s

• [SLOW TEST:8.400 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:20:22.410: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-4ntm
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 04:20:22.520: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4ntm" in namespace "e2e-tests-subpath-hzr58" to be "success or failure"
Feb 18 04:20:22.523: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Pending", Reason="", readiness=false. Elapsed: 3.710821ms
Feb 18 04:20:24.528: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008410061s
Feb 18 04:20:26.534: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 4.014100428s
Feb 18 04:20:28.539: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 6.019414731s
Feb 18 04:20:30.545: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 8.024853903s
Feb 18 04:20:32.572: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 10.051811157s
Feb 18 04:20:34.578: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 12.058061183s
Feb 18 04:20:36.583: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 14.063606847s
Feb 18 04:20:38.631: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 16.110809762s
Feb 18 04:20:40.636: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 18.116262376s
Feb 18 04:20:42.641: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 20.121571306s
Feb 18 04:20:44.647: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Running", Reason="", readiness=false. Elapsed: 22.127527251s
Feb 18 04:20:46.653: INFO: Pod "pod-subpath-test-downwardapi-4ntm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.132815037s
STEP: Saw pod success
Feb 18 04:20:46.653: INFO: Pod "pod-subpath-test-downwardapi-4ntm" satisfied condition "success or failure"
Feb 18 04:20:46.657: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-subpath-test-downwardapi-4ntm container test-container-subpath-downwardapi-4ntm: <nil>
STEP: delete the pod
Feb 18 04:20:46.682: INFO: Waiting for pod pod-subpath-test-downwardapi-4ntm to disappear
Feb 18 04:20:46.685: INFO: Pod pod-subpath-test-downwardapi-4ntm no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4ntm
Feb 18 04:20:46.686: INFO: Deleting pod "pod-subpath-test-downwardapi-4ntm" in namespace "e2e-tests-subpath-hzr58"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:20:46.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hzr58" for this suite.
Feb 18 04:20:52.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:20:52.792: INFO: namespace: e2e-tests-subpath-hzr58, resource: bindings, ignored listing per whitelist
Feb 18 04:20:52.827: INFO: namespace e2e-tests-subpath-hzr58 deletion completed in 6.133789753s

• [SLOW TEST:30.418 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:20:52.828: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-khqsp/secret-test-943455bb-3334-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:20:52.943: INFO: Waiting up to 5m0s for pod "pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-khqsp" to be "success or failure"
Feb 18 04:20:52.946: INFO: Pod "pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.597231ms
Feb 18 04:20:54.952: INFO: Pod "pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009491106s
Feb 18 04:20:56.958: INFO: Pod "pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01489859s
STEP: Saw pod success
Feb 18 04:20:56.958: INFO: Pod "pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:20:56.961: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1 container env-test: <nil>
STEP: delete the pod
Feb 18 04:20:56.986: INFO: Waiting for pod pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:20:56.989: INFO: Pod pod-configmaps-94355ebe-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:20:56.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-khqsp" for this suite.
Feb 18 04:21:03.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:21:03.119: INFO: namespace: e2e-tests-secrets-khqsp, resource: bindings, ignored listing per whitelist
Feb 18 04:21:03.122: INFO: namespace e2e-tests-secrets-khqsp deletion completed in 6.128055848s

• [SLOW TEST:10.295 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:21:03.122: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9a5daff1-3334-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:21:03.279: INFO: Waiting up to 5m0s for pod "pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-hm9md" to be "success or failure"
Feb 18 04:21:03.284: INFO: Pod "pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.962041ms
Feb 18 04:21:05.290: INFO: Pod "pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010636301s
Feb 18 04:21:07.297: INFO: Pod "pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018335964s
STEP: Saw pod success
Feb 18 04:21:07.297: INFO: Pod "pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:21:07.305: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:21:07.332: INFO: Waiting for pod pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:21:07.336: INFO: Pod pod-secrets-9a5e633b-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:21:07.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hm9md" for this suite.
Feb 18 04:21:13.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:21:13.386: INFO: namespace: e2e-tests-secrets-hm9md, resource: bindings, ignored listing per whitelist
Feb 18 04:21:13.492: INFO: namespace e2e-tests-secrets-hm9md deletion completed in 6.151004386s

• [SLOW TEST:10.370 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:21:13.492: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:21:13.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-pkn9p" to be "success or failure"
Feb 18 04:21:13.697: INFO: Pod "downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.494887ms
Feb 18 04:21:15.703: INFO: Pod "downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009305593s
Feb 18 04:21:17.708: INFO: Pod "downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014556217s
STEP: Saw pod success
Feb 18 04:21:17.708: INFO: Pod "downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:21:17.712: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:21:17.739: INFO: Waiting for pod downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:21:17.744: INFO: Pod downwardapi-volume-a093b10d-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:21:17.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkn9p" for this suite.
Feb 18 04:21:23.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:21:23.966: INFO: namespace: e2e-tests-projected-pkn9p, resource: bindings, ignored listing per whitelist
Feb 18 04:21:23.971: INFO: namespace e2e-tests-projected-pkn9p deletion completed in 6.221272942s

• [SLOW TEST:10.478 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:21:23.971: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 18 04:21:24.075: INFO: Waiting up to 5m0s for pod "downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-pzjwp" to be "success or failure"
Feb 18 04:21:24.078: INFO: Pod "downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.412621ms
Feb 18 04:21:26.084: INFO: Pod "downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009349562s
Feb 18 04:21:28.090: INFO: Pod "downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014896413s
STEP: Saw pod success
Feb 18 04:21:28.090: INFO: Pod "downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:21:28.094: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 04:21:28.119: INFO: Waiting for pod downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:21:28.123: INFO: Pod downward-api-a6c3d087-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:21:28.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pzjwp" for this suite.
Feb 18 04:21:34.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:21:34.229: INFO: namespace: e2e-tests-downward-api-pzjwp, resource: bindings, ignored listing per whitelist
Feb 18 04:21:34.273: INFO: namespace e2e-tests-downward-api-pzjwp deletion completed in 6.144555398s

• [SLOW TEST:10.302 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:21:34.273: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 18 04:21:34.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:34.665: INFO: stderr: ""
Feb 18 04:21:34.665: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 04:21:34.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:34.851: INFO: stderr: ""
Feb 18 04:21:34.851: INFO: stdout: "update-demo-nautilus-4l6tf update-demo-nautilus-jhk5q "
Feb 18 04:21:34.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-4l6tf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:35.008: INFO: stderr: ""
Feb 18 04:21:35.008: INFO: stdout: ""
Feb 18 04:21:35.008: INFO: update-demo-nautilus-4l6tf is created but not running
Feb 18 04:21:40.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:40.187: INFO: stderr: ""
Feb 18 04:21:40.187: INFO: stdout: "update-demo-nautilus-4l6tf update-demo-nautilus-jhk5q "
Feb 18 04:21:40.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-4l6tf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:40.348: INFO: stderr: ""
Feb 18 04:21:40.348: INFO: stdout: "true"
Feb 18 04:21:40.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-4l6tf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:40.507: INFO: stderr: ""
Feb 18 04:21:40.507: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 04:21:40.507: INFO: validating pod update-demo-nautilus-4l6tf
Feb 18 04:21:40.515: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 04:21:40.515: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 04:21:40.515: INFO: update-demo-nautilus-4l6tf is verified up and running
Feb 18 04:21:40.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-jhk5q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:40.682: INFO: stderr: ""
Feb 18 04:21:40.682: INFO: stdout: "true"
Feb 18 04:21:40.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-jhk5q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:21:40.856: INFO: stderr: ""
Feb 18 04:21:40.856: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 04:21:40.856: INFO: validating pod update-demo-nautilus-jhk5q
Feb 18 04:21:40.863: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 04:21:40.863: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 04:21:40.863: INFO: update-demo-nautilus-jhk5q is verified up and running
STEP: rolling-update to new replication controller
Feb 18 04:21:40.865: INFO: scanned /root for discovery docs: <nil>
Feb 18 04:21:40.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:22:03.804: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 18 04:22:03.805: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 04:22:03.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:22:04.020: INFO: stderr: ""
Feb 18 04:22:04.020: INFO: stdout: "update-demo-kitten-8bxs7 update-demo-kitten-q7c62 "
Feb 18 04:22:04.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-kitten-8bxs7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:22:04.175: INFO: stderr: ""
Feb 18 04:22:04.175: INFO: stdout: "true"
Feb 18 04:22:04.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-kitten-8bxs7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:22:04.342: INFO: stderr: ""
Feb 18 04:22:04.342: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 18 04:22:04.342: INFO: validating pod update-demo-kitten-8bxs7
Feb 18 04:22:04.350: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 18 04:22:04.350: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 18 04:22:04.350: INFO: update-demo-kitten-8bxs7 is verified up and running
Feb 18 04:22:04.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-kitten-q7c62 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:22:04.509: INFO: stderr: ""
Feb 18 04:22:04.509: INFO: stdout: "true"
Feb 18 04:22:04.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-kitten-q7c62 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-rzxb9'
Feb 18 04:22:04.674: INFO: stderr: ""
Feb 18 04:22:04.674: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 18 04:22:04.674: INFO: validating pod update-demo-kitten-q7c62
Feb 18 04:22:04.681: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 18 04:22:04.681: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 18 04:22:04.681: INFO: update-demo-kitten-q7c62 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:22:04.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rzxb9" for this suite.
Feb 18 04:22:28.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:22:28.815: INFO: namespace: e2e-tests-kubectl-rzxb9, resource: bindings, ignored listing per whitelist
Feb 18 04:22:28.823: INFO: namespace e2e-tests-kubectl-rzxb9 deletion completed in 24.136258256s

• [SLOW TEST:54.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:22:28.823: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cd6b09d5-3334-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:22:28.928: INFO: Waiting up to 5m0s for pod "pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-5n622" to be "success or failure"
Feb 18 04:22:28.932: INFO: Pod "pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535998ms
Feb 18 04:22:30.937: INFO: Pod "pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008813002s
Feb 18 04:22:32.943: INFO: Pod "pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014386169s
STEP: Saw pod success
Feb 18 04:22:32.943: INFO: Pod "pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:22:32.947: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1 container secret-env-test: <nil>
STEP: delete the pod
Feb 18 04:22:32.971: INFO: Waiting for pod pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:22:32.974: INFO: Pod pod-secrets-cd6bbae7-3334-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:22:32.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5n622" for this suite.
Feb 18 04:22:38.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:22:39.066: INFO: namespace: e2e-tests-secrets-5n622, resource: bindings, ignored listing per whitelist
Feb 18 04:22:39.106: INFO: namespace e2e-tests-secrets-5n622 deletion completed in 6.126792796s

• [SLOW TEST:10.283 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:22:39.106: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 04:22:39.280: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 18 04:22:44.286: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 18 04:22:44.286: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 04:22:44.310: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-cd7gg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cd7gg/deployments/test-cleanup-deployment,UID:d692e3fa-3334-11e9-9a73-8a88965a7424,ResourceVersion:341644,Generation:1,CreationTimestamp:2019-02-18 04:22:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 18 04:22:44.314: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:22:44.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cd7gg" for this suite.
Feb 18 04:22:50.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:22:50.384: INFO: namespace: e2e-tests-deployment-cd7gg, resource: bindings, ignored listing per whitelist
Feb 18 04:22:50.481: INFO: namespace e2e-tests-deployment-cd7gg deletion completed in 6.155090332s

• [SLOW TEST:11.375 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:22:50.481: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-fvgb
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 04:22:50.586: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fvgb" in namespace "e2e-tests-subpath-fvdc9" to be "success or failure"
Feb 18 04:22:50.595: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.98073ms
Feb 18 04:22:52.600: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014374345s
Feb 18 04:22:54.605: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 4.019621406s
Feb 18 04:22:56.612: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 6.025847472s
Feb 18 04:22:58.617: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 8.031574488s
Feb 18 04:23:00.623: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 10.037349883s
Feb 18 04:23:02.628: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 12.041884305s
Feb 18 04:23:04.633: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 14.047185056s
Feb 18 04:23:06.639: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 16.053383325s
Feb 18 04:23:08.645: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 18.059134615s
Feb 18 04:23:10.651: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 20.065313598s
Feb 18 04:23:12.656: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Running", Reason="", readiness=false. Elapsed: 22.070521328s
Feb 18 04:23:14.671: INFO: Pod "pod-subpath-test-configmap-fvgb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.08553784s
STEP: Saw pod success
Feb 18 04:23:14.671: INFO: Pod "pod-subpath-test-configmap-fvgb" satisfied condition "success or failure"
Feb 18 04:23:14.676: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-subpath-test-configmap-fvgb container test-container-subpath-configmap-fvgb: <nil>
STEP: delete the pod
Feb 18 04:23:14.705: INFO: Waiting for pod pod-subpath-test-configmap-fvgb to disappear
Feb 18 04:23:14.710: INFO: Pod pod-subpath-test-configmap-fvgb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fvgb
Feb 18 04:23:14.710: INFO: Deleting pod "pod-subpath-test-configmap-fvgb" in namespace "e2e-tests-subpath-fvdc9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:23:14.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fvdc9" for this suite.
Feb 18 04:23:20.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:23:20.789: INFO: namespace: e2e-tests-subpath-fvdc9, resource: bindings, ignored listing per whitelist
Feb 18 04:23:20.853: INFO: namespace e2e-tests-subpath-fvdc9 deletion completed in 6.135217112s

• [SLOW TEST:30.372 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:23:20.854: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 18 04:23:21.175: INFO: Pod name wrapped-volume-race-ec8eae11-3334-11e9-94e0-0a580af401c1: Found 0 pods out of 5
Feb 18 04:23:26.186: INFO: Pod name wrapped-volume-race-ec8eae11-3334-11e9-94e0-0a580af401c1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ec8eae11-3334-11e9-94e0-0a580af401c1 in namespace e2e-tests-emptydir-wrapper-rjv6l, will wait for the garbage collector to delete the pods
Feb 18 04:23:36.318: INFO: Deleting ReplicationController wrapped-volume-race-ec8eae11-3334-11e9-94e0-0a580af401c1 took: 46.594727ms
Feb 18 04:23:36.418: INFO: Terminating ReplicationController wrapped-volume-race-ec8eae11-3334-11e9-94e0-0a580af401c1 pods took: 100.300625ms
STEP: Creating RC which spawns configmap-volume pods
Feb 18 04:24:17.942: INFO: Pod name wrapped-volume-race-0e635cff-3335-11e9-94e0-0a580af401c1: Found 0 pods out of 5
Feb 18 04:24:22.952: INFO: Pod name wrapped-volume-race-0e635cff-3335-11e9-94e0-0a580af401c1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0e635cff-3335-11e9-94e0-0a580af401c1 in namespace e2e-tests-emptydir-wrapper-rjv6l, will wait for the garbage collector to delete the pods
Feb 18 04:24:33.046: INFO: Deleting ReplicationController wrapped-volume-race-0e635cff-3335-11e9-94e0-0a580af401c1 took: 9.710271ms
Feb 18 04:24:33.246: INFO: Terminating ReplicationController wrapped-volume-race-0e635cff-3335-11e9-94e0-0a580af401c1 pods took: 200.30413ms
STEP: Creating RC which spawns configmap-volume pods
Feb 18 04:25:17.969: INFO: Pod name wrapped-volume-race-322b014a-3335-11e9-94e0-0a580af401c1: Found 0 pods out of 5
Feb 18 04:25:22.979: INFO: Pod name wrapped-volume-race-322b014a-3335-11e9-94e0-0a580af401c1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-322b014a-3335-11e9-94e0-0a580af401c1 in namespace e2e-tests-emptydir-wrapper-rjv6l, will wait for the garbage collector to delete the pods
Feb 18 04:25:35.080: INFO: Deleting ReplicationController wrapped-volume-race-322b014a-3335-11e9-94e0-0a580af401c1 took: 11.504737ms
Feb 18 04:25:35.280: INFO: Terminating ReplicationController wrapped-volume-race-322b014a-3335-11e9-94e0-0a580af401c1 pods took: 200.321922ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:26:18.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-rjv6l" for this suite.
Feb 18 04:26:26.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:26:26.480: INFO: namespace: e2e-tests-emptydir-wrapper-rjv6l, resource: bindings, ignored listing per whitelist
Feb 18 04:26:26.588: INFO: namespace e2e-tests-emptydir-wrapper-rjv6l deletion completed in 8.140400191s

• [SLOW TEST:185.734 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:26:26.588: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 18 04:26:26.739: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-86rp5,SelfLink:/api/v1/namespaces/e2e-tests-watch-86rp5/configmaps/e2e-watch-test-watch-closed,UID:5b28e57c-3335-11e9-9a73-8a88965a7424,ResourceVersion:342869,Generation:0,CreationTimestamp:2019-02-18 04:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 04:26:26.740: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-86rp5,SelfLink:/api/v1/namespaces/e2e-tests-watch-86rp5/configmaps/e2e-watch-test-watch-closed,UID:5b28e57c-3335-11e9-9a73-8a88965a7424,ResourceVersion:342870,Generation:0,CreationTimestamp:2019-02-18 04:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 18 04:26:26.758: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-86rp5,SelfLink:/api/v1/namespaces/e2e-tests-watch-86rp5/configmaps/e2e-watch-test-watch-closed,UID:5b28e57c-3335-11e9-9a73-8a88965a7424,ResourceVersion:342871,Generation:0,CreationTimestamp:2019-02-18 04:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 04:26:26.758: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-86rp5,SelfLink:/api/v1/namespaces/e2e-tests-watch-86rp5/configmaps/e2e-watch-test-watch-closed,UID:5b28e57c-3335-11e9-9a73-8a88965a7424,ResourceVersion:342872,Generation:0,CreationTimestamp:2019-02-18 04:26:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:26:26.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-86rp5" for this suite.
Feb 18 04:26:32.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:26:32.894: INFO: namespace: e2e-tests-watch-86rp5, resource: bindings, ignored listing per whitelist
Feb 18 04:26:32.899: INFO: namespace e2e-tests-watch-86rp5 deletion completed in 6.136515071s

• [SLOW TEST:6.312 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:26:32.900: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-t29xc
Feb 18 04:26:35.011: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-t29xc
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 04:26:35.014: INFO: Initial restart count of pod liveness-http is 0
Feb 18 04:26:49.066: INFO: Restart count of pod e2e-tests-container-probe-t29xc/liveness-http is now 1 (14.051747593s elapsed)
Feb 18 04:27:09.124: INFO: Restart count of pod e2e-tests-container-probe-t29xc/liveness-http is now 2 (34.109286501s elapsed)
Feb 18 04:27:27.175: INFO: Restart count of pod e2e-tests-container-probe-t29xc/liveness-http is now 3 (52.160998485s elapsed)
Feb 18 04:27:49.384: INFO: Restart count of pod e2e-tests-container-probe-t29xc/liveness-http is now 4 (1m14.369655566s elapsed)
Feb 18 04:28:55.568: INFO: Restart count of pod e2e-tests-container-probe-t29xc/liveness-http is now 5 (2m20.553283382s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:28:55.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-t29xc" for this suite.
Feb 18 04:29:01.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:29:01.619: INFO: namespace: e2e-tests-container-probe-t29xc, resource: bindings, ignored listing per whitelist
Feb 18 04:29:01.724: INFO: namespace e2e-tests-container-probe-t29xc deletion completed in 6.138372961s

• [SLOW TEST:148.825 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:29:01.725: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 18 04:29:05.887: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:05.892: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:07.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:07.897: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:09.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:09.897: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:11.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:11.897: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:13.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:13.897: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:15.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:15.901: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:17.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:17.898: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:19.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:19.898: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:21.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:21.897: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:23.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:23.898: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:25.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:25.897: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 04:29:27.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 04:29:27.897: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:29:27.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bxpwp" for this suite.
Feb 18 04:29:49.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:29:49.988: INFO: namespace: e2e-tests-container-lifecycle-hook-bxpwp, resource: bindings, ignored listing per whitelist
Feb 18 04:29:50.039: INFO: namespace e2e-tests-container-lifecycle-hook-bxpwp deletion completed in 22.135022232s

• [SLOW TEST:48.315 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:29:50.040: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d4670480-3335-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:29:50.144: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-bp664" to be "success or failure"
Feb 18 04:29:50.148: INFO: Pod "pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.792498ms
Feb 18 04:29:52.153: INFO: Pod "pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008626411s
STEP: Saw pod success
Feb 18 04:29:52.153: INFO: Pod "pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:29:52.156: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:29:52.178: INFO: Waiting for pod pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:29:52.182: INFO: Pod pod-projected-secrets-d467b54f-3335-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:29:52.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bp664" for this suite.
Feb 18 04:29:58.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:29:58.267: INFO: namespace: e2e-tests-projected-bp664, resource: bindings, ignored listing per whitelist
Feb 18 04:29:58.329: INFO: namespace e2e-tests-projected-bp664 deletion completed in 6.140555355s

• [SLOW TEST:8.290 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:29:58.330: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 18 04:29:58.427: INFO: Waiting up to 5m0s for pod "pod-d9573e9d-3335-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-2hmlg" to be "success or failure"
Feb 18 04:29:58.436: INFO: Pod "pod-d9573e9d-3335-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.700325ms
Feb 18 04:30:00.441: INFO: Pod "pod-d9573e9d-3335-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014388655s
STEP: Saw pod success
Feb 18 04:30:00.442: INFO: Pod "pod-d9573e9d-3335-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:30:00.445: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-d9573e9d-3335-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:30:00.527: INFO: Waiting for pod pod-d9573e9d-3335-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:30:00.531: INFO: Pod pod-d9573e9d-3335-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:30:00.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2hmlg" for this suite.
Feb 18 04:30:06.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:30:06.739: INFO: namespace: e2e-tests-emptydir-2hmlg, resource: bindings, ignored listing per whitelist
Feb 18 04:30:06.810: INFO: namespace e2e-tests-emptydir-2hmlg deletion completed in 6.274066233s

• [SLOW TEST:8.481 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:30:06.811: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:30:17.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-97k8l" for this suite.
Feb 18 04:30:39.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:30:40.088: INFO: namespace: e2e-tests-replication-controller-97k8l, resource: bindings, ignored listing per whitelist
Feb 18 04:30:40.113: INFO: namespace e2e-tests-replication-controller-97k8l deletion completed in 22.128831995s

• [SLOW TEST:33.302 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:30:40.113: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 18 04:30:40.210: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 18 04:30:40.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:30:40.662: INFO: stderr: ""
Feb 18 04:30:40.662: INFO: stdout: "service/redis-slave created\n"
Feb 18 04:30:40.662: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 18 04:30:40.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:30:41.076: INFO: stderr: ""
Feb 18 04:30:41.076: INFO: stdout: "service/redis-master created\n"
Feb 18 04:30:41.076: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 18 04:30:41.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:30:41.434: INFO: stderr: ""
Feb 18 04:30:41.434: INFO: stdout: "service/frontend created\n"
Feb 18 04:30:41.434: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 18 04:30:41.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:30:41.737: INFO: stderr: ""
Feb 18 04:30:41.737: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 18 04:30:41.737: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 18 04:30:41.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:30:42.059: INFO: stderr: ""
Feb 18 04:30:42.059: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 18 04:30:42.060: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 18 04:30:42.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:30:42.445: INFO: stderr: ""
Feb 18 04:30:42.445: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 18 04:30:42.445: INFO: Waiting for all frontend pods to be Running.
Feb 18 04:30:47.495: INFO: Waiting for frontend to serve content.
Feb 18 04:30:47.522: INFO: Trying to add a new entry to the guestbook.
Feb 18 04:30:47.547: INFO: Verifying that added entry can be retrieved.
Feb 18 04:30:47.572: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:30:52.597: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:30:57.623: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:02.647: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:07.672: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:12.695: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:17.720: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:22.743: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:27.764: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:32.789: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:37.813: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 18 04:31:42.833: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 18 04:31:47.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:31:48.340: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:31:48.340: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 04:31:48.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:31:48.520: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:31:48.520: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 04:31:48.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:31:48.891: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:31:48.891: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 04:31:48.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:31:49.089: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:31:49.089: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 04:31:49.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:31:49.277: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:31:49.277: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 04:31:49.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-77f8p'
Feb 18 04:31:49.475: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:31:49.475: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:31:49.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-77f8p" for this suite.
Feb 18 04:32:27.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:32:27.539: INFO: namespace: e2e-tests-kubectl-77f8p, resource: bindings, ignored listing per whitelist
Feb 18 04:32:27.612: INFO: namespace e2e-tests-kubectl-77f8p deletion completed in 38.128495163s

• [SLOW TEST:107.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:32:27.612: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 18 04:32:27.723: INFO: Waiting up to 5m0s for pod "downward-api-32549fba-3336-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-bsmjv" to be "success or failure"
Feb 18 04:32:27.727: INFO: Pod "downward-api-32549fba-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.573448ms
Feb 18 04:32:29.733: INFO: Pod "downward-api-32549fba-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009345669s
Feb 18 04:32:31.753: INFO: Pod "downward-api-32549fba-3336-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030123108s
STEP: Saw pod success
Feb 18 04:32:31.753: INFO: Pod "downward-api-32549fba-3336-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:32:31.757: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downward-api-32549fba-3336-11e9-94e0-0a580af401c1 container dapi-container: <nil>
STEP: delete the pod
Feb 18 04:32:31.783: INFO: Waiting for pod downward-api-32549fba-3336-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:32:31.786: INFO: Pod downward-api-32549fba-3336-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:32:31.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bsmjv" for this suite.
Feb 18 04:32:37.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:32:37.920: INFO: namespace: e2e-tests-downward-api-bsmjv, resource: bindings, ignored listing per whitelist
Feb 18 04:32:37.930: INFO: namespace e2e-tests-downward-api-bsmjv deletion completed in 6.138683496s

• [SLOW TEST:10.318 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:32:37.930: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-387b9a17-3336-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:32:38.050: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-ltfzh" to be "success or failure"
Feb 18 04:32:38.054: INFO: Pod "pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.325478ms
Feb 18 04:32:40.059: INFO: Pod "pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008885281s
Feb 18 04:32:42.064: INFO: Pod "pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014098645s
STEP: Saw pod success
Feb 18 04:32:42.064: INFO: Pod "pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:32:42.068: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:32:42.091: INFO: Waiting for pod pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:32:42.094: INFO: Pod pod-projected-secrets-387c426f-3336-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:32:42.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ltfzh" for this suite.
Feb 18 04:32:48.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:32:48.139: INFO: namespace: e2e-tests-projected-ltfzh, resource: bindings, ignored listing per whitelist
Feb 18 04:32:48.246: INFO: namespace e2e-tests-projected-ltfzh deletion completed in 6.145933533s

• [SLOW TEST:10.315 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:32:48.246: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 18 04:32:48.355: INFO: Waiting up to 5m0s for pod "client-containers-3ea08255-3336-11e9-94e0-0a580af401c1" in namespace "e2e-tests-containers-qvplq" to be "success or failure"
Feb 18 04:32:48.359: INFO: Pod "client-containers-3ea08255-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.986991ms
Feb 18 04:32:50.364: INFO: Pod "client-containers-3ea08255-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009316146s
Feb 18 04:32:52.370: INFO: Pod "client-containers-3ea08255-3336-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014920356s
STEP: Saw pod success
Feb 18 04:32:52.370: INFO: Pod "client-containers-3ea08255-3336-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:32:52.374: INFO: Trying to get logs from node xen16-168.ebaotech.com pod client-containers-3ea08255-3336-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:32:52.398: INFO: Waiting for pod client-containers-3ea08255-3336-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:32:52.401: INFO: Pod client-containers-3ea08255-3336-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:32:52.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qvplq" for this suite.
Feb 18 04:32:58.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:32:58.433: INFO: namespace: e2e-tests-containers-qvplq, resource: bindings, ignored listing per whitelist
Feb 18 04:32:58.536: INFO: namespace e2e-tests-containers-qvplq deletion completed in 6.129861633s

• [SLOW TEST:10.290 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:32:58.536: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-dm85j
Feb 18 04:33:02.644: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-dm85j
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 04:33:02.647: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:37:03.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dm85j" for this suite.
Feb 18 04:37:09.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:37:09.425: INFO: namespace: e2e-tests-container-probe-dm85j, resource: bindings, ignored listing per whitelist
Feb 18 04:37:09.512: INFO: namespace e2e-tests-container-probe-dm85j deletion completed in 6.137619657s

• [SLOW TEST:250.976 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:37:09.513: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:37:09.623: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-2svpt" to be "success or failure"
Feb 18 04:37:09.631: INFO: Pod "downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.772632ms
Feb 18 04:37:11.637: INFO: Pod "downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014246318s
Feb 18 04:37:13.643: INFO: Pod "downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019895366s
STEP: Saw pod success
Feb 18 04:37:13.643: INFO: Pod "downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:37:13.646: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:37:13.679: INFO: Waiting for pod downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:37:13.683: INFO: Pod downwardapi-volume-da5aa945-3336-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:37:13.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2svpt" for this suite.
Feb 18 04:37:19.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:37:19.742: INFO: namespace: e2e-tests-downward-api-2svpt, resource: bindings, ignored listing per whitelist
Feb 18 04:37:19.817: INFO: namespace e2e-tests-downward-api-2svpt deletion completed in 6.128995158s

• [SLOW TEST:10.305 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:37:19.818: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sppql
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-sppql
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-sppql
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-sppql
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-sppql
Feb 18 04:37:23.960: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-sppql, name: ss-0, uid: e0dae6e0-3336-11e9-9a73-8a88965a7424, status phase: Pending. Waiting for statefulset controller to delete.
Feb 18 04:37:27.435: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-sppql, name: ss-0, uid: e0dae6e0-3336-11e9-9a73-8a88965a7424, status phase: Failed. Waiting for statefulset controller to delete.
Feb 18 04:37:27.443: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-sppql, name: ss-0, uid: e0dae6e0-3336-11e9-9a73-8a88965a7424, status phase: Failed. Waiting for statefulset controller to delete.
Feb 18 04:37:27.447: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-sppql
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-sppql
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-sppql and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 04:37:31.481: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sppql
Feb 18 04:37:31.487: INFO: Scaling statefulset ss to 0
Feb 18 04:37:41.539: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 04:37:41.542: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:37:41.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sppql" for this suite.
Feb 18 04:37:47.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:37:47.737: INFO: namespace: e2e-tests-statefulset-sppql, resource: bindings, ignored listing per whitelist
Feb 18 04:37:47.741: INFO: namespace e2e-tests-statefulset-sppql deletion completed in 6.13382855s

• [SLOW TEST:27.923 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:37:47.741: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:37:47.856: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-5w24m" to be "success or failure"
Feb 18 04:37:47.865: INFO: Pod "downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.9569ms
Feb 18 04:37:49.871: INFO: Pod "downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01518085s
Feb 18 04:37:51.877: INFO: Pod "downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020953812s
STEP: Saw pod success
Feb 18 04:37:51.877: INFO: Pod "downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:37:51.881: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:37:51.904: INFO: Waiting for pod downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:37:51.908: INFO: Pod downwardapi-volume-f123f9b4-3336-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:37:51.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5w24m" for this suite.
Feb 18 04:37:57.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:37:58.030: INFO: namespace: e2e-tests-downward-api-5w24m, resource: bindings, ignored listing per whitelist
Feb 18 04:37:58.045: INFO: namespace e2e-tests-downward-api-5w24m deletion completed in 6.130883079s

• [SLOW TEST:10.304 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:37:58.045: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 18 04:37:58.155: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 18 04:38:03.162: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:38:04.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-frqz6" for this suite.
Feb 18 04:38:10.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:38:10.375: INFO: namespace: e2e-tests-replication-controller-frqz6, resource: bindings, ignored listing per whitelist
Feb 18 04:38:10.386: INFO: namespace e2e-tests-replication-controller-frqz6 deletion completed in 6.147567578s

• [SLOW TEST:12.341 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:38:10.387: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 18 04:38:11.008: INFO: created pod pod-service-account-defaultsa
Feb 18 04:38:11.008: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 18 04:38:11.021: INFO: created pod pod-service-account-mountsa
Feb 18 04:38:11.021: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 18 04:38:11.028: INFO: created pod pod-service-account-nomountsa
Feb 18 04:38:11.028: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 18 04:38:11.035: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 18 04:38:11.035: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 18 04:38:11.043: INFO: created pod pod-service-account-mountsa-mountspec
Feb 18 04:38:11.043: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 18 04:38:11.050: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 18 04:38:11.050: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 18 04:38:11.056: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 18 04:38:11.056: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 18 04:38:11.063: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 18 04:38:11.063: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 18 04:38:11.073: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 18 04:38:11.073: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:38:11.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-lrtxk" for this suite.
Feb 18 04:38:33.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:38:33.178: INFO: namespace: e2e-tests-svcaccounts-lrtxk, resource: bindings, ignored listing per whitelist
Feb 18 04:38:33.249: INFO: namespace e2e-tests-svcaccounts-lrtxk deletion completed in 22.147731247s

• [SLOW TEST:22.862 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:38:33.249: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 04:38:33.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 version'
Feb 18 04:38:33.502: INFO: stderr: ""
Feb 18 04:38:33.502: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:38:33.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6nszh" for this suite.
Feb 18 04:38:39.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:38:39.640: INFO: namespace: e2e-tests-kubectl-6nszh, resource: bindings, ignored listing per whitelist
Feb 18 04:38:39.643: INFO: namespace e2e-tests-kubectl-6nszh deletion completed in 6.133621582s

• [SLOW TEST:6.394 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:38:39.643: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 18 04:38:39.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:40.441: INFO: stderr: ""
Feb 18 04:38:40.441: INFO: stdout: "pod/pause created\n"
Feb 18 04:38:40.441: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 18 04:38:40.441: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-9z58j" to be "running and ready"
Feb 18 04:38:40.446: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.419244ms
Feb 18 04:38:42.452: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010774881s
Feb 18 04:38:44.459: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.017832232s
Feb 18 04:38:44.459: INFO: Pod "pause" satisfied condition "running and ready"
Feb 18 04:38:44.459: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 18 04:38:44.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:44.634: INFO: stderr: ""
Feb 18 04:38:44.634: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 18 04:38:44.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pod pause -L testing-label --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:44.800: INFO: stderr: ""
Feb 18 04:38:44.800: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 18 04:38:44.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 label pods pause testing-label- --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:44.973: INFO: stderr: ""
Feb 18 04:38:44.973: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 18 04:38:44.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pod pause -L testing-label --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:45.147: INFO: stderr: ""
Feb 18 04:38:45.147: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 18 04:38:45.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:45.316: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:38:45.317: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 18 04:38:45.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-9z58j'
Feb 18 04:38:45.498: INFO: stderr: "No resources found.\n"
Feb 18 04:38:45.498: INFO: stdout: ""
Feb 18 04:38:45.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -l name=pause --namespace=e2e-tests-kubectl-9z58j -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 04:38:45.663: INFO: stderr: ""
Feb 18 04:38:45.664: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:38:45.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9z58j" for this suite.
Feb 18 04:38:51.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:38:51.800: INFO: namespace: e2e-tests-kubectl-9z58j, resource: bindings, ignored listing per whitelist
Feb 18 04:38:51.800: INFO: namespace e2e-tests-kubectl-9z58j deletion completed in 6.130536275s

• [SLOW TEST:12.157 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:38:51.800: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 18 04:38:56.447: INFO: Successfully updated pod "pod-update-17537564-3337-11e9-94e0-0a580af401c1"
STEP: verifying the updated pod is in kubernetes
Feb 18 04:38:56.480: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:38:56.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zrhjk" for this suite.
Feb 18 04:39:18.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:39:18.619: INFO: namespace: e2e-tests-pods-zrhjk, resource: bindings, ignored listing per whitelist
Feb 18 04:39:18.619: INFO: namespace e2e-tests-pods-zrhjk deletion completed in 22.133096649s

• [SLOW TEST:26.819 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:39:18.620: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-276a99d4-3337-11e9-94e0-0a580af401c1
STEP: Creating configMap with name cm-test-opt-upd-276a9a5b-3337-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-276a99d4-3337-11e9-94e0-0a580af401c1
STEP: Updating configmap cm-test-opt-upd-276a9a5b-3337-11e9-94e0-0a580af401c1
STEP: Creating configMap with name cm-test-opt-create-276a9a93-3337-11e9-94e0-0a580af401c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:40:29.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c4sdv" for this suite.
Feb 18 04:40:51.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:40:51.882: INFO: namespace: e2e-tests-configmap-c4sdv, resource: bindings, ignored listing per whitelist
Feb 18 04:40:51.903: INFO: namespace e2e-tests-configmap-c4sdv deletion completed in 22.142839811s

• [SLOW TEST:93.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:40:51.903: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 18 04:41:00.049: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:00.049: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:00.394: INFO: Exec stderr: ""
Feb 18 04:41:00.394: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:00.395: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:00.746: INFO: Exec stderr: ""
Feb 18 04:41:00.746: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:00.746: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:01.103: INFO: Exec stderr: ""
Feb 18 04:41:01.103: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:01.103: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:01.505: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 18 04:41:01.505: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:01.505: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:01.844: INFO: Exec stderr: ""
Feb 18 04:41:01.844: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:01.844: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:02.242: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 18 04:41:02.242: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:02.242: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:02.589: INFO: Exec stderr: ""
Feb 18 04:41:02.589: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:02.589: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:02.967: INFO: Exec stderr: ""
Feb 18 04:41:02.967: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:02.967: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:03.303: INFO: Exec stderr: ""
Feb 18 04:41:03.303: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rn5pj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:41:03.303: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:41:03.664: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:41:03.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rn5pj" for this suite.
Feb 18 04:41:49.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:41:49.774: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rn5pj, resource: bindings, ignored listing per whitelist
Feb 18 04:41:49.836: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rn5pj deletion completed in 46.165019749s

• [SLOW TEST:57.933 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:41:49.836: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 18 04:41:49.943: INFO: Waiting up to 5m0s for pod "pod-8170716d-3337-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-rxllg" to be "success or failure"
Feb 18 04:41:49.948: INFO: Pod "pod-8170716d-3337-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.879821ms
Feb 18 04:41:51.957: INFO: Pod "pod-8170716d-3337-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013235303s
Feb 18 04:41:53.962: INFO: Pod "pod-8170716d-3337-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018744986s
Feb 18 04:41:55.968: INFO: Pod "pod-8170716d-3337-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024506728s
STEP: Saw pod success
Feb 18 04:41:55.968: INFO: Pod "pod-8170716d-3337-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:41:55.972: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-8170716d-3337-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:41:55.998: INFO: Waiting for pod pod-8170716d-3337-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:41:56.002: INFO: Pod pod-8170716d-3337-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:41:56.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rxllg" for this suite.
Feb 18 04:42:02.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:42:02.100: INFO: namespace: e2e-tests-emptydir-rxllg, resource: bindings, ignored listing per whitelist
Feb 18 04:42:02.146: INFO: namespace e2e-tests-emptydir-rxllg deletion completed in 6.138241689s

• [SLOW TEST:12.310 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:42:02.147: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6dp88
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 04:42:02.266: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 04:42:24.335: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.253:8080/dial?request=hostName&protocol=udp&host=10.244.1.252&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6dp88 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 04:42:24.335: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
Feb 18 04:42:24.675: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:42:24.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6dp88" for this suite.
Feb 18 04:42:46.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:42:46.729: INFO: namespace: e2e-tests-pod-network-test-6dp88, resource: bindings, ignored listing per whitelist
Feb 18 04:42:46.822: INFO: namespace e2e-tests-pod-network-test-6dp88 deletion completed in 22.13976924s

• [SLOW TEST:44.675 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:42:46.822: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:42:50.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-nwmjn" for this suite.
Feb 18 04:42:56.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:42:57.009: INFO: namespace: e2e-tests-kubelet-test-nwmjn, resource: bindings, ignored listing per whitelist
Feb 18 04:42:57.086: INFO: namespace e2e-tests-kubelet-test-nwmjn deletion completed in 6.135400323s

• [SLOW TEST:10.264 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:42:57.086: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a985b184-3337-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume secrets
Feb 18 04:42:57.299: INFO: Waiting up to 5m0s for pod "pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1" in namespace "e2e-tests-secrets-74s5v" to be "success or failure"
Feb 18 04:42:57.303: INFO: Pod "pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.536766ms
Feb 18 04:42:59.308: INFO: Pod "pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009310035s
Feb 18 04:43:01.314: INFO: Pod "pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015222014s
STEP: Saw pod success
Feb 18 04:43:01.314: INFO: Pod "pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:43:01.318: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 04:43:01.344: INFO: Waiting for pod pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:43:01.349: INFO: Pod pod-secrets-a995dbca-3337-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:43:01.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-74s5v" for this suite.
Feb 18 04:43:07.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:43:07.465: INFO: namespace: e2e-tests-secrets-74s5v, resource: bindings, ignored listing per whitelist
Feb 18 04:43:07.494: INFO: namespace e2e-tests-secrets-74s5v deletion completed in 6.138060103s

• [SLOW TEST:10.408 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:43:07.495: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 18 04:43:07.607: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-bkf7n" to be "success or failure"
Feb 18 04:43:07.610: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.539592ms
Feb 18 04:43:09.616: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009452196s
Feb 18 04:43:11.622: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015382026s
STEP: Saw pod success
Feb 18 04:43:11.622: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 18 04:43:11.626: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 18 04:43:11.651: INFO: Waiting for pod pod-host-path-test to disappear
Feb 18 04:43:11.655: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:43:11.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-bkf7n" for this suite.
Feb 18 04:43:17.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:43:17.716: INFO: namespace: e2e-tests-hostpath-bkf7n, resource: bindings, ignored listing per whitelist
Feb 18 04:43:17.800: INFO: namespace e2e-tests-hostpath-bkf7n deletion completed in 6.138728451s

• [SLOW TEST:10.305 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:43:17.800: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b5e1806f-3337-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:43:17.929: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-kdbrb" to be "success or failure"
Feb 18 04:43:17.933: INFO: Pod "pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380122ms
Feb 18 04:43:19.938: INFO: Pod "pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008529017s
STEP: Saw pod success
Feb 18 04:43:19.938: INFO: Pod "pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:43:19.942: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:43:19.966: INFO: Waiting for pod pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:43:19.970: INFO: Pod pod-projected-configmaps-b5e230ef-3337-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:43:19.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kdbrb" for this suite.
Feb 18 04:43:25.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:43:26.072: INFO: namespace: e2e-tests-projected-kdbrb, resource: bindings, ignored listing per whitelist
Feb 18 04:43:26.328: INFO: namespace e2e-tests-projected-kdbrb deletion completed in 6.352108708s

• [SLOW TEST:8.528 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:43:26.328: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1
Feb 18 04:43:26.426: INFO: Pod name my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1: Found 0 pods out of 1
Feb 18 04:43:31.432: INFO: Pod name my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1: Found 1 pods out of 1
Feb 18 04:43:31.432: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1" are running
Feb 18 04:43:31.436: INFO: Pod "my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1-8hn9f" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 04:43:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 04:43:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 04:43:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-18 04:43:26 +0000 UTC Reason: Message:}])
Feb 18 04:43:31.436: INFO: Trying to dial the pod
Feb 18 04:43:36.452: INFO: Controller my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1: Got expected result from replica 1 [my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1-8hn9f]: "my-hostname-basic-baf24bfb-3337-11e9-94e0-0a580af401c1-8hn9f", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:43:36.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-48xlw" for this suite.
Feb 18 04:43:42.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:43:42.565: INFO: namespace: e2e-tests-replication-controller-48xlw, resource: bindings, ignored listing per whitelist
Feb 18 04:43:42.611: INFO: namespace e2e-tests-replication-controller-48xlw deletion completed in 6.152467057s

• [SLOW TEST:16.282 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:43:42.611: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:43:46.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7rf4g" for this suite.
Feb 18 04:44:28.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:44:28.802: INFO: namespace: e2e-tests-kubelet-test-7rf4g, resource: bindings, ignored listing per whitelist
Feb 18 04:44:28.894: INFO: namespace e2e-tests-kubelet-test-7rf4g deletion completed in 42.140053418s

• [SLOW TEST:46.284 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:44:28.895: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 18 04:44:29.028: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ggwtz,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggwtz/configmaps/e2e-watch-test-resource-version,UID:e03d8e34-3337-11e9-9a73-8a88965a7424,ResourceVersion:345435,Generation:0,CreationTimestamp:2019-02-18 04:44:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 04:44:29.028: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ggwtz,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggwtz/configmaps/e2e-watch-test-resource-version,UID:e03d8e34-3337-11e9-9a73-8a88965a7424,ResourceVersion:345436,Generation:0,CreationTimestamp:2019-02-18 04:44:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:44:29.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ggwtz" for this suite.
Feb 18 04:44:35.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:44:35.149: INFO: namespace: e2e-tests-watch-ggwtz, resource: bindings, ignored listing per whitelist
Feb 18 04:44:35.168: INFO: namespace e2e-tests-watch-ggwtz deletion completed in 6.135144934s

• [SLOW TEST:6.273 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:44:35.168: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e3fcb6d7-3337-11e9-94e0-0a580af401c1
STEP: Creating secret with name s-test-opt-upd-e3fcb760-3337-11e9-94e0-0a580af401c1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e3fcb6d7-3337-11e9-94e0-0a580af401c1
STEP: Updating secret s-test-opt-upd-e3fcb760-3337-11e9-94e0-0a580af401c1
STEP: Creating secret with name s-test-opt-create-e3fcb79e-3337-11e9-94e0-0a580af401c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:44:41.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v4bvg" for this suite.
Feb 18 04:44:59.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:44:59.537: INFO: namespace: e2e-tests-projected-v4bvg, resource: bindings, ignored listing per whitelist
Feb 18 04:44:59.554: INFO: namespace e2e-tests-projected-v4bvg deletion completed in 18.131089505s

• [SLOW TEST:24.386 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:44:59.555: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 18 04:45:04.197: INFO: Successfully updated pod "labelsupdatef284165f-3337-11e9-94e0-0a580af401c1"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:45:06.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jv4nq" for this suite.
Feb 18 04:45:28.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:45:28.324: INFO: namespace: e2e-tests-downward-api-jv4nq, resource: bindings, ignored listing per whitelist
Feb 18 04:45:28.371: INFO: namespace e2e-tests-downward-api-jv4nq deletion completed in 22.132658027s

• [SLOW TEST:28.817 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:45:28.372: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-03d14eb6-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:45:28.686: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-rs6m6" to be "success or failure"
Feb 18 04:45:28.693: INFO: Pod "pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.700475ms
Feb 18 04:45:30.698: INFO: Pod "pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012523908s
STEP: Saw pod success
Feb 18 04:45:30.698: INFO: Pod "pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:45:30.702: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:45:30.725: INFO: Waiting for pod pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:45:30.728: INFO: Pod pod-projected-configmaps-03d1ec1d-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:45:30.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rs6m6" for this suite.
Feb 18 04:45:36.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:45:36.778: INFO: namespace: e2e-tests-projected-rs6m6, resource: bindings, ignored listing per whitelist
Feb 18 04:45:36.867: INFO: namespace e2e-tests-projected-rs6m6 deletion completed in 6.13482734s

• [SLOW TEST:8.495 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:45:36.868: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-08c2228b-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:45:36.975: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-zx6st" to be "success or failure"
Feb 18 04:45:36.980: INFO: Pod "pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.495586ms
Feb 18 04:45:38.986: INFO: Pod "pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010572791s
STEP: Saw pod success
Feb 18 04:45:38.986: INFO: Pod "pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:45:38.990: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:45:39.025: INFO: Waiting for pod pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:45:39.028: INFO: Pod pod-projected-configmaps-08c2c2e6-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:45:39.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zx6st" for this suite.
Feb 18 04:45:45.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:45:45.123: INFO: namespace: e2e-tests-projected-zx6st, resource: bindings, ignored listing per whitelist
Feb 18 04:45:45.166: INFO: namespace e2e-tests-projected-zx6st deletion completed in 6.132459391s

• [SLOW TEST:8.299 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:45:45.166: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:45:45.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-rxlp9" to be "success or failure"
Feb 18 04:45:45.281: INFO: Pod "downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.397375ms
Feb 18 04:45:47.288: INFO: Pod "downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012201816s
STEP: Saw pod success
Feb 18 04:45:47.288: INFO: Pod "downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:45:47.293: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:45:47.319: INFO: Waiting for pod downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:45:47.322: INFO: Pod downwardapi-volume-0db52753-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:45:47.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rxlp9" for this suite.
Feb 18 04:45:53.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:45:53.382: INFO: namespace: e2e-tests-downward-api-rxlp9, resource: bindings, ignored listing per whitelist
Feb 18 04:45:53.478: INFO: namespace e2e-tests-downward-api-rxlp9 deletion completed in 6.150523844s

• [SLOW TEST:8.311 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:45:53.478: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 18 04:45:53.580: INFO: Waiting up to 5m0s for pod "pod-12a870f4-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-876hn" to be "success or failure"
Feb 18 04:45:53.583: INFO: Pod "pod-12a870f4-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.474157ms
Feb 18 04:45:55.588: INFO: Pod "pod-12a870f4-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008621953s
STEP: Saw pod success
Feb 18 04:45:55.588: INFO: Pod "pod-12a870f4-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:45:55.592: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-12a870f4-3338-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:45:55.619: INFO: Waiting for pod pod-12a870f4-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:45:55.622: INFO: Pod pod-12a870f4-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:45:55.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-876hn" for this suite.
Feb 18 04:46:01.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:46:01.671: INFO: namespace: e2e-tests-emptydir-876hn, resource: bindings, ignored listing per whitelist
Feb 18 04:46:01.767: INFO: namespace e2e-tests-emptydir-876hn deletion completed in 6.140717563s

• [SLOW TEST:8.289 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:46:01.767: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-fpvc7 in namespace e2e-tests-proxy-n6tfg
I0218 04:46:01.890452      17 runners.go:184] Created replication controller with name: proxy-service-fpvc7, namespace: e2e-tests-proxy-n6tfg, replica count: 1
I0218 04:46:02.941005      17 runners.go:184] proxy-service-fpvc7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0218 04:46:03.941362      17 runners.go:184] proxy-service-fpvc7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0218 04:46:04.941750      17 runners.go:184] proxy-service-fpvc7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 18 04:46:04.946: INFO: setup took 3.080159981s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 18 04:46:04.961: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 13.638591ms)
Feb 18 04:46:04.962: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 15.405069ms)
Feb 18 04:46:04.962: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 15.827276ms)
Feb 18 04:46:04.963: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.805583ms)
Feb 18 04:46:04.963: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.787306ms)
Feb 18 04:46:04.963: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 16.40165ms)
Feb 18 04:46:04.963: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 16.416847ms)
Feb 18 04:46:04.963: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 16.520223ms)
Feb 18 04:46:04.964: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 16.788592ms)
Feb 18 04:46:04.965: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 18.596322ms)
Feb 18 04:46:04.967: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 20.038528ms)
Feb 18 04:46:04.974: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 27.285797ms)
Feb 18 04:46:04.978: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 31.223891ms)
Feb 18 04:46:04.979: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 32.556411ms)
Feb 18 04:46:04.979: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 32.509901ms)
Feb 18 04:46:04.980: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 33.343683ms)
Feb 18 04:46:04.998: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 17.630451ms)
Feb 18 04:46:04.999: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 18.795009ms)
Feb 18 04:46:05.000: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 19.823998ms)
Feb 18 04:46:05.001: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 20.289412ms)
Feb 18 04:46:05.001: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 20.813066ms)
Feb 18 04:46:05.001: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 20.925731ms)
Feb 18 04:46:05.002: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 21.829145ms)
Feb 18 04:46:05.002: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 22.084899ms)
Feb 18 04:46:05.002: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 22.016704ms)
Feb 18 04:46:05.002: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 21.614929ms)
Feb 18 04:46:05.002: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 21.449214ms)
Feb 18 04:46:05.002: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 21.500884ms)
Feb 18 04:46:05.003: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 22.112443ms)
Feb 18 04:46:05.003: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 22.290957ms)
Feb 18 04:46:05.003: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 22.650285ms)
Feb 18 04:46:05.003: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 22.337868ms)
Feb 18 04:46:05.010: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 6.965304ms)
Feb 18 04:46:05.019: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 16.16257ms)
Feb 18 04:46:05.020: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 16.636132ms)
Feb 18 04:46:05.020: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 16.614909ms)
Feb 18 04:46:05.021: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 17.408783ms)
Feb 18 04:46:05.021: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 17.579486ms)
Feb 18 04:46:05.021: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 17.784743ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 18.399627ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 18.789869ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 18.665884ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 18.83652ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 19.14192ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 19.278326ms)
Feb 18 04:46:05.022: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 19.584504ms)
Feb 18 04:46:05.023: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 19.599566ms)
Feb 18 04:46:05.023: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 19.528008ms)
Feb 18 04:46:05.038: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 14.737768ms)
Feb 18 04:46:05.039: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 15.535938ms)
Feb 18 04:46:05.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 16.658197ms)
Feb 18 04:46:05.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 16.303399ms)
Feb 18 04:46:05.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 16.66351ms)
Feb 18 04:46:05.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 16.852669ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 17.519453ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 17.411029ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 17.529261ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 17.845589ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 17.782041ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 17.606979ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 17.726833ms)
Feb 18 04:46:05.041: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 17.87925ms)
Feb 18 04:46:05.044: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 20.672761ms)
Feb 18 04:46:05.046: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 22.968292ms)
Feb 18 04:46:05.092: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 44.900287ms)
Feb 18 04:46:05.092: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 45.248554ms)
Feb 18 04:46:05.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 45.944163ms)
Feb 18 04:46:05.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 45.994568ms)
Feb 18 04:46:05.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 46.31081ms)
Feb 18 04:46:05.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 46.377086ms)
Feb 18 04:46:05.094: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 47.286451ms)
Feb 18 04:46:05.094: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 47.849927ms)
Feb 18 04:46:05.094: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 47.406646ms)
Feb 18 04:46:05.095: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 47.845228ms)
Feb 18 04:46:05.095: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 48.062909ms)
Feb 18 04:46:05.096: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 48.871901ms)
Feb 18 04:46:05.096: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 49.365453ms)
Feb 18 04:46:05.097: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 50.085062ms)
Feb 18 04:46:05.100: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 53.200895ms)
Feb 18 04:46:05.102: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 55.110608ms)
Feb 18 04:46:05.133: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 30.64003ms)
Feb 18 04:46:05.134: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 32.371717ms)
Feb 18 04:46:05.138: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 35.996518ms)
Feb 18 04:46:05.138: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 36.154024ms)
Feb 18 04:46:05.138: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 35.803221ms)
Feb 18 04:46:05.138: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 35.910961ms)
Feb 18 04:46:05.139: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 36.95695ms)
Feb 18 04:46:05.140: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 37.113151ms)
Feb 18 04:46:05.140: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 37.479459ms)
Feb 18 04:46:05.140: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 38.286134ms)
Feb 18 04:46:05.168: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 65.60664ms)
Feb 18 04:46:05.184: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 81.314134ms)
Feb 18 04:46:05.184: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 81.25455ms)
Feb 18 04:46:05.184: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 81.912571ms)
Feb 18 04:46:05.184: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 81.451617ms)
Feb 18 04:46:05.184: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 81.760859ms)
Feb 18 04:46:05.196: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 10.951789ms)
Feb 18 04:46:05.197: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 11.700781ms)
Feb 18 04:46:05.197: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 12.164763ms)
Feb 18 04:46:05.197: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 12.633102ms)
Feb 18 04:46:05.197: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 11.93548ms)
Feb 18 04:46:05.199: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 13.241969ms)
Feb 18 04:46:05.199: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.029332ms)
Feb 18 04:46:05.199: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 13.957987ms)
Feb 18 04:46:05.199: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 14.142765ms)
Feb 18 04:46:05.199: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 14.2419ms)
Feb 18 04:46:05.201: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 15.43862ms)
Feb 18 04:46:05.202: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 18.076011ms)
Feb 18 04:46:05.236: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 51.126661ms)
Feb 18 04:46:05.237: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 51.80427ms)
Feb 18 04:46:05.237: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 51.366622ms)
Feb 18 04:46:05.237: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 52.901775ms)
Feb 18 04:46:05.245: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 7.395073ms)
Feb 18 04:46:05.249: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 11.286312ms)
Feb 18 04:46:05.251: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 13.297022ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 13.584599ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.387225ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 13.207956ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 13.58365ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 14.551968ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 14.191742ms)
Feb 18 04:46:05.252: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 14.153671ms)
Feb 18 04:46:05.253: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 14.539513ms)
Feb 18 04:46:05.255: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 16.513288ms)
Feb 18 04:46:05.255: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 17.335967ms)
Feb 18 04:46:05.255: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 16.832331ms)
Feb 18 04:46:05.255: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 16.807269ms)
Feb 18 04:46:05.256: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 17.627888ms)
Feb 18 04:46:05.264: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 7.913375ms)
Feb 18 04:46:05.266: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 8.565155ms)
Feb 18 04:46:05.266: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 8.614534ms)
Feb 18 04:46:05.266: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 9.731923ms)
Feb 18 04:46:05.266: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 9.362252ms)
Feb 18 04:46:05.267: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 9.961306ms)
Feb 18 04:46:05.267: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 10.124142ms)
Feb 18 04:46:05.267: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 10.284202ms)
Feb 18 04:46:05.267: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 9.882385ms)
Feb 18 04:46:05.267: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 10.231595ms)
Feb 18 04:46:05.269: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 12.831405ms)
Feb 18 04:46:05.270: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 12.726513ms)
Feb 18 04:46:05.270: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 12.560362ms)
Feb 18 04:46:05.270: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 13.444891ms)
Feb 18 04:46:05.270: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 12.999023ms)
Feb 18 04:46:05.270: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 12.861608ms)
Feb 18 04:46:05.280: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 10.072567ms)
Feb 18 04:46:05.281: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 9.83637ms)
Feb 18 04:46:05.281: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 10.087427ms)
Feb 18 04:46:05.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 11.196664ms)
Feb 18 04:46:05.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 12.724928ms)
Feb 18 04:46:05.283: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 12.224269ms)
Feb 18 04:46:05.284: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 12.981412ms)
Feb 18 04:46:05.284: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 14.5066ms)
Feb 18 04:46:05.284: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 13.98235ms)
Feb 18 04:46:05.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 13.862423ms)
Feb 18 04:46:05.286: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.008553ms)
Feb 18 04:46:05.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 15.846985ms)
Feb 18 04:46:05.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 17.162455ms)
Feb 18 04:46:05.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 16.537528ms)
Feb 18 04:46:05.287: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 15.910044ms)
Feb 18 04:46:05.288: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 15.848763ms)
Feb 18 04:46:05.293: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 5.068284ms)
Feb 18 04:46:05.296: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 8.084471ms)
Feb 18 04:46:05.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 10.815833ms)
Feb 18 04:46:05.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 10.723757ms)
Feb 18 04:46:05.300: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 11.591906ms)
Feb 18 04:46:05.300: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 11.869862ms)
Feb 18 04:46:05.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 12.179546ms)
Feb 18 04:46:05.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 12.416462ms)
Feb 18 04:46:05.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 12.683166ms)
Feb 18 04:46:05.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 12.575158ms)
Feb 18 04:46:05.301: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 12.910334ms)
Feb 18 04:46:05.303: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 15.139263ms)
Feb 18 04:46:05.303: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 15.174504ms)
Feb 18 04:46:05.304: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 15.565388ms)
Feb 18 04:46:05.304: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 16.010031ms)
Feb 18 04:46:05.304: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 15.991753ms)
Feb 18 04:46:05.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 10.087341ms)
Feb 18 04:46:05.316: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 11.563395ms)
Feb 18 04:46:05.316: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 11.320276ms)
Feb 18 04:46:05.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 13.812184ms)
Feb 18 04:46:05.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 14.439073ms)
Feb 18 04:46:05.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 13.927051ms)
Feb 18 04:46:05.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.983976ms)
Feb 18 04:46:05.319: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 14.313726ms)
Feb 18 04:46:05.320: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 14.296493ms)
Feb 18 04:46:05.320: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 14.773159ms)
Feb 18 04:46:05.320: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 15.834365ms)
Feb 18 04:46:05.320: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 15.044884ms)
Feb 18 04:46:05.320: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 15.237733ms)
Feb 18 04:46:05.321: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 15.462643ms)
Feb 18 04:46:05.321: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 15.881125ms)
Feb 18 04:46:05.321: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 15.789176ms)
Feb 18 04:46:05.335: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 12.186955ms)
Feb 18 04:46:05.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 12.745013ms)
Feb 18 04:46:05.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 12.712051ms)
Feb 18 04:46:05.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 14.787315ms)
Feb 18 04:46:05.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 12.508862ms)
Feb 18 04:46:05.336: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 13.733636ms)
Feb 18 04:46:05.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 15.706074ms)
Feb 18 04:46:05.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.837599ms)
Feb 18 04:46:05.337: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 14.629589ms)
Feb 18 04:46:05.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.96797ms)
Feb 18 04:46:05.338: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 16.39007ms)
Feb 18 04:46:05.339: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 15.145499ms)
Feb 18 04:46:05.339: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 16.685544ms)
Feb 18 04:46:05.339: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 16.042218ms)
Feb 18 04:46:05.339: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 17.138462ms)
Feb 18 04:46:05.339: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 17.047541ms)
Feb 18 04:46:05.345: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 5.952496ms)
Feb 18 04:46:05.346: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 6.040782ms)
Feb 18 04:46:05.346: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 7.110752ms)
Feb 18 04:46:05.349: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 9.348027ms)
Feb 18 04:46:05.350: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 9.859692ms)
Feb 18 04:46:05.352: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 11.504253ms)
Feb 18 04:46:05.352: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 12.834077ms)
Feb 18 04:46:05.353: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 12.974721ms)
Feb 18 04:46:05.354: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.730796ms)
Feb 18 04:46:05.354: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 14.142459ms)
Feb 18 04:46:05.354: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 14.341081ms)
Feb 18 04:46:05.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 17.614951ms)
Feb 18 04:46:05.357: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 17.441926ms)
Feb 18 04:46:05.358: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 18.375891ms)
Feb 18 04:46:05.358: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 17.516564ms)
Feb 18 04:46:05.358: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 18.112775ms)
Feb 18 04:46:05.370: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 12.289387ms)
Feb 18 04:46:05.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.784156ms)
Feb 18 04:46:05.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 15.91805ms)
Feb 18 04:46:05.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 16.262651ms)
Feb 18 04:46:05.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 16.484797ms)
Feb 18 04:46:05.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 16.068877ms)
Feb 18 04:46:05.374: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 16.268344ms)
Feb 18 04:46:05.375: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 16.399517ms)
Feb 18 04:46:05.375: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 16.270674ms)
Feb 18 04:46:05.375: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 16.428569ms)
Feb 18 04:46:05.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 21.644944ms)
Feb 18 04:46:05.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 21.649623ms)
Feb 18 04:46:05.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 21.701687ms)
Feb 18 04:46:05.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 22.194217ms)
Feb 18 04:46:05.380: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 22.055308ms)
Feb 18 04:46:05.436: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 77.446992ms)
Feb 18 04:46:05.443: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 7.414007ms)
Feb 18 04:46:05.445: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 8.735465ms)
Feb 18 04:46:05.445: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 8.622855ms)
Feb 18 04:46:05.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 12.538363ms)
Feb 18 04:46:05.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 13.337564ms)
Feb 18 04:46:05.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 14.654783ms)
Feb 18 04:46:05.451: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 12.70851ms)
Feb 18 04:46:05.451: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 13.811233ms)
Feb 18 04:46:05.452: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 15.306836ms)
Feb 18 04:46:05.452: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 13.889196ms)
Feb 18 04:46:05.452: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 15.673135ms)
Feb 18 04:46:05.452: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 15.355062ms)
Feb 18 04:46:05.453: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 14.735535ms)
Feb 18 04:46:05.453: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 16.611435ms)
Feb 18 04:46:05.453: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 15.566863ms)
Feb 18 04:46:05.455: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 17.362783ms)
Feb 18 04:46:05.461: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 6.365653ms)
Feb 18 04:46:05.469: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 13.213024ms)
Feb 18 04:46:05.469: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.823126ms)
Feb 18 04:46:05.470: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 14.278988ms)
Feb 18 04:46:05.470: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 13.696094ms)
Feb 18 04:46:05.473: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 16.33668ms)
Feb 18 04:46:05.473: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 17.085135ms)
Feb 18 04:46:05.473: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 17.351364ms)
Feb 18 04:46:05.473: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 17.069126ms)
Feb 18 04:46:05.474: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 18.361515ms)
Feb 18 04:46:05.476: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 19.827302ms)
Feb 18 04:46:05.476: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 21.512088ms)
Feb 18 04:46:05.477: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 21.027668ms)
Feb 18 04:46:05.477: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 21.417838ms)
Feb 18 04:46:05.477: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 21.938105ms)
Feb 18 04:46:05.477: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 21.352496ms)
Feb 18 04:46:05.489: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 11.265803ms)
Feb 18 04:46:05.490: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 12.124446ms)
Feb 18 04:46:05.490: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 12.665072ms)
Feb 18 04:46:05.490: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 12.852134ms)
Feb 18 04:46:05.491: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 13.633764ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 14.673461ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 14.862712ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 15.074959ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 14.852119ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 14.908268ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 15.423433ms)
Feb 18 04:46:05.493: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 15.544552ms)
Feb 18 04:46:05.494: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 15.621393ms)
Feb 18 04:46:05.494: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 15.688312ms)
Feb 18 04:46:05.494: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 16.145714ms)
Feb 18 04:46:05.496: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 18.081223ms)
Feb 18 04:46:05.507: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 10.779617ms)
Feb 18 04:46:05.507: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 10.834987ms)
Feb 18 04:46:05.507: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 11.08312ms)
Feb 18 04:46:05.507: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 11.229384ms)
Feb 18 04:46:05.508: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 11.129374ms)
Feb 18 04:46:05.508: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 11.401348ms)
Feb 18 04:46:05.510: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.874754ms)
Feb 18 04:46:05.510: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 14.0331ms)
Feb 18 04:46:05.511: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 14.057511ms)
Feb 18 04:46:05.511: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 14.479332ms)
Feb 18 04:46:05.514: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 17.509096ms)
Feb 18 04:46:05.514: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 17.969844ms)
Feb 18 04:46:05.515: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 17.893233ms)
Feb 18 04:46:05.515: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 17.945653ms)
Feb 18 04:46:05.515: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 18.081026ms)
Feb 18 04:46:05.515: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 19.157582ms)
Feb 18 04:46:05.529: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname1/proxy/: foo (200; 13.358867ms)
Feb 18 04:46:05.529: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc/proxy/rewriteme"... (200; 13.296955ms)
Feb 18 04:46:05.529: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 13.495178ms)
Feb 18 04:46:05.529: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname1/proxy/: foo (200; 13.561938ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:443/proxy/... (200; 15.757357ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:1080/proxy/... (200; 15.633263ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:162/proxy/: bar (200; 16.037793ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/http:proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 15.593094ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:460/proxy/: tls baz (200; 15.869447ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/http:proxy-service-fpvc7:portname2/proxy/: bar (200; 15.789066ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/proxy-service-fpvc7:portname2/proxy/: bar (200; 15.886292ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/https:proxy-service-fpvc7-6zbbc:462/proxy/: tls qux (200; 16.017421ms)
Feb 18 04:46:05.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname1/proxy/: tls baz (200; 16.92347ms)
Feb 18 04:46:05.533: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:1080/proxy/rewri... (200; 16.459631ms)
Feb 18 04:46:05.533: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/pods/proxy-service-fpvc7-6zbbc:160/proxy/: foo (200; 17.285327ms)
Feb 18 04:46:05.534: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-n6tfg/services/https:proxy-service-fpvc7:tlsportname2/proxy/: tls qux (200; 17.963997ms)
STEP: deleting ReplicationController proxy-service-fpvc7 in namespace e2e-tests-proxy-n6tfg, will wait for the garbage collector to delete the pods
Feb 18 04:46:05.596: INFO: Deleting ReplicationController proxy-service-fpvc7 took: 8.054436ms
Feb 18 04:46:05.696: INFO: Terminating ReplicationController proxy-service-fpvc7 pods took: 100.324177ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:46:07.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-n6tfg" for this suite.
Feb 18 04:46:14.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:46:14.077: INFO: namespace: e2e-tests-proxy-n6tfg, resource: bindings, ignored listing per whitelist
Feb 18 04:46:14.135: INFO: namespace e2e-tests-proxy-n6tfg deletion completed in 6.131979678s

• [SLOW TEST:12.368 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:46:14.135: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1ef8ed95-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:46:14.247: INFO: Waiting up to 5m0s for pod "pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-kg2v6" to be "success or failure"
Feb 18 04:46:14.252: INFO: Pod "pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.250089ms
Feb 18 04:46:16.259: INFO: Pod "pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011699279s
STEP: Saw pod success
Feb 18 04:46:16.259: INFO: Pod "pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:46:16.263: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:46:16.287: INFO: Waiting for pod pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:46:16.290: INFO: Pod pod-configmaps-1ef9d327-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:46:16.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kg2v6" for this suite.
Feb 18 04:46:22.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:46:22.370: INFO: namespace: e2e-tests-configmap-kg2v6, resource: bindings, ignored listing per whitelist
Feb 18 04:46:22.418: INFO: namespace e2e-tests-configmap-kg2v6 deletion completed in 6.122578551s

• [SLOW TEST:8.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:46:22.418: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-23e8810c-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:46:22.527: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-6wkg2" to be "success or failure"
Feb 18 04:46:22.532: INFO: Pod "pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.753141ms
Feb 18 04:46:24.538: INFO: Pod "pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011031862s
STEP: Saw pod success
Feb 18 04:46:24.538: INFO: Pod "pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:46:24.542: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:46:24.566: INFO: Waiting for pod pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:46:24.569: INFO: Pod pod-projected-configmaps-23e9268d-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:46:24.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6wkg2" for this suite.
Feb 18 04:46:30.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:46:30.608: INFO: namespace: e2e-tests-projected-6wkg2, resource: bindings, ignored listing per whitelist
Feb 18 04:46:30.714: INFO: namespace e2e-tests-projected-6wkg2 deletion completed in 6.139432647s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:46:30.714: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 04:46:30.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-g8v5q'
Feb 18 04:46:31.152: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 04:46:31.152: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 18 04:46:35.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-g8v5q'
Feb 18 04:46:35.525: INFO: stderr: ""
Feb 18 04:46:35.525: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:46:35.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g8v5q" for this suite.
Feb 18 04:46:41.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:46:41.628: INFO: namespace: e2e-tests-kubectl-g8v5q, resource: bindings, ignored listing per whitelist
Feb 18 04:46:41.728: INFO: namespace e2e-tests-kubectl-g8v5q deletion completed in 6.195843678s

• [SLOW TEST:11.014 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:46:41.728: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 18 04:46:41.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 create -f - --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:42.109: INFO: stderr: ""
Feb 18 04:46:42.109: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 04:46:42.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:42.282: INFO: stderr: ""
Feb 18 04:46:42.282: INFO: stdout: "update-demo-nautilus-9r9kv update-demo-nautilus-bmswr "
Feb 18 04:46:42.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-9r9kv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:42.455: INFO: stderr: ""
Feb 18 04:46:42.455: INFO: stdout: ""
Feb 18 04:46:42.455: INFO: update-demo-nautilus-9r9kv is created but not running
Feb 18 04:46:47.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:47.636: INFO: stderr: ""
Feb 18 04:46:47.636: INFO: stdout: "update-demo-nautilus-9r9kv update-demo-nautilus-bmswr "
Feb 18 04:46:47.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-9r9kv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:47.801: INFO: stderr: ""
Feb 18 04:46:47.801: INFO: stdout: "true"
Feb 18 04:46:47.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-9r9kv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:47.952: INFO: stderr: ""
Feb 18 04:46:47.952: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 04:46:47.952: INFO: validating pod update-demo-nautilus-9r9kv
Feb 18 04:46:47.960: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 04:46:47.960: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 04:46:47.960: INFO: update-demo-nautilus-9r9kv is verified up and running
Feb 18 04:46:47.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-bmswr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:48.140: INFO: stderr: ""
Feb 18 04:46:48.140: INFO: stdout: "true"
Feb 18 04:46:48.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods update-demo-nautilus-bmswr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:48.302: INFO: stderr: ""
Feb 18 04:46:48.302: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 04:46:48.302: INFO: validating pod update-demo-nautilus-bmswr
Feb 18 04:46:48.309: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 04:46:48.309: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 04:46:48.309: INFO: update-demo-nautilus-bmswr is verified up and running
STEP: using delete to clean up resources
Feb 18 04:46:48.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:48.569: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 04:46:48.569: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 18 04:46:48.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-cxxmk'
Feb 18 04:46:48.808: INFO: stderr: "No resources found.\n"
Feb 18 04:46:48.808: INFO: stdout: ""
Feb 18 04:46:48.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-647419003 get pods -l name=update-demo --namespace=e2e-tests-kubectl-cxxmk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 04:46:48.987: INFO: stderr: ""
Feb 18 04:46:48.987: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:46:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cxxmk" for this suite.
Feb 18 04:47:11.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:47:11.083: INFO: namespace: e2e-tests-kubectl-cxxmk, resource: bindings, ignored listing per whitelist
Feb 18 04:47:11.125: INFO: namespace e2e-tests-kubectl-cxxmk deletion completed in 22.132589138s

• [SLOW TEST:29.397 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:47:11.125: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-410567b3-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:47:11.371: INFO: Waiting up to 5m0s for pod "pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-fm7vn" to be "success or failure"
Feb 18 04:47:11.453: INFO: Pod "pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 81.529387ms
Feb 18 04:47:13.458: INFO: Pod "pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086671208s
STEP: Saw pod success
Feb 18 04:47:13.458: INFO: Pod "pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:47:13.462: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:47:13.490: INFO: Waiting for pod pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:47:13.493: INFO: Pod pod-configmaps-410638ee-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:47:13.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fm7vn" for this suite.
Feb 18 04:47:19.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:47:19.586: INFO: namespace: e2e-tests-configmap-fm7vn, resource: bindings, ignored listing per whitelist
Feb 18 04:47:19.630: INFO: namespace e2e-tests-configmap-fm7vn deletion completed in 6.131333324s

• [SLOW TEST:8.504 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:47:19.630: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-gcdnp/configmap-test-46026be5-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:47:19.738: INFO: Waiting up to 5m0s for pod "pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-gcdnp" to be "success or failure"
Feb 18 04:47:19.743: INFO: Pod "pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.345765ms
Feb 18 04:47:21.748: INFO: Pod "pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00953833s
STEP: Saw pod success
Feb 18 04:47:21.748: INFO: Pod "pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:47:21.751: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1 container env-test: <nil>
STEP: delete the pod
Feb 18 04:47:21.776: INFO: Waiting for pod pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:47:21.780: INFO: Pod pod-configmaps-460313ef-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:47:21.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gcdnp" for this suite.
Feb 18 04:47:27.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:47:27.900: INFO: namespace: e2e-tests-configmap-gcdnp, resource: bindings, ignored listing per whitelist
Feb 18 04:47:27.956: INFO: namespace e2e-tests-configmap-gcdnp deletion completed in 6.171117259s

• [SLOW TEST:8.326 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:47:27.956: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-5xgtw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-5xgtw
STEP: Deleting pre-stop pod
Feb 18 04:47:41.126: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:47:41.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-5xgtw" for this suite.
Feb 18 04:48:19.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:48:19.376: INFO: namespace: e2e-tests-prestop-5xgtw, resource: bindings, ignored listing per whitelist
Feb 18 04:48:19.381: INFO: namespace e2e-tests-prestop-5xgtw deletion completed in 38.229565503s

• [SLOW TEST:51.425 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:48:19.381: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:48:19.483: INFO: Waiting up to 5m0s for pod "downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-downward-api-7pq6h" to be "success or failure"
Feb 18 04:48:19.487: INFO: Pod "downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.868855ms
Feb 18 04:48:21.493: INFO: Pod "downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009158224s
STEP: Saw pod success
Feb 18 04:48:21.493: INFO: Pod "downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:48:21.497: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:48:21.526: INFO: Waiting for pod downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:48:21.530: INFO: Pod downwardapi-volume-699f2e17-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:48:21.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7pq6h" for this suite.
Feb 18 04:48:27.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:48:27.573: INFO: namespace: e2e-tests-downward-api-7pq6h, resource: bindings, ignored listing per whitelist
Feb 18 04:48:27.697: INFO: namespace e2e-tests-downward-api-7pq6h deletion completed in 6.162211112s

• [SLOW TEST:8.316 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:48:27.698: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 18 04:48:27.898: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6ea24434-3338-11e9-9a73-8a88965a7424", Controller:(*bool)(0xc00139e1fa), BlockOwnerDeletion:(*bool)(0xc00139e1fb)}}
Feb 18 04:48:27.907: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6e9ee6ae-3338-11e9-9a73-8a88965a7424", Controller:(*bool)(0xc001e5c292), BlockOwnerDeletion:(*bool)(0xc001e5c293)}}
Feb 18 04:48:27.916: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6ea023f4-3338-11e9-9a73-8a88965a7424", Controller:(*bool)(0xc00139e3ea), BlockOwnerDeletion:(*bool)(0xc00139e3eb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:48:32.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lkndb" for this suite.
Feb 18 04:48:38.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:48:38.995: INFO: namespace: e2e-tests-gc-lkndb, resource: bindings, ignored listing per whitelist
Feb 18 04:48:39.081: INFO: namespace e2e-tests-gc-lkndb deletion completed in 6.141072722s

• [SLOW TEST:11.383 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:48:39.081: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-zstk9
I0218 04:48:39.318870      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-zstk9, replica count: 1
I0218 04:48:40.369493      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0218 04:48:41.369754      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 18 04:48:41.491: INFO: Created: latency-svc-rvw6z
Feb 18 04:48:41.504: INFO: Got endpoints: latency-svc-rvw6z [34.205144ms]
Feb 18 04:48:41.525: INFO: Created: latency-svc-6pmgj
Feb 18 04:48:41.531: INFO: Got endpoints: latency-svc-6pmgj [27.00236ms]
Feb 18 04:48:41.568: INFO: Created: latency-svc-w9s7w
Feb 18 04:48:41.576: INFO: Got endpoints: latency-svc-w9s7w [72.339997ms]
Feb 18 04:48:41.580: INFO: Created: latency-svc-7kjrj
Feb 18 04:48:41.587: INFO: Got endpoints: latency-svc-7kjrj [82.702804ms]
Feb 18 04:48:41.659: INFO: Created: latency-svc-hr4d6
Feb 18 04:48:41.671: INFO: Got endpoints: latency-svc-hr4d6 [166.92986ms]
Feb 18 04:48:41.680: INFO: Created: latency-svc-kls72
Feb 18 04:48:41.689: INFO: Got endpoints: latency-svc-kls72 [184.561529ms]
Feb 18 04:48:41.698: INFO: Created: latency-svc-wcn5t
Feb 18 04:48:41.702: INFO: Got endpoints: latency-svc-wcn5t [197.194992ms]
Feb 18 04:48:41.756: INFO: Created: latency-svc-r5zbw
Feb 18 04:48:41.764: INFO: Got endpoints: latency-svc-r5zbw [259.256594ms]
Feb 18 04:48:41.780: INFO: Created: latency-svc-tc6jg
Feb 18 04:48:41.786: INFO: Got endpoints: latency-svc-tc6jg [281.462215ms]
Feb 18 04:48:41.811: INFO: Created: latency-svc-d66r8
Feb 18 04:48:41.816: INFO: Got endpoints: latency-svc-d66r8 [311.749924ms]
Feb 18 04:48:41.826: INFO: Created: latency-svc-5pvz7
Feb 18 04:48:41.831: INFO: Got endpoints: latency-svc-5pvz7 [326.158016ms]
Feb 18 04:48:42.077: INFO: Created: latency-svc-h5w8f
Feb 18 04:48:42.083: INFO: Got endpoints: latency-svc-h5w8f [578.108618ms]
Feb 18 04:48:42.111: INFO: Created: latency-svc-brrnb
Feb 18 04:48:42.115: INFO: Got endpoints: latency-svc-brrnb [610.458571ms]
Feb 18 04:48:42.131: INFO: Created: latency-svc-xnrpp
Feb 18 04:48:42.135: INFO: Got endpoints: latency-svc-xnrpp [629.927121ms]
Feb 18 04:48:42.370: INFO: Created: latency-svc-d5hc6
Feb 18 04:48:42.379: INFO: Got endpoints: latency-svc-d5hc6 [874.21035ms]
Feb 18 04:48:42.391: INFO: Created: latency-svc-nh96n
Feb 18 04:48:42.395: INFO: Got endpoints: latency-svc-nh96n [890.257551ms]
Feb 18 04:48:42.405: INFO: Created: latency-svc-rcnt7
Feb 18 04:48:42.410: INFO: Got endpoints: latency-svc-rcnt7 [879.215612ms]
Feb 18 04:48:42.598: INFO: Created: latency-svc-bjdt5
Feb 18 04:48:42.598: INFO: Got endpoints: latency-svc-bjdt5 [1.021977313s]
Feb 18 04:48:42.603: INFO: Created: latency-svc-bbprt
Feb 18 04:48:42.608: INFO: Got endpoints: latency-svc-bbprt [1.020894692s]
Feb 18 04:48:42.672: INFO: Created: latency-svc-899v7
Feb 18 04:48:42.678: INFO: Got endpoints: latency-svc-899v7 [1.006676163s]
Feb 18 04:48:42.806: INFO: Created: latency-svc-kmmm7
Feb 18 04:48:42.812: INFO: Created: latency-svc-9g5nq
Feb 18 04:48:42.817: INFO: Got endpoints: latency-svc-9g5nq [1.115507151s]
Feb 18 04:48:42.818: INFO: Got endpoints: latency-svc-kmmm7 [1.128591058s]
Feb 18 04:48:42.827: INFO: Created: latency-svc-gjt6j
Feb 18 04:48:42.832: INFO: Got endpoints: latency-svc-gjt6j [1.068667382s]
Feb 18 04:48:42.971: INFO: Created: latency-svc-pzl5l
Feb 18 04:48:42.980: INFO: Got endpoints: latency-svc-pzl5l [1.193555115s]
Feb 18 04:48:43.029: INFO: Created: latency-svc-2kgxn
Feb 18 04:48:43.042: INFO: Got endpoints: latency-svc-2kgxn [1.225809839s]
Feb 18 04:48:43.059: INFO: Created: latency-svc-cvjtr
Feb 18 04:48:43.059: INFO: Got endpoints: latency-svc-cvjtr [1.227751098s]
Feb 18 04:48:43.067: INFO: Created: latency-svc-7swb2
Feb 18 04:48:43.076: INFO: Got endpoints: latency-svc-7swb2 [993.351785ms]
Feb 18 04:48:43.085: INFO: Created: latency-svc-p9jgp
Feb 18 04:48:43.098: INFO: Got endpoints: latency-svc-p9jgp [983.060792ms]
Feb 18 04:48:43.119: INFO: Created: latency-svc-zslx5
Feb 18 04:48:43.125: INFO: Got endpoints: latency-svc-zslx5 [48.782915ms]
Feb 18 04:48:43.156: INFO: Created: latency-svc-swqmq
Feb 18 04:48:43.162: INFO: Got endpoints: latency-svc-swqmq [1.02708189s]
Feb 18 04:48:43.184: INFO: Created: latency-svc-qczjf
Feb 18 04:48:43.189: INFO: Got endpoints: latency-svc-qczjf [809.738346ms]
Feb 18 04:48:43.204: INFO: Created: latency-svc-4p8kd
Feb 18 04:48:43.211: INFO: Got endpoints: latency-svc-4p8kd [815.896594ms]
Feb 18 04:48:43.223: INFO: Created: latency-svc-rcf58
Feb 18 04:48:43.235: INFO: Got endpoints: latency-svc-rcf58 [824.881167ms]
Feb 18 04:48:43.242: INFO: Created: latency-svc-whwhz
Feb 18 04:48:43.251: INFO: Got endpoints: latency-svc-whwhz [652.74489ms]
Feb 18 04:48:43.306: INFO: Created: latency-svc-rgr6x
Feb 18 04:48:43.312: INFO: Got endpoints: latency-svc-rgr6x [703.314677ms]
Feb 18 04:48:43.319: INFO: Created: latency-svc-hnsd2
Feb 18 04:48:43.325: INFO: Got endpoints: latency-svc-hnsd2 [646.459789ms]
Feb 18 04:48:43.344: INFO: Created: latency-svc-pq649
Feb 18 04:48:43.349: INFO: Got endpoints: latency-svc-pq649 [531.820743ms]
Feb 18 04:48:43.358: INFO: Created: latency-svc-t9jdx
Feb 18 04:48:43.362: INFO: Got endpoints: latency-svc-t9jdx [544.172714ms]
Feb 18 04:48:43.373: INFO: Created: latency-svc-jjmk4
Feb 18 04:48:43.379: INFO: Got endpoints: latency-svc-jjmk4 [546.570568ms]
Feb 18 04:48:43.387: INFO: Created: latency-svc-z7dhj
Feb 18 04:48:43.393: INFO: Got endpoints: latency-svc-z7dhj [413.094996ms]
Feb 18 04:48:43.401: INFO: Created: latency-svc-6qwwm
Feb 18 04:48:43.414: INFO: Got endpoints: latency-svc-6qwwm [371.465591ms]
Feb 18 04:48:43.427: INFO: Created: latency-svc-v88zt
Feb 18 04:48:43.427: INFO: Got endpoints: latency-svc-v88zt [368.726212ms]
Feb 18 04:48:43.436: INFO: Created: latency-svc-gtnnn
Feb 18 04:48:43.440: INFO: Got endpoints: latency-svc-gtnnn [341.845738ms]
Feb 18 04:48:43.456: INFO: Created: latency-svc-q4t5c
Feb 18 04:48:43.461: INFO: Got endpoints: latency-svc-q4t5c [335.99665ms]
Feb 18 04:48:43.474: INFO: Created: latency-svc-glrlj
Feb 18 04:48:43.475: INFO: Got endpoints: latency-svc-glrlj [313.079327ms]
Feb 18 04:48:43.494: INFO: Created: latency-svc-6lq7z
Feb 18 04:48:43.498: INFO: Got endpoints: latency-svc-6lq7z [309.277176ms]
Feb 18 04:48:43.512: INFO: Created: latency-svc-trdhx
Feb 18 04:48:43.521: INFO: Got endpoints: latency-svc-trdhx [309.847568ms]
Feb 18 04:48:43.526: INFO: Created: latency-svc-tt5ck
Feb 18 04:48:43.530: INFO: Got endpoints: latency-svc-tt5ck [294.596326ms]
Feb 18 04:48:43.545: INFO: Created: latency-svc-cgh8j
Feb 18 04:48:43.555: INFO: Got endpoints: latency-svc-cgh8j [303.712313ms]
Feb 18 04:48:43.576: INFO: Created: latency-svc-x28jf
Feb 18 04:48:43.585: INFO: Got endpoints: latency-svc-x28jf [272.91994ms]
Feb 18 04:48:43.597: INFO: Created: latency-svc-46jbr
Feb 18 04:48:43.603: INFO: Got endpoints: latency-svc-46jbr [278.742013ms]
Feb 18 04:48:43.619: INFO: Created: latency-svc-xv2n6
Feb 18 04:48:43.632: INFO: Got endpoints: latency-svc-xv2n6 [283.048683ms]
Feb 18 04:48:43.638: INFO: Created: latency-svc-kkkzh
Feb 18 04:48:43.644: INFO: Got endpoints: latency-svc-kkkzh [282.088235ms]
Feb 18 04:48:43.663: INFO: Created: latency-svc-s5rcs
Feb 18 04:48:43.713: INFO: Got endpoints: latency-svc-s5rcs [334.325382ms]
Feb 18 04:48:43.717: INFO: Created: latency-svc-f8g7t
Feb 18 04:48:43.748: INFO: Created: latency-svc-kd2ng
Feb 18 04:48:43.778: INFO: Got endpoints: latency-svc-kd2ng [364.601396ms]
Feb 18 04:48:43.779: INFO: Got endpoints: latency-svc-f8g7t [385.65479ms]
Feb 18 04:48:43.784: INFO: Created: latency-svc-p2fbv
Feb 18 04:48:43.808: INFO: Got endpoints: latency-svc-p2fbv [380.99041ms]
Feb 18 04:48:43.830: INFO: Created: latency-svc-vrgl7
Feb 18 04:48:43.838: INFO: Got endpoints: latency-svc-vrgl7 [397.73649ms]
Feb 18 04:48:43.877: INFO: Created: latency-svc-7tdcr
Feb 18 04:48:43.882: INFO: Got endpoints: latency-svc-7tdcr [420.89224ms]
Feb 18 04:48:43.889: INFO: Created: latency-svc-cxgx4
Feb 18 04:48:43.895: INFO: Got endpoints: latency-svc-cxgx4 [419.52175ms]
Feb 18 04:48:43.904: INFO: Created: latency-svc-cr9sv
Feb 18 04:48:43.905: INFO: Got endpoints: latency-svc-cr9sv [406.616726ms]
Feb 18 04:48:43.911: INFO: Created: latency-svc-f8crc
Feb 18 04:48:43.916: INFO: Got endpoints: latency-svc-f8crc [394.926787ms]
Feb 18 04:48:43.928: INFO: Created: latency-svc-sc7zf
Feb 18 04:48:43.931: INFO: Got endpoints: latency-svc-sc7zf [401.027713ms]
Feb 18 04:48:43.941: INFO: Created: latency-svc-hdvqh
Feb 18 04:48:43.945: INFO: Got endpoints: latency-svc-hdvqh [390.138244ms]
Feb 18 04:48:43.960: INFO: Created: latency-svc-qxw64
Feb 18 04:48:43.975: INFO: Got endpoints: latency-svc-qxw64 [390.67672ms]
Feb 18 04:48:43.982: INFO: Created: latency-svc-gtvh7
Feb 18 04:48:43.986: INFO: Got endpoints: latency-svc-gtvh7 [382.717107ms]
Feb 18 04:48:43.991: INFO: Created: latency-svc-g65gm
Feb 18 04:48:43.996: INFO: Got endpoints: latency-svc-g65gm [363.779913ms]
Feb 18 04:48:44.003: INFO: Created: latency-svc-cvq66
Feb 18 04:48:44.011: INFO: Got endpoints: latency-svc-cvq66 [366.589937ms]
Feb 18 04:48:44.017: INFO: Created: latency-svc-mclbl
Feb 18 04:48:44.023: INFO: Got endpoints: latency-svc-mclbl [309.37146ms]
Feb 18 04:48:44.031: INFO: Created: latency-svc-gqt9g
Feb 18 04:48:44.039: INFO: Got endpoints: latency-svc-gqt9g [260.872487ms]
Feb 18 04:48:44.065: INFO: Created: latency-svc-ngwv4
Feb 18 04:48:44.070: INFO: Got endpoints: latency-svc-ngwv4 [291.376433ms]
Feb 18 04:48:44.093: INFO: Created: latency-svc-22wc4
Feb 18 04:48:44.104: INFO: Got endpoints: latency-svc-22wc4 [295.86121ms]
Feb 18 04:48:44.130: INFO: Created: latency-svc-5z7kg
Feb 18 04:48:44.140: INFO: Got endpoints: latency-svc-5z7kg [301.609248ms]
Feb 18 04:48:44.150: INFO: Created: latency-svc-m5plb
Feb 18 04:48:44.151: INFO: Got endpoints: latency-svc-m5plb [268.771626ms]
Feb 18 04:48:44.173: INFO: Created: latency-svc-9xmsd
Feb 18 04:48:44.175: INFO: Got endpoints: latency-svc-9xmsd [280.055108ms]
Feb 18 04:48:44.193: INFO: Created: latency-svc-rrbhx
Feb 18 04:48:44.199: INFO: Got endpoints: latency-svc-rrbhx [294.221363ms]
Feb 18 04:48:44.207: INFO: Created: latency-svc-w7ppz
Feb 18 04:48:44.214: INFO: Got endpoints: latency-svc-w7ppz [298.239191ms]
Feb 18 04:48:44.223: INFO: Created: latency-svc-wkc9r
Feb 18 04:48:44.238: INFO: Got endpoints: latency-svc-wkc9r [306.812986ms]
Feb 18 04:48:44.248: INFO: Created: latency-svc-n7d2w
Feb 18 04:48:44.263: INFO: Created: latency-svc-vrrj9
Feb 18 04:48:44.281: INFO: Created: latency-svc-kvx58
Feb 18 04:48:44.340: INFO: Got endpoints: latency-svc-n7d2w [394.367516ms]
Feb 18 04:48:44.341: INFO: Got endpoints: latency-svc-vrrj9 [365.248593ms]
Feb 18 04:48:44.346: INFO: Created: latency-svc-l9lh7
Feb 18 04:48:44.414: INFO: Got endpoints: latency-svc-kvx58 [427.53935ms]
Feb 18 04:48:44.419: INFO: Created: latency-svc-6ws9b
Feb 18 04:48:44.430: INFO: Created: latency-svc-mt97f
Feb 18 04:48:44.435: INFO: Got endpoints: latency-svc-l9lh7 [438.945499ms]
Feb 18 04:48:44.443: INFO: Created: latency-svc-6hxhb
Feb 18 04:48:44.453: INFO: Created: latency-svc-tdw7j
Feb 18 04:48:44.464: INFO: Created: latency-svc-p6pqq
Feb 18 04:48:44.476: INFO: Created: latency-svc-z99v8
Feb 18 04:48:44.488: INFO: Created: latency-svc-7hzst
Feb 18 04:48:44.489: INFO: Got endpoints: latency-svc-6ws9b [477.784128ms]
Feb 18 04:48:44.500: INFO: Created: latency-svc-dqhlz
Feb 18 04:48:44.513: INFO: Created: latency-svc-kttdj
Feb 18 04:48:44.534: INFO: Created: latency-svc-hkpj7
Feb 18 04:48:44.535: INFO: Got endpoints: latency-svc-mt97f [512.094228ms]
Feb 18 04:48:44.549: INFO: Created: latency-svc-rcrq7
Feb 18 04:48:44.560: INFO: Created: latency-svc-nbvph
Feb 18 04:48:44.571: INFO: Created: latency-svc-jbdgj
Feb 18 04:48:44.581: INFO: Created: latency-svc-r8gp9
Feb 18 04:48:44.585: INFO: Got endpoints: latency-svc-6hxhb [545.694151ms]
Feb 18 04:48:44.612: INFO: Created: latency-svc-lph6f
Feb 18 04:48:44.628: INFO: Created: latency-svc-jml62
Feb 18 04:48:44.643: INFO: Got endpoints: latency-svc-tdw7j [573.323029ms]
Feb 18 04:48:44.646: INFO: Created: latency-svc-d22v7
Feb 18 04:48:44.662: INFO: Created: latency-svc-tdgdf
Feb 18 04:48:44.675: INFO: Created: latency-svc-82xbc
Feb 18 04:48:44.685: INFO: Got endpoints: latency-svc-p6pqq [580.731116ms]
Feb 18 04:48:44.700: INFO: Created: latency-svc-8j65q
Feb 18 04:48:44.736: INFO: Got endpoints: latency-svc-z99v8 [595.831349ms]
Feb 18 04:48:44.751: INFO: Created: latency-svc-knwdg
Feb 18 04:48:44.784: INFO: Got endpoints: latency-svc-7hzst [633.363098ms]
Feb 18 04:48:44.802: INFO: Created: latency-svc-4whvc
Feb 18 04:48:44.835: INFO: Got endpoints: latency-svc-dqhlz [660.205101ms]
Feb 18 04:48:44.850: INFO: Created: latency-svc-ws2qb
Feb 18 04:48:44.885: INFO: Got endpoints: latency-svc-kttdj [685.952716ms]
Feb 18 04:48:44.904: INFO: Created: latency-svc-4kn8n
Feb 18 04:48:44.937: INFO: Got endpoints: latency-svc-hkpj7 [722.544845ms]
Feb 18 04:48:44.953: INFO: Created: latency-svc-btbj8
Feb 18 04:48:44.985: INFO: Got endpoints: latency-svc-rcrq7 [747.461633ms]
Feb 18 04:48:45.014: INFO: Created: latency-svc-6549r
Feb 18 04:48:45.035: INFO: Got endpoints: latency-svc-nbvph [695.601408ms]
Feb 18 04:48:45.052: INFO: Created: latency-svc-jgbpz
Feb 18 04:48:45.085: INFO: Got endpoints: latency-svc-jbdgj [744.650292ms]
Feb 18 04:48:45.101: INFO: Created: latency-svc-ps6vj
Feb 18 04:48:45.136: INFO: Got endpoints: latency-svc-r8gp9 [721.693205ms]
Feb 18 04:48:45.148: INFO: Created: latency-svc-mnskl
Feb 18 04:48:45.184: INFO: Got endpoints: latency-svc-lph6f [749.231992ms]
Feb 18 04:48:45.199: INFO: Created: latency-svc-6622w
Feb 18 04:48:45.236: INFO: Got endpoints: latency-svc-jml62 [746.836237ms]
Feb 18 04:48:45.303: INFO: Got endpoints: latency-svc-d22v7 [768.111562ms]
Feb 18 04:48:45.306: INFO: Created: latency-svc-948vb
Feb 18 04:48:45.321: INFO: Created: latency-svc-qjshl
Feb 18 04:48:45.335: INFO: Got endpoints: latency-svc-tdgdf [749.967217ms]
Feb 18 04:48:45.349: INFO: Created: latency-svc-m77p6
Feb 18 04:48:45.386: INFO: Got endpoints: latency-svc-82xbc [742.640102ms]
Feb 18 04:48:45.407: INFO: Created: latency-svc-59g88
Feb 18 04:48:45.436: INFO: Got endpoints: latency-svc-8j65q [750.474327ms]
Feb 18 04:48:45.450: INFO: Created: latency-svc-ncz7h
Feb 18 04:48:45.485: INFO: Got endpoints: latency-svc-knwdg [749.19431ms]
Feb 18 04:48:45.509: INFO: Created: latency-svc-bhqhb
Feb 18 04:48:45.535: INFO: Got endpoints: latency-svc-4whvc [750.203475ms]
Feb 18 04:48:45.550: INFO: Created: latency-svc-rvcl6
Feb 18 04:48:45.586: INFO: Got endpoints: latency-svc-ws2qb [750.583537ms]
Feb 18 04:48:45.605: INFO: Created: latency-svc-z86k7
Feb 18 04:48:45.635: INFO: Got endpoints: latency-svc-4kn8n [749.679228ms]
Feb 18 04:48:45.657: INFO: Created: latency-svc-mtkkb
Feb 18 04:48:45.685: INFO: Got endpoints: latency-svc-btbj8 [747.889638ms]
Feb 18 04:48:45.722: INFO: Created: latency-svc-56ftx
Feb 18 04:48:45.735: INFO: Got endpoints: latency-svc-6549r [749.750125ms]
Feb 18 04:48:45.759: INFO: Created: latency-svc-mjsft
Feb 18 04:48:45.784: INFO: Got endpoints: latency-svc-jgbpz [748.744316ms]
Feb 18 04:48:45.807: INFO: Created: latency-svc-vvt9z
Feb 18 04:48:45.836: INFO: Got endpoints: latency-svc-ps6vj [750.390322ms]
Feb 18 04:48:45.852: INFO: Created: latency-svc-z9fxd
Feb 18 04:48:45.886: INFO: Got endpoints: latency-svc-mnskl [750.697268ms]
Feb 18 04:48:45.904: INFO: Created: latency-svc-mjkkq
Feb 18 04:48:45.936: INFO: Got endpoints: latency-svc-6622w [751.284508ms]
Feb 18 04:48:45.956: INFO: Created: latency-svc-j2vv7
Feb 18 04:48:45.986: INFO: Got endpoints: latency-svc-948vb [750.882376ms]
Feb 18 04:48:46.010: INFO: Created: latency-svc-r56bq
Feb 18 04:48:46.035: INFO: Got endpoints: latency-svc-qjshl [731.573436ms]
Feb 18 04:48:46.052: INFO: Created: latency-svc-lcpht
Feb 18 04:48:46.085: INFO: Got endpoints: latency-svc-m77p6 [750.098879ms]
Feb 18 04:48:46.105: INFO: Created: latency-svc-jc5gh
Feb 18 04:48:46.138: INFO: Got endpoints: latency-svc-59g88 [751.976016ms]
Feb 18 04:48:46.156: INFO: Created: latency-svc-q54tg
Feb 18 04:48:46.190: INFO: Got endpoints: latency-svc-ncz7h [754.602338ms]
Feb 18 04:48:46.216: INFO: Created: latency-svc-q45pp
Feb 18 04:48:46.235: INFO: Got endpoints: latency-svc-bhqhb [750.338947ms]
Feb 18 04:48:46.272: INFO: Created: latency-svc-l4z5j
Feb 18 04:48:46.285: INFO: Got endpoints: latency-svc-rvcl6 [750.428868ms]
Feb 18 04:48:46.301: INFO: Created: latency-svc-gw6w8
Feb 18 04:48:46.336: INFO: Got endpoints: latency-svc-z86k7 [750.590474ms]
Feb 18 04:48:46.354: INFO: Created: latency-svc-26dr4
Feb 18 04:48:46.386: INFO: Got endpoints: latency-svc-mtkkb [750.555902ms]
Feb 18 04:48:46.403: INFO: Created: latency-svc-62798
Feb 18 04:48:46.435: INFO: Got endpoints: latency-svc-56ftx [750.300254ms]
Feb 18 04:48:46.455: INFO: Created: latency-svc-9lxhf
Feb 18 04:48:46.487: INFO: Got endpoints: latency-svc-mjsft [751.238324ms]
Feb 18 04:48:46.506: INFO: Created: latency-svc-mbc5g
Feb 18 04:48:46.535: INFO: Got endpoints: latency-svc-vvt9z [750.954618ms]
Feb 18 04:48:46.552: INFO: Created: latency-svc-dvgzx
Feb 18 04:48:46.587: INFO: Got endpoints: latency-svc-z9fxd [751.059803ms]
Feb 18 04:48:46.606: INFO: Created: latency-svc-9bb7c
Feb 18 04:48:46.635: INFO: Got endpoints: latency-svc-mjkkq [748.454438ms]
Feb 18 04:48:46.653: INFO: Created: latency-svc-44kzd
Feb 18 04:48:46.685: INFO: Got endpoints: latency-svc-j2vv7 [749.555032ms]
Feb 18 04:48:46.713: INFO: Created: latency-svc-4xrlw
Feb 18 04:48:46.734: INFO: Got endpoints: latency-svc-r56bq [747.698896ms]
Feb 18 04:48:46.755: INFO: Created: latency-svc-vr7ls
Feb 18 04:48:46.787: INFO: Got endpoints: latency-svc-lcpht [751.713579ms]
Feb 18 04:48:46.852: INFO: Got endpoints: latency-svc-jc5gh [766.609182ms]
Feb 18 04:48:46.871: INFO: Created: latency-svc-hvwc6
Feb 18 04:48:46.946: INFO: Got endpoints: latency-svc-q54tg [807.791112ms]
Feb 18 04:48:46.946: INFO: Got endpoints: latency-svc-q45pp [755.60309ms]
Feb 18 04:48:46.952: INFO: Created: latency-svc-59pw9
Feb 18 04:48:46.996: INFO: Got endpoints: latency-svc-l4z5j [760.099706ms]
Feb 18 04:48:46.997: INFO: Created: latency-svc-vgwzj
Feb 18 04:48:47.028: INFO: Created: latency-svc-sk2c9
Feb 18 04:48:47.162: INFO: Got endpoints: latency-svc-26dr4 [825.748287ms]
Feb 18 04:48:47.162: INFO: Got endpoints: latency-svc-gw6w8 [877.06636ms]
Feb 18 04:48:47.164: INFO: Got endpoints: latency-svc-62798 [777.794779ms]
Feb 18 04:48:47.175: INFO: Created: latency-svc-q2vzc
Feb 18 04:48:47.188: INFO: Got endpoints: latency-svc-9lxhf [752.806705ms]
Feb 18 04:48:47.194: INFO: Created: latency-svc-24hbr
Feb 18 04:48:47.206: INFO: Created: latency-svc-d55sw
Feb 18 04:48:47.218: INFO: Created: latency-svc-mhtkn
Feb 18 04:48:47.230: INFO: Created: latency-svc-7vtk4
Feb 18 04:48:47.236: INFO: Got endpoints: latency-svc-mbc5g [749.040004ms]
Feb 18 04:48:47.251: INFO: Created: latency-svc-qthlj
Feb 18 04:48:47.286: INFO: Got endpoints: latency-svc-dvgzx [750.755926ms]
Feb 18 04:48:47.319: INFO: Created: latency-svc-29qdb
Feb 18 04:48:47.335: INFO: Got endpoints: latency-svc-9bb7c [747.693793ms]
Feb 18 04:48:47.349: INFO: Created: latency-svc-54hbr
Feb 18 04:48:47.385: INFO: Got endpoints: latency-svc-44kzd [749.939217ms]
Feb 18 04:48:47.402: INFO: Created: latency-svc-ck9gh
Feb 18 04:48:47.435: INFO: Got endpoints: latency-svc-4xrlw [749.016504ms]
Feb 18 04:48:47.451: INFO: Created: latency-svc-8npm7
Feb 18 04:48:47.485: INFO: Got endpoints: latency-svc-vr7ls [750.857789ms]
Feb 18 04:48:47.498: INFO: Created: latency-svc-67jrr
Feb 18 04:48:47.534: INFO: Got endpoints: latency-svc-hvwc6 [747.625396ms]
Feb 18 04:48:47.551: INFO: Created: latency-svc-qtlvm
Feb 18 04:48:47.586: INFO: Got endpoints: latency-svc-59pw9 [733.513661ms]
Feb 18 04:48:47.602: INFO: Created: latency-svc-d66vc
Feb 18 04:48:47.639: INFO: Got endpoints: latency-svc-vgwzj [693.115349ms]
Feb 18 04:48:47.661: INFO: Created: latency-svc-gdp6t
Feb 18 04:48:47.685: INFO: Got endpoints: latency-svc-sk2c9 [738.575381ms]
Feb 18 04:48:47.712: INFO: Created: latency-svc-9b6rz
Feb 18 04:48:47.792: INFO: Got endpoints: latency-svc-24hbr [629.462366ms]
Feb 18 04:48:47.792: INFO: Got endpoints: latency-svc-q2vzc [796.403711ms]
Feb 18 04:48:47.818: INFO: Created: latency-svc-49g5g
Feb 18 04:48:47.830: INFO: Created: latency-svc-bz6c2
Feb 18 04:48:47.836: INFO: Got endpoints: latency-svc-d55sw [673.667489ms]
Feb 18 04:48:47.853: INFO: Created: latency-svc-mx7nd
Feb 18 04:48:47.886: INFO: Got endpoints: latency-svc-mhtkn [722.495886ms]
Feb 18 04:48:47.963: INFO: Got endpoints: latency-svc-7vtk4 [774.658137ms]
Feb 18 04:48:47.964: INFO: Created: latency-svc-pfw5t
Feb 18 04:48:48.192: INFO: Got endpoints: latency-svc-qthlj [956.233738ms]
Feb 18 04:48:48.194: INFO: Got endpoints: latency-svc-29qdb [907.637214ms]
Feb 18 04:48:48.194: INFO: Created: latency-svc-8xqrw
Feb 18 04:48:48.196: INFO: Got endpoints: latency-svc-8npm7 [761.044491ms]
Feb 18 04:48:48.196: INFO: Got endpoints: latency-svc-ck9gh [810.866033ms]
Feb 18 04:48:48.196: INFO: Got endpoints: latency-svc-54hbr [861.023845ms]
Feb 18 04:48:48.230: INFO: Created: latency-svc-lthkw
Feb 18 04:48:48.243: INFO: Got endpoints: latency-svc-67jrr [757.317325ms]
Feb 18 04:48:48.451: INFO: Got endpoints: latency-svc-d66vc [865.396688ms]
Feb 18 04:48:48.451: INFO: Got endpoints: latency-svc-qtlvm [916.830595ms]
Feb 18 04:48:48.455: INFO: Created: latency-svc-5jkxh
Feb 18 04:48:48.458: INFO: Got endpoints: latency-svc-gdp6t [818.355693ms]
Feb 18 04:48:48.461: INFO: Got endpoints: latency-svc-9b6rz [776.145607ms]
Feb 18 04:48:48.475: INFO: Created: latency-svc-qx258
Feb 18 04:48:48.487: INFO: Got endpoints: latency-svc-49g5g [694.710891ms]
Feb 18 04:48:48.492: INFO: Created: latency-svc-wfshs
Feb 18 04:48:48.505: INFO: Created: latency-svc-x79fs
Feb 18 04:48:48.518: INFO: Created: latency-svc-tmfk9
Feb 18 04:48:48.534: INFO: Created: latency-svc-7hsjp
Feb 18 04:48:48.535: INFO: Got endpoints: latency-svc-bz6c2 [743.536719ms]
Feb 18 04:48:48.677: INFO: Got endpoints: latency-svc-pfw5t [790.6653ms]
Feb 18 04:48:48.677: INFO: Got endpoints: latency-svc-mx7nd [840.842576ms]
Feb 18 04:48:48.681: INFO: Created: latency-svc-jpwnf
Feb 18 04:48:48.684: INFO: Got endpoints: latency-svc-8xqrw [721.375113ms]
Feb 18 04:48:48.695: INFO: Created: latency-svc-rjhl7
Feb 18 04:48:48.710: INFO: Created: latency-svc-ftmkr
Feb 18 04:48:48.723: INFO: Created: latency-svc-d5445
Feb 18 04:48:48.740: INFO: Got endpoints: latency-svc-lthkw [547.849225ms]
Feb 18 04:48:48.742: INFO: Created: latency-svc-52ckn
Feb 18 04:48:48.755: INFO: Created: latency-svc-kw2f2
Feb 18 04:48:48.764: INFO: Created: latency-svc-rhbhb
Feb 18 04:48:48.785: INFO: Created: latency-svc-xqs49
Feb 18 04:48:48.792: INFO: Got endpoints: latency-svc-5jkxh [598.23464ms]
Feb 18 04:48:48.898: INFO: Got endpoints: latency-svc-wfshs [702.472775ms]
Feb 18 04:48:48.898: INFO: Created: latency-svc-tgxwg
Feb 18 04:48:48.898: INFO: Got endpoints: latency-svc-qx258 [702.676933ms]
Feb 18 04:48:49.068: INFO: Got endpoints: latency-svc-x79fs [872.135045ms]
Feb 18 04:48:49.071: INFO: Created: latency-svc-nbw47
Feb 18 04:48:49.072: INFO: Got endpoints: latency-svc-7hsjp [620.433983ms]
Feb 18 04:48:49.072: INFO: Got endpoints: latency-svc-tmfk9 [829.266512ms]
Feb 18 04:48:49.082: INFO: Created: latency-svc-prbgr
Feb 18 04:48:49.091: INFO: Got endpoints: latency-svc-jpwnf [639.71923ms]
Feb 18 04:48:49.104: INFO: Created: latency-svc-dt9w9
Feb 18 04:48:49.115: INFO: Created: latency-svc-4vzqk
Feb 18 04:48:49.138: INFO: Got endpoints: latency-svc-rjhl7 [680.540647ms]
Feb 18 04:48:49.139: INFO: Created: latency-svc-gcktw
Feb 18 04:48:49.148: INFO: Created: latency-svc-sjxhk
Feb 18 04:48:49.162: INFO: Created: latency-svc-cdsl7
Feb 18 04:48:49.178: INFO: Created: latency-svc-54f6p
Feb 18 04:48:49.185: INFO: Got endpoints: latency-svc-ftmkr [723.213704ms]
Feb 18 04:48:49.199: INFO: Created: latency-svc-9zvrp
Feb 18 04:48:49.235: INFO: Got endpoints: latency-svc-d5445 [748.335008ms]
Feb 18 04:48:49.365: INFO: Got endpoints: latency-svc-52ckn [829.849781ms]
Feb 18 04:48:49.365: INFO: Got endpoints: latency-svc-kw2f2 [688.404564ms]
Feb 18 04:48:49.369: INFO: Created: latency-svc-gz4zs
Feb 18 04:48:49.403: INFO: Got endpoints: latency-svc-rhbhb [726.444621ms]
Feb 18 04:48:49.403: INFO: Created: latency-svc-fq4m2
Feb 18 04:48:49.417: INFO: Created: latency-svc-xlxfx
Feb 18 04:48:49.428: INFO: Created: latency-svc-6f8xp
Feb 18 04:48:49.433: INFO: Got endpoints: latency-svc-xqs49 [748.997675ms]
Feb 18 04:48:49.447: INFO: Created: latency-svc-5gmqv
Feb 18 04:48:49.487: INFO: Got endpoints: latency-svc-tgxwg [747.093714ms]
Feb 18 04:48:49.505: INFO: Created: latency-svc-rxx6z
Feb 18 04:48:49.535: INFO: Got endpoints: latency-svc-nbw47 [742.746689ms]
Feb 18 04:48:49.554: INFO: Created: latency-svc-cfvmv
Feb 18 04:48:49.584: INFO: Got endpoints: latency-svc-prbgr [685.735172ms]
Feb 18 04:48:49.601: INFO: Created: latency-svc-4p6gc
Feb 18 04:48:49.819: INFO: Got endpoints: latency-svc-dt9w9 [920.845957ms]
Feb 18 04:48:49.819: INFO: Got endpoints: latency-svc-sjxhk [747.448701ms]
Feb 18 04:48:49.819: INFO: Got endpoints: latency-svc-4vzqk [751.291689ms]
Feb 18 04:48:49.819: INFO: Got endpoints: latency-svc-gcktw [747.59606ms]
Feb 18 04:48:49.837: INFO: Created: latency-svc-496qt
Feb 18 04:48:49.837: INFO: Got endpoints: latency-svc-cdsl7 [746.255772ms]
Feb 18 04:48:49.885: INFO: Got endpoints: latency-svc-54f6p [746.457302ms]
Feb 18 04:48:49.964: INFO: Got endpoints: latency-svc-9zvrp [778.80552ms]
Feb 18 04:48:49.984: INFO: Got endpoints: latency-svc-gz4zs [748.951323ms]
Feb 18 04:48:50.034: INFO: Got endpoints: latency-svc-fq4m2 [668.854872ms]
Feb 18 04:48:50.085: INFO: Got endpoints: latency-svc-xlxfx [719.883915ms]
Feb 18 04:48:50.136: INFO: Got endpoints: latency-svc-6f8xp [732.065961ms]
Feb 18 04:48:50.185: INFO: Got endpoints: latency-svc-5gmqv [751.38595ms]
Feb 18 04:48:50.242: INFO: Got endpoints: latency-svc-rxx6z [754.660336ms]
Feb 18 04:48:50.286: INFO: Got endpoints: latency-svc-cfvmv [750.981685ms]
Feb 18 04:48:50.336: INFO: Got endpoints: latency-svc-4p6gc [751.70061ms]
Feb 18 04:48:50.385: INFO: Got endpoints: latency-svc-496qt [565.706157ms]
Feb 18 04:48:50.385: INFO: Latencies: [27.00236ms 48.782915ms 72.339997ms 82.702804ms 166.92986ms 184.561529ms 197.194992ms 259.256594ms 260.872487ms 268.771626ms 272.91994ms 278.742013ms 280.055108ms 281.462215ms 282.088235ms 283.048683ms 291.376433ms 294.221363ms 294.596326ms 295.86121ms 298.239191ms 301.609248ms 303.712313ms 306.812986ms 309.277176ms 309.37146ms 309.847568ms 311.749924ms 313.079327ms 326.158016ms 334.325382ms 335.99665ms 341.845738ms 363.779913ms 364.601396ms 365.248593ms 366.589937ms 368.726212ms 371.465591ms 380.99041ms 382.717107ms 385.65479ms 390.138244ms 390.67672ms 394.367516ms 394.926787ms 397.73649ms 401.027713ms 406.616726ms 413.094996ms 419.52175ms 420.89224ms 427.53935ms 438.945499ms 477.784128ms 512.094228ms 531.820743ms 544.172714ms 545.694151ms 546.570568ms 547.849225ms 565.706157ms 573.323029ms 578.108618ms 580.731116ms 595.831349ms 598.23464ms 610.458571ms 620.433983ms 629.462366ms 629.927121ms 633.363098ms 639.71923ms 646.459789ms 652.74489ms 660.205101ms 668.854872ms 673.667489ms 680.540647ms 685.735172ms 685.952716ms 688.404564ms 693.115349ms 694.710891ms 695.601408ms 702.472775ms 702.676933ms 703.314677ms 719.883915ms 721.375113ms 721.693205ms 722.495886ms 722.544845ms 723.213704ms 726.444621ms 731.573436ms 732.065961ms 733.513661ms 738.575381ms 742.640102ms 742.746689ms 743.536719ms 744.650292ms 746.255772ms 746.457302ms 746.836237ms 747.093714ms 747.448701ms 747.461633ms 747.59606ms 747.625396ms 747.693793ms 747.698896ms 747.889638ms 748.335008ms 748.454438ms 748.744316ms 748.951323ms 748.997675ms 749.016504ms 749.040004ms 749.19431ms 749.231992ms 749.555032ms 749.679228ms 749.750125ms 749.939217ms 749.967217ms 750.098879ms 750.203475ms 750.300254ms 750.338947ms 750.390322ms 750.428868ms 750.474327ms 750.555902ms 750.583537ms 750.590474ms 750.697268ms 750.755926ms 750.857789ms 750.882376ms 750.954618ms 750.981685ms 751.059803ms 751.238324ms 751.284508ms 751.291689ms 751.38595ms 751.70061ms 751.713579ms 751.976016ms 752.806705ms 754.602338ms 754.660336ms 755.60309ms 757.317325ms 760.099706ms 761.044491ms 766.609182ms 768.111562ms 774.658137ms 776.145607ms 777.794779ms 778.80552ms 790.6653ms 796.403711ms 807.791112ms 809.738346ms 810.866033ms 815.896594ms 818.355693ms 824.881167ms 825.748287ms 829.266512ms 829.849781ms 840.842576ms 861.023845ms 865.396688ms 872.135045ms 874.21035ms 877.06636ms 879.215612ms 890.257551ms 907.637214ms 916.830595ms 920.845957ms 956.233738ms 983.060792ms 993.351785ms 1.006676163s 1.020894692s 1.021977313s 1.02708189s 1.068667382s 1.115507151s 1.128591058s 1.193555115s 1.225809839s 1.227751098s]
Feb 18 04:48:50.385: INFO: 50 %ile: 742.746689ms
Feb 18 04:48:50.385: INFO: 90 %ile: 874.21035ms
Feb 18 04:48:50.385: INFO: 99 %ile: 1.225809839s
Feb 18 04:48:50.385: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:48:50.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-zstk9" for this suite.
Feb 18 04:49:08.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:49:08.501: INFO: namespace: e2e-tests-svc-latency-zstk9, resource: bindings, ignored listing per whitelist
Feb 18 04:49:08.535: INFO: namespace e2e-tests-svc-latency-zstk9 deletion completed in 18.14137977s

• [SLOW TEST:29.454 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:49:08.535: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-86ed4bfe-3338-11e9-94e0-0a580af401c1
STEP: Creating a pod to test consume configMaps
Feb 18 04:49:08.652: INFO: Waiting up to 5m0s for pod "pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-configmap-wc7x5" to be "success or failure"
Feb 18 04:49:08.659: INFO: Pod "pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.949644ms
Feb 18 04:49:10.665: INFO: Pod "pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012895691s
Feb 18 04:49:12.671: INFO: Pod "pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018865309s
STEP: Saw pod success
Feb 18 04:49:12.671: INFO: Pod "pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:49:12.676: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 04:49:12.733: INFO: Waiting for pod pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:49:12.736: INFO: Pod pod-configmaps-86edfb55-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:49:12.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wc7x5" for this suite.
Feb 18 04:49:18.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:49:18.794: INFO: namespace: e2e-tests-configmap-wc7x5, resource: bindings, ignored listing per whitelist
Feb 18 04:49:18.871: INFO: namespace e2e-tests-configmap-wc7x5 deletion completed in 6.130288764s

• [SLOW TEST:10.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:49:18.871: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0218 04:49:20.078525      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 04:49:20.078: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:49:20.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lbzqx" for this suite.
Feb 18 04:49:26.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:49:26.138: INFO: namespace: e2e-tests-gc-lbzqx, resource: bindings, ignored listing per whitelist
Feb 18 04:49:26.222: INFO: namespace e2e-tests-gc-lbzqx deletion completed in 6.139903783s

• [SLOW TEST:7.351 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:49:26.222: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 18 04:49:26.333: INFO: Waiting up to 5m0s for pod "pod-9177c42e-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-emptydir-78nqj" to be "success or failure"
Feb 18 04:49:26.339: INFO: Pod "pod-9177c42e-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.357209ms
Feb 18 04:49:28.348: INFO: Pod "pod-9177c42e-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015247498s
Feb 18 04:49:30.353: INFO: Pod "pod-9177c42e-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020280031s
STEP: Saw pod success
Feb 18 04:49:30.354: INFO: Pod "pod-9177c42e-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:49:30.357: INFO: Trying to get logs from node xen16-168.ebaotech.com pod pod-9177c42e-3338-11e9-94e0-0a580af401c1 container test-container: <nil>
STEP: delete the pod
Feb 18 04:49:30.384: INFO: Waiting for pod pod-9177c42e-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:49:30.388: INFO: Pod pod-9177c42e-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:49:30.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-78nqj" for this suite.
Feb 18 04:49:36.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:49:36.475: INFO: namespace: e2e-tests-emptydir-78nqj, resource: bindings, ignored listing per whitelist
Feb 18 04:49:36.524: INFO: namespace e2e-tests-emptydir-78nqj deletion completed in 6.130884795s

• [SLOW TEST:10.301 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 18 04:49:36.524: INFO: >>> kubeConfig: /tmp/kubeconfig-647419003
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 18 04:49:36.625: INFO: Waiting up to 5m0s for pod "downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1" in namespace "e2e-tests-projected-dfdzt" to be "success or failure"
Feb 18 04:49:36.630: INFO: Pod "downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.61303ms
Feb 18 04:49:38.635: INFO: Pod "downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009703563s
STEP: Saw pod success
Feb 18 04:49:38.635: INFO: Pod "downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1" satisfied condition "success or failure"
Feb 18 04:49:38.639: INFO: Trying to get logs from node xen16-168.ebaotech.com pod downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1 container client-container: <nil>
STEP: delete the pod
Feb 18 04:49:38.662: INFO: Waiting for pod downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1 to disappear
Feb 18 04:49:38.665: INFO: Pod downwardapi-volume-979a6d36-3338-11e9-94e0-0a580af401c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 18 04:49:38.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dfdzt" for this suite.
Feb 18 04:49:44.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 04:49:44.727: INFO: namespace: e2e-tests-projected-dfdzt, resource: bindings, ignored listing per whitelist
Feb 18 04:49:44.805: INFO: namespace e2e-tests-projected-dfdzt deletion completed in 6.135085605s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SFeb 18 04:49:44.805: INFO: Running AfterSuite actions on all nodes
Feb 18 04:49:44.805: INFO: Running AfterSuite actions on node 1
Feb 18 04:49:44.805: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6052.860 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h40m54.72247612s
Test Suite Passed
