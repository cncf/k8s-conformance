I1207 06:08:22.583510      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-542553880
I1207 06:08:22.583692      15 e2e.go:224] Starting e2e run "7fda7ca2-f9e6-11e8-9cb3-16e60f4677a4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544162901 - Will randomize all specs
Will run 201 of 1946 specs

Dec  7 06:08:22.811: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 06:08:22.815: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  7 06:08:22.832: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  7 06:08:22.902: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  7 06:08:22.902: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Dec  7 06:08:22.902: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  7 06:08:22.913: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  7 06:08:22.913: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'cloud-controller-manager' (0 seconds elapsed)
Dec  7 06:08:22.913: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  7 06:08:22.913: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kubeadm-probe' (0 seconds elapsed)
Dec  7 06:08:22.913: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'pharmer-flex' (0 seconds elapsed)
Dec  7 06:08:22.913: INFO: e2e test version: v1.13.0
Dec  7 06:08:22.915: INFO: kube-apiserver version: v1.13.0
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:08:22.915: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename daemonsets
Dec  7 06:08:22.999: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:08:23.019: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec  7 06:08:23.028: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nmmt8/daemonsets","resourceVersion":"1579"},"items":null}

Dec  7 06:08:23.032: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nmmt8/pods","resourceVersion":"1579"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:08:23.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nmmt8" for this suite.
Dec  7 06:08:29.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:08:29.091: INFO: namespace: e2e-tests-daemonsets-nmmt8, resource: bindings, ignored listing per whitelist
Dec  7 06:08:29.140: INFO: namespace e2e-tests-daemonsets-nmmt8 deletion completed in 6.100575243s

S [SKIPPING] [6.225 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  7 06:08:23.019: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:08:29.146: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  7 06:08:29.750: INFO: created pod pod-service-account-defaultsa
Dec  7 06:08:29.750: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  7 06:08:29.770: INFO: created pod pod-service-account-mountsa
Dec  7 06:08:29.770: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  7 06:08:29.784: INFO: created pod pod-service-account-nomountsa
Dec  7 06:08:29.784: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  7 06:08:29.793: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  7 06:08:29.793: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  7 06:08:29.823: INFO: created pod pod-service-account-mountsa-mountspec
Dec  7 06:08:29.823: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  7 06:08:29.850: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  7 06:08:29.850: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  7 06:08:29.858: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  7 06:08:29.858: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  7 06:08:29.904: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  7 06:08:29.904: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  7 06:08:29.986: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  7 06:08:29.986: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:08:29.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-6nhlj" for this suite.
Dec  7 06:08:52.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:08:52.120: INFO: namespace: e2e-tests-svcaccounts-6nhlj, resource: bindings, ignored listing per whitelist
Dec  7 06:08:52.141: INFO: namespace e2e-tests-svcaccounts-6nhlj deletion completed in 22.137454069s

• [SLOW TEST:22.996 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:08:52.141: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-cmlcp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cmlcp to expose endpoints map[]
Dec  7 06:08:52.222: INFO: Get endpoints failed (4.831881ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  7 06:08:53.226: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cmlcp exposes endpoints map[] (1.008739694s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-cmlcp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cmlcp to expose endpoints map[pod1:[100]]
Dec  7 06:08:54.254: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cmlcp exposes endpoints map[pod1:[100]] (1.017737612s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-cmlcp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cmlcp to expose endpoints map[pod1:[100] pod2:[101]]
Dec  7 06:08:55.297: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cmlcp exposes endpoints map[pod1:[100] pod2:[101]] (1.031570875s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-cmlcp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cmlcp to expose endpoints map[pod2:[101]]
Dec  7 06:08:55.319: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cmlcp exposes endpoints map[pod2:[101]] (13.69676ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-cmlcp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-cmlcp to expose endpoints map[]
Dec  7 06:08:55.337: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-cmlcp exposes endpoints map[] (3.767722ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:08:55.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-cmlcp" for this suite.
Dec  7 06:09:17.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:09:17.501: INFO: namespace: e2e-tests-services-cmlcp, resource: bindings, ignored listing per whitelist
Dec  7 06:09:17.508: INFO: namespace e2e-tests-services-cmlcp deletion completed in 22.137762392s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:25.367 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:09:17.508: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-6b5kp.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-6b5kp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-6b5kp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-6b5kp.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-6b5kp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-6b5kp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  7 06:09:31.690: INFO: DNS probes using e2e-tests-dns-6b5kp/dns-test-a1205ef1-f9e6-11e8-9cb3-16e60f4677a4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:09:31.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-6b5kp" for this suite.
Dec  7 06:09:37.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:09:37.813: INFO: namespace: e2e-tests-dns-6b5kp, resource: bindings, ignored listing per whitelist
Dec  7 06:09:37.864: INFO: namespace e2e-tests-dns-6b5kp deletion completed in 6.134988848s

• [SLOW TEST:20.356 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:09:37.866: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:09:37.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-wfd82" to be "success or failure"
Dec  7 06:09:37.974: INFO: Pod "downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.8687ms
Dec  7 06:09:39.978: INFO: Pod "downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019274485s
STEP: Saw pod success
Dec  7 06:09:39.978: INFO: Pod "downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:09:39.980: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:09:40.019: INFO: Waiting for pod downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:09:40.073: INFO: Pod downwardapi-volume-ad43e87e-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:09:40.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wfd82" for this suite.
Dec  7 06:09:46.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:09:46.147: INFO: namespace: e2e-tests-downward-api-wfd82, resource: bindings, ignored listing per whitelist
Dec  7 06:09:46.196: INFO: namespace e2e-tests-downward-api-wfd82 deletion completed in 6.117047006s

• [SLOW TEST:8.331 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:09:46.196: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  7 06:09:46.270: INFO: Waiting up to 5m0s for pod "pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-qj2kn" to be "success or failure"
Dec  7 06:09:46.274: INFO: Pod "pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.544514ms
Dec  7 06:09:48.277: INFO: Pod "pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007227951s
Dec  7 06:09:50.281: INFO: Pod "pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010885796s
STEP: Saw pod success
Dec  7 06:09:50.281: INFO: Pod "pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:09:50.283: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:09:50.300: INFO: Waiting for pod pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:09:50.308: INFO: Pod pod-b2387f16-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:09:50.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qj2kn" for this suite.
Dec  7 06:09:56.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:09:56.343: INFO: namespace: e2e-tests-emptydir-qj2kn, resource: bindings, ignored listing per whitelist
Dec  7 06:09:56.407: INFO: namespace e2e-tests-emptydir-qj2kn deletion completed in 6.095578051s

• [SLOW TEST:10.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:09:56.408: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  7 06:09:56.477: INFO: Waiting up to 5m0s for pod "downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-s5k5k" to be "success or failure"
Dec  7 06:09:56.486: INFO: Pod "downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.165438ms
Dec  7 06:09:58.490: INFO: Pod "downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012381628s
Dec  7 06:10:00.492: INFO: Pod "downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01533528s
STEP: Saw pod success
Dec  7 06:10:00.493: INFO: Pod "downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:10:00.495: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 06:10:00.519: INFO: Waiting for pod downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:10:00.524: INFO: Pod downward-api-b84db21e-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:10:00.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s5k5k" for this suite.
Dec  7 06:10:06.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:10:06.550: INFO: namespace: e2e-tests-downward-api-s5k5k, resource: bindings, ignored listing per whitelist
Dec  7 06:10:06.655: INFO: namespace e2e-tests-downward-api-s5k5k deletion completed in 6.126012748s

• [SLOW TEST:10.247 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:10:06.655: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-g6ln
STEP: Creating a pod to test atomic-volume-subpath
Dec  7 06:10:06.763: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-g6ln" in namespace "e2e-tests-subpath-hb8fn" to be "success or failure"
Dec  7 06:10:06.778: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Pending", Reason="", readiness=false. Elapsed: 14.421623ms
Dec  7 06:10:08.782: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018719559s
Dec  7 06:10:10.786: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 4.022544594s
Dec  7 06:10:12.790: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 6.026258104s
Dec  7 06:10:14.794: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 8.030287919s
Dec  7 06:10:16.797: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 10.033830264s
Dec  7 06:10:18.801: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 12.03730991s
Dec  7 06:10:20.804: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 14.041173424s
Dec  7 06:10:22.808: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 16.044955803s
Dec  7 06:10:24.813: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 18.049235458s
Dec  7 06:10:26.816: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 20.052991346s
Dec  7 06:10:28.824: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Running", Reason="", readiness=false. Elapsed: 22.060602067s
Dec  7 06:10:30.827: INFO: Pod "pod-subpath-test-secret-g6ln": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.064087007s
STEP: Saw pod success
Dec  7 06:10:30.827: INFO: Pod "pod-subpath-test-secret-g6ln" satisfied condition "success or failure"
Dec  7 06:10:30.831: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-subpath-test-secret-g6ln container test-container-subpath-secret-g6ln: <nil>
STEP: delete the pod
Dec  7 06:10:30.858: INFO: Waiting for pod pod-subpath-test-secret-g6ln to disappear
Dec  7 06:10:30.879: INFO: Pod pod-subpath-test-secret-g6ln no longer exists
STEP: Deleting pod pod-subpath-test-secret-g6ln
Dec  7 06:10:30.879: INFO: Deleting pod "pod-subpath-test-secret-g6ln" in namespace "e2e-tests-subpath-hb8fn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:10:30.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hb8fn" for this suite.
Dec  7 06:10:36.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:10:36.955: INFO: namespace: e2e-tests-subpath-hb8fn, resource: bindings, ignored listing per whitelist
Dec  7 06:10:36.987: INFO: namespace e2e-tests-subpath-hb8fn deletion completed in 6.09853999s

• [SLOW TEST:30.332 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:10:36.987: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  7 06:10:41.097: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-d07f9e93-f9e6-11e8-9cb3-16e60f4677a4", GenerateName:"", Namespace:"e2e-tests-pods-w7ltg", SelfLink:"/api/v1/namespaces/e2e-tests-pods-w7ltg/pods/pod-submit-remove-d07f9e93-f9e6-11e8-9cb3-16e60f4677a4", UID:"d08051f8-f9e6-11e8-bee8-5a54dcfa39ab", ResourceVersion:"2099", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679759837, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"61910643"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.22/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-s8z9d", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00159ac00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-s8z9d", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001501cd8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"2gb-pool-qefm5t", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000830840), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001501d20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001501d80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001501d88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001501d8c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679759837, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679759840, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679759840, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679759837, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.132.155.16", PodIP:"192.168.1.22", StartTime:(*v1.Time)(0xc001447b00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001447b20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://fb1accfce5a60155f91874459dea5f130329546f415660241f43f549b2136f42"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:10:47.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-w7ltg" for this suite.
Dec  7 06:10:53.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:10:53.766: INFO: namespace: e2e-tests-pods-w7ltg, resource: bindings, ignored listing per whitelist
Dec  7 06:10:53.830: INFO: namespace e2e-tests-pods-w7ltg deletion completed in 6.096403384s

• [SLOW TEST:16.843 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:10:53.831: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  7 06:10:56.437: INFO: Successfully updated pod "pod-update-da880613-f9e6-11e8-9cb3-16e60f4677a4"
STEP: verifying the updated pod is in kubernetes
Dec  7 06:10:56.443: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:10:56.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h8fbm" for this suite.
Dec  7 06:11:18.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:11:18.531: INFO: namespace: e2e-tests-pods-h8fbm, resource: bindings, ignored listing per whitelist
Dec  7 06:11:18.577: INFO: namespace e2e-tests-pods-h8fbm deletion completed in 22.123774112s

• [SLOW TEST:24.746 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:11:18.579: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  7 06:11:18.655: INFO: Waiting up to 5m0s for pod "client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-containers-gds5k" to be "success or failure"
Dec  7 06:11:18.664: INFO: Pod "client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015081ms
Dec  7 06:11:20.667: INFO: Pod "client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011512918s
Dec  7 06:11:22.671: INFO: Pod "client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015031721s
STEP: Saw pod success
Dec  7 06:11:22.671: INFO: Pod "client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:11:22.673: INFO: Trying to get logs from node 2gb-pool-qefm5t pod client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:11:22.695: INFO: Waiting for pod client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:11:22.699: INFO: Pod client-containers-e9490dbf-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:11:22.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gds5k" for this suite.
Dec  7 06:11:28.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:11:28.807: INFO: namespace: e2e-tests-containers-gds5k, resource: bindings, ignored listing per whitelist
Dec  7 06:11:28.807: INFO: namespace e2e-tests-containers-gds5k deletion completed in 6.105647885s

• [SLOW TEST:10.229 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:11:28.809: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:11:28.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-scvkc'
Dec  7 06:11:29.146: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  7 06:11:29.146: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  7 06:11:29.165: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-59tmd]
Dec  7 06:11:29.165: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-59tmd" in namespace "e2e-tests-kubectl-scvkc" to be "running and ready"
Dec  7 06:11:29.170: INFO: Pod "e2e-test-nginx-rc-59tmd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.140173ms
Dec  7 06:11:31.174: INFO: Pod "e2e-test-nginx-rc-59tmd": Phase="Running", Reason="", readiness=true. Elapsed: 2.008499741s
Dec  7 06:11:31.174: INFO: Pod "e2e-test-nginx-rc-59tmd" satisfied condition "running and ready"
Dec  7 06:11:31.174: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-59tmd]
Dec  7 06:11:31.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-scvkc'
Dec  7 06:11:31.304: INFO: stderr: ""
Dec  7 06:11:31.304: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec  7 06:11:31.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-scvkc'
Dec  7 06:11:31.425: INFO: stderr: ""
Dec  7 06:11:31.425: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:11:31.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-scvkc" for this suite.
Dec  7 06:11:37.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:11:37.526: INFO: namespace: e2e-tests-kubectl-scvkc, resource: bindings, ignored listing per whitelist
Dec  7 06:11:37.528: INFO: namespace e2e-tests-kubectl-scvkc deletion completed in 6.093808348s

• [SLOW TEST:8.719 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:11:37.530: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  7 06:11:37.596: INFO: Waiting up to 5m0s for pod "client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-containers-gdk9d" to be "success or failure"
Dec  7 06:11:37.599: INFO: Pod "client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.134341ms
Dec  7 06:11:39.603: INFO: Pod "client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006973591s
STEP: Saw pod success
Dec  7 06:11:39.603: INFO: Pod "client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:11:39.607: INFO: Trying to get logs from node 2gb-pool-qefm5t pod client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:11:39.634: INFO: Waiting for pod client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:11:39.638: INFO: Pod client-containers-f4939b55-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:11:39.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gdk9d" for this suite.
Dec  7 06:11:45.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:11:45.676: INFO: namespace: e2e-tests-containers-gdk9d, resource: bindings, ignored listing per whitelist
Dec  7 06:11:45.765: INFO: namespace e2e-tests-containers-gdk9d deletion completed in 6.123135056s

• [SLOW TEST:8.236 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:11:45.767: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:11:45.865: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-j5t7f" to be "success or failure"
Dec  7 06:11:45.883: INFO: Pod "downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.964679ms
Dec  7 06:11:47.886: INFO: Pod "downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02162878s
STEP: Saw pod success
Dec  7 06:11:47.886: INFO: Pod "downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:11:47.888: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:11:47.921: INFO: Waiting for pod downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:11:47.929: INFO: Pod downwardapi-volume-f9805bf3-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:11:47.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j5t7f" for this suite.
Dec  7 06:11:53.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:11:53.995: INFO: namespace: e2e-tests-projected-j5t7f, resource: bindings, ignored listing per whitelist
Dec  7 06:11:54.060: INFO: namespace e2e-tests-projected-j5t7f deletion completed in 6.12499689s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:11:54.062: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fe702100-f9e6-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:11:54.146: INFO: Waiting up to 5m0s for pod "pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-v7bvf" to be "success or failure"
Dec  7 06:11:54.154: INFO: Pod "pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.233155ms
Dec  7 06:11:56.158: INFO: Pod "pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011929047s
STEP: Saw pod success
Dec  7 06:11:56.158: INFO: Pod "pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:11:56.161: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:11:56.190: INFO: Waiting for pod pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:11:56.204: INFO: Pod pod-secrets-fe70a1dc-f9e6-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:11:56.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v7bvf" for this suite.
Dec  7 06:12:02.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:12:02.268: INFO: namespace: e2e-tests-secrets-v7bvf, resource: bindings, ignored listing per whitelist
Dec  7 06:12:02.340: INFO: namespace e2e-tests-secrets-v7bvf deletion completed in 6.116032191s

• [SLOW TEST:8.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:12:02.344: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-035fdcec-f9e7-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:12:02.430: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-vtcnf" to be "success or failure"
Dec  7 06:12:02.435: INFO: Pod "pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.745636ms
Dec  7 06:12:04.440: INFO: Pod "pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00998125s
STEP: Saw pod success
Dec  7 06:12:04.440: INFO: Pod "pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:12:04.442: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:12:04.469: INFO: Waiting for pod pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:12:04.484: INFO: Pod pod-projected-secrets-03608cc2-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:12:04.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vtcnf" for this suite.
Dec  7 06:12:10.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:12:10.512: INFO: namespace: e2e-tests-projected-vtcnf, resource: bindings, ignored listing per whitelist
Dec  7 06:12:10.590: INFO: namespace e2e-tests-projected-vtcnf deletion completed in 6.102867069s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:12:10.594: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  7 06:12:10.658: INFO: Waiting up to 5m0s for pod "var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-var-expansion-98q88" to be "success or failure"
Dec  7 06:12:10.662: INFO: Pod "var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.505384ms
Dec  7 06:12:12.666: INFO: Pod "var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007306808s
STEP: Saw pod success
Dec  7 06:12:12.666: INFO: Pod "var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:12:12.668: INFO: Trying to get logs from node 2gb-pool-qefm5t pod var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 06:12:12.687: INFO: Waiting for pod var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:12:12.704: INFO: Pod var-expansion-084884e7-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:12:12.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-98q88" for this suite.
Dec  7 06:12:18.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:12:18.789: INFO: namespace: e2e-tests-var-expansion-98q88, resource: bindings, ignored listing per whitelist
Dec  7 06:12:18.812: INFO: namespace e2e-tests-var-expansion-98q88 deletion completed in 6.096064979s

• [SLOW TEST:8.218 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:12:18.813: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:12:18.897: INFO: Creating deployment "nginx-deployment"
Dec  7 06:12:18.902: INFO: Waiting for observed generation 1
Dec  7 06:12:20.909: INFO: Waiting for all required pods to come up
Dec  7 06:12:20.913: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  7 06:12:26.924: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  7 06:12:26.931: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  7 06:12:26.941: INFO: Updating deployment nginx-deployment
Dec  7 06:12:26.941: INFO: Waiting for observed generation 2
Dec  7 06:12:28.958: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  7 06:12:28.964: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  7 06:12:28.967: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  7 06:12:28.976: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  7 06:12:28.976: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  7 06:12:28.980: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  7 06:12:28.985: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  7 06:12:28.985: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  7 06:12:28.997: INFO: Updating deployment nginx-deployment
Dec  7 06:12:28.997: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  7 06:12:29.007: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  7 06:12:29.028: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  7 06:12:29.090: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-6krdr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6krdr/deployments/nginx-deployment,UID:0d32306a-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2670,Generation:3,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2018-12-07 06:12:27 +0000 UTC 2018-12-07 06:12:18 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2018-12-07 06:12:29 +0000 UTC 2018-12-07 06:12:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  7 06:12:29.116: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-6krdr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6krdr/replicasets/nginx-deployment-65bbdb5f8,UID:11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2667,Generation:3,CreationTimestamp:2018-12-07 06:12:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0d32306a-f9e7-11e8-bee8-5a54dcfa39ab 0xc001752ec7 0xc001752ec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  7 06:12:29.116: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  7 06:12:29.117: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-6krdr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6krdr/replicasets/nginx-deployment-555b55d965,UID:0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2664,Generation:3,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0d32306a-f9e7-11e8-bee8-5a54dcfa39ab 0xc001752e07 0xc001752e08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  7 06:12:29.162: INFO: Pod "nginx-deployment-555b55d965-49qzv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-49qzv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-49qzv,UID:133bc372-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2678,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fa8e0 0xc0016fa8e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fa950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fa970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:12:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.162: INFO: Pod "nginx-deployment-555b55d965-4zpfq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4zpfq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-4zpfq,UID:1346b4f1-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2683,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fab67 0xc0016fab68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fabd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fabf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.163: INFO: Pod "nginx-deployment-555b55d965-6z548" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6z548,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-6z548,UID:13468cb0-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2691,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fac47 0xc0016fac48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016facf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fad10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.163: INFO: Pod "nginx-deployment-555b55d965-7hx99" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7hx99,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-7hx99,UID:0d3cd7f5-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2582,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fae50 0xc0016fae51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016faed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016faef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.32,StartTime:2018-12-07 06:12:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://fdfd302746f18106a83cbd474420ae4696b5328c82c5ab6ff4424cf8d94e8523}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.166: INFO: Pod "nginx-deployment-555b55d965-bhj6z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bhj6z,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-bhj6z,UID:133d4ecc-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2682,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fb027 0xc0016fb028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fb0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fb0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.166: INFO: Pod "nginx-deployment-555b55d965-jx9fl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jx9fl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-jx9fl,UID:1346d65f-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2686,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fb130 0xc0016fb131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fb1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fb210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.169: INFO: Pod "nginx-deployment-555b55d965-k9gm8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k9gm8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-k9gm8,UID:0d39de6c-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2592,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fb277 0xc0016fb278}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fb2f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fb310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.33,StartTime:2018-12-07 06:12:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://768a779ba4f68a4ec3cc569c5b0e6f444f4ca9dd09b3fe6a2cd37680b59e711b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.170: INFO: Pod "nginx-deployment-555b55d965-kf72p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kf72p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-kf72p,UID:1346e472-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2684,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fb3e7 0xc0016fb3e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fb490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fb4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.170: INFO: Pod "nginx-deployment-555b55d965-nt6pt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nt6pt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-nt6pt,UID:0d3cc5b9-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2568,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.37/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fb517 0xc0016fb518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fb590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fb5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.37,StartTime:2018-12-07 06:12:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://ba5df238e6594955a6a1b799a71e616599ea0fe67a527336a8a30e4e5d6d0e50}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.171: INFO: Pod "nginx-deployment-555b55d965-qvhrx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qvhrx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-qvhrx,UID:0d36f6e4-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2527,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fb697 0xc0016fb698}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fb710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fb730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.31,StartTime:2018-12-07 06:12:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://76e5798cdb93fc221d563ce84a2aa0695629042de5459137e472560ce8d4d855}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-555b55d965-rnlrq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rnlrq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-rnlrq,UID:0d4071a2-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2561,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.40/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fba27 0xc0016fba28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016fbaa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016fbac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:19 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.40,StartTime:2018-12-07 06:12:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://07bf84460db4993cb9ddee4d88b38f20fc18c9f9d0185066400a4d54009bbe7d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-555b55d965-rrrr5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rrrr5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-rrrr5,UID:0d3ccf2e-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2565,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.38/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc0016fbb97 0xc0016fbb98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115a030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115a050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.38,StartTime:2018-12-07 06:12:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://528d3e1a64769003c9bce6fa4596bc67caef01f1c7dc536c303b09b9d15b6808}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-555b55d965-xjlrl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xjlrl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-xjlrl,UID:0d3a1592-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2575,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.34/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115a197 0xc00115a198}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115a210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115a230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.34,StartTime:2018-12-07 06:12:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://ea9dd2e0a69ad86a0f644e23ca4659089e8198ab6ef7be4251b0fd35c93e5153}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-555b55d965-xwzdm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xwzdm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-xwzdm,UID:0d3ffef7-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2587,Generation:0,CreationTimestamp:2018-12-07 06:12:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115a3b7 0xc00115a3b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115a430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115a450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:18 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.36,StartTime:2018-12-07 06:12:19 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-07 06:12:22 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://a480e921be29c55fe229a2bd4051d85c18e9a9c3efda4a6e64c695ba8494151e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-555b55d965-z54k6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z54k6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-555b55d965-z54k6,UID:133d2291-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2685,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 0d33e12a-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115a657 0xc00115a658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115a6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115a6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-65bbdb5f8-44p59" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-44p59,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-44p59,UID:120170cc-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2655,Generation:0,CreationTimestamp:2018-12-07 06:12:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.41/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115a770 0xc00115a771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115a8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115a8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:12:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.172: INFO: Pod "nginx-deployment-65bbdb5f8-89b56" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-89b56,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-89b56,UID:133e2553-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2679,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115a9b0 0xc00115a9b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115aac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115aae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.173: INFO: Pod "nginx-deployment-65bbdb5f8-d85xw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d85xw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-d85xw,UID:13460a97-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2680,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115ab50 0xc00115ab51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115abc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115abe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.173: INFO: Pod "nginx-deployment-65bbdb5f8-h5qpx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h5qpx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-h5qpx,UID:11fdf666-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2656,Generation:0,CreationTimestamp:2018-12-07 06:12:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.42/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115acb7 0xc00115acb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115ad30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115ad50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:12:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.173: INFO: Pod "nginx-deployment-65bbdb5f8-pbnlh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pbnlh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-pbnlh,UID:120965fb-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2647,Generation:0,CreationTimestamp:2018-12-07 06:12:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115ae20 0xc00115ae21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115b1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115b1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:12:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.173: INFO: Pod "nginx-deployment-65bbdb5f8-qm78w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qm78w,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-qm78w,UID:13460169-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2690,Generation:0,CreationTimestamp:2018-12-07 06:12:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115b2b0 0xc00115b2b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115b330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115b350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.173: INFO: Pod "nginx-deployment-65bbdb5f8-rcq9c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rcq9c,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-rcq9c,UID:1200a350-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2659,Generation:0,CreationTimestamp:2018-12-07 06:12:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.43/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115b3d0 0xc00115b3d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115b450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115b470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:26 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:12:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  7 06:12:29.173: INFO: Pod "nginx-deployment-65bbdb5f8-vm288" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vm288,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-6krdr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6krdr/pods/nginx-deployment-65bbdb5f8-vm288,UID:120c6f69-f9e7-11e8-bee8-5a54dcfa39ab,ResourceVersion:2651,Generation:0,CreationTimestamp:2018-12-07 06:12:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 11fd4e05-f9e7-11e8-bee8-5a54dcfa39ab 0xc00115b530 0xc00115b531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zvfkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zvfkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-zvfkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00115b5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00115b5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:12:27 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:12:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:12:29.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6krdr" for this suite.
Dec  7 06:12:37.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:12:37.406: INFO: namespace: e2e-tests-deployment-6krdr, resource: bindings, ignored listing per whitelist
Dec  7 06:12:37.412: INFO: namespace e2e-tests-deployment-6krdr deletion completed in 8.209867685s

• [SLOW TEST:18.599 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:12:37.413: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-184b3e1f-f9e7-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:12:37.529: INFO: Waiting up to 5m0s for pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-t87hm" to be "success or failure"
Dec  7 06:12:37.537: INFO: Pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.226463ms
Dec  7 06:12:39.581: INFO: Pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052372328s
Dec  7 06:12:41.585: INFO: Pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056253513s
Dec  7 06:12:43.589: INFO: Pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.059882124s
Dec  7 06:12:45.595: INFO: Pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.065945516s
STEP: Saw pod success
Dec  7 06:12:45.595: INFO: Pod "pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:12:45.600: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:12:45.638: INFO: Waiting for pod pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:12:45.649: INFO: Pod pod-configmaps-184c2779-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:12:45.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t87hm" for this suite.
Dec  7 06:12:51.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:12:51.723: INFO: namespace: e2e-tests-configmap-t87hm, resource: bindings, ignored listing per whitelist
Dec  7 06:12:51.758: INFO: namespace e2e-tests-configmap-t87hm deletion completed in 6.10155034s

• [SLOW TEST:14.345 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:12:51.758: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  7 06:12:51.851: INFO: Waiting up to 5m0s for pod "pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-5cp4d" to be "success or failure"
Dec  7 06:12:51.857: INFO: Pod "pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854608ms
Dec  7 06:12:53.861: INFO: Pod "pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009884274s
STEP: Saw pod success
Dec  7 06:12:53.861: INFO: Pod "pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:12:53.863: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:12:53.884: INFO: Waiting for pod pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:12:53.886: INFO: Pod pod-20d4fb76-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:12:53.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5cp4d" for this suite.
Dec  7 06:12:59.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:12:59.953: INFO: namespace: e2e-tests-emptydir-5cp4d, resource: bindings, ignored listing per whitelist
Dec  7 06:13:00.014: INFO: namespace e2e-tests-emptydir-5cp4d deletion completed in 6.125188265s

• [SLOW TEST:8.256 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:13:00.015: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:13:00.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5tgdz'
Dec  7 06:13:00.520: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  7 06:13:00.520: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec  7 06:13:02.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5tgdz'
Dec  7 06:13:02.664: INFO: stderr: ""
Dec  7 06:13:02.664: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:13:02.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5tgdz" for this suite.
Dec  7 06:13:08.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:13:08.742: INFO: namespace: e2e-tests-kubectl-5tgdz, resource: bindings, ignored listing per whitelist
Dec  7 06:13:08.784: INFO: namespace e2e-tests-kubectl-5tgdz deletion completed in 6.116793083s

• [SLOW TEST:8.769 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:13:08.784: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  7 06:13:08.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 --namespace=e2e-tests-kubectl-shtr7 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  7 06:13:10.733: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  7 06:13:10.733: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:13:12.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-shtr7" for this suite.
Dec  7 06:13:18.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:13:18.799: INFO: namespace: e2e-tests-kubectl-shtr7, resource: bindings, ignored listing per whitelist
Dec  7 06:13:18.846: INFO: namespace e2e-tests-kubectl-shtr7 deletion completed in 6.100650688s

• [SLOW TEST:10.062 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:13:18.846: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  7 06:13:18.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:19.190: INFO: stderr: ""
Dec  7 06:13:19.190: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  7 06:13:19.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:19.316: INFO: stderr: ""
Dec  7 06:13:19.316: INFO: stdout: "update-demo-nautilus-74kht update-demo-nautilus-84zfd "
Dec  7 06:13:19.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:19.421: INFO: stderr: ""
Dec  7 06:13:19.421: INFO: stdout: ""
Dec  7 06:13:19.421: INFO: update-demo-nautilus-74kht is created but not running
Dec  7 06:13:24.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:24.532: INFO: stderr: ""
Dec  7 06:13:24.532: INFO: stdout: "update-demo-nautilus-74kht update-demo-nautilus-84zfd "
Dec  7 06:13:24.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:24.634: INFO: stderr: ""
Dec  7 06:13:24.634: INFO: stdout: "true"
Dec  7 06:13:24.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:24.747: INFO: stderr: ""
Dec  7 06:13:24.747: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:13:24.747: INFO: validating pod update-demo-nautilus-74kht
Dec  7 06:13:24.753: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:13:24.753: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:13:24.753: INFO: update-demo-nautilus-74kht is verified up and running
Dec  7 06:13:24.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-84zfd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:24.852: INFO: stderr: ""
Dec  7 06:13:24.852: INFO: stdout: "true"
Dec  7 06:13:24.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-84zfd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:24.976: INFO: stderr: ""
Dec  7 06:13:24.976: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:13:24.976: INFO: validating pod update-demo-nautilus-84zfd
Dec  7 06:13:24.982: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:13:24.982: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:13:24.982: INFO: update-demo-nautilus-84zfd is verified up and running
STEP: scaling down the replication controller
Dec  7 06:13:24.985: INFO: scanned /root for discovery docs: <nil>
Dec  7 06:13:24.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:26.141: INFO: stderr: ""
Dec  7 06:13:26.141: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  7 06:13:26.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:26.243: INFO: stderr: ""
Dec  7 06:13:26.243: INFO: stdout: "update-demo-nautilus-74kht update-demo-nautilus-84zfd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  7 06:13:31.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:31.361: INFO: stderr: ""
Dec  7 06:13:31.361: INFO: stdout: "update-demo-nautilus-74kht update-demo-nautilus-84zfd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  7 06:13:36.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:36.472: INFO: stderr: ""
Dec  7 06:13:36.472: INFO: stdout: "update-demo-nautilus-74kht update-demo-nautilus-84zfd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  7 06:13:41.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:41.586: INFO: stderr: ""
Dec  7 06:13:41.587: INFO: stdout: "update-demo-nautilus-74kht "
Dec  7 06:13:41.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:41.685: INFO: stderr: ""
Dec  7 06:13:41.685: INFO: stdout: "true"
Dec  7 06:13:41.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:41.801: INFO: stderr: ""
Dec  7 06:13:41.801: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:13:41.801: INFO: validating pod update-demo-nautilus-74kht
Dec  7 06:13:41.805: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:13:41.805: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:13:41.806: INFO: update-demo-nautilus-74kht is verified up and running
STEP: scaling up the replication controller
Dec  7 06:13:41.811: INFO: scanned /root for discovery docs: <nil>
Dec  7 06:13:41.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:42.954: INFO: stderr: ""
Dec  7 06:13:42.954: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  7 06:13:42.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.082: INFO: stderr: ""
Dec  7 06:13:43.082: INFO: stdout: "update-demo-nautilus-74kht update-demo-nautilus-gckht "
Dec  7 06:13:43.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.236: INFO: stderr: ""
Dec  7 06:13:43.236: INFO: stdout: "true"
Dec  7 06:13:43.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-74kht -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.364: INFO: stderr: ""
Dec  7 06:13:43.364: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:13:43.364: INFO: validating pod update-demo-nautilus-74kht
Dec  7 06:13:43.368: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:13:43.368: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:13:43.368: INFO: update-demo-nautilus-74kht is verified up and running
Dec  7 06:13:43.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-gckht -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.476: INFO: stderr: ""
Dec  7 06:13:43.476: INFO: stdout: "true"
Dec  7 06:13:43.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-gckht -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.589: INFO: stderr: ""
Dec  7 06:13:43.589: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:13:43.589: INFO: validating pod update-demo-nautilus-gckht
Dec  7 06:13:43.594: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:13:43.594: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:13:43.594: INFO: update-demo-nautilus-gckht is verified up and running
STEP: using delete to clean up resources
Dec  7 06:13:43.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.740: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:13:43.740: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  7 06:13:43.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-x8msp'
Dec  7 06:13:43.927: INFO: stderr: "No resources found.\n"
Dec  7 06:13:43.927: INFO: stdout: ""
Dec  7 06:13:43.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -l name=update-demo --namespace=e2e-tests-kubectl-x8msp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  7 06:13:44.114: INFO: stderr: ""
Dec  7 06:13:44.114: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:13:44.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x8msp" for this suite.
Dec  7 06:14:06.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:14:06.235: INFO: namespace: e2e-tests-kubectl-x8msp, resource: bindings, ignored listing per whitelist
Dec  7 06:14:06.238: INFO: namespace e2e-tests-kubectl-x8msp deletion completed in 22.117752597s

• [SLOW TEST:47.392 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:14:06.243: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:14:06.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-tnc7f'
Dec  7 06:14:06.484: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  7 06:14:06.484: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  7 06:14:06.491: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  7 06:14:06.500: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  7 06:14:06.516: INFO: scanned /root for discovery docs: <nil>
Dec  7 06:14:06.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-tnc7f'
Dec  7 06:14:22.341: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  7 06:14:22.341: INFO: stdout: "Created e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9\nScaling up e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  7 06:14:22.341: INFO: stdout: "Created e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9\nScaling up e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  7 06:14:22.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tnc7f'
Dec  7 06:14:22.476: INFO: stderr: ""
Dec  7 06:14:22.476: INFO: stdout: "e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9-qrkpk "
Dec  7 06:14:22.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9-qrkpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tnc7f'
Dec  7 06:14:22.583: INFO: stderr: ""
Dec  7 06:14:22.583: INFO: stdout: "true"
Dec  7 06:14:22.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9-qrkpk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tnc7f'
Dec  7 06:14:22.680: INFO: stderr: ""
Dec  7 06:14:22.680: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  7 06:14:22.680: INFO: e2e-test-nginx-rc-eb3148304ff0e8a9959aa3b3e98155c9-qrkpk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec  7 06:14:22.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tnc7f'
Dec  7 06:14:22.816: INFO: stderr: ""
Dec  7 06:14:22.816: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:14:22.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tnc7f" for this suite.
Dec  7 06:14:28.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:14:28.857: INFO: namespace: e2e-tests-kubectl-tnc7f, resource: bindings, ignored listing per whitelist
Dec  7 06:14:28.928: INFO: namespace e2e-tests-kubectl-tnc7f deletion completed in 6.107455388s

• [SLOW TEST:22.685 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:14:28.934: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:14:29.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fc2j9" for this suite.
Dec  7 06:14:51.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:14:51.068: INFO: namespace: e2e-tests-pods-fc2j9, resource: bindings, ignored listing per whitelist
Dec  7 06:14:51.160: INFO: namespace e2e-tests-pods-fc2j9 deletion completed in 22.127239249s

• [SLOW TEST:22.227 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:14:51.162: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  7 06:14:53.765: INFO: Successfully updated pod "labelsupdate67fe47f9-f9e7-11e8-9cb3-16e60f4677a4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:14:55.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5vd48" for this suite.
Dec  7 06:15:17.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:15:17.821: INFO: namespace: e2e-tests-downward-api-5vd48, resource: bindings, ignored listing per whitelist
Dec  7 06:15:17.892: INFO: namespace e2e-tests-downward-api-5vd48 deletion completed in 22.100178281s

• [SLOW TEST:26.730 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:15:17.892: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qxznm/configmap-test-77ec705e-f9e7-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:15:17.968: INFO: Waiting up to 5m0s for pod "pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-qxznm" to be "success or failure"
Dec  7 06:15:17.975: INFO: Pod "pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.367992ms
Dec  7 06:15:19.978: INFO: Pod "pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009586909s
STEP: Saw pod success
Dec  7 06:15:19.978: INFO: Pod "pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:15:19.980: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4 container env-test: <nil>
STEP: delete the pod
Dec  7 06:15:20.000: INFO: Waiting for pod pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:15:20.004: INFO: Pod pod-configmaps-77ed473e-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:15:20.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qxznm" for this suite.
Dec  7 06:15:26.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:15:26.104: INFO: namespace: e2e-tests-configmap-qxznm, resource: bindings, ignored listing per whitelist
Dec  7 06:15:26.129: INFO: namespace e2e-tests-configmap-qxznm deletion completed in 6.106849618s

• [SLOW TEST:8.238 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:15:26.130: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-7cd64e47-f9e7-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-7cd64e47-f9e7-11e8-9cb3-16e60f4677a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:15:30.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dcndh" for this suite.
Dec  7 06:15:52.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:15:52.302: INFO: namespace: e2e-tests-configmap-dcndh, resource: bindings, ignored listing per whitelist
Dec  7 06:15:52.349: INFO: namespace e2e-tests-configmap-dcndh deletion completed in 22.094246812s

• [SLOW TEST:26.219 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:15:52.350: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:15:52.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-j94sw" to be "success or failure"
Dec  7 06:15:52.429: INFO: Pod "downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.400784ms
Dec  7 06:15:54.432: INFO: Pod "downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013209261s
STEP: Saw pod success
Dec  7 06:15:54.433: INFO: Pod "downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:15:54.435: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:15:54.457: INFO: Waiting for pod downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:15:54.461: INFO: Pod downwardapi-volume-8c761eb6-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:15:54.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j94sw" for this suite.
Dec  7 06:16:00.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:16:00.490: INFO: namespace: e2e-tests-projected-j94sw, resource: bindings, ignored listing per whitelist
Dec  7 06:16:00.563: INFO: namespace e2e-tests-projected-j94sw deletion completed in 6.098345792s

• [SLOW TEST:8.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:16:00.565: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:16:04.694: INFO: Waiting up to 5m0s for pod "client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-pods-2x6zc" to be "success or failure"
Dec  7 06:16:04.719: INFO: Pod "client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.117654ms
Dec  7 06:16:06.724: INFO: Pod "client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0297958s
STEP: Saw pod success
Dec  7 06:16:06.724: INFO: Pod "client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:16:06.727: INFO: Trying to get logs from node 2gb-pool-qefm5t pod client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4 container env3cont: <nil>
STEP: delete the pod
Dec  7 06:16:06.755: INFO: Waiting for pod client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:16:06.761: INFO: Pod client-envvars-93c74bd6-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:16:06.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2x6zc" for this suite.
Dec  7 06:16:48.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:16:48.816: INFO: namespace: e2e-tests-pods-2x6zc, resource: bindings, ignored listing per whitelist
Dec  7 06:16:48.903: INFO: namespace e2e-tests-pods-2x6zc deletion completed in 42.130612218s

• [SLOW TEST:48.339 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:16:48.906: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-fvkgc
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-fvkgc
STEP: Deleting pre-stop pod
Dec  7 06:17:00.048: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:17:00.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-fvkgc" for this suite.
Dec  7 06:17:38.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:17:38.149: INFO: namespace: e2e-tests-prestop-fvkgc, resource: bindings, ignored listing per whitelist
Dec  7 06:17:38.185: INFO: namespace e2e-tests-prestop-fvkgc deletion completed in 38.120598991s

• [SLOW TEST:49.280 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:17:38.186: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec  7 06:18:18.292: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:18:18.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6qf6x" for this suite.
Dec  7 06:18:24.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:18:24.406: INFO: namespace: e2e-tests-gc-6qf6x, resource: bindings, ignored listing per whitelist
Dec  7 06:18:24.422: INFO: namespace e2e-tests-gc-6qf6x deletion completed in 6.12651944s

• [SLOW TEST:46.236 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:18:24.422: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-t9st
STEP: Creating a pod to test atomic-volume-subpath
Dec  7 06:18:24.557: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-t9st" in namespace "e2e-tests-subpath-9tc2p" to be "success or failure"
Dec  7 06:18:24.567: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Pending", Reason="", readiness=false. Elapsed: 10.395102ms
Dec  7 06:18:26.572: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014600041s
Dec  7 06:18:28.575: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018064503s
Dec  7 06:18:30.578: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 6.021177945s
Dec  7 06:18:32.581: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 8.024345627s
Dec  7 06:18:34.585: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 10.027457152s
Dec  7 06:18:36.589: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 12.031539885s
Dec  7 06:18:38.593: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 14.035912594s
Dec  7 06:18:40.597: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 16.039477736s
Dec  7 06:18:42.601: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 18.04364632s
Dec  7 06:18:44.604: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 20.046755031s
Dec  7 06:18:46.608: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Running", Reason="", readiness=false. Elapsed: 22.051349061s
Dec  7 06:18:48.612: INFO: Pod "pod-subpath-test-configmap-t9st": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054667552s
STEP: Saw pod success
Dec  7 06:18:48.612: INFO: Pod "pod-subpath-test-configmap-t9st" satisfied condition "success or failure"
Dec  7 06:18:48.615: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-subpath-test-configmap-t9st container test-container-subpath-configmap-t9st: <nil>
STEP: delete the pod
Dec  7 06:18:48.638: INFO: Waiting for pod pod-subpath-test-configmap-t9st to disappear
Dec  7 06:18:48.641: INFO: Pod pod-subpath-test-configmap-t9st no longer exists
STEP: Deleting pod pod-subpath-test-configmap-t9st
Dec  7 06:18:48.641: INFO: Deleting pod "pod-subpath-test-configmap-t9st" in namespace "e2e-tests-subpath-9tc2p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:18:48.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9tc2p" for this suite.
Dec  7 06:18:54.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:18:54.679: INFO: namespace: e2e-tests-subpath-9tc2p, resource: bindings, ignored listing per whitelist
Dec  7 06:18:54.767: INFO: namespace e2e-tests-subpath-9tc2p deletion completed in 6.114947139s

• [SLOW TEST:30.344 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:18:54.769: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f9336df3-f9e7-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:18:54.869: INFO: Waiting up to 5m0s for pod "pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-m47cc" to be "success or failure"
Dec  7 06:18:54.881: INFO: Pod "pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.7528ms
Dec  7 06:18:56.885: INFO: Pod "pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015314272s
STEP: Saw pod success
Dec  7 06:18:56.885: INFO: Pod "pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:18:56.887: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:18:56.911: INFO: Waiting for pod pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:18:56.916: INFO: Pod pod-secrets-f93417c3-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:18:56.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m47cc" for this suite.
Dec  7 06:19:02.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:19:02.955: INFO: namespace: e2e-tests-secrets-m47cc, resource: bindings, ignored listing per whitelist
Dec  7 06:19:03.036: INFO: namespace e2e-tests-secrets-m47cc deletion completed in 6.113581516s

• [SLOW TEST:8.268 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:19:03.036: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  7 06:19:03.105: INFO: Waiting up to 5m0s for pod "client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-containers-t76n9" to be "success or failure"
Dec  7 06:19:03.109: INFO: Pod "client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251722ms
Dec  7 06:19:05.113: INFO: Pod "client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007773349s
STEP: Saw pod success
Dec  7 06:19:05.113: INFO: Pod "client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:19:05.115: INFO: Trying to get logs from node 2gb-pool-qefm5t pod client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:19:05.139: INFO: Waiting for pod client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:19:05.143: INFO: Pod client-containers-fe1e8b17-f9e7-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:19:05.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-t76n9" for this suite.
Dec  7 06:19:11.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:19:11.257: INFO: namespace: e2e-tests-containers-t76n9, resource: bindings, ignored listing per whitelist
Dec  7 06:19:11.265: INFO: namespace e2e-tests-containers-t76n9 deletion completed in 6.116864621s

• [SLOW TEST:8.229 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:19:11.266: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  7 06:19:11.354: INFO: Waiting up to 5m0s for pod "pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-qnd5c" to be "success or failure"
Dec  7 06:19:11.360: INFO: Pod "pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.24716ms
Dec  7 06:19:13.367: INFO: Pod "pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012855789s
STEP: Saw pod success
Dec  7 06:19:13.367: INFO: Pod "pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:19:13.370: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:19:13.389: INFO: Waiting for pod pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:19:13.395: INFO: Pod pod-0307cba7-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:19:13.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qnd5c" for this suite.
Dec  7 06:19:19.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:19:19.429: INFO: namespace: e2e-tests-emptydir-qnd5c, resource: bindings, ignored listing per whitelist
Dec  7 06:19:19.509: INFO: namespace e2e-tests-emptydir-qnd5c deletion completed in 6.106781284s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:19:19.509: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-07fa1994-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:19:19.649: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-xt9x8" to be "success or failure"
Dec  7 06:19:19.664: INFO: Pod "pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.477345ms
Dec  7 06:19:21.668: INFO: Pod "pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019676903s
STEP: Saw pod success
Dec  7 06:19:21.669: INFO: Pod "pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:19:21.671: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:19:21.697: INFO: Waiting for pod pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:19:21.702: INFO: Pod pod-projected-secrets-07fabaa1-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:19:21.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xt9x8" for this suite.
Dec  7 06:19:27.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:19:27.822: INFO: namespace: e2e-tests-projected-xt9x8, resource: bindings, ignored listing per whitelist
Dec  7 06:19:27.824: INFO: namespace e2e-tests-projected-xt9x8 deletion completed in 6.118359637s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:19:27.825: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0ce624f2-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:19:27.907: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-7xgc9" to be "success or failure"
Dec  7 06:19:27.910: INFO: Pod "pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.034337ms
Dec  7 06:19:29.914: INFO: Pod "pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007269333s
STEP: Saw pod success
Dec  7 06:19:29.914: INFO: Pod "pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:19:29.918: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:19:29.943: INFO: Waiting for pod pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:19:29.948: INFO: Pod pod-projected-configmaps-0ce6d3e4-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:19:29.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7xgc9" for this suite.
Dec  7 06:19:35.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:19:36.049: INFO: namespace: e2e-tests-projected-7xgc9, resource: bindings, ignored listing per whitelist
Dec  7 06:19:36.070: INFO: namespace e2e-tests-projected-7xgc9 deletion completed in 6.117844213s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:19:36.070: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-11d14449-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating secret with name s-test-opt-upd-11d144b6-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-11d14449-f9e8-11e8-9cb3-16e60f4677a4
STEP: Updating secret s-test-opt-upd-11d144b6-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating secret with name s-test-opt-create-11d144ed-f9e8-11e8-9cb3-16e60f4677a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:19:40.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2sx62" for this suite.
Dec  7 06:20:02.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:02.388: INFO: namespace: e2e-tests-projected-2sx62, resource: bindings, ignored listing per whitelist
Dec  7 06:20:02.395: INFO: namespace e2e-tests-projected-2sx62 deletion completed in 22.127390242s

• [SLOW TEST:26.325 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:20:02.395: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  7 06:20:02.496: INFO: Waiting up to 5m0s for pod "downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-st7mt" to be "success or failure"
Dec  7 06:20:02.512: INFO: Pod "downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.544308ms
Dec  7 06:20:04.517: INFO: Pod "downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020386055s
STEP: Saw pod success
Dec  7 06:20:04.517: INFO: Pod "downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:20:04.520: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 06:20:04.544: INFO: Waiting for pod downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:20:04.558: INFO: Pod downward-api-21843986-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:20:04.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-st7mt" for this suite.
Dec  7 06:20:10.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:10.658: INFO: namespace: e2e-tests-downward-api-st7mt, resource: bindings, ignored listing per whitelist
Dec  7 06:20:10.667: INFO: namespace e2e-tests-downward-api-st7mt deletion completed in 6.105137691s

• [SLOW TEST:8.272 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:20:10.670: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2670ad24-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:20:10.805: INFO: Waiting up to 5m0s for pod "pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-dlw2g" to be "success or failure"
Dec  7 06:20:10.809: INFO: Pod "pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.800546ms
Dec  7 06:20:12.813: INFO: Pod "pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008334461s
STEP: Saw pod success
Dec  7 06:20:12.813: INFO: Pod "pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:20:12.816: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:20:12.849: INFO: Waiting for pod pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:20:12.852: INFO: Pod pod-secrets-26789222-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:20:12.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dlw2g" for this suite.
Dec  7 06:20:18.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:18.982: INFO: namespace: e2e-tests-secrets-dlw2g, resource: bindings, ignored listing per whitelist
Dec  7 06:20:18.986: INFO: namespace e2e-tests-secrets-dlw2g deletion completed in 6.129659895s
STEP: Destroying namespace "e2e-tests-secret-namespace-94tzp" for this suite.
Dec  7 06:20:25.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:25.091: INFO: namespace: e2e-tests-secret-namespace-94tzp, resource: bindings, ignored listing per whitelist
Dec  7 06:20:25.117: INFO: namespace e2e-tests-secret-namespace-94tzp deletion completed in 6.130536649s

• [SLOW TEST:14.448 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:20:25.118: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2f0de1e5-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:20:25.213: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-4hbzt" to be "success or failure"
Dec  7 06:20:25.231: INFO: Pod "pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.520249ms
Dec  7 06:20:27.247: INFO: Pod "pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033222082s
STEP: Saw pod success
Dec  7 06:20:27.247: INFO: Pod "pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:20:27.250: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:20:27.271: INFO: Waiting for pod pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:20:27.273: INFO: Pod pod-projected-configmaps-2f0e9b26-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:20:27.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4hbzt" for this suite.
Dec  7 06:20:33.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:33.316: INFO: namespace: e2e-tests-projected-4hbzt, resource: bindings, ignored listing per whitelist
Dec  7 06:20:33.486: INFO: namespace e2e-tests-projected-4hbzt deletion completed in 6.209463373s

• [SLOW TEST:8.367 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:20:33.486: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:20:33.565: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-ztcsb" to be "success or failure"
Dec  7 06:20:33.570: INFO: Pod "downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.061469ms
Dec  7 06:20:35.573: INFO: Pod "downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008492499s
STEP: Saw pod success
Dec  7 06:20:35.573: INFO: Pod "downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:20:35.576: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:20:35.604: INFO: Waiting for pod downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:20:35.608: INFO: Pod downwardapi-volume-3409a867-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:20:35.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ztcsb" for this suite.
Dec  7 06:20:41.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:41.703: INFO: namespace: e2e-tests-downward-api-ztcsb, resource: bindings, ignored listing per whitelist
Dec  7 06:20:41.720: INFO: namespace e2e-tests-downward-api-ztcsb deletion completed in 6.108461223s

• [SLOW TEST:8.234 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:20:41.720: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:20:41.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7m7n9" for this suite.
Dec  7 06:20:47.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:20:47.877: INFO: namespace: e2e-tests-services-7m7n9, resource: bindings, ignored listing per whitelist
Dec  7 06:20:47.909: INFO: namespace e2e-tests-services-7m7n9 deletion completed in 6.10261489s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.189 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:20:47.911: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  7 06:20:47.975: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  7 06:20:47.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:20:48.178: INFO: stderr: ""
Dec  7 06:20:48.178: INFO: stdout: "service/redis-slave created\n"
Dec  7 06:20:48.178: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  7 06:20:48.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:20:48.412: INFO: stderr: ""
Dec  7 06:20:48.412: INFO: stdout: "service/redis-master created\n"
Dec  7 06:20:48.412: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  7 06:20:48.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:20:48.632: INFO: stderr: ""
Dec  7 06:20:48.632: INFO: stdout: "service/frontend created\n"
Dec  7 06:20:48.633: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  7 06:20:48.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:20:48.837: INFO: stderr: ""
Dec  7 06:20:48.837: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  7 06:20:48.837: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  7 06:20:48.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:20:49.093: INFO: stderr: ""
Dec  7 06:20:49.093: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  7 06:20:49.093: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  7 06:20:49.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:20:49.589: INFO: stderr: ""
Dec  7 06:20:49.589: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  7 06:20:49.589: INFO: Waiting for all frontend pods to be Running.
Dec  7 06:21:14.640: INFO: Waiting for frontend to serve content.
Dec  7 06:21:19.663: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  7 06:21:24.680: INFO: Trying to add a new entry to the guestbook.
Dec  7 06:21:24.697: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  7 06:21:24.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:21:24.834: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:21:24.834: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  7 06:21:24.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:21:24.982: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:21:24.982: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  7 06:21:24.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:21:25.135: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:21:25.135: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  7 06:21:25.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:21:25.256: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:21:25.256: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  7 06:21:25.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:21:25.577: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:21:25.577: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  7 06:21:25.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xfhzs'
Dec  7 06:21:25.872: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:21:25.872: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:21:25.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xfhzs" for this suite.
Dec  7 06:22:03.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:22:03.962: INFO: namespace: e2e-tests-kubectl-xfhzs, resource: bindings, ignored listing per whitelist
Dec  7 06:22:04.019: INFO: namespace e2e-tests-kubectl-xfhzs deletion completed in 38.124642102s

• [SLOW TEST:76.109 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:22:04.022: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  7 06:22:04.094: INFO: Waiting up to 5m0s for pod "pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-5jgst" to be "success or failure"
Dec  7 06:22:04.096: INFO: Pod "pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429122ms
Dec  7 06:22:06.100: INFO: Pod "pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006060468s
STEP: Saw pod success
Dec  7 06:22:06.100: INFO: Pod "pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:22:06.103: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:22:06.133: INFO: Waiting for pod pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:22:06.136: INFO: Pod pod-69ff7f23-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:22:06.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5jgst" for this suite.
Dec  7 06:22:12.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:22:12.221: INFO: namespace: e2e-tests-emptydir-5jgst, resource: bindings, ignored listing per whitelist
Dec  7 06:22:12.252: INFO: namespace e2e-tests-emptydir-5jgst deletion completed in 6.10508948s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:22:12.252: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-422w7
I1207 06:22:12.312212      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-422w7, replica count: 1
I1207 06:22:13.362852      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1207 06:22:14.363095      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  7 06:22:14.473: INFO: Created: latency-svc-6frhr
Dec  7 06:22:14.486: INFO: Got endpoints: latency-svc-6frhr [22.644512ms]
Dec  7 06:22:14.507: INFO: Created: latency-svc-kkpxv
Dec  7 06:22:14.508: INFO: Got endpoints: latency-svc-kkpxv [22.066399ms]
Dec  7 06:22:14.517: INFO: Created: latency-svc-fx72s
Dec  7 06:22:14.518: INFO: Got endpoints: latency-svc-fx72s [32.264101ms]
Dec  7 06:22:14.534: INFO: Created: latency-svc-x879s
Dec  7 06:22:14.539: INFO: Created: latency-svc-phmxs
Dec  7 06:22:14.540: INFO: Got endpoints: latency-svc-x879s [54.160272ms]
Dec  7 06:22:14.541: INFO: Got endpoints: latency-svc-phmxs [54.390352ms]
Dec  7 06:22:14.552: INFO: Created: latency-svc-6tr5k
Dec  7 06:22:14.558: INFO: Got endpoints: latency-svc-6tr5k [71.010647ms]
Dec  7 06:22:14.579: INFO: Created: latency-svc-4lhr5
Dec  7 06:22:14.589: INFO: Got endpoints: latency-svc-4lhr5 [102.179623ms]
Dec  7 06:22:14.598: INFO: Created: latency-svc-g7g4j
Dec  7 06:22:14.602: INFO: Got endpoints: latency-svc-g7g4j [115.150301ms]
Dec  7 06:22:14.612: INFO: Created: latency-svc-j47pm
Dec  7 06:22:14.615: INFO: Got endpoints: latency-svc-j47pm [128.283629ms]
Dec  7 06:22:14.624: INFO: Created: latency-svc-l5sbf
Dec  7 06:22:14.629: INFO: Got endpoints: latency-svc-l5sbf [141.752955ms]
Dec  7 06:22:14.637: INFO: Created: latency-svc-8tfz4
Dec  7 06:22:14.640: INFO: Got endpoints: latency-svc-8tfz4 [153.331585ms]
Dec  7 06:22:14.661: INFO: Created: latency-svc-wdnvz
Dec  7 06:22:14.664: INFO: Got endpoints: latency-svc-wdnvz [176.635589ms]
Dec  7 06:22:14.680: INFO: Created: latency-svc-pz27n
Dec  7 06:22:14.684: INFO: Got endpoints: latency-svc-pz27n [197.282434ms]
Dec  7 06:22:14.695: INFO: Created: latency-svc-29ss6
Dec  7 06:22:14.697: INFO: Got endpoints: latency-svc-29ss6 [210.009428ms]
Dec  7 06:22:14.710: INFO: Created: latency-svc-jw67l
Dec  7 06:22:14.712: INFO: Got endpoints: latency-svc-jw67l [224.53091ms]
Dec  7 06:22:14.739: INFO: Created: latency-svc-5ppm9
Dec  7 06:22:14.749: INFO: Got endpoints: latency-svc-5ppm9 [262.303156ms]
Dec  7 06:22:14.752: INFO: Created: latency-svc-2gj7s
Dec  7 06:22:14.756: INFO: Got endpoints: latency-svc-2gj7s [247.583246ms]
Dec  7 06:22:14.770: INFO: Created: latency-svc-m6qv9
Dec  7 06:22:14.774: INFO: Got endpoints: latency-svc-m6qv9 [255.897435ms]
Dec  7 06:22:14.784: INFO: Created: latency-svc-2fdvp
Dec  7 06:22:14.786: INFO: Got endpoints: latency-svc-2fdvp [245.685581ms]
Dec  7 06:22:14.806: INFO: Created: latency-svc-gmnvq
Dec  7 06:22:14.809: INFO: Got endpoints: latency-svc-gmnvq [268.205551ms]
Dec  7 06:22:14.843: INFO: Created: latency-svc-z9bnb
Dec  7 06:22:14.844: INFO: Got endpoints: latency-svc-z9bnb [285.86669ms]
Dec  7 06:22:14.857: INFO: Created: latency-svc-sc488
Dec  7 06:22:14.861: INFO: Got endpoints: latency-svc-sc488 [272.209799ms]
Dec  7 06:22:14.864: INFO: Created: latency-svc-fwl42
Dec  7 06:22:14.868: INFO: Got endpoints: latency-svc-fwl42 [266.178932ms]
Dec  7 06:22:14.876: INFO: Created: latency-svc-rwrsj
Dec  7 06:22:14.878: INFO: Got endpoints: latency-svc-rwrsj [262.532259ms]
Dec  7 06:22:14.890: INFO: Created: latency-svc-qmkvj
Dec  7 06:22:14.890: INFO: Got endpoints: latency-svc-qmkvj [261.482721ms]
Dec  7 06:22:14.926: INFO: Created: latency-svc-5kklq
Dec  7 06:22:14.929: INFO: Got endpoints: latency-svc-5kklq [288.397436ms]
Dec  7 06:22:14.939: INFO: Created: latency-svc-2vxwn
Dec  7 06:22:14.941: INFO: Got endpoints: latency-svc-2vxwn [277.658522ms]
Dec  7 06:22:14.958: INFO: Created: latency-svc-nld6g
Dec  7 06:22:14.964: INFO: Got endpoints: latency-svc-nld6g [279.389385ms]
Dec  7 06:22:14.970: INFO: Created: latency-svc-fzlrf
Dec  7 06:22:14.974: INFO: Got endpoints: latency-svc-fzlrf [277.22172ms]
Dec  7 06:22:14.981: INFO: Created: latency-svc-czrhd
Dec  7 06:22:14.982: INFO: Got endpoints: latency-svc-czrhd [270.690116ms]
Dec  7 06:22:14.994: INFO: Created: latency-svc-k2zsb
Dec  7 06:22:14.999: INFO: Got endpoints: latency-svc-k2zsb [249.624887ms]
Dec  7 06:22:15.010: INFO: Created: latency-svc-hp6xc
Dec  7 06:22:15.010: INFO: Got endpoints: latency-svc-hp6xc [254.696822ms]
Dec  7 06:22:15.031: INFO: Created: latency-svc-z8t7j
Dec  7 06:22:15.032: INFO: Got endpoints: latency-svc-z8t7j [256.972004ms]
Dec  7 06:22:15.045: INFO: Created: latency-svc-rjzbd
Dec  7 06:22:15.052: INFO: Got endpoints: latency-svc-rjzbd [266.058148ms]
Dec  7 06:22:15.064: INFO: Created: latency-svc-lrxnl
Dec  7 06:22:15.071: INFO: Got endpoints: latency-svc-lrxnl [261.538628ms]
Dec  7 06:22:15.105: INFO: Created: latency-svc-qm8lx
Dec  7 06:22:15.110: INFO: Got endpoints: latency-svc-qm8lx [265.678676ms]
Dec  7 06:22:15.119: INFO: Created: latency-svc-7rjxp
Dec  7 06:22:15.121: INFO: Got endpoints: latency-svc-7rjxp [259.209226ms]
Dec  7 06:22:15.139: INFO: Created: latency-svc-hsz5v
Dec  7 06:22:15.144: INFO: Got endpoints: latency-svc-hsz5v [275.363796ms]
Dec  7 06:22:15.151: INFO: Created: latency-svc-pzhml
Dec  7 06:22:15.156: INFO: Got endpoints: latency-svc-pzhml [277.578955ms]
Dec  7 06:22:15.175: INFO: Created: latency-svc-wtrkv
Dec  7 06:22:15.186: INFO: Got endpoints: latency-svc-wtrkv [295.693676ms]
Dec  7 06:22:15.198: INFO: Created: latency-svc-tx4ls
Dec  7 06:22:15.205: INFO: Got endpoints: latency-svc-tx4ls [275.573701ms]
Dec  7 06:22:15.209: INFO: Created: latency-svc-f6hhd
Dec  7 06:22:15.210: INFO: Got endpoints: latency-svc-f6hhd [268.037955ms]
Dec  7 06:22:15.227: INFO: Created: latency-svc-mx9bc
Dec  7 06:22:15.229: INFO: Got endpoints: latency-svc-mx9bc [264.804685ms]
Dec  7 06:22:15.242: INFO: Created: latency-svc-459qx
Dec  7 06:22:15.249: INFO: Got endpoints: latency-svc-459qx [274.225522ms]
Dec  7 06:22:15.258: INFO: Created: latency-svc-fhxg4
Dec  7 06:22:15.266: INFO: Got endpoints: latency-svc-fhxg4 [282.998238ms]
Dec  7 06:22:15.275: INFO: Created: latency-svc-ptj5c
Dec  7 06:22:15.278: INFO: Got endpoints: latency-svc-ptj5c [279.443017ms]
Dec  7 06:22:15.308: INFO: Created: latency-svc-hpd8v
Dec  7 06:22:15.316: INFO: Created: latency-svc-njmt8
Dec  7 06:22:15.328: INFO: Got endpoints: latency-svc-hpd8v [317.300212ms]
Dec  7 06:22:15.338: INFO: Created: latency-svc-7nf4b
Dec  7 06:22:15.360: INFO: Created: latency-svc-bz8lc
Dec  7 06:22:15.360: INFO: Created: latency-svc-jvjwr
Dec  7 06:22:15.371: INFO: Created: latency-svc-2gnnn
Dec  7 06:22:15.378: INFO: Got endpoints: latency-svc-njmt8 [346.500026ms]
Dec  7 06:22:15.416: INFO: Created: latency-svc-g646p
Dec  7 06:22:15.426: INFO: Created: latency-svc-pm82q
Dec  7 06:22:15.428: INFO: Got endpoints: latency-svc-7nf4b [375.52701ms]
Dec  7 06:22:15.440: INFO: Created: latency-svc-sqpdk
Dec  7 06:22:15.446: INFO: Created: latency-svc-9jccc
Dec  7 06:22:15.459: INFO: Created: latency-svc-p46dl
Dec  7 06:22:15.470: INFO: Created: latency-svc-5d4rc
Dec  7 06:22:15.480: INFO: Created: latency-svc-k9kb9
Dec  7 06:22:15.482: INFO: Got endpoints: latency-svc-jvjwr [411.117815ms]
Dec  7 06:22:15.498: INFO: Created: latency-svc-sfcvf
Dec  7 06:22:15.510: INFO: Created: latency-svc-tr4c7
Dec  7 06:22:15.523: INFO: Created: latency-svc-7lsgs
Dec  7 06:22:15.541: INFO: Got endpoints: latency-svc-bz8lc [430.71939ms]
Dec  7 06:22:15.549: INFO: Created: latency-svc-p9pgp
Dec  7 06:22:15.576: INFO: Created: latency-svc-nppl4
Dec  7 06:22:15.603: INFO: Got endpoints: latency-svc-2gnnn [482.380432ms]
Dec  7 06:22:15.603: INFO: Created: latency-svc-h59cv
Dec  7 06:22:15.627: INFO: Created: latency-svc-5zmsj
Dec  7 06:22:15.632: INFO: Got endpoints: latency-svc-g646p [487.544976ms]
Dec  7 06:22:15.739: INFO: Got endpoints: latency-svc-pm82q [583.260122ms]
Dec  7 06:22:15.745: INFO: Got endpoints: latency-svc-sqpdk [558.301922ms]
Dec  7 06:22:15.747: INFO: Created: latency-svc-pdknm
Dec  7 06:22:15.768: INFO: Created: latency-svc-tznpr
Dec  7 06:22:15.783: INFO: Got endpoints: latency-svc-9jccc [577.898458ms]
Dec  7 06:22:15.785: INFO: Created: latency-svc-qs7wl
Dec  7 06:22:15.804: INFO: Created: latency-svc-bz4nv
Dec  7 06:22:15.814: INFO: Created: latency-svc-9vfp2
Dec  7 06:22:15.827: INFO: Got endpoints: latency-svc-p46dl [617.10944ms]
Dec  7 06:22:15.858: INFO: Created: latency-svc-j8kpv
Dec  7 06:22:15.877: INFO: Got endpoints: latency-svc-5d4rc [648.096625ms]
Dec  7 06:22:15.892: INFO: Created: latency-svc-w8n7b
Dec  7 06:22:15.932: INFO: Got endpoints: latency-svc-k9kb9 [682.382527ms]
Dec  7 06:22:15.949: INFO: Created: latency-svc-cpvq6
Dec  7 06:22:15.977: INFO: Got endpoints: latency-svc-sfcvf [711.171216ms]
Dec  7 06:22:15.993: INFO: Created: latency-svc-mppvd
Dec  7 06:22:16.027: INFO: Got endpoints: latency-svc-tr4c7 [748.339346ms]
Dec  7 06:22:16.044: INFO: Created: latency-svc-twdm6
Dec  7 06:22:16.079: INFO: Got endpoints: latency-svc-7lsgs [750.996221ms]
Dec  7 06:22:16.096: INFO: Created: latency-svc-9t47m
Dec  7 06:22:16.127: INFO: Got endpoints: latency-svc-p9pgp [748.665566ms]
Dec  7 06:22:16.143: INFO: Created: latency-svc-kz2sx
Dec  7 06:22:16.182: INFO: Got endpoints: latency-svc-nppl4 [753.733478ms]
Dec  7 06:22:16.199: INFO: Created: latency-svc-5mbp8
Dec  7 06:22:16.229: INFO: Got endpoints: latency-svc-h59cv [746.666816ms]
Dec  7 06:22:16.245: INFO: Created: latency-svc-vhvsm
Dec  7 06:22:16.277: INFO: Got endpoints: latency-svc-5zmsj [735.886822ms]
Dec  7 06:22:16.296: INFO: Created: latency-svc-jnj9m
Dec  7 06:22:16.331: INFO: Got endpoints: latency-svc-pdknm [727.23392ms]
Dec  7 06:22:16.350: INFO: Created: latency-svc-9v596
Dec  7 06:22:16.377: INFO: Got endpoints: latency-svc-tznpr [745.435053ms]
Dec  7 06:22:16.396: INFO: Created: latency-svc-r4p9p
Dec  7 06:22:16.427: INFO: Got endpoints: latency-svc-qs7wl [687.967204ms]
Dec  7 06:22:16.450: INFO: Created: latency-svc-mp59c
Dec  7 06:22:16.482: INFO: Got endpoints: latency-svc-bz4nv [737.037485ms]
Dec  7 06:22:16.496: INFO: Created: latency-svc-n2pqf
Dec  7 06:22:16.531: INFO: Got endpoints: latency-svc-9vfp2 [747.877098ms]
Dec  7 06:22:16.554: INFO: Created: latency-svc-rfnc5
Dec  7 06:22:16.580: INFO: Got endpoints: latency-svc-j8kpv [752.224907ms]
Dec  7 06:22:16.599: INFO: Created: latency-svc-jqw5f
Dec  7 06:22:16.628: INFO: Got endpoints: latency-svc-w8n7b [750.223836ms]
Dec  7 06:22:16.641: INFO: Created: latency-svc-9f7b2
Dec  7 06:22:16.677: INFO: Got endpoints: latency-svc-cpvq6 [745.343505ms]
Dec  7 06:22:16.703: INFO: Created: latency-svc-f8q6f
Dec  7 06:22:16.728: INFO: Got endpoints: latency-svc-mppvd [751.074584ms]
Dec  7 06:22:16.747: INFO: Created: latency-svc-bzs7r
Dec  7 06:22:16.790: INFO: Got endpoints: latency-svc-twdm6 [762.352565ms]
Dec  7 06:22:16.816: INFO: Created: latency-svc-n554r
Dec  7 06:22:16.828: INFO: Got endpoints: latency-svc-9t47m [748.408961ms]
Dec  7 06:22:16.838: INFO: Created: latency-svc-752xq
Dec  7 06:22:16.879: INFO: Got endpoints: latency-svc-kz2sx [752.344799ms]
Dec  7 06:22:16.902: INFO: Created: latency-svc-b4htv
Dec  7 06:22:16.928: INFO: Got endpoints: latency-svc-5mbp8 [745.869412ms]
Dec  7 06:22:16.944: INFO: Created: latency-svc-j9csf
Dec  7 06:22:16.977: INFO: Got endpoints: latency-svc-vhvsm [747.696671ms]
Dec  7 06:22:16.990: INFO: Created: latency-svc-5f4wb
Dec  7 06:22:17.029: INFO: Got endpoints: latency-svc-jnj9m [751.546999ms]
Dec  7 06:22:17.044: INFO: Created: latency-svc-tp88t
Dec  7 06:22:17.079: INFO: Got endpoints: latency-svc-9v596 [748.54099ms]
Dec  7 06:22:17.106: INFO: Created: latency-svc-fr7xt
Dec  7 06:22:17.127: INFO: Got endpoints: latency-svc-r4p9p [749.534278ms]
Dec  7 06:22:17.147: INFO: Created: latency-svc-x8ghr
Dec  7 06:22:17.178: INFO: Got endpoints: latency-svc-mp59c [750.624897ms]
Dec  7 06:22:17.192: INFO: Created: latency-svc-kch2n
Dec  7 06:22:17.229: INFO: Got endpoints: latency-svc-n2pqf [746.201474ms]
Dec  7 06:22:17.244: INFO: Created: latency-svc-fdzhn
Dec  7 06:22:17.277: INFO: Got endpoints: latency-svc-rfnc5 [745.897241ms]
Dec  7 06:22:17.292: INFO: Created: latency-svc-4lcgf
Dec  7 06:22:17.328: INFO: Got endpoints: latency-svc-jqw5f [748.853798ms]
Dec  7 06:22:17.342: INFO: Created: latency-svc-r655c
Dec  7 06:22:17.377: INFO: Got endpoints: latency-svc-9f7b2 [748.965471ms]
Dec  7 06:22:17.390: INFO: Created: latency-svc-wz52b
Dec  7 06:22:17.427: INFO: Got endpoints: latency-svc-f8q6f [749.584998ms]
Dec  7 06:22:17.443: INFO: Created: latency-svc-fwmwd
Dec  7 06:22:17.477: INFO: Got endpoints: latency-svc-bzs7r [748.569766ms]
Dec  7 06:22:17.492: INFO: Created: latency-svc-ztbmf
Dec  7 06:22:17.528: INFO: Got endpoints: latency-svc-n554r [737.747249ms]
Dec  7 06:22:17.546: INFO: Created: latency-svc-pfd7b
Dec  7 06:22:17.581: INFO: Got endpoints: latency-svc-752xq [752.992152ms]
Dec  7 06:22:17.606: INFO: Created: latency-svc-bpkt7
Dec  7 06:22:17.628: INFO: Got endpoints: latency-svc-b4htv [748.66648ms]
Dec  7 06:22:17.643: INFO: Created: latency-svc-8mpsw
Dec  7 06:22:17.678: INFO: Got endpoints: latency-svc-j9csf [749.740346ms]
Dec  7 06:22:17.699: INFO: Created: latency-svc-92pfh
Dec  7 06:22:17.727: INFO: Got endpoints: latency-svc-5f4wb [749.912112ms]
Dec  7 06:22:17.741: INFO: Created: latency-svc-xttmr
Dec  7 06:22:17.777: INFO: Got endpoints: latency-svc-tp88t [747.84552ms]
Dec  7 06:22:17.805: INFO: Created: latency-svc-wjtjb
Dec  7 06:22:17.830: INFO: Got endpoints: latency-svc-fr7xt [750.411514ms]
Dec  7 06:22:17.847: INFO: Created: latency-svc-w55wh
Dec  7 06:22:17.877: INFO: Got endpoints: latency-svc-x8ghr [749.938973ms]
Dec  7 06:22:17.892: INFO: Created: latency-svc-lpnbw
Dec  7 06:22:17.935: INFO: Got endpoints: latency-svc-kch2n [756.466414ms]
Dec  7 06:22:17.952: INFO: Created: latency-svc-xm6hx
Dec  7 06:22:17.979: INFO: Got endpoints: latency-svc-fdzhn [749.871372ms]
Dec  7 06:22:18.000: INFO: Created: latency-svc-z6895
Dec  7 06:22:18.031: INFO: Got endpoints: latency-svc-4lcgf [753.617664ms]
Dec  7 06:22:18.051: INFO: Created: latency-svc-8cg8h
Dec  7 06:22:18.077: INFO: Got endpoints: latency-svc-r655c [748.690803ms]
Dec  7 06:22:18.089: INFO: Created: latency-svc-hnstb
Dec  7 06:22:18.127: INFO: Got endpoints: latency-svc-wz52b [749.677809ms]
Dec  7 06:22:18.145: INFO: Created: latency-svc-2ltkd
Dec  7 06:22:18.177: INFO: Got endpoints: latency-svc-fwmwd [749.434075ms]
Dec  7 06:22:18.199: INFO: Created: latency-svc-hzn62
Dec  7 06:22:18.234: INFO: Got endpoints: latency-svc-ztbmf [756.369088ms]
Dec  7 06:22:18.257: INFO: Created: latency-svc-nv9lz
Dec  7 06:22:18.278: INFO: Got endpoints: latency-svc-pfd7b [749.728005ms]
Dec  7 06:22:18.303: INFO: Created: latency-svc-p6hs2
Dec  7 06:22:18.327: INFO: Got endpoints: latency-svc-bpkt7 [746.016502ms]
Dec  7 06:22:18.340: INFO: Created: latency-svc-vwfjh
Dec  7 06:22:18.378: INFO: Got endpoints: latency-svc-8mpsw [749.35009ms]
Dec  7 06:22:18.405: INFO: Created: latency-svc-826zr
Dec  7 06:22:18.431: INFO: Got endpoints: latency-svc-92pfh [753.219112ms]
Dec  7 06:22:18.447: INFO: Created: latency-svc-lphmm
Dec  7 06:22:18.480: INFO: Got endpoints: latency-svc-xttmr [752.075886ms]
Dec  7 06:22:18.491: INFO: Created: latency-svc-b4nlb
Dec  7 06:22:18.528: INFO: Got endpoints: latency-svc-wjtjb [750.8682ms]
Dec  7 06:22:18.542: INFO: Created: latency-svc-t62n7
Dec  7 06:22:18.577: INFO: Got endpoints: latency-svc-w55wh [747.118567ms]
Dec  7 06:22:18.593: INFO: Created: latency-svc-dxrj5
Dec  7 06:22:18.628: INFO: Got endpoints: latency-svc-lpnbw [750.403099ms]
Dec  7 06:22:18.647: INFO: Created: latency-svc-sfh2l
Dec  7 06:22:18.692: INFO: Got endpoints: latency-svc-xm6hx [756.413687ms]
Dec  7 06:22:18.708: INFO: Created: latency-svc-75zl8
Dec  7 06:22:18.726: INFO: Got endpoints: latency-svc-z6895 [747.418563ms]
Dec  7 06:22:18.740: INFO: Created: latency-svc-shq42
Dec  7 06:22:18.777: INFO: Got endpoints: latency-svc-8cg8h [745.708274ms]
Dec  7 06:22:18.793: INFO: Created: latency-svc-8dsz8
Dec  7 06:22:18.832: INFO: Got endpoints: latency-svc-hnstb [754.129884ms]
Dec  7 06:22:18.854: INFO: Created: latency-svc-m5789
Dec  7 06:22:18.879: INFO: Got endpoints: latency-svc-2ltkd [751.464718ms]
Dec  7 06:22:18.890: INFO: Created: latency-svc-xbdmg
Dec  7 06:22:18.928: INFO: Got endpoints: latency-svc-hzn62 [750.851941ms]
Dec  7 06:22:18.943: INFO: Created: latency-svc-7dw6d
Dec  7 06:22:18.979: INFO: Got endpoints: latency-svc-nv9lz [745.22705ms]
Dec  7 06:22:19.000: INFO: Created: latency-svc-tr4sl
Dec  7 06:22:19.029: INFO: Got endpoints: latency-svc-p6hs2 [751.191597ms]
Dec  7 06:22:19.121: INFO: Got endpoints: latency-svc-vwfjh [793.592957ms]
Dec  7 06:22:19.133: INFO: Got endpoints: latency-svc-826zr [755.449776ms]
Dec  7 06:22:19.138: INFO: Created: latency-svc-lhz9p
Dec  7 06:22:19.144: INFO: Created: latency-svc-85wsh
Dec  7 06:22:19.152: INFO: Created: latency-svc-qwwkj
Dec  7 06:22:19.182: INFO: Got endpoints: latency-svc-lphmm [750.503676ms]
Dec  7 06:22:19.200: INFO: Created: latency-svc-5l65b
Dec  7 06:22:19.229: INFO: Got endpoints: latency-svc-b4nlb [749.582998ms]
Dec  7 06:22:19.248: INFO: Created: latency-svc-cbxdm
Dec  7 06:22:19.279: INFO: Got endpoints: latency-svc-t62n7 [750.540548ms]
Dec  7 06:22:19.308: INFO: Created: latency-svc-p2ljh
Dec  7 06:22:19.334: INFO: Got endpoints: latency-svc-dxrj5 [756.709985ms]
Dec  7 06:22:19.348: INFO: Created: latency-svc-lzp8d
Dec  7 06:22:19.380: INFO: Got endpoints: latency-svc-sfh2l [752.187731ms]
Dec  7 06:22:19.400: INFO: Created: latency-svc-9zwqm
Dec  7 06:22:19.427: INFO: Got endpoints: latency-svc-75zl8 [734.057727ms]
Dec  7 06:22:19.445: INFO: Created: latency-svc-9j9mf
Dec  7 06:22:19.478: INFO: Got endpoints: latency-svc-shq42 [751.831142ms]
Dec  7 06:22:19.495: INFO: Created: latency-svc-xsnxh
Dec  7 06:22:19.543: INFO: Got endpoints: latency-svc-8dsz8 [765.043189ms]
Dec  7 06:22:19.565: INFO: Created: latency-svc-qx856
Dec  7 06:22:19.577: INFO: Got endpoints: latency-svc-m5789 [745.327845ms]
Dec  7 06:22:19.588: INFO: Created: latency-svc-wjr6h
Dec  7 06:22:19.627: INFO: Got endpoints: latency-svc-xbdmg [747.781836ms]
Dec  7 06:22:19.638: INFO: Created: latency-svc-xqqfl
Dec  7 06:22:19.677: INFO: Got endpoints: latency-svc-7dw6d [748.823068ms]
Dec  7 06:22:19.689: INFO: Created: latency-svc-kdgd6
Dec  7 06:22:19.730: INFO: Got endpoints: latency-svc-tr4sl [750.836269ms]
Dec  7 06:22:19.746: INFO: Created: latency-svc-g9s6t
Dec  7 06:22:19.777: INFO: Got endpoints: latency-svc-lhz9p [748.148594ms]
Dec  7 06:22:19.792: INFO: Created: latency-svc-5598t
Dec  7 06:22:19.828: INFO: Got endpoints: latency-svc-85wsh [706.568321ms]
Dec  7 06:22:19.840: INFO: Created: latency-svc-w58fb
Dec  7 06:22:19.882: INFO: Got endpoints: latency-svc-qwwkj [748.16286ms]
Dec  7 06:22:19.897: INFO: Created: latency-svc-q4bzp
Dec  7 06:22:19.929: INFO: Got endpoints: latency-svc-5l65b [746.893504ms]
Dec  7 06:22:19.951: INFO: Created: latency-svc-7c76w
Dec  7 06:22:19.984: INFO: Got endpoints: latency-svc-cbxdm [754.482412ms]
Dec  7 06:22:20.005: INFO: Created: latency-svc-sxm8x
Dec  7 06:22:20.043: INFO: Got endpoints: latency-svc-p2ljh [763.708005ms]
Dec  7 06:22:20.082: INFO: Created: latency-svc-xrnb4
Dec  7 06:22:20.088: INFO: Got endpoints: latency-svc-lzp8d [753.756036ms]
Dec  7 06:22:20.123: INFO: Created: latency-svc-gbrw2
Dec  7 06:22:20.128: INFO: Got endpoints: latency-svc-9zwqm [747.469495ms]
Dec  7 06:22:20.141: INFO: Created: latency-svc-tnlzn
Dec  7 06:22:20.177: INFO: Got endpoints: latency-svc-9j9mf [750.261403ms]
Dec  7 06:22:20.195: INFO: Created: latency-svc-t7rd9
Dec  7 06:22:20.227: INFO: Got endpoints: latency-svc-xsnxh [748.650511ms]
Dec  7 06:22:20.244: INFO: Created: latency-svc-dbsl2
Dec  7 06:22:20.278: INFO: Got endpoints: latency-svc-qx856 [735.661507ms]
Dec  7 06:22:20.298: INFO: Created: latency-svc-dd5nm
Dec  7 06:22:20.329: INFO: Got endpoints: latency-svc-wjr6h [751.901051ms]
Dec  7 06:22:20.343: INFO: Created: latency-svc-j9lcx
Dec  7 06:22:20.378: INFO: Got endpoints: latency-svc-xqqfl [751.439011ms]
Dec  7 06:22:20.398: INFO: Created: latency-svc-pb69m
Dec  7 06:22:20.428: INFO: Got endpoints: latency-svc-kdgd6 [750.636718ms]
Dec  7 06:22:20.442: INFO: Created: latency-svc-c2slt
Dec  7 06:22:20.481: INFO: Got endpoints: latency-svc-g9s6t [750.588943ms]
Dec  7 06:22:20.515: INFO: Created: latency-svc-782q8
Dec  7 06:22:20.530: INFO: Got endpoints: latency-svc-5598t [752.574874ms]
Dec  7 06:22:20.546: INFO: Created: latency-svc-hc86h
Dec  7 06:22:20.577: INFO: Got endpoints: latency-svc-w58fb [749.585793ms]
Dec  7 06:22:20.593: INFO: Created: latency-svc-k7pvn
Dec  7 06:22:20.628: INFO: Got endpoints: latency-svc-q4bzp [745.736044ms]
Dec  7 06:22:20.641: INFO: Created: latency-svc-5jjn2
Dec  7 06:22:20.678: INFO: Got endpoints: latency-svc-7c76w [748.934607ms]
Dec  7 06:22:20.696: INFO: Created: latency-svc-pt2pl
Dec  7 06:22:20.729: INFO: Got endpoints: latency-svc-sxm8x [744.350324ms]
Dec  7 06:22:20.744: INFO: Created: latency-svc-dt24m
Dec  7 06:22:20.778: INFO: Got endpoints: latency-svc-xrnb4 [734.786437ms]
Dec  7 06:22:20.794: INFO: Created: latency-svc-99jqm
Dec  7 06:22:20.828: INFO: Got endpoints: latency-svc-gbrw2 [739.413958ms]
Dec  7 06:22:20.856: INFO: Created: latency-svc-bxjxs
Dec  7 06:22:20.879: INFO: Got endpoints: latency-svc-tnlzn [750.949934ms]
Dec  7 06:22:20.896: INFO: Created: latency-svc-sdjpg
Dec  7 06:22:20.928: INFO: Got endpoints: latency-svc-t7rd9 [751.101829ms]
Dec  7 06:22:20.945: INFO: Created: latency-svc-wj2xh
Dec  7 06:22:20.980: INFO: Got endpoints: latency-svc-dbsl2 [752.053449ms]
Dec  7 06:22:20.998: INFO: Created: latency-svc-frqvt
Dec  7 06:22:21.030: INFO: Got endpoints: latency-svc-dd5nm [751.482364ms]
Dec  7 06:22:21.044: INFO: Created: latency-svc-svn4q
Dec  7 06:22:21.079: INFO: Got endpoints: latency-svc-j9lcx [749.327995ms]
Dec  7 06:22:21.102: INFO: Created: latency-svc-w4ccq
Dec  7 06:22:21.127: INFO: Got endpoints: latency-svc-pb69m [749.103952ms]
Dec  7 06:22:21.146: INFO: Created: latency-svc-jf2fj
Dec  7 06:22:21.180: INFO: Got endpoints: latency-svc-c2slt [752.359968ms]
Dec  7 06:22:21.234: INFO: Got endpoints: latency-svc-782q8 [752.741789ms]
Dec  7 06:22:21.235: INFO: Created: latency-svc-95qnb
Dec  7 06:22:21.248: INFO: Created: latency-svc-6wts9
Dec  7 06:22:21.278: INFO: Got endpoints: latency-svc-hc86h [747.428181ms]
Dec  7 06:22:21.303: INFO: Created: latency-svc-k9cb7
Dec  7 06:22:21.328: INFO: Got endpoints: latency-svc-k7pvn [750.534889ms]
Dec  7 06:22:21.340: INFO: Created: latency-svc-9ghtf
Dec  7 06:22:21.380: INFO: Got endpoints: latency-svc-5jjn2 [751.804072ms]
Dec  7 06:22:21.393: INFO: Created: latency-svc-6ljnp
Dec  7 06:22:21.435: INFO: Got endpoints: latency-svc-pt2pl [756.490032ms]
Dec  7 06:22:21.449: INFO: Created: latency-svc-cm9tc
Dec  7 06:22:21.479: INFO: Got endpoints: latency-svc-dt24m [750.434159ms]
Dec  7 06:22:21.500: INFO: Created: latency-svc-2vt9j
Dec  7 06:22:21.532: INFO: Got endpoints: latency-svc-99jqm [754.07412ms]
Dec  7 06:22:21.548: INFO: Created: latency-svc-pfw8t
Dec  7 06:22:21.580: INFO: Got endpoints: latency-svc-bxjxs [752.272923ms]
Dec  7 06:22:21.598: INFO: Created: latency-svc-9tccc
Dec  7 06:22:21.627: INFO: Got endpoints: latency-svc-sdjpg [747.705266ms]
Dec  7 06:22:21.640: INFO: Created: latency-svc-xgczv
Dec  7 06:22:21.680: INFO: Got endpoints: latency-svc-wj2xh [751.766942ms]
Dec  7 06:22:21.701: INFO: Created: latency-svc-zgg9p
Dec  7 06:22:21.728: INFO: Got endpoints: latency-svc-frqvt [747.552605ms]
Dec  7 06:22:21.744: INFO: Created: latency-svc-jc78q
Dec  7 06:22:21.780: INFO: Got endpoints: latency-svc-svn4q [749.345958ms]
Dec  7 06:22:21.794: INFO: Created: latency-svc-mvlgb
Dec  7 06:22:21.829: INFO: Got endpoints: latency-svc-w4ccq [749.802488ms]
Dec  7 06:22:21.840: INFO: Created: latency-svc-jbvq6
Dec  7 06:22:21.881: INFO: Got endpoints: latency-svc-jf2fj [753.090429ms]
Dec  7 06:22:21.902: INFO: Created: latency-svc-56pcc
Dec  7 06:22:21.927: INFO: Got endpoints: latency-svc-95qnb [746.915744ms]
Dec  7 06:22:21.940: INFO: Created: latency-svc-vpx94
Dec  7 06:22:21.980: INFO: Got endpoints: latency-svc-6wts9 [745.894908ms]
Dec  7 06:22:22.007: INFO: Created: latency-svc-h4xd5
Dec  7 06:22:22.027: INFO: Got endpoints: latency-svc-k9cb7 [749.322765ms]
Dec  7 06:22:22.049: INFO: Created: latency-svc-58bmt
Dec  7 06:22:22.077: INFO: Got endpoints: latency-svc-9ghtf [748.419136ms]
Dec  7 06:22:22.090: INFO: Created: latency-svc-xw544
Dec  7 06:22:22.127: INFO: Got endpoints: latency-svc-6ljnp [746.85897ms]
Dec  7 06:22:22.144: INFO: Created: latency-svc-rtkqg
Dec  7 06:22:22.181: INFO: Got endpoints: latency-svc-cm9tc [745.86212ms]
Dec  7 06:22:22.201: INFO: Created: latency-svc-94qqp
Dec  7 06:22:22.230: INFO: Got endpoints: latency-svc-2vt9j [749.78821ms]
Dec  7 06:22:22.249: INFO: Created: latency-svc-8lmds
Dec  7 06:22:22.278: INFO: Got endpoints: latency-svc-pfw8t [745.339629ms]
Dec  7 06:22:22.297: INFO: Created: latency-svc-rshzp
Dec  7 06:22:22.328: INFO: Got endpoints: latency-svc-9tccc [747.213483ms]
Dec  7 06:22:22.377: INFO: Got endpoints: latency-svc-xgczv [749.591322ms]
Dec  7 06:22:22.432: INFO: Got endpoints: latency-svc-zgg9p [752.00012ms]
Dec  7 06:22:22.478: INFO: Got endpoints: latency-svc-jc78q [750.853019ms]
Dec  7 06:22:22.528: INFO: Got endpoints: latency-svc-mvlgb [748.930237ms]
Dec  7 06:22:22.578: INFO: Got endpoints: latency-svc-jbvq6 [749.372453ms]
Dec  7 06:22:22.627: INFO: Got endpoints: latency-svc-56pcc [746.149549ms]
Dec  7 06:22:22.677: INFO: Got endpoints: latency-svc-vpx94 [749.925241ms]
Dec  7 06:22:22.729: INFO: Got endpoints: latency-svc-h4xd5 [748.818976ms]
Dec  7 06:22:22.777: INFO: Got endpoints: latency-svc-58bmt [749.668326ms]
Dec  7 06:22:22.827: INFO: Got endpoints: latency-svc-xw544 [750.240008ms]
Dec  7 06:22:22.880: INFO: Got endpoints: latency-svc-rtkqg [753.257857ms]
Dec  7 06:22:22.927: INFO: Got endpoints: latency-svc-94qqp [745.563902ms]
Dec  7 06:22:22.981: INFO: Got endpoints: latency-svc-8lmds [751.218972ms]
Dec  7 06:22:23.031: INFO: Got endpoints: latency-svc-rshzp [752.289357ms]
Dec  7 06:22:23.031: INFO: Latencies: [22.066399ms 32.264101ms 54.160272ms 54.390352ms 71.010647ms 102.179623ms 115.150301ms 128.283629ms 141.752955ms 153.331585ms 176.635589ms 197.282434ms 210.009428ms 224.53091ms 245.685581ms 247.583246ms 249.624887ms 254.696822ms 255.897435ms 256.972004ms 259.209226ms 261.482721ms 261.538628ms 262.303156ms 262.532259ms 264.804685ms 265.678676ms 266.058148ms 266.178932ms 268.037955ms 268.205551ms 270.690116ms 272.209799ms 274.225522ms 275.363796ms 275.573701ms 277.22172ms 277.578955ms 277.658522ms 279.389385ms 279.443017ms 282.998238ms 285.86669ms 288.397436ms 295.693676ms 317.300212ms 346.500026ms 375.52701ms 411.117815ms 430.71939ms 482.380432ms 487.544976ms 558.301922ms 577.898458ms 583.260122ms 617.10944ms 648.096625ms 682.382527ms 687.967204ms 706.568321ms 711.171216ms 727.23392ms 734.057727ms 734.786437ms 735.661507ms 735.886822ms 737.037485ms 737.747249ms 739.413958ms 744.350324ms 745.22705ms 745.327845ms 745.339629ms 745.343505ms 745.435053ms 745.563902ms 745.708274ms 745.736044ms 745.86212ms 745.869412ms 745.894908ms 745.897241ms 746.016502ms 746.149549ms 746.201474ms 746.666816ms 746.85897ms 746.893504ms 746.915744ms 747.118567ms 747.213483ms 747.418563ms 747.428181ms 747.469495ms 747.552605ms 747.696671ms 747.705266ms 747.781836ms 747.84552ms 747.877098ms 748.148594ms 748.16286ms 748.339346ms 748.408961ms 748.419136ms 748.54099ms 748.569766ms 748.650511ms 748.665566ms 748.66648ms 748.690803ms 748.818976ms 748.823068ms 748.853798ms 748.930237ms 748.934607ms 748.965471ms 749.103952ms 749.322765ms 749.327995ms 749.345958ms 749.35009ms 749.372453ms 749.434075ms 749.534278ms 749.582998ms 749.584998ms 749.585793ms 749.591322ms 749.668326ms 749.677809ms 749.728005ms 749.740346ms 749.78821ms 749.802488ms 749.871372ms 749.912112ms 749.925241ms 749.938973ms 750.223836ms 750.240008ms 750.261403ms 750.403099ms 750.411514ms 750.434159ms 750.503676ms 750.534889ms 750.540548ms 750.588943ms 750.624897ms 750.636718ms 750.836269ms 750.851941ms 750.853019ms 750.8682ms 750.949934ms 750.996221ms 751.074584ms 751.101829ms 751.191597ms 751.218972ms 751.439011ms 751.464718ms 751.482364ms 751.546999ms 751.766942ms 751.804072ms 751.831142ms 751.901051ms 752.00012ms 752.053449ms 752.075886ms 752.187731ms 752.224907ms 752.272923ms 752.289357ms 752.344799ms 752.359968ms 752.574874ms 752.741789ms 752.992152ms 753.090429ms 753.219112ms 753.257857ms 753.617664ms 753.733478ms 753.756036ms 754.07412ms 754.129884ms 754.482412ms 755.449776ms 756.369088ms 756.413687ms 756.466414ms 756.490032ms 756.709985ms 762.352565ms 763.708005ms 765.043189ms 793.592957ms]
Dec  7 06:22:23.031: INFO: 50 %ile: 748.148594ms
Dec  7 06:22:23.031: INFO: 90 %ile: 752.992152ms
Dec  7 06:22:23.031: INFO: 99 %ile: 765.043189ms
Dec  7 06:22:23.031: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:22:23.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-422w7" for this suite.
Dec  7 06:22:41.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:22:41.075: INFO: namespace: e2e-tests-svc-latency-422w7, resource: bindings, ignored listing per whitelist
Dec  7 06:22:41.143: INFO: namespace e2e-tests-svc-latency-422w7 deletion completed in 18.10948979s

• [SLOW TEST:28.891 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:22:41.144: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  7 06:22:49.258: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:22:49.261: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:22:51.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:22:51.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:22:53.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:22:53.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:22:55.262: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:22:55.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:22:57.262: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:22:57.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:22:59.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:22:59.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:01.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:01.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:03.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:03.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:05.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:05.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:07.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:07.266: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:09.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:09.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:11.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:11.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:13.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:13.264: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:15.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:15.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:17.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:17.265: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  7 06:23:19.261: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  7 06:23:19.265: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:23:19.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-599l4" for this suite.
Dec  7 06:23:41.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:23:41.369: INFO: namespace: e2e-tests-container-lifecycle-hook-599l4, resource: bindings, ignored listing per whitelist
Dec  7 06:23:41.377: INFO: namespace e2e-tests-container-lifecycle-hook-599l4 deletion completed in 22.108556722s

• [SLOW TEST:60.234 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:23:41.380: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:23:41.493: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a40986ab-f9e8-11e8-bee8-5a54dcfa39ab", Controller:(*bool)(0xc0017334f2), BlockOwnerDeletion:(*bool)(0xc0017334f3)}}
Dec  7 06:23:41.499: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a407c49c-f9e8-11e8-bee8-5a54dcfa39ab", Controller:(*bool)(0xc000ada71e), BlockOwnerDeletion:(*bool)(0xc000ada71f)}}
Dec  7 06:23:41.506: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a40896db-f9e8-11e8-bee8-5a54dcfa39ab", Controller:(*bool)(0xc00173381a), BlockOwnerDeletion:(*bool)(0xc00173381b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:23:46.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l4pbk" for this suite.
Dec  7 06:23:52.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:23:52.588: INFO: namespace: e2e-tests-gc-l4pbk, resource: bindings, ignored listing per whitelist
Dec  7 06:23:52.618: INFO: namespace e2e-tests-gc-l4pbk deletion completed in 6.095886304s

• [SLOW TEST:11.239 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:23:52.620: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-aabb5e7c-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:23:52.703: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-9vvt8" to be "success or failure"
Dec  7 06:23:52.713: INFO: Pod "pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.864616ms
Dec  7 06:23:54.716: INFO: Pod "pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013404908s
STEP: Saw pod success
Dec  7 06:23:54.716: INFO: Pod "pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:23:54.719: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:23:54.745: INFO: Waiting for pod pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:23:54.753: INFO: Pod pod-projected-configmaps-aabbdb6f-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:23:54.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9vvt8" for this suite.
Dec  7 06:24:00.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:24:00.869: INFO: namespace: e2e-tests-projected-9vvt8, resource: bindings, ignored listing per whitelist
Dec  7 06:24:00.876: INFO: namespace e2e-tests-projected-9vvt8 deletion completed in 6.118998489s

• [SLOW TEST:8.256 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:24:00.876: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-g6n4t in namespace e2e-tests-proxy-tkx26
I1207 06:24:00.958563      15 runners.go:184] Created replication controller with name: proxy-service-g6n4t, namespace: e2e-tests-proxy-tkx26, replica count: 1
I1207 06:24:02.009176      15 runners.go:184] proxy-service-g6n4t Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1207 06:24:03.009323      15 runners.go:184] proxy-service-g6n4t Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1207 06:24:04.009571      15 runners.go:184] proxy-service-g6n4t Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1207 06:24:05.009810      15 runners.go:184] proxy-service-g6n4t Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1207 06:24:06.010096      15 runners.go:184] proxy-service-g6n4t Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  7 06:24:06.012: INFO: setup took 5.073046417s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  7 06:24:06.030: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 16.176027ms)
Dec  7 06:24:06.030: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 16.52941ms)
Dec  7 06:24:06.030: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 16.194451ms)
Dec  7 06:24:06.030: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 17.870279ms)
Dec  7 06:24:06.030: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 17.821211ms)
Dec  7 06:24:06.031: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 17.66296ms)
Dec  7 06:24:06.036: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 23.292011ms)
Dec  7 06:24:06.038: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 24.581044ms)
Dec  7 06:24:06.038: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 25.446338ms)
Dec  7 06:24:06.039: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 25.22739ms)
Dec  7 06:24:06.043: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 30.450461ms)
Dec  7 06:24:06.045: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 31.480623ms)
Dec  7 06:24:06.045: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 32.235378ms)
Dec  7 06:24:06.046: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 33.519743ms)
Dec  7 06:24:06.046: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 33.063167ms)
Dec  7 06:24:06.047: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 34.168216ms)
Dec  7 06:24:06.066: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 18.785845ms)
Dec  7 06:24:06.068: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 21.001964ms)
Dec  7 06:24:06.071: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 24.026042ms)
Dec  7 06:24:06.071: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 24.316088ms)
Dec  7 06:24:06.072: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 24.536298ms)
Dec  7 06:24:06.072: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 25.01538ms)
Dec  7 06:24:06.078: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 30.104452ms)
Dec  7 06:24:06.078: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 30.620162ms)
Dec  7 06:24:06.079: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 32.383137ms)
Dec  7 06:24:06.080: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 32.249991ms)
Dec  7 06:24:06.082: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 35.076891ms)
Dec  7 06:24:06.083: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 35.666904ms)
Dec  7 06:24:06.086: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 38.792475ms)
Dec  7 06:24:06.087: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 39.502544ms)
Dec  7 06:24:06.090: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 43.022096ms)
Dec  7 06:24:06.091: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 43.905692ms)
Dec  7 06:24:06.108: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 16.776984ms)
Dec  7 06:24:06.109: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 16.358781ms)
Dec  7 06:24:06.109: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 16.76674ms)
Dec  7 06:24:06.109: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 17.052895ms)
Dec  7 06:24:06.110: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 17.859641ms)
Dec  7 06:24:06.111: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 18.77743ms)
Dec  7 06:24:06.111: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 19.929576ms)
Dec  7 06:24:06.112: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 19.921642ms)
Dec  7 06:24:06.113: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 21.230588ms)
Dec  7 06:24:06.113: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 20.888282ms)
Dec  7 06:24:06.114: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 22.14918ms)
Dec  7 06:24:06.114: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 21.7953ms)
Dec  7 06:24:06.114: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 21.378981ms)
Dec  7 06:24:06.114: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 21.457597ms)
Dec  7 06:24:06.115: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 22.817712ms)
Dec  7 06:24:06.116: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 23.29051ms)
Dec  7 06:24:06.123: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 7.286557ms)
Dec  7 06:24:06.125: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 8.091633ms)
Dec  7 06:24:06.126: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 8.479288ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 20.365948ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 19.627646ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 20.997645ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 19.706448ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 21.216035ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 21.103826ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 19.991433ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 20.837711ms)
Dec  7 06:24:06.137: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 20.958742ms)
Dec  7 06:24:06.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 20.594854ms)
Dec  7 06:24:06.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 20.714739ms)
Dec  7 06:24:06.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 20.986653ms)
Dec  7 06:24:06.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 21.00035ms)
Dec  7 06:24:06.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 4.528769ms)
Dec  7 06:24:06.149: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 9.790149ms)
Dec  7 06:24:06.150: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 10.219978ms)
Dec  7 06:24:06.151: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 11.693734ms)
Dec  7 06:24:06.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 12.811579ms)
Dec  7 06:24:06.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 12.77847ms)
Dec  7 06:24:06.152: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 13.387893ms)
Dec  7 06:24:06.154: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 14.568084ms)
Dec  7 06:24:06.155: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 15.383642ms)
Dec  7 06:24:06.155: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 15.666262ms)
Dec  7 06:24:06.157: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 17.410401ms)
Dec  7 06:24:06.157: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 17.422278ms)
Dec  7 06:24:06.158: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 19.41727ms)
Dec  7 06:24:06.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 19.442065ms)
Dec  7 06:24:06.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 20.001345ms)
Dec  7 06:24:06.159: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 19.748549ms)
Dec  7 06:24:06.174: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 14.629612ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 18.430909ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 18.206917ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 18.046855ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 18.356418ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 18.440813ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 18.29622ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 18.286717ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 18.248026ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 18.273011ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 18.382546ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 18.444272ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 18.822089ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 18.710313ms)
Dec  7 06:24:06.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 18.703407ms)
Dec  7 06:24:06.179: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 19.362111ms)
Dec  7 06:24:06.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 3.489984ms)
Dec  7 06:24:06.189: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 9.535892ms)
Dec  7 06:24:06.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 10.075767ms)
Dec  7 06:24:06.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 10.862222ms)
Dec  7 06:24:06.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 11.146935ms)
Dec  7 06:24:06.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 9.758716ms)
Dec  7 06:24:06.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 10.365953ms)
Dec  7 06:24:06.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 11.204056ms)
Dec  7 06:24:06.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 11.771972ms)
Dec  7 06:24:06.192: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 11.621134ms)
Dec  7 06:24:06.192: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 11.323941ms)
Dec  7 06:24:06.193: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 12.098698ms)
Dec  7 06:24:06.194: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 12.523745ms)
Dec  7 06:24:06.196: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 15.582269ms)
Dec  7 06:24:06.196: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 14.750849ms)
Dec  7 06:24:06.196: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 15.275606ms)
Dec  7 06:24:06.208: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 10.921639ms)
Dec  7 06:24:06.208: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 11.61182ms)
Dec  7 06:24:06.209: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 11.789797ms)
Dec  7 06:24:06.209: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 11.20474ms)
Dec  7 06:24:06.209: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 11.847647ms)
Dec  7 06:24:06.211: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 12.829744ms)
Dec  7 06:24:06.211: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 13.130727ms)
Dec  7 06:24:06.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 13.974631ms)
Dec  7 06:24:06.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 15.419914ms)
Dec  7 06:24:06.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 15.401356ms)
Dec  7 06:24:06.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 14.520921ms)
Dec  7 06:24:06.213: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 14.539744ms)
Dec  7 06:24:06.213: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 14.899369ms)
Dec  7 06:24:06.213: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 15.415264ms)
Dec  7 06:24:06.213: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 16.258389ms)
Dec  7 06:24:06.214: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 16.123292ms)
Dec  7 06:24:06.223: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 8.730291ms)
Dec  7 06:24:06.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 8.532655ms)
Dec  7 06:24:06.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 9.51428ms)
Dec  7 06:24:06.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 9.345636ms)
Dec  7 06:24:06.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 8.781293ms)
Dec  7 06:24:06.224: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 9.536954ms)
Dec  7 06:24:06.225: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 9.94974ms)
Dec  7 06:24:06.226: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 10.624559ms)
Dec  7 06:24:06.226: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 11.355031ms)
Dec  7 06:24:06.227: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 11.689534ms)
Dec  7 06:24:06.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 13.325824ms)
Dec  7 06:24:06.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 12.731481ms)
Dec  7 06:24:06.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 12.609291ms)
Dec  7 06:24:06.228: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 13.873137ms)
Dec  7 06:24:06.229: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 13.096686ms)
Dec  7 06:24:06.230: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 14.378397ms)
Dec  7 06:24:06.236: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 5.631361ms)
Dec  7 06:24:06.236: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 5.828127ms)
Dec  7 06:24:06.236: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 5.837231ms)
Dec  7 06:24:06.237: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 7.332258ms)
Dec  7 06:24:06.239: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 8.915274ms)
Dec  7 06:24:06.239: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 8.601095ms)
Dec  7 06:24:06.239: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 8.743447ms)
Dec  7 06:24:06.239: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 8.661555ms)
Dec  7 06:24:06.239: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 8.8435ms)
Dec  7 06:24:06.239: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 9.059695ms)
Dec  7 06:24:06.240: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 9.52452ms)
Dec  7 06:24:06.241: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 10.854399ms)
Dec  7 06:24:06.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 11.235255ms)
Dec  7 06:24:06.242: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 11.615935ms)
Dec  7 06:24:06.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 12.022925ms)
Dec  7 06:24:06.243: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 12.408923ms)
Dec  7 06:24:06.252: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 8.838986ms)
Dec  7 06:24:06.252: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 9.073268ms)
Dec  7 06:24:06.252: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 8.32261ms)
Dec  7 06:24:06.252: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 7.959427ms)
Dec  7 06:24:06.253: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 8.698994ms)
Dec  7 06:24:06.254: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 10.327927ms)
Dec  7 06:24:06.254: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 10.137667ms)
Dec  7 06:24:06.255: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 10.050648ms)
Dec  7 06:24:06.255: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 10.953108ms)
Dec  7 06:24:06.255: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 10.454135ms)
Dec  7 06:24:06.255: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 11.227958ms)
Dec  7 06:24:06.255: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 11.766222ms)
Dec  7 06:24:06.256: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 11.590086ms)
Dec  7 06:24:06.256: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 11.489228ms)
Dec  7 06:24:06.256: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 11.419064ms)
Dec  7 06:24:06.257: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 12.672306ms)
Dec  7 06:24:06.266: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 7.435972ms)
Dec  7 06:24:06.266: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 9.424418ms)
Dec  7 06:24:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 9.829911ms)
Dec  7 06:24:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 8.918775ms)
Dec  7 06:24:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 9.986952ms)
Dec  7 06:24:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 9.20972ms)
Dec  7 06:24:06.267: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 9.401609ms)
Dec  7 06:24:06.268: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 9.917271ms)
Dec  7 06:24:06.268: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 10.101613ms)
Dec  7 06:24:06.268: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 10.442728ms)
Dec  7 06:24:06.274: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 16.996397ms)
Dec  7 06:24:06.274: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 16.891144ms)
Dec  7 06:24:06.275: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 17.985851ms)
Dec  7 06:24:06.276: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 19.288685ms)
Dec  7 06:24:06.277: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 19.836251ms)
Dec  7 06:24:06.277: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 19.095484ms)
Dec  7 06:24:06.286: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 8.68536ms)
Dec  7 06:24:06.295: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 18.01ms)
Dec  7 06:24:06.298: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 20.088438ms)
Dec  7 06:24:06.298: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 20.67003ms)
Dec  7 06:24:06.299: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 20.799872ms)
Dec  7 06:24:06.299: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 20.89188ms)
Dec  7 06:24:06.300: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 22.724562ms)
Dec  7 06:24:06.300: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 22.623795ms)
Dec  7 06:24:06.301: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 23.399566ms)
Dec  7 06:24:06.301: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 23.294322ms)
Dec  7 06:24:06.301: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 23.452163ms)
Dec  7 06:24:06.301: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 23.380728ms)
Dec  7 06:24:06.303: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 25.46922ms)
Dec  7 06:24:06.304: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 26.03446ms)
Dec  7 06:24:06.304: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 26.29705ms)
Dec  7 06:24:06.305: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 27.626173ms)
Dec  7 06:24:06.318: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 11.91835ms)
Dec  7 06:24:06.318: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 12.265796ms)
Dec  7 06:24:06.321: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 14.883256ms)
Dec  7 06:24:06.321: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 15.330646ms)
Dec  7 06:24:06.321: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 15.411949ms)
Dec  7 06:24:06.323: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 17.135998ms)
Dec  7 06:24:06.323: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 17.295824ms)
Dec  7 06:24:06.323: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 17.537491ms)
Dec  7 06:24:06.323: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 17.69301ms)
Dec  7 06:24:06.324: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 18.013109ms)
Dec  7 06:24:06.324: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 18.569244ms)
Dec  7 06:24:06.325: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 19.546688ms)
Dec  7 06:24:06.326: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 19.78293ms)
Dec  7 06:24:06.326: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 20.262549ms)
Dec  7 06:24:06.326: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 20.831892ms)
Dec  7 06:24:06.327: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 21.224816ms)
Dec  7 06:24:06.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 10.316503ms)
Dec  7 06:24:06.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 11.213722ms)
Dec  7 06:24:06.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 10.85024ms)
Dec  7 06:24:06.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 11.2789ms)
Dec  7 06:24:06.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 12.68015ms)
Dec  7 06:24:06.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 13.399634ms)
Dec  7 06:24:06.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 12.992905ms)
Dec  7 06:24:06.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 13.085578ms)
Dec  7 06:24:06.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 12.601109ms)
Dec  7 06:24:06.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 14.549173ms)
Dec  7 06:24:06.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 18.712039ms)
Dec  7 06:24:06.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 18.04333ms)
Dec  7 06:24:06.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 20.185411ms)
Dec  7 06:24:06.348: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 19.004025ms)
Dec  7 06:24:06.348: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 18.780088ms)
Dec  7 06:24:06.349: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 20.782497ms)
Dec  7 06:24:06.360: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 9.577636ms)
Dec  7 06:24:06.360: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 11.487803ms)
Dec  7 06:24:06.360: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 11.299423ms)
Dec  7 06:24:06.361: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 10.162719ms)
Dec  7 06:24:06.362: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 11.734753ms)
Dec  7 06:24:06.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 12.530232ms)
Dec  7 06:24:06.363: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 12.884516ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 13.84463ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 14.143889ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 13.813167ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 13.031191ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 15.37565ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 14.745515ms)
Dec  7 06:24:06.364: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 15.108251ms)
Dec  7 06:24:06.365: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 14.925919ms)
Dec  7 06:24:06.365: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 15.081769ms)
Dec  7 06:24:06.379: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 13.225951ms)
Dec  7 06:24:06.383: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 16.580053ms)
Dec  7 06:24:06.384: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 17.745104ms)
Dec  7 06:24:06.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 19.363481ms)
Dec  7 06:24:06.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 19.360725ms)
Dec  7 06:24:06.385: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 19.076086ms)
Dec  7 06:24:06.386: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 19.37554ms)
Dec  7 06:24:06.386: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 19.199214ms)
Dec  7 06:24:06.401: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 34.479458ms)
Dec  7 06:24:06.401: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 34.758834ms)
Dec  7 06:24:06.401: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 34.456671ms)
Dec  7 06:24:06.401: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 34.891619ms)
Dec  7 06:24:06.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 36.457432ms)
Dec  7 06:24:06.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 36.577961ms)
Dec  7 06:24:06.403: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 36.928603ms)
Dec  7 06:24:06.404: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 37.493542ms)
Dec  7 06:24:06.418: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 13.521986ms)
Dec  7 06:24:06.418: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 11.856324ms)
Dec  7 06:24:06.419: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 14.58667ms)
Dec  7 06:24:06.421: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 16.316738ms)
Dec  7 06:24:06.421: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 15.881341ms)
Dec  7 06:24:06.422: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 16.386158ms)
Dec  7 06:24:06.422: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 17.286646ms)
Dec  7 06:24:06.422: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 17.19035ms)
Dec  7 06:24:06.422: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 16.359637ms)
Dec  7 06:24:06.423: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 18.223577ms)
Dec  7 06:24:06.424: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 19.724893ms)
Dec  7 06:24:06.424: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 17.791878ms)
Dec  7 06:24:06.424: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 19.075596ms)
Dec  7 06:24:06.425: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 20.250614ms)
Dec  7 06:24:06.425: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 20.106667ms)
Dec  7 06:24:06.425: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 19.941558ms)
Dec  7 06:24:06.430: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 4.462577ms)
Dec  7 06:24:06.433: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 6.572137ms)
Dec  7 06:24:06.433: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 7.036668ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 11.331937ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 12.134857ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 12.517735ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 11.128921ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 12.147825ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 11.422767ms)
Dec  7 06:24:06.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 12.392466ms)
Dec  7 06:24:06.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 12.762441ms)
Dec  7 06:24:06.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 11.799074ms)
Dec  7 06:24:06.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 13.300691ms)
Dec  7 06:24:06.440: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 12.264452ms)
Dec  7 06:24:06.441: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 14.249233ms)
Dec  7 06:24:06.442: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 14.516357ms)
Dec  7 06:24:06.451: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:1080/proxy/rewri... (200; 8.820733ms)
Dec  7 06:24:06.456: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:460/proxy/: tls baz (200; 13.651591ms)
Dec  7 06:24:06.457: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:1080/proxy/... (200; 15.031987ms)
Dec  7 06:24:06.458: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:443/proxy/... (200; 15.842418ms)
Dec  7 06:24:06.458: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 16.370617ms)
Dec  7 06:24:06.459: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 16.456604ms)
Dec  7 06:24:06.459: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/https:proxy-service-g6n4t-c7pxp:462/proxy/: tls qux (200; 16.634769ms)
Dec  7 06:24:06.460: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp:160/proxy/: foo (200; 17.551455ms)
Dec  7 06:24:06.460: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/http:proxy-service-g6n4t-c7pxp:162/proxy/: bar (200; 18.14347ms)
Dec  7 06:24:06.460: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-tkx26/pods/proxy-service-g6n4t-c7pxp/proxy/rewriteme"... (200; 17.27661ms)
Dec  7 06:24:06.461: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname1/proxy/: tls baz (200; 19.451383ms)
Dec  7 06:24:06.464: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname2/proxy/: bar (200; 22.422101ms)
Dec  7 06:24:06.465: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname2/proxy/: bar (200; 22.90144ms)
Dec  7 06:24:06.466: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/https:proxy-service-g6n4t:tlsportname2/proxy/: tls qux (200; 23.81561ms)
Dec  7 06:24:06.466: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/proxy-service-g6n4t:portname1/proxy/: foo (200; 23.878208ms)
Dec  7 06:24:06.466: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-tkx26/services/http:proxy-service-g6n4t:portname1/proxy/: foo (200; 24.465113ms)
STEP: deleting ReplicationController proxy-service-g6n4t in namespace e2e-tests-proxy-tkx26, will wait for the garbage collector to delete the pods
Dec  7 06:24:06.526: INFO: Deleting ReplicationController proxy-service-g6n4t took: 6.893005ms
Dec  7 06:24:06.626: INFO: Terminating ReplicationController proxy-service-g6n4t pods took: 100.377227ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:24:17.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-tkx26" for this suite.
Dec  7 06:24:23.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:24:23.822: INFO: namespace: e2e-tests-proxy-tkx26, resource: bindings, ignored listing per whitelist
Dec  7 06:24:23.831: INFO: namespace e2e-tests-proxy-tkx26 deletion completed in 6.094918633s

• [SLOW TEST:22.955 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:24:23.831: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:24:23.906: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  7 06:24:28.910: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  7 06:24:28.910: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  7 06:24:28.927: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-2tr26,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2tr26/deployments/test-cleanup-deployment,UID:c0528f5f-f9e8-11e8-bee8-5a54dcfa39ab,ResourceVersion:6652,Generation:1,CreationTimestamp:2018-12-07 06:24:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  7 06:24:28.932: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:24:28.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2tr26" for this suite.
Dec  7 06:24:34.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:24:35.017: INFO: namespace: e2e-tests-deployment-2tr26, resource: bindings, ignored listing per whitelist
Dec  7 06:24:35.054: INFO: namespace e2e-tests-deployment-2tr26 deletion completed in 6.115252706s

• [SLOW TEST:11.223 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:24:35.056: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  7 06:24:35.143: INFO: Waiting up to 5m0s for pod "pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-7cjqr" to be "success or failure"
Dec  7 06:24:35.146: INFO: Pod "pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.933672ms
Dec  7 06:24:37.149: INFO: Pod "pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006255774s
STEP: Saw pod success
Dec  7 06:24:37.149: INFO: Pod "pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:24:37.152: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:24:37.169: INFO: Waiting for pod pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:24:37.175: INFO: Pod pod-c407d3b3-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:24:37.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7cjqr" for this suite.
Dec  7 06:24:43.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:24:43.226: INFO: namespace: e2e-tests-emptydir-7cjqr, resource: bindings, ignored listing per whitelist
Dec  7 06:24:43.285: INFO: namespace e2e-tests-emptydir-7cjqr deletion completed in 6.093696181s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:24:43.286: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-dwtkc/secret-test-c8f45048-f9e8-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:24:43.409: INFO: Waiting up to 5m0s for pod "pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-dwtkc" to be "success or failure"
Dec  7 06:24:43.414: INFO: Pod "pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.318312ms
Dec  7 06:24:45.418: INFO: Pod "pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009150096s
STEP: Saw pod success
Dec  7 06:24:45.418: INFO: Pod "pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:24:45.420: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4 container env-test: <nil>
STEP: delete the pod
Dec  7 06:24:45.441: INFO: Waiting for pod pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:24:45.443: INFO: Pod pod-configmaps-c8f4d198-f9e8-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:24:45.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dwtkc" for this suite.
Dec  7 06:24:51.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:24:51.547: INFO: namespace: e2e-tests-secrets-dwtkc, resource: bindings, ignored listing per whitelist
Dec  7 06:24:51.593: INFO: namespace e2e-tests-secrets-dwtkc deletion completed in 6.143397539s

• [SLOW TEST:8.307 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:24:51.593: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec  7 06:24:52.731: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:24:52.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2n9tw" for this suite.
Dec  7 06:24:58.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:24:58.812: INFO: namespace: e2e-tests-gc-2n9tw, resource: bindings, ignored listing per whitelist
Dec  7 06:24:58.833: INFO: namespace e2e-tests-gc-2n9tw deletion completed in 6.098743345s

• [SLOW TEST:7.240 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:24:58.834: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-m2tzs
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  7 06:24:58.924: INFO: Found 0 stateful pods, waiting for 3
Dec  7 06:25:08.931: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 06:25:08.931: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 06:25:08.931: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  7 06:25:08.973: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  7 06:25:19.016: INFO: Updating stateful set ss2
Dec  7 06:25:19.027: INFO: Waiting for Pod e2e-tests-statefulset-m2tzs/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  7 06:25:29.096: INFO: Found 2 stateful pods, waiting for 3
Dec  7 06:25:39.099: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 06:25:39.099: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 06:25:39.099: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  7 06:25:39.122: INFO: Updating stateful set ss2
Dec  7 06:25:39.148: INFO: Waiting for Pod e2e-tests-statefulset-m2tzs/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  7 06:25:49.178: INFO: Updating stateful set ss2
Dec  7 06:25:49.191: INFO: Waiting for StatefulSet e2e-tests-statefulset-m2tzs/ss2 to complete update
Dec  7 06:25:49.191: INFO: Waiting for Pod e2e-tests-statefulset-m2tzs/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  7 06:25:59.199: INFO: Waiting for StatefulSet e2e-tests-statefulset-m2tzs/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  7 06:26:09.200: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m2tzs
Dec  7 06:26:09.204: INFO: Scaling statefulset ss2 to 0
Dec  7 06:26:39.254: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 06:26:39.258: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:26:39.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-m2tzs" for this suite.
Dec  7 06:26:45.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:26:45.371: INFO: namespace: e2e-tests-statefulset-m2tzs, resource: bindings, ignored listing per whitelist
Dec  7 06:26:45.422: INFO: namespace e2e-tests-statefulset-m2tzs deletion completed in 6.114385545s

• [SLOW TEST:106.587 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:26:45.426: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:26:47.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vtns2" for this suite.
Dec  7 06:27:25.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:27:25.642: INFO: namespace: e2e-tests-kubelet-test-vtns2, resource: bindings, ignored listing per whitelist
Dec  7 06:27:25.690: INFO: namespace e2e-tests-kubelet-test-vtns2 deletion completed in 38.102911779s

• [SLOW TEST:40.264 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:27:25.692: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-29bb0a6a-f9e9-11e8-9cb3-16e60f4677a4
STEP: Creating configMap with name cm-test-opt-upd-29bb0aae-f9e9-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-29bb0a6a-f9e9-11e8-9cb3-16e60f4677a4
STEP: Updating configmap cm-test-opt-upd-29bb0aae-f9e9-11e8-9cb3-16e60f4677a4
STEP: Creating configMap with name cm-test-opt-create-29bb0ac7-f9e9-11e8-9cb3-16e60f4677a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:27:29.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m5sjh" for this suite.
Dec  7 06:27:51.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:27:51.908: INFO: namespace: e2e-tests-configmap-m5sjh, resource: bindings, ignored listing per whitelist
Dec  7 06:27:51.997: INFO: namespace e2e-tests-configmap-m5sjh deletion completed in 22.128211073s

• [SLOW TEST:26.305 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:27:51.999: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:27:52.076: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:27:54.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8xthw" for this suite.
Dec  7 06:28:48.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:28:48.146: INFO: namespace: e2e-tests-pods-8xthw, resource: bindings, ignored listing per whitelist
Dec  7 06:28:48.216: INFO: namespace e2e-tests-pods-8xthw deletion completed in 54.093913272s

• [SLOW TEST:56.217 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:28:48.218: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:28:48.297: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-f6rl2" to be "success or failure"
Dec  7 06:28:48.302: INFO: Pod "downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.158193ms
Dec  7 06:28:50.306: INFO: Pod "downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008278961s
STEP: Saw pod success
Dec  7 06:28:50.306: INFO: Pod "downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:28:50.307: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:28:50.332: INFO: Waiting for pod downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:28:50.356: INFO: Pod downwardapi-volume-5aeba212-f9e9-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:28:50.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f6rl2" for this suite.
Dec  7 06:28:56.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:28:56.410: INFO: namespace: e2e-tests-projected-f6rl2, resource: bindings, ignored listing per whitelist
Dec  7 06:28:56.462: INFO: namespace e2e-tests-projected-f6rl2 deletion completed in 6.102955533s

• [SLOW TEST:8.244 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:28:56.463: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  7 06:28:56.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:28:56.868: INFO: stderr: ""
Dec  7 06:28:56.868: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  7 06:28:56.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:28:56.984: INFO: stderr: ""
Dec  7 06:28:56.984: INFO: stdout: "update-demo-nautilus-6rj28 update-demo-nautilus-xsjhs "
Dec  7 06:28:56.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-6rj28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:28:57.081: INFO: stderr: ""
Dec  7 06:28:57.081: INFO: stdout: ""
Dec  7 06:28:57.081: INFO: update-demo-nautilus-6rj28 is created but not running
Dec  7 06:29:02.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:02.187: INFO: stderr: ""
Dec  7 06:29:02.187: INFO: stdout: "update-demo-nautilus-6rj28 update-demo-nautilus-xsjhs "
Dec  7 06:29:02.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-6rj28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:02.291: INFO: stderr: ""
Dec  7 06:29:02.291: INFO: stdout: "true"
Dec  7 06:29:02.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-6rj28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:02.392: INFO: stderr: ""
Dec  7 06:29:02.392: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:29:02.392: INFO: validating pod update-demo-nautilus-6rj28
Dec  7 06:29:02.399: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:29:02.399: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:29:02.399: INFO: update-demo-nautilus-6rj28 is verified up and running
Dec  7 06:29:02.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-xsjhs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:02.510: INFO: stderr: ""
Dec  7 06:29:02.510: INFO: stdout: "true"
Dec  7 06:29:02.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-xsjhs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:02.628: INFO: stderr: ""
Dec  7 06:29:02.628: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 06:29:02.628: INFO: validating pod update-demo-nautilus-xsjhs
Dec  7 06:29:02.633: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 06:29:02.633: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 06:29:02.634: INFO: update-demo-nautilus-xsjhs is verified up and running
STEP: using delete to clean up resources
Dec  7 06:29:02.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:02.746: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 06:29:02.746: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  7 06:29:02.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-n24fp'
Dec  7 06:29:03.043: INFO: stderr: "No resources found.\n"
Dec  7 06:29:03.043: INFO: stdout: ""
Dec  7 06:29:03.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -l name=update-demo --namespace=e2e-tests-kubectl-n24fp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  7 06:29:03.297: INFO: stderr: ""
Dec  7 06:29:03.297: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:29:03.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n24fp" for this suite.
Dec  7 06:29:09.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:29:09.357: INFO: namespace: e2e-tests-kubectl-n24fp, resource: bindings, ignored listing per whitelist
Dec  7 06:29:09.405: INFO: namespace e2e-tests-kubectl-n24fp deletion completed in 6.10295317s

• [SLOW TEST:12.942 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:29:09.406: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:29:09.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-9bthp" to be "success or failure"
Dec  7 06:29:09.492: INFO: Pod "downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.892552ms
Dec  7 06:29:11.495: INFO: Pod "downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013234163s
Dec  7 06:29:13.499: INFO: Pod "downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016890636s
STEP: Saw pod success
Dec  7 06:29:13.499: INFO: Pod "downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:29:13.501: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:29:13.521: INFO: Waiting for pod downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:29:13.524: INFO: Pod downwardapi-volume-678c54f8-f9e9-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:29:13.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9bthp" for this suite.
Dec  7 06:29:19.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:29:19.577: INFO: namespace: e2e-tests-downward-api-9bthp, resource: bindings, ignored listing per whitelist
Dec  7 06:29:19.670: INFO: namespace e2e-tests-downward-api-9bthp deletion completed in 6.126715374s

• [SLOW TEST:10.264 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:29:19.671: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  7 06:29:19.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-9685s'
Dec  7 06:29:19.966: INFO: stderr: ""
Dec  7 06:29:19.966: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  7 06:29:20.970: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:29:20.970: INFO: Found 0 / 1
Dec  7 06:29:21.970: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:29:21.970: INFO: Found 1 / 1
Dec  7 06:29:21.970: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  7 06:29:21.973: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:29:21.973: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  7 06:29:21.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 patch pod redis-master-vlmpq --namespace=e2e-tests-kubectl-9685s -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  7 06:29:22.117: INFO: stderr: ""
Dec  7 06:29:22.118: INFO: stdout: "pod/redis-master-vlmpq patched\n"
STEP: checking annotations
Dec  7 06:29:22.121: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:29:22.121: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:29:22.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9685s" for this suite.
Dec  7 06:29:44.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:29:44.170: INFO: namespace: e2e-tests-kubectl-9685s, resource: bindings, ignored listing per whitelist
Dec  7 06:29:44.234: INFO: namespace e2e-tests-kubectl-9685s deletion completed in 22.108687564s

• [SLOW TEST:24.564 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:29:44.237: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  7 06:29:44.327: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:44.331: INFO: Number of nodes with available pods: 0
Dec  7 06:29:44.331: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:45.334: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:45.337: INFO: Number of nodes with available pods: 0
Dec  7 06:29:45.337: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:46.335: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:46.338: INFO: Number of nodes with available pods: 1
Dec  7 06:29:46.339: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  7 06:29:46.357: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:46.359: INFO: Number of nodes with available pods: 0
Dec  7 06:29:46.359: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:47.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:47.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:47.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:48.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:48.367: INFO: Number of nodes with available pods: 0
Dec  7 06:29:48.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:49.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:49.367: INFO: Number of nodes with available pods: 0
Dec  7 06:29:49.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:50.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:50.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:50.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:51.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:51.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:51.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:52.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:52.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:52.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:53.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:53.368: INFO: Number of nodes with available pods: 0
Dec  7 06:29:53.368: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:54.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:54.367: INFO: Number of nodes with available pods: 0
Dec  7 06:29:54.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:55.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:55.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:55.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:56.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:56.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:56.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:57.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:57.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:57.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:58.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:58.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:58.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:29:59.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:29:59.366: INFO: Number of nodes with available pods: 0
Dec  7 06:29:59.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:00.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:00.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:00.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:01.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:01.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:01.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:02.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:02.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:02.368: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:03.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:03.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:03.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:04.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:04.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:04.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:05.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:05.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:05.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:06.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:06.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:06.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:07.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:07.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:07.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:08.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:08.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:08.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:09.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:09.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:09.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:10.365: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:10.369: INFO: Number of nodes with available pods: 0
Dec  7 06:30:10.370: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:11.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:11.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:11.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:12.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:12.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:12.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:13.365: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:13.368: INFO: Number of nodes with available pods: 0
Dec  7 06:30:13.368: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:14.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:14.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:14.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:15.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:15.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:15.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:16.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:16.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:16.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:17.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:17.365: INFO: Number of nodes with available pods: 0
Dec  7 06:30:17.365: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:18.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:18.368: INFO: Number of nodes with available pods: 0
Dec  7 06:30:18.368: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:19.367: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:19.371: INFO: Number of nodes with available pods: 0
Dec  7 06:30:19.371: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:20.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:20.369: INFO: Number of nodes with available pods: 0
Dec  7 06:30:20.369: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:21.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:21.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:21.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:22.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:22.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:22.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:23.365: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:23.369: INFO: Number of nodes with available pods: 0
Dec  7 06:30:23.369: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:24.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:24.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:24.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:25.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:25.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:25.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:26.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:26.367: INFO: Number of nodes with available pods: 0
Dec  7 06:30:26.367: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:27.365: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:27.369: INFO: Number of nodes with available pods: 0
Dec  7 06:30:27.369: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:28.363: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:28.366: INFO: Number of nodes with available pods: 0
Dec  7 06:30:28.366: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:29.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:29.368: INFO: Number of nodes with available pods: 0
Dec  7 06:30:29.368: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:30:30.364: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 06:30:30.367: INFO: Number of nodes with available pods: 1
Dec  7 06:30:30.367: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4t2kw, will wait for the garbage collector to delete the pods
Dec  7 06:30:30.431: INFO: Deleting DaemonSet.extensions daemon-set took: 8.277423ms
Dec  7 06:30:30.531: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.310251ms
Dec  7 06:31:03.835: INFO: Number of nodes with available pods: 0
Dec  7 06:31:03.835: INFO: Number of running nodes: 0, number of available pods: 0
Dec  7 06:31:03.837: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4t2kw/daemonsets","resourceVersion":"7832"},"items":null}

Dec  7 06:31:03.840: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4t2kw/pods","resourceVersion":"7832"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:31:03.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4t2kw" for this suite.
Dec  7 06:31:09.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:31:09.917: INFO: namespace: e2e-tests-daemonsets-4t2kw, resource: bindings, ignored listing per whitelist
Dec  7 06:31:09.944: INFO: namespace e2e-tests-daemonsets-4t2kw deletion completed in 6.096095297s

• [SLOW TEST:85.708 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:31:09.946: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:31:10.047: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-htkps" to be "success or failure"
Dec  7 06:31:10.072: INFO: Pod "downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.609023ms
Dec  7 06:31:12.075: INFO: Pod "downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4": Phase="Running", Reason="", readiness=true. Elapsed: 2.028591415s
Dec  7 06:31:14.079: INFO: Pod "downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032213067s
STEP: Saw pod success
Dec  7 06:31:14.079: INFO: Pod "downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:31:14.081: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:31:14.111: INFO: Waiting for pod downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:31:14.119: INFO: Pod downwardapi-volume-af68d96a-f9e9-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:31:14.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-htkps" for this suite.
Dec  7 06:31:20.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:31:20.181: INFO: namespace: e2e-tests-projected-htkps, resource: bindings, ignored listing per whitelist
Dec  7 06:31:20.216: INFO: namespace e2e-tests-projected-htkps deletion completed in 6.093957375s

• [SLOW TEST:10.271 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:31:20.218: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9cx8l
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  7 06:31:20.290: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  7 06:31:42.361: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.130:8080/dial?request=hostName&protocol=udp&host=192.168.1.129&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-9cx8l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 06:31:42.361: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 06:31:42.487: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:31:42.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9cx8l" for this suite.
Dec  7 06:32:04.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:32:04.575: INFO: namespace: e2e-tests-pod-network-test-9cx8l, resource: bindings, ignored listing per whitelist
Dec  7 06:32:04.588: INFO: namespace e2e-tests-pod-network-test-9cx8l deletion completed in 22.097958554s

• [SLOW TEST:44.370 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:32:04.588: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:32:06.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-jcdpt" for this suite.
Dec  7 06:32:48.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:32:48.726: INFO: namespace: e2e-tests-kubelet-test-jcdpt, resource: bindings, ignored listing per whitelist
Dec  7 06:32:48.786: INFO: namespace e2e-tests-kubelet-test-jcdpt deletion completed in 42.098942463s

• [SLOW TEST:44.197 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:32:48.787: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ea50f59a-f9e9-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:32:48.878: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-hgkqv" to be "success or failure"
Dec  7 06:32:48.887: INFO: Pod "pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.817177ms
Dec  7 06:32:50.891: INFO: Pod "pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0128356s
STEP: Saw pod success
Dec  7 06:32:50.891: INFO: Pod "pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:32:50.894: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:32:50.913: INFO: Waiting for pod pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:32:50.915: INFO: Pod pod-projected-configmaps-ea5178b4-f9e9-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:32:50.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hgkqv" for this suite.
Dec  7 06:32:56.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:32:56.976: INFO: namespace: e2e-tests-projected-hgkqv, resource: bindings, ignored listing per whitelist
Dec  7 06:32:57.023: INFO: namespace e2e-tests-projected-hgkqv deletion completed in 6.0985798s

• [SLOW TEST:8.235 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:32:57.023: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:32:57.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-plkh6'
Dec  7 06:32:57.241: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  7 06:32:57.241: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec  7 06:32:59.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-plkh6'
Dec  7 06:32:59.365: INFO: stderr: ""
Dec  7 06:32:59.365: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:32:59.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-plkh6" for this suite.
Dec  7 06:33:21.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:33:21.403: INFO: namespace: e2e-tests-kubectl-plkh6, resource: bindings, ignored listing per whitelist
Dec  7 06:33:21.463: INFO: namespace e2e-tests-kubectl-plkh6 deletion completed in 22.093676319s

• [SLOW TEST:24.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:33:21.463: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  7 06:33:24.079: INFO: Successfully updated pod "annotationupdatefdca67b1-f9e9-11e8-9cb3-16e60f4677a4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:33:28.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dnpwx" for this suite.
Dec  7 06:33:50.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:33:50.183: INFO: namespace: e2e-tests-projected-dnpwx, resource: bindings, ignored listing per whitelist
Dec  7 06:33:50.216: INFO: namespace e2e-tests-projected-dnpwx deletion completed in 22.100068237s

• [SLOW TEST:28.753 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:33:50.216: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:33:50.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 version'
Dec  7 06:33:50.382: INFO: stderr: ""
Dec  7 06:33:50.382: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T20:56:12Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:33:50.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kxkrl" for this suite.
Dec  7 06:33:56.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:33:56.477: INFO: namespace: e2e-tests-kubectl-kxkrl, resource: bindings, ignored listing per whitelist
Dec  7 06:33:56.498: INFO: namespace e2e-tests-kubectl-kxkrl deletion completed in 6.113262098s

• [SLOW TEST:6.283 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:33:56.501: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-78vk9
Dec  7 06:34:00.615: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-78vk9
STEP: checking the pod's current state and verifying that restartCount is present
Dec  7 06:34:00.618: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:38:01.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-78vk9" for this suite.
Dec  7 06:38:07.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:38:07.180: INFO: namespace: e2e-tests-container-probe-78vk9, resource: bindings, ignored listing per whitelist
Dec  7 06:38:07.208: INFO: namespace e2e-tests-container-probe-78vk9 deletion completed in 6.106255697s

• [SLOW TEST:250.707 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:38:07.209: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:38:09.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-2bfb8" for this suite.
Dec  7 06:38:15.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:38:15.418: INFO: namespace: e2e-tests-emptydir-wrapper-2bfb8, resource: bindings, ignored listing per whitelist
Dec  7 06:38:15.441: INFO: namespace e2e-tests-emptydir-wrapper-2bfb8 deletion completed in 6.099541384s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:38:15.442: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  7 06:38:15.518: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8681,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  7 06:38:15.518: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8681,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  7 06:38:25.525: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8695,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  7 06:38:25.525: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8695,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  7 06:38:35.545: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8709,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  7 06:38:35.545: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8709,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  7 06:38:45.552: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8723,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  7 06:38:45.553: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-a,UID:ad03d56d-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8723,Generation:0,CreationTimestamp:2018-12-07 06:38:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  7 06:38:55.560: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-b,UID:c4e14720-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8737,Generation:0,CreationTimestamp:2018-12-07 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  7 06:38:55.560: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-b,UID:c4e14720-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8737,Generation:0,CreationTimestamp:2018-12-07 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  7 06:39:05.569: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-b,UID:c4e14720-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8751,Generation:0,CreationTimestamp:2018-12-07 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  7 06:39:05.569: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fptrz,SelfLink:/api/v1/namespaces/e2e-tests-watch-fptrz/configmaps/e2e-watch-test-configmap-b,UID:c4e14720-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8751,Generation:0,CreationTimestamp:2018-12-07 06:38:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:39:15.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fptrz" for this suite.
Dec  7 06:39:21.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:39:21.619: INFO: namespace: e2e-tests-watch-fptrz, resource: bindings, ignored listing per whitelist
Dec  7 06:39:21.670: INFO: namespace e2e-tests-watch-fptrz deletion completed in 6.096804184s

• [SLOW TEST:66.229 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:39:21.670: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  7 06:39:21.753: INFO: namespace e2e-tests-kubectl-55l5t
Dec  7 06:39:21.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-55l5t'
Dec  7 06:39:22.099: INFO: stderr: ""
Dec  7 06:39:22.099: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  7 06:39:23.103: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:39:23.103: INFO: Found 0 / 1
Dec  7 06:39:24.103: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:39:24.103: INFO: Found 1 / 1
Dec  7 06:39:24.103: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  7 06:39:24.106: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 06:39:24.106: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  7 06:39:24.106: INFO: wait on redis-master startup in e2e-tests-kubectl-55l5t 
Dec  7 06:39:24.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 logs redis-master-75lwr redis-master --namespace=e2e-tests-kubectl-55l5t'
Dec  7 06:39:24.227: INFO: stderr: ""
Dec  7 06:39:24.227: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Dec 06:39:23.011 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Dec 06:39:23.011 # Server started, Redis version 3.2.12\n1:M 07 Dec 06:39:23.011 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Dec 06:39:23.011 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  7 06:39:24.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-55l5t'
Dec  7 06:39:24.382: INFO: stderr: ""
Dec  7 06:39:24.382: INFO: stdout: "service/rm2 exposed\n"
Dec  7 06:39:24.388: INFO: Service rm2 in namespace e2e-tests-kubectl-55l5t found.
STEP: exposing service
Dec  7 06:39:26.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-55l5t'
Dec  7 06:39:26.510: INFO: stderr: ""
Dec  7 06:39:26.510: INFO: stdout: "service/rm3 exposed\n"
Dec  7 06:39:26.513: INFO: Service rm3 in namespace e2e-tests-kubectl-55l5t found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:39:28.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-55l5t" for this suite.
Dec  7 06:39:50.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:39:50.561: INFO: namespace: e2e-tests-kubectl-55l5t, resource: bindings, ignored listing per whitelist
Dec  7 06:39:50.622: INFO: namespace e2e-tests-kubectl-55l5t deletion completed in 22.099144176s

• [SLOW TEST:28.951 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:39:50.623: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  7 06:39:52.699: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e5bcd035-f9ea-11e8-9cb3-16e60f4677a4,GenerateName:,Namespace:e2e-tests-events-mcfpb,SelfLink:/api/v1/namespaces/e2e-tests-events-mcfpb/pods/send-events-e5bcd035-f9ea-11e8-9cb3-16e60f4677a4,UID:e5bd7043-f9ea-11e8-bee8-5a54dcfa39ab,ResourceVersion:8878,Generation:0,CreationTimestamp:2018-12-07 06:39:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 682030036,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.138/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-f48fn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-f48fn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-f48fn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00199d820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00199d840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:39:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:39:51 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:39:51 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:39:50 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.138,StartTime:2018-12-07 06:39:50 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-07 06:39:51 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a299f481e7abf57c039918557f2a36524f33b8383e2783311f6e3e52277dcc75}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  7 06:39:54.702: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  7 06:39:56.706: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:39:56.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-mcfpb" for this suite.
Dec  7 06:40:38.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:40:38.817: INFO: namespace: e2e-tests-events-mcfpb, resource: bindings, ignored listing per whitelist
Dec  7 06:40:38.840: INFO: namespace e2e-tests-events-mcfpb deletion completed in 42.12315679s

• [SLOW TEST:48.217 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:40:38.842: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-027cfed1-f9eb-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:40:38.930: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-lvqcf" to be "success or failure"
Dec  7 06:40:38.942: INFO: Pod "pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.468479ms
Dec  7 06:40:40.946: INFO: Pod "pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016318266s
Dec  7 06:40:42.950: INFO: Pod "pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020003831s
STEP: Saw pod success
Dec  7 06:40:42.950: INFO: Pod "pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:40:42.953: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:40:42.982: INFO: Waiting for pod pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:40:42.993: INFO: Pod pod-projected-secrets-027de905-f9eb-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:40:42.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lvqcf" for this suite.
Dec  7 06:40:49.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:40:49.048: INFO: namespace: e2e-tests-projected-lvqcf, resource: bindings, ignored listing per whitelist
Dec  7 06:40:49.099: INFO: namespace e2e-tests-projected-lvqcf deletion completed in 6.101768709s

• [SLOW TEST:10.258 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:40:49.103: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:40:58.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xw4ft" for this suite.
Dec  7 06:41:20.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:41:20.272: INFO: namespace: e2e-tests-replication-controller-xw4ft, resource: bindings, ignored listing per whitelist
Dec  7 06:41:20.305: INFO: namespace e2e-tests-replication-controller-xw4ft deletion completed in 22.097470616s

• [SLOW TEST:31.203 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:41:20.306: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:41:26.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-7d2z4" for this suite.
Dec  7 06:41:32.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:41:32.581: INFO: namespace: e2e-tests-namespaces-7d2z4, resource: bindings, ignored listing per whitelist
Dec  7 06:41:32.624: INFO: namespace e2e-tests-namespaces-7d2z4 deletion completed in 6.127300151s
STEP: Destroying namespace "e2e-tests-nsdeletetest-t2pn8" for this suite.
Dec  7 06:41:32.626: INFO: Namespace e2e-tests-nsdeletetest-t2pn8 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vcpm7" for this suite.
Dec  7 06:41:38.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:41:38.725: INFO: namespace: e2e-tests-nsdeletetest-vcpm7, resource: bindings, ignored listing per whitelist
Dec  7 06:41:38.728: INFO: namespace e2e-tests-nsdeletetest-vcpm7 deletion completed in 6.102143255s

• [SLOW TEST:18.423 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:41:38.729: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:41:38.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-h74tg'
Dec  7 06:41:38.925: INFO: stderr: ""
Dec  7 06:41:38.925: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  7 06:41:43.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-h74tg -o json'
Dec  7 06:41:44.078: INFO: stderr: ""
Dec  7 06:41:44.078: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.1.141/32\"\n        },\n        \"creationTimestamp\": \"2018-12-07T06:41:38Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-h74tg\",\n        \"resourceVersion\": \"9138\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-h74tg/pods/e2e-test-nginx-pod\",\n        \"uid\": \"263e3fac-f9eb-11e8-bee8-5a54dcfa39ab\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-chth7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"2gb-pool-qefm5t\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-chth7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-chth7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-07T06:41:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-07T06:41:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-07T06:41:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-07T06:41:38Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://59f8a95325f24269c0fb36b8baf9c707afb88fa4b33b3364e7994bfea95bb867\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-07T06:41:39Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.132.155.16\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.1.141\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-07T06:41:38Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  7 06:41:44.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 replace -f - --namespace=e2e-tests-kubectl-h74tg'
Dec  7 06:41:44.321: INFO: stderr: ""
Dec  7 06:41:44.321: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec  7 06:41:44.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-h74tg'
Dec  7 06:41:46.057: INFO: stderr: ""
Dec  7 06:41:46.057: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:41:46.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h74tg" for this suite.
Dec  7 06:41:52.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:41:52.160: INFO: namespace: e2e-tests-kubectl-h74tg, resource: bindings, ignored listing per whitelist
Dec  7 06:41:52.172: INFO: namespace e2e-tests-kubectl-h74tg deletion completed in 6.109792536s

• [SLOW TEST:13.444 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:41:52.173: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2e31519e-f9eb-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:41:52.251: INFO: Waiting up to 5m0s for pod "pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-f44gj" to be "success or failure"
Dec  7 06:41:52.261: INFO: Pod "pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.278135ms
Dec  7 06:41:54.265: INFO: Pod "pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014387278s
STEP: Saw pod success
Dec  7 06:41:54.265: INFO: Pod "pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:41:54.268: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:41:54.292: INFO: Waiting for pod pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:41:54.294: INFO: Pod pod-secrets-2e31f74c-f9eb-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:41:54.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f44gj" for this suite.
Dec  7 06:42:00.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:42:00.368: INFO: namespace: e2e-tests-secrets-f44gj, resource: bindings, ignored listing per whitelist
Dec  7 06:42:00.423: INFO: namespace e2e-tests-secrets-f44gj deletion completed in 6.123608476s

• [SLOW TEST:8.250 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:42:00.424: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  7 06:42:03.034: INFO: Successfully updated pod "pod-update-activedeadlineseconds-331d304e-f9eb-11e8-9cb3-16e60f4677a4"
Dec  7 06:42:03.034: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-331d304e-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-pods-5b2rr" to be "terminated due to deadline exceeded"
Dec  7 06:42:03.038: INFO: Pod "pod-update-activedeadlineseconds-331d304e-f9eb-11e8-9cb3-16e60f4677a4": Phase="Running", Reason="", readiness=true. Elapsed: 3.311145ms
Dec  7 06:42:05.041: INFO: Pod "pod-update-activedeadlineseconds-331d304e-f9eb-11e8-9cb3-16e60f4677a4": Phase="Running", Reason="", readiness=true. Elapsed: 2.007186443s
Dec  7 06:42:07.046: INFO: Pod "pod-update-activedeadlineseconds-331d304e-f9eb-11e8-9cb3-16e60f4677a4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011613628s
Dec  7 06:42:07.046: INFO: Pod "pod-update-activedeadlineseconds-331d304e-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:42:07.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5b2rr" for this suite.
Dec  7 06:42:13.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:42:13.131: INFO: namespace: e2e-tests-pods-5b2rr, resource: bindings, ignored listing per whitelist
Dec  7 06:42:13.175: INFO: namespace e2e-tests-pods-5b2rr deletion completed in 6.126105684s

• [SLOW TEST:12.751 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:42:13.176: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  7 06:42:13.262: INFO: Waiting up to 5m0s for pod "pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-kgzfq" to be "success or failure"
Dec  7 06:42:13.267: INFO: Pod "pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.876269ms
Dec  7 06:42:15.271: INFO: Pod "pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008904522s
STEP: Saw pod success
Dec  7 06:42:15.271: INFO: Pod "pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:42:15.274: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:42:15.302: INFO: Waiting for pod pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:42:15.307: INFO: Pod pod-3ab7e257-f9eb-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:42:15.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kgzfq" for this suite.
Dec  7 06:42:21.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:42:21.416: INFO: namespace: e2e-tests-emptydir-kgzfq, resource: bindings, ignored listing per whitelist
Dec  7 06:42:21.430: INFO: namespace e2e-tests-emptydir-kgzfq deletion completed in 6.117240438s

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:42:21.431: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:42:21.508: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  7 06:42:21.518: INFO: Number of nodes with available pods: 0
Dec  7 06:42:21.518: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  7 06:42:21.552: INFO: Number of nodes with available pods: 0
Dec  7 06:42:21.552: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:22.556: INFO: Number of nodes with available pods: 0
Dec  7 06:42:22.556: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:23.557: INFO: Number of nodes with available pods: 1
Dec  7 06:42:23.557: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  7 06:42:23.587: INFO: Number of nodes with available pods: 1
Dec  7 06:42:23.587: INFO: Number of running nodes: 0, number of available pods: 1
Dec  7 06:42:24.591: INFO: Number of nodes with available pods: 0
Dec  7 06:42:24.591: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  7 06:42:24.710: INFO: Number of nodes with available pods: 0
Dec  7 06:42:24.710: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:25.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:25.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:26.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:26.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:27.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:27.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:28.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:28.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:29.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:29.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:30.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:30.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:31.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:31.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:32.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:32.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:33.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:33.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:34.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:34.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:35.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:35.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:36.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:36.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:37.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:37.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:38.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:38.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:39.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:39.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:40.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:40.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:41.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:41.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:42.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:42.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:43.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:43.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:44.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:44.716: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:45.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:45.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:46.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:46.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:47.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:47.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:48.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:48.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:49.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:49.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:50.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:50.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:51.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:51.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:52.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:52.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:53.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:53.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:54.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:54.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:55.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:55.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:56.715: INFO: Number of nodes with available pods: 0
Dec  7 06:42:56.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:57.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:57.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:58.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:58.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:42:59.714: INFO: Number of nodes with available pods: 0
Dec  7 06:42:59.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:00.714: INFO: Number of nodes with available pods: 0
Dec  7 06:43:00.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:01.714: INFO: Number of nodes with available pods: 0
Dec  7 06:43:01.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:02.715: INFO: Number of nodes with available pods: 0
Dec  7 06:43:02.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:03.714: INFO: Number of nodes with available pods: 0
Dec  7 06:43:03.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:04.714: INFO: Number of nodes with available pods: 0
Dec  7 06:43:04.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:05.715: INFO: Number of nodes with available pods: 0
Dec  7 06:43:05.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:06.714: INFO: Number of nodes with available pods: 0
Dec  7 06:43:06.715: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:07.718: INFO: Number of nodes with available pods: 0
Dec  7 06:43:07.722: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:08.714: INFO: Number of nodes with available pods: 0
Dec  7 06:43:08.714: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 06:43:09.715: INFO: Number of nodes with available pods: 1
Dec  7 06:43:09.715: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-pjzd9, will wait for the garbage collector to delete the pods
Dec  7 06:43:09.780: INFO: Deleting DaemonSet.extensions daemon-set took: 6.558767ms
Dec  7 06:43:09.881: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.376815ms
Dec  7 06:43:47.784: INFO: Number of nodes with available pods: 0
Dec  7 06:43:47.784: INFO: Number of running nodes: 0, number of available pods: 0
Dec  7 06:43:47.786: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pjzd9/daemonsets","resourceVersion":"9461"},"items":null}

Dec  7 06:43:47.788: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pjzd9/pods","resourceVersion":"9461"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:43:47.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pjzd9" for this suite.
Dec  7 06:43:53.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:43:53.870: INFO: namespace: e2e-tests-daemonsets-pjzd9, resource: bindings, ignored listing per whitelist
Dec  7 06:43:53.918: INFO: namespace e2e-tests-daemonsets-pjzd9 deletion completed in 6.112075059s

• [SLOW TEST:92.487 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:43:53.918: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-76c1be18-f9eb-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:43:53.995: INFO: Waiting up to 5m0s for pod "pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-8qdb6" to be "success or failure"
Dec  7 06:43:54.002: INFO: Pod "pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.675374ms
Dec  7 06:43:56.006: INFO: Pod "pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011355713s
STEP: Saw pod success
Dec  7 06:43:56.006: INFO: Pod "pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:43:56.009: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:43:56.034: INFO: Waiting for pod pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:43:56.043: INFO: Pod pod-secrets-76c27d35-f9eb-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:43:56.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8qdb6" for this suite.
Dec  7 06:44:02.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:44:02.075: INFO: namespace: e2e-tests-secrets-8qdb6, resource: bindings, ignored listing per whitelist
Dec  7 06:44:02.159: INFO: namespace e2e-tests-secrets-8qdb6 deletion completed in 6.111593875s

• [SLOW TEST:8.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:44:02.159: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec  7 06:44:12.280: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:44:12.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k5qrs" for this suite.
Dec  7 06:44:18.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:44:18.361: INFO: namespace: e2e-tests-gc-k5qrs, resource: bindings, ignored listing per whitelist
Dec  7 06:44:18.400: INFO: namespace e2e-tests-gc-k5qrs deletion completed in 6.115261959s

• [SLOW TEST:16.241 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:44:18.402: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-tsb5z
Dec  7 06:44:22.514: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-tsb5z
STEP: checking the pod's current state and verifying that restartCount is present
Dec  7 06:44:22.517: INFO: Initial restart count of pod liveness-http is 0
Dec  7 06:44:40.554: INFO: Restart count of pod e2e-tests-container-probe-tsb5z/liveness-http is now 1 (18.036329552s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:44:40.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tsb5z" for this suite.
Dec  7 06:44:46.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:44:46.633: INFO: namespace: e2e-tests-container-probe-tsb5z, resource: bindings, ignored listing per whitelist
Dec  7 06:44:46.696: INFO: namespace e2e-tests-container-probe-tsb5z deletion completed in 6.109595644s

• [SLOW TEST:28.294 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:44:46.696: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  7 06:44:46.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 cluster-info'
Dec  7 06:44:46.882: INFO: stderr: ""
Dec  7 06:44:46.882: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:44:46.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z9ftj" for this suite.
Dec  7 06:44:52.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:44:52.913: INFO: namespace: e2e-tests-kubectl-z9ftj, resource: bindings, ignored listing per whitelist
Dec  7 06:44:52.993: INFO: namespace e2e-tests-kubectl-z9ftj deletion completed in 6.106863237s

• [SLOW TEST:6.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:44:52.994: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  7 06:44:53.065: INFO: Waiting up to 5m0s for pod "pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-kc6pt" to be "success or failure"
Dec  7 06:44:53.069: INFO: Pod "pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.484716ms
Dec  7 06:44:55.072: INFO: Pod "pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006646031s
Dec  7 06:44:57.076: INFO: Pod "pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010632521s
STEP: Saw pod success
Dec  7 06:44:57.076: INFO: Pod "pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:44:57.079: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 06:44:57.104: INFO: Waiting for pod pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:44:57.107: INFO: Pod pod-99f7a8e4-f9eb-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:44:57.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kc6pt" for this suite.
Dec  7 06:45:03.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:45:03.237: INFO: namespace: e2e-tests-emptydir-kc6pt, resource: bindings, ignored listing per whitelist
Dec  7 06:45:03.258: INFO: namespace e2e-tests-emptydir-kc6pt deletion completed in 6.140461101s

• [SLOW TEST:10.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:45:03.260: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a0205d8b-f9eb-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:45:03.407: INFO: Waiting up to 5m0s for pod "pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-wfkzf" to be "success or failure"
Dec  7 06:45:03.412: INFO: Pod "pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.482907ms
Dec  7 06:45:05.427: INFO: Pod "pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019753439s
STEP: Saw pod success
Dec  7 06:45:05.427: INFO: Pod "pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:45:05.431: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:45:05.459: INFO: Waiting for pod pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:45:05.462: INFO: Pod pod-configmaps-a0214861-f9eb-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:45:05.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wfkzf" for this suite.
Dec  7 06:45:11.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:45:11.509: INFO: namespace: e2e-tests-configmap-wfkzf, resource: bindings, ignored listing per whitelist
Dec  7 06:45:11.612: INFO: namespace e2e-tests-configmap-wfkzf deletion completed in 6.139089101s

• [SLOW TEST:8.352 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:45:11.614: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:45:13.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8x8vn" for this suite.
Dec  7 06:45:59.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:45:59.816: INFO: namespace: e2e-tests-kubelet-test-8x8vn, resource: bindings, ignored listing per whitelist
Dec  7 06:45:59.827: INFO: namespace e2e-tests-kubelet-test-8x8vn deletion completed in 46.098836217s

• [SLOW TEST:48.213 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:45:59.827: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-868j
STEP: Creating a pod to test atomic-volume-subpath
Dec  7 06:45:59.912: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-868j" in namespace "e2e-tests-subpath-mntxg" to be "success or failure"
Dec  7 06:45:59.920: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Pending", Reason="", readiness=false. Elapsed: 8.19338ms
Dec  7 06:46:01.924: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012200986s
Dec  7 06:46:03.929: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 4.016512102s
Dec  7 06:46:05.933: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 6.020425526s
Dec  7 06:46:07.936: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 8.023755674s
Dec  7 06:46:09.940: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 10.027967049s
Dec  7 06:46:11.944: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 12.031762756s
Dec  7 06:46:13.948: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 14.035446013s
Dec  7 06:46:15.959: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 16.046547545s
Dec  7 06:46:17.963: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 18.050848904s
Dec  7 06:46:19.967: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 20.05461497s
Dec  7 06:46:21.971: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Running", Reason="", readiness=false. Elapsed: 22.058548762s
Dec  7 06:46:23.974: INFO: Pod "pod-subpath-test-downwardapi-868j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061901872s
STEP: Saw pod success
Dec  7 06:46:23.974: INFO: Pod "pod-subpath-test-downwardapi-868j" satisfied condition "success or failure"
Dec  7 06:46:23.977: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-subpath-test-downwardapi-868j container test-container-subpath-downwardapi-868j: <nil>
STEP: delete the pod
Dec  7 06:46:24.008: INFO: Waiting for pod pod-subpath-test-downwardapi-868j to disappear
Dec  7 06:46:24.017: INFO: Pod pod-subpath-test-downwardapi-868j no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-868j
Dec  7 06:46:24.017: INFO: Deleting pod "pod-subpath-test-downwardapi-868j" in namespace "e2e-tests-subpath-mntxg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:46:24.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mntxg" for this suite.
Dec  7 06:46:30.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:46:30.080: INFO: namespace: e2e-tests-subpath-mntxg, resource: bindings, ignored listing per whitelist
Dec  7 06:46:30.134: INFO: namespace e2e-tests-subpath-mntxg deletion completed in 6.099689105s

• [SLOW TEST:30.307 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:46:30.135: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:46:30.216: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  7 06:46:30.227: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  7 06:46:35.231: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  7 06:46:35.231: INFO: Creating deployment "test-rolling-update-deployment"
Dec  7 06:46:35.235: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  7 06:46:35.247: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  7 06:46:37.254: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  7 06:46:37.257: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  7 06:46:37.266: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-q5xkn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q5xkn/deployments/test-rolling-update-deployment,UID:d6de8dfc-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:9995,Generation:1,CreationTimestamp:2018-12-07 06:46:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-07 06:46:35 +0000 UTC 2018-12-07 06:46:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-07 06:46:37 +0000 UTC 2018-12-07 06:46:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  7 06:46:37.271: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-q5xkn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q5xkn/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:d6e1cc40-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:9986,Generation:1,CreationTimestamp:2018-12-07 06:46:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d6de8dfc-f9eb-11e8-bee8-5a54dcfa39ab 0xc002157047 0xc002157048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  7 06:46:37.271: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  7 06:46:37.271: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-q5xkn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-q5xkn/replicasets/test-rolling-update-controller,UID:d3e14227-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:9994,Generation:2,CreationTimestamp:2018-12-07 06:46:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d6de8dfc-f9eb-11e8-bee8-5a54dcfa39ab 0xc002156e77 0xc002156e78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  7 06:46:37.275: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-dzqkc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-dzqkc,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-q5xkn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-q5xkn/pods/test-rolling-update-deployment-68b55d7bc6-dzqkc,UID:d6e29237-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:9985,Generation:0,CreationTimestamp:2018-12-07 06:46:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.156/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 d6e1cc40-f9eb-11e8-bee8-5a54dcfa39ab 0xc002157fd7 0xc002157fd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-p88jc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p88jc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p88jc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cca180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cca1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:46:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:46:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:46:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:46:35 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.156,StartTime:2018-12-07 06:46:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-07 06:46:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://11dfe89f988aaa08dea33f63aeddf145e2e5d0290d43fd6879ab8f5b5748351a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:46:37.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-q5xkn" for this suite.
Dec  7 06:46:43.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:46:43.361: INFO: namespace: e2e-tests-deployment-q5xkn, resource: bindings, ignored listing per whitelist
Dec  7 06:46:43.383: INFO: namespace e2e-tests-deployment-q5xkn deletion completed in 6.10354307s

• [SLOW TEST:13.248 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:46:43.384: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:46:43.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-x9hjc'
Dec  7 06:46:43.604: INFO: stderr: ""
Dec  7 06:46:43.604: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec  7 06:46:43.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x9hjc'
Dec  7 06:46:57.728: INFO: stderr: ""
Dec  7 06:46:57.728: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:46:57.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x9hjc" for this suite.
Dec  7 06:47:03.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:47:03.759: INFO: namespace: e2e-tests-kubectl-x9hjc, resource: bindings, ignored listing per whitelist
Dec  7 06:47:03.860: INFO: namespace e2e-tests-kubectl-x9hjc deletion completed in 6.12563692s

• [SLOW TEST:20.476 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:47:03.861: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 06:47:03.925: INFO: Creating deployment "test-recreate-deployment"
Dec  7 06:47:03.934: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  7 06:47:03.948: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  7 06:47:05.955: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  7 06:47:05.959: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  7 06:47:05.966: INFO: Updating deployment test-recreate-deployment
Dec  7 06:47:05.966: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  7 06:47:06.098: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-fxwj2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fxwj2/deployments/test-recreate-deployment,UID:e7f8d419-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:10129,Generation:2,CreationTimestamp:2018-12-07 06:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-07 06:47:06 +0000 UTC 2018-12-07 06:47:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-07 06:47:06 +0000 UTC 2018-12-07 06:47:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  7 06:47:06.105: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-fxwj2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fxwj2/replicasets/test-recreate-deployment-697fbf54bf,UID:e939fe21-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:10126,Generation:1,CreationTimestamp:2018-12-07 06:47:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e7f8d419-f9eb-11e8-bee8-5a54dcfa39ab 0xc00244f017 0xc00244f018}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  7 06:47:06.105: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  7 06:47:06.105: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-fxwj2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fxwj2/replicasets/test-recreate-deployment-5dfdcc846d,UID:e7fa8f4a-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:10118,Generation:2,CreationTimestamp:2018-12-07 06:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment e7f8d419-f9eb-11e8-bee8-5a54dcfa39ab 0xc00244ef57 0xc00244ef58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  7 06:47:06.113: INFO: Pod "test-recreate-deployment-697fbf54bf-lfsss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-lfsss,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-fxwj2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fxwj2/pods/test-recreate-deployment-697fbf54bf-lfsss,UID:e93b24dc-f9eb-11e8-bee8-5a54dcfa39ab,ResourceVersion:10130,Generation:0,CreationTimestamp:2018-12-07 06:47:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf e939fe21-f9eb-11e8-bee8-5a54dcfa39ab 0xc002440d67 0xc002440d68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pmx6q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pmx6q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pmx6q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002440e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002440eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:47:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:47:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:47:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:47:06 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:,StartTime:2018-12-07 06:47:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:47:06.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fxwj2" for this suite.
Dec  7 06:47:12.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:47:12.214: INFO: namespace: e2e-tests-deployment-fxwj2, resource: bindings, ignored listing per whitelist
Dec  7 06:47:12.230: INFO: namespace e2e-tests-deployment-fxwj2 deletion completed in 6.113138304s

• [SLOW TEST:8.370 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:47:12.231: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jf5qc
Dec  7 06:47:14.346: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jf5qc
STEP: checking the pod's current state and verifying that restartCount is present
Dec  7 06:47:14.348: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:51:14.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jf5qc" for this suite.
Dec  7 06:51:20.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:51:20.941: INFO: namespace: e2e-tests-container-probe-jf5qc, resource: bindings, ignored listing per whitelist
Dec  7 06:51:20.941: INFO: namespace e2e-tests-container-probe-jf5qc deletion completed in 6.106137578s

• [SLOW TEST:248.710 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:51:20.941: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 06:51:21.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-25hzp" to be "success or failure"
Dec  7 06:51:21.031: INFO: Pod "downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.69336ms
Dec  7 06:51:23.035: INFO: Pod "downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017364192s
STEP: Saw pod success
Dec  7 06:51:23.035: INFO: Pod "downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:51:23.038: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 06:51:23.056: INFO: Waiting for pod downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:51:23.059: INFO: Pod downwardapi-volume-81347125-f9ec-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:51:23.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-25hzp" for this suite.
Dec  7 06:51:29.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:51:29.138: INFO: namespace: e2e-tests-downward-api-25hzp, resource: bindings, ignored listing per whitelist
Dec  7 06:51:29.168: INFO: namespace e2e-tests-downward-api-25hzp deletion completed in 6.094178079s

• [SLOW TEST:8.226 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:51:29.168: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-861baafc-f9ec-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 06:51:29.248: INFO: Waiting up to 5m0s for pod "pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-cgd8d" to be "success or failure"
Dec  7 06:51:29.260: INFO: Pod "pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.98958ms
Dec  7 06:51:31.264: INFO: Pod "pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015976451s
STEP: Saw pod success
Dec  7 06:51:31.264: INFO: Pod "pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:51:31.267: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 06:51:31.287: INFO: Waiting for pod pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:51:31.290: INFO: Pod pod-secrets-861c5a9f-f9ec-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:51:31.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cgd8d" for this suite.
Dec  7 06:51:37.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:51:37.377: INFO: namespace: e2e-tests-secrets-cgd8d, resource: bindings, ignored listing per whitelist
Dec  7 06:51:37.399: INFO: namespace e2e-tests-secrets-cgd8d deletion completed in 6.102211196s

• [SLOW TEST:8.231 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:51:37.400: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8b045b8f-f9ec-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:51:37.481: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-j6z64" to be "success or failure"
Dec  7 06:51:37.485: INFO: Pod "pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066945ms
Dec  7 06:51:39.489: INFO: Pod "pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008137039s
STEP: Saw pod success
Dec  7 06:51:39.489: INFO: Pod "pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:51:39.492: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 06:51:39.518: INFO: Waiting for pod pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:51:39.533: INFO: Pod pod-configmaps-8b04d9b4-f9ec-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:51:39.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j6z64" for this suite.
Dec  7 06:51:45.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:51:45.589: INFO: namespace: e2e-tests-configmap-j6z64, resource: bindings, ignored listing per whitelist
Dec  7 06:51:45.677: INFO: namespace e2e-tests-configmap-j6z64 deletion completed in 6.135632528s

• [SLOW TEST:8.278 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:51:45.678: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  7 06:51:51.783: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:51:51.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dbg2s" for this suite.
Dec  7 06:51:57.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:51:57.864: INFO: namespace: e2e-tests-gc-dbg2s, resource: bindings, ignored listing per whitelist
Dec  7 06:51:57.883: INFO: namespace e2e-tests-gc-dbg2s deletion completed in 6.097125138s

• [SLOW TEST:12.205 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:51:57.886: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:52:57.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5tttq" for this suite.
Dec  7 06:53:09.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:53:10.090: INFO: namespace: e2e-tests-container-probe-5tttq, resource: bindings, ignored listing per whitelist
Dec  7 06:53:10.122: INFO: namespace e2e-tests-container-probe-5tttq deletion completed in 12.160347305s

• [SLOW TEST:72.236 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:53:10.123: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  7 06:53:10.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ksbvz'
Dec  7 06:53:10.473: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  7 06:53:10.473: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec  7 06:53:10.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-ksbvz'
Dec  7 06:53:10.660: INFO: stderr: ""
Dec  7 06:53:10.660: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:53:10.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ksbvz" for this suite.
Dec  7 06:53:32.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:53:32.712: INFO: namespace: e2e-tests-kubectl-ksbvz, resource: bindings, ignored listing per whitelist
Dec  7 06:53:32.774: INFO: namespace e2e-tests-kubectl-ksbvz deletion completed in 22.109850435s

• [SLOW TEST:22.651 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:53:32.775: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-prbts
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-prbts
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-prbts
Dec  7 06:53:32.881: INFO: Found 0 stateful pods, waiting for 1
Dec  7 06:53:42.886: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  7 06:53:42.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 06:53:43.076: INFO: stderr: ""
Dec  7 06:53:43.076: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 06:53:43.076: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 06:53:43.080: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  7 06:53:53.084: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 06:53:53.084: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 06:53:53.096: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:53:53.096: INFO: ss-0  2gb-pool-qefm5t  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:53:53.096: INFO: 
Dec  7 06:53:53.096: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  7 06:53:54.103: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996493326s
Dec  7 06:53:55.107: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990049647s
Dec  7 06:53:56.112: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985940018s
Dec  7 06:53:57.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981050522s
Dec  7 06:53:58.120: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977128323s
Dec  7 06:53:59.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972956146s
Dec  7 06:54:00.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968883831s
Dec  7 06:54:01.132: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964504663s
Dec  7 06:54:02.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.846541ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-prbts
Dec  7 06:54:03.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:54:03.369: INFO: stderr: ""
Dec  7 06:54:03.369: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 06:54:03.369: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 06:54:03.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:54:03.584: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  7 06:54:03.584: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 06:54:03.584: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 06:54:03.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:54:03.780: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  7 06:54:03.780: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 06:54:03.780: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 06:54:03.785: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec  7 06:54:13.790: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 06:54:13.790: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 06:54:13.790: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  7 06:54:13.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 06:54:13.980: INFO: stderr: ""
Dec  7 06:54:13.980: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 06:54:13.980: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 06:54:13.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 06:54:14.160: INFO: stderr: ""
Dec  7 06:54:14.160: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 06:54:14.160: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 06:54:14.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 06:54:14.345: INFO: stderr: ""
Dec  7 06:54:14.345: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 06:54:14.345: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 06:54:14.345: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 06:54:14.349: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  7 06:54:24.356: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 06:54:24.356: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 06:54:24.356: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 06:54:24.368: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:24.368: INFO: ss-0  2gb-pool-qefm5t  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:24.368: INFO: ss-1  2gb-pool-qefm5t  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  }]
Dec  7 06:54:24.368: INFO: ss-2  2gb-pool-qefm5t  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  }]
Dec  7 06:54:24.368: INFO: 
Dec  7 06:54:24.368: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  7 06:54:25.374: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:25.374: INFO: ss-0  2gb-pool-qefm5t  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:25.374: INFO: ss-1  2gb-pool-qefm5t  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  }]
Dec  7 06:54:25.374: INFO: ss-2  2gb-pool-qefm5t  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:53 +0000 UTC  }]
Dec  7 06:54:25.374: INFO: 
Dec  7 06:54:25.374: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  7 06:54:26.379: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:26.379: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:26.379: INFO: 
Dec  7 06:54:26.379: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:27.383: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:27.384: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:27.384: INFO: 
Dec  7 06:54:27.384: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:28.388: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:28.388: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:28.388: INFO: 
Dec  7 06:54:28.388: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:29.393: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:29.393: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:29.393: INFO: 
Dec  7 06:54:29.393: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:30.398: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:30.398: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:30.398: INFO: 
Dec  7 06:54:30.398: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:31.402: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:31.402: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:31.402: INFO: 
Dec  7 06:54:31.402: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:32.406: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:32.406: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:32.406: INFO: 
Dec  7 06:54:32.406: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  7 06:54:33.410: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec  7 06:54:33.410: INFO: ss-0  2gb-pool-qefm5t  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:54:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 06:53:32 +0000 UTC  }]
Dec  7 06:54:33.411: INFO: 
Dec  7 06:54:33.411: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-prbts
Dec  7 06:54:34.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:54:34.548: INFO: rc: 1
Dec  7 06:54:34.549: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001198480 exit status 1 <nil> <nil> true [0xc00137b278 0xc00137b2c0 0xc00137b338] [0xc00137b278 0xc00137b2c0 0xc00137b338] [0xc00137b290 0xc00137b310] [0x92f8e0 0x92f8e0] 0xc00123f320 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec  7 06:54:44.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:54:44.629: INFO: rc: 1
Dec  7 06:54:44.629: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b1890 exit status 1 <nil> <nil> true [0xc001780380 0xc0017803d0 0xc001780428] [0xc001780380 0xc0017803d0 0xc001780428] [0xc0017803c0 0xc001780408] [0x92f8e0 0x92f8e0] 0xc001950d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:54:54.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:54:54.716: INFO: rc: 1
Dec  7 06:54:54.716: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b1d40 exit status 1 <nil> <nil> true [0xc001780440 0xc001780478 0xc0017804c0] [0xc001780440 0xc001780478 0xc0017804c0] [0xc001780470 0xc0017804b0] [0x92f8e0 0x92f8e0] 0xc001951260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:55:04.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:55:04.811: INFO: rc: 1
Dec  7 06:55:04.811: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000ec0150 exit status 1 <nil> <nil> true [0xc0017804e0 0xc001780508 0xc001780520] [0xc0017804e0 0xc001780508 0xc001780520] [0xc001780500 0xc001780518] [0x92f8e0 0x92f8e0] 0xc001951620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:55:14.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:55:14.916: INFO: rc: 1
Dec  7 06:55:14.916: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001198a80 exit status 1 <nil> <nil> true [0xc00137b368 0xc00137b458 0xc00137b568] [0xc00137b368 0xc00137b458 0xc00137b568] [0xc00137b428 0xc00137b518] [0x92f8e0 0x92f8e0] 0xc00123fc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:55:24.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:55:25.016: INFO: rc: 1
Dec  7 06:55:25.017: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001199110 exit status 1 <nil> <nil> true [0xc00137b5a8 0xc00137b6f8 0xc00137b790] [0xc00137b5a8 0xc00137b6f8 0xc00137b790] [0xc00137b680 0xc00137b758] [0x92f8e0 0x92f8e0] 0xc001ae87e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:55:35.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:55:35.100: INFO: rc: 1
Dec  7 06:55:35.100: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0011994d0 exit status 1 <nil> <nil> true [0xc00137b808 0xc00137b8c0 0xc00137b908] [0xc00137b808 0xc00137b8c0 0xc00137b908] [0xc00137b8b0 0xc00137b8f0] [0x92f8e0 0x92f8e0] 0xc001ae9080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:55:45.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:55:45.184: INFO: rc: 1
Dec  7 06:55:45.184: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0011998c0 exit status 1 <nil> <nil> true [0xc00137b918 0xc00137b950 0xc00137b968] [0xc00137b918 0xc00137b950 0xc00137b968] [0xc00137b938 0xc00137b960] [0x92f8e0 0x92f8e0] 0xc001ae9740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:55:55.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:55:55.297: INFO: rc: 1
Dec  7 06:55:55.297: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001199cb0 exit status 1 <nil> <nil> true [0xc00137b9a8 0xc00137b9e0 0xc00137ba30] [0xc00137b9a8 0xc00137b9e0 0xc00137ba30] [0xc00137b9c8 0xc00137ba10] [0x92f8e0 0x92f8e0] 0xc001ae9c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:56:05.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:56:05.389: INFO: rc: 1
Dec  7 06:56:05.389: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000ec04e0 exit status 1 <nil> <nil> true [0xc001780528 0xc001780548 0xc001780590] [0xc001780528 0xc001780548 0xc001780590] [0xc001780538 0xc001780580] [0x92f8e0 0x92f8e0] 0xc001951aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:56:15.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:56:15.492: INFO: rc: 1
Dec  7 06:56:15.492: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000c561b0 exit status 1 <nil> <nil> true [0xc00137ba40 0xc00137ba70 0xc00137ba98] [0xc00137ba40 0xc00137ba70 0xc00137ba98] [0xc00137ba60 0xc00137ba88] [0x92f8e0 0x92f8e0] 0xc001ae9f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:56:25.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:56:25.578: INFO: rc: 1
Dec  7 06:56:25.579: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0011985d0 exit status 1 <nil> <nil> true [0xc00137a190 0xc00137a590 0xc00137a740] [0xc00137a190 0xc00137a590 0xc00137a740] [0xc00137a340 0xc00137a6c0] [0x92f8e0 0x92f8e0] 0xc001ae8900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:56:35.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:56:35.705: INFO: rc: 1
Dec  7 06:56:35.706: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001198b40 exit status 1 <nil> <nil> true [0xc00137a858 0xc00137aaa8 0xc00137ad88] [0xc00137a858 0xc00137aaa8 0xc00137ad88] [0xc00137aa70 0xc00137ac48] [0x92f8e0 0x92f8e0] 0xc001ae90e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:56:45.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:56:45.802: INFO: rc: 1
Dec  7 06:56:45.802: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b0420 exit status 1 <nil> <nil> true [0xc001780000 0xc001780030 0xc001780048] [0xc001780000 0xc001780030 0xc001780048] [0xc001780028 0xc001780040] [0x92f8e0 0x92f8e0] 0xc00123e840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:56:55.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:56:55.886: INFO: rc: 1
Dec  7 06:56:55.886: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001199200 exit status 1 <nil> <nil> true [0xc00137ade0 0xc00137af20 0xc00137b028] [0xc00137ade0 0xc00137af20 0xc00137b028] [0xc00137aeb0 0xc00137aff8] [0x92f8e0 0x92f8e0] 0xc001ae97a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:57:05.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:57:05.997: INFO: rc: 1
Dec  7 06:57:05.998: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001199620 exit status 1 <nil> <nil> true [0xc00137b048 0xc00137b168 0xc00137b218] [0xc00137b048 0xc00137b168 0xc00137b218] [0xc00137b118 0xc00137b1e8] [0x92f8e0 0x92f8e0] 0xc001ae9c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:57:15.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:57:16.094: INFO: rc: 1
Dec  7 06:57:16.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001199a10 exit status 1 <nil> <nil> true [0xc00137b270 0xc00137b290 0xc00137b310] [0xc00137b270 0xc00137b290 0xc00137b310] [0xc00137b288 0xc00137b2c8] [0x92f8e0 0x92f8e0] 0xc00151c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:57:26.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:57:26.192: INFO: rc: 1
Dec  7 06:57:26.192: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001199e00 exit status 1 <nil> <nil> true [0xc00137b338 0xc00137b428 0xc00137b518] [0xc00137b338 0xc00137b428 0xc00137b518] [0xc00137b3d0 0xc00137b4a0] [0x92f8e0 0x92f8e0] 0xc00151ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:57:36.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:57:36.284: INFO: rc: 1
Dec  7 06:57:36.284: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0012a7e30 exit status 1 <nil> <nil> true [0xc00137b568 0xc00137b680 0xc00137b758] [0xc00137b568 0xc00137b680 0xc00137b758] [0xc00137b628 0xc00137b718] [0x92f8e0 0x92f8e0] 0xc00151d8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:57:46.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:57:46.377: INFO: rc: 1
Dec  7 06:57:46.377: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b07e0 exit status 1 <nil> <nil> true [0xc001780050 0xc0017800a8 0xc0017800d8] [0xc001780050 0xc0017800a8 0xc0017800d8] [0xc0017800a0 0xc0017800d0] [0x92f8e0 0x92f8e0] 0xc00123f020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:57:56.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:57:56.469: INFO: rc: 1
Dec  7 06:57:56.469: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000ce1140 exit status 1 <nil> <nil> true [0xc00137b790 0xc00137b8b0 0xc00137b8f0] [0xc00137b790 0xc00137b8b0 0xc00137b8f0] [0xc00137b860 0xc00137b8e8] [0x92f8e0 0x92f8e0] 0xc0008300c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:58:06.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:58:06.557: INFO: rc: 1
Dec  7 06:58:06.557: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000ce1500 exit status 1 <nil> <nil> true [0xc00137b908 0xc00137b938 0xc00137b960] [0xc00137b908 0xc00137b938 0xc00137b960] [0xc00137b928 0xc00137b958] [0x92f8e0 0x92f8e0] 0xc0008303c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:58:16.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:58:16.672: INFO: rc: 1
Dec  7 06:58:16.672: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b0e10 exit status 1 <nil> <nil> true [0xc0017800e8 0xc001780110 0xc001780128] [0xc0017800e8 0xc001780110 0xc001780128] [0xc001780108 0xc001780120] [0x92f8e0 0x92f8e0] 0xc00123f800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:58:26.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:58:26.804: INFO: rc: 1
Dec  7 06:58:26.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001198090 exit status 1 <nil> <nil> true [0xc001780020 0xc001780038 0xc001780050] [0xc001780020 0xc001780038 0xc001780050] [0xc001780030 0xc001780048] [0x92f8e0 0x92f8e0] 0xc00151c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:58:36.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:58:36.892: INFO: rc: 1
Dec  7 06:58:36.892: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b0450 exit status 1 <nil> <nil> true [0xc00137a080 0xc00137a340 0xc00137a6c0] [0xc00137a080 0xc00137a340 0xc00137a6c0] [0xc00137a300 0xc00137a5e0] [0x92f8e0 0x92f8e0] 0xc001ae8900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:58:46.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:58:46.992: INFO: rc: 1
Dec  7 06:58:46.992: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b0990 exit status 1 <nil> <nil> true [0xc00137a740 0xc00137aa70 0xc00137ac48] [0xc00137a740 0xc00137aa70 0xc00137ac48] [0xc00137a920 0xc00137ab78] [0x92f8e0 0x92f8e0] 0xc001ae90e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:58:56.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:58:57.083: INFO: rc: 1
Dec  7 06:58:57.083: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001198690 exit status 1 <nil> <nil> true [0xc001780070 0xc0017800c0 0xc0017800e8] [0xc001780070 0xc0017800c0 0xc0017800e8] [0xc0017800a8 0xc0017800d8] [0x92f8e0 0x92f8e0] 0xc00151d2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:59:07.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:59:07.178: INFO: rc: 1
Dec  7 06:59:07.178: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b0e70 exit status 1 <nil> <nil> true [0xc00137ad88 0xc00137aeb0 0xc00137aff8] [0xc00137ad88 0xc00137aeb0 0xc00137aff8] [0xc00137ae80 0xc00137af98] [0x92f8e0 0x92f8e0] 0xc001ae97a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:59:17.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:59:17.277: INFO: rc: 1
Dec  7 06:59:17.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001198c30 exit status 1 <nil> <nil> true [0xc0017800f0 0xc001780118 0xc001780130] [0xc0017800f0 0xc001780118 0xc001780130] [0xc001780110 0xc001780128] [0x92f8e0 0x92f8e0] 0xc00123e120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:59:27.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:59:27.362: INFO: rc: 1
Dec  7 06:59:27.362: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010b1740 exit status 1 <nil> <nil> true [0xc00137b028 0xc00137b118 0xc00137b1e8] [0xc00137b028 0xc00137b118 0xc00137b1e8] [0xc00137b0e8 0xc00137b1b0] [0x92f8e0 0x92f8e0] 0xc001ae9c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  7 06:59:37.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-prbts ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 06:59:37.452: INFO: rc: 1
Dec  7 06:59:37.452: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec  7 06:59:37.452: INFO: Scaling statefulset ss to 0
Dec  7 06:59:37.461: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  7 06:59:37.464: INFO: Deleting all statefulset in ns e2e-tests-statefulset-prbts
Dec  7 06:59:37.466: INFO: Scaling statefulset ss to 0
Dec  7 06:59:37.473: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 06:59:37.475: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:59:37.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-prbts" for this suite.
Dec  7 06:59:43.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:59:43.568: INFO: namespace: e2e-tests-statefulset-prbts, resource: bindings, ignored listing per whitelist
Dec  7 06:59:43.611: INFO: namespace e2e-tests-statefulset-prbts deletion completed in 6.120157315s

• [SLOW TEST:370.837 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:59:43.614: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  7 06:59:43.702: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-dcx4m,SelfLink:/api/v1/namespaces/e2e-tests-watch-dcx4m/configmaps/e2e-watch-test-resource-version,UID:acd1f3ba-f9ed-11e8-bee8-5a54dcfa39ab,ResourceVersion:11663,Generation:0,CreationTimestamp:2018-12-07 06:59:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  7 06:59:43.702: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-dcx4m,SelfLink:/api/v1/namespaces/e2e-tests-watch-dcx4m/configmaps/e2e-watch-test-resource-version,UID:acd1f3ba-f9ed-11e8-bee8-5a54dcfa39ab,ResourceVersion:11664,Generation:0,CreationTimestamp:2018-12-07 06:59:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:59:43.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dcx4m" for this suite.
Dec  7 06:59:49.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:59:49.736: INFO: namespace: e2e-tests-watch-dcx4m, resource: bindings, ignored listing per whitelist
Dec  7 06:59:49.789: INFO: namespace e2e-tests-watch-dcx4m deletion completed in 6.084468716s

• [SLOW TEST:6.176 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:59:49.790: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tdsj4/configmap-test-b07f07cf-f9ed-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 06:59:49.857: INFO: Waiting up to 5m0s for pod "pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-tdsj4" to be "success or failure"
Dec  7 06:59:49.873: INFO: Pod "pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.518636ms
Dec  7 06:59:51.876: INFO: Pod "pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019047455s
STEP: Saw pod success
Dec  7 06:59:51.877: INFO: Pod "pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 06:59:51.879: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4 container env-test: <nil>
STEP: delete the pod
Dec  7 06:59:51.900: INFO: Waiting for pod pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 06:59:51.902: INFO: Pod pod-configmaps-b07f8ba4-f9ed-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 06:59:51.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tdsj4" for this suite.
Dec  7 06:59:57.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 06:59:57.969: INFO: namespace: e2e-tests-configmap-tdsj4, resource: bindings, ignored listing per whitelist
Dec  7 06:59:58.008: INFO: namespace e2e-tests-configmap-tdsj4 deletion completed in 6.094761538s

• [SLOW TEST:8.218 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 06:59:58.010: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  7 06:59:58.084: INFO: Waiting up to 5m0s for pod "client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-containers-nslrd" to be "success or failure"
Dec  7 06:59:58.088: INFO: Pod "client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.693959ms
Dec  7 07:00:00.092: INFO: Pod "client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007612728s
STEP: Saw pod success
Dec  7 07:00:00.092: INFO: Pod "client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:00:00.095: INFO: Trying to get logs from node 2gb-pool-qefm5t pod client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:00:00.119: INFO: Waiting for pod client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:00:00.121: INFO: Pod client-containers-b566aaa5-f9ed-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:00:00.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nslrd" for this suite.
Dec  7 07:00:06.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:00:06.161: INFO: namespace: e2e-tests-containers-nslrd, resource: bindings, ignored listing per whitelist
Dec  7 07:00:06.220: INFO: namespace e2e-tests-containers-nslrd deletion completed in 6.095855605s

• [SLOW TEST:8.211 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:00:06.225: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  7 07:00:06.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 api-versions'
Dec  7 07:00:06.463: INFO: stderr: ""
Dec  7 07:00:06.464: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:00:06.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n228p" for this suite.
Dec  7 07:00:12.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:00:12.556: INFO: namespace: e2e-tests-kubectl-n228p, resource: bindings, ignored listing per whitelist
Dec  7 07:00:12.574: INFO: namespace e2e-tests-kubectl-n228p deletion completed in 6.106349904s

• [SLOW TEST:6.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:00:12.577: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-p4c44
Dec  7 07:00:14.697: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-p4c44
STEP: checking the pod's current state and verifying that restartCount is present
Dec  7 07:00:14.700: INFO: Initial restart count of pod liveness-exec is 0
Dec  7 07:01:04.807: INFO: Restart count of pod e2e-tests-container-probe-p4c44/liveness-exec is now 1 (50.10660703s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:01:04.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p4c44" for this suite.
Dec  7 07:01:10.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:01:10.863: INFO: namespace: e2e-tests-container-probe-p4c44, resource: bindings, ignored listing per whitelist
Dec  7 07:01:10.938: INFO: namespace e2e-tests-container-probe-p4c44 deletion completed in 6.115007114s

• [SLOW TEST:58.362 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:01:10.939: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  7 07:01:11.006: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:01:14.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xblnn" for this suite.
Dec  7 07:01:36.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:01:36.961: INFO: namespace: e2e-tests-init-container-xblnn, resource: bindings, ignored listing per whitelist
Dec  7 07:01:37.040: INFO: namespace e2e-tests-init-container-xblnn deletion completed in 22.167772938s

• [SLOW TEST:26.105 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:01:37.044: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  7 07:01:39.140: INFO: Pod pod-hostip-f06da702-f9ed-11e8-9cb3-16e60f4677a4 has hostIP: 10.132.155.16
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:01:39.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bfg64" for this suite.
Dec  7 07:02:01.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:02:01.209: INFO: namespace: e2e-tests-pods-bfg64, resource: bindings, ignored listing per whitelist
Dec  7 07:02:01.306: INFO: namespace e2e-tests-pods-bfg64 deletion completed in 22.160780378s

• [SLOW TEST:24.262 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:02:01.309: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  7 07:02:03.468: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:02:27.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-d4jbw" for this suite.
Dec  7 07:02:33.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:02:33.642: INFO: namespace: e2e-tests-namespaces-d4jbw, resource: bindings, ignored listing per whitelist
Dec  7 07:02:33.663: INFO: namespace e2e-tests-namespaces-d4jbw deletion completed in 6.139217371s
STEP: Destroying namespace "e2e-tests-nsdeletetest-245rk" for this suite.
Dec  7 07:02:33.666: INFO: Namespace e2e-tests-nsdeletetest-245rk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-sfmss" for this suite.
Dec  7 07:02:39.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:02:39.716: INFO: namespace: e2e-tests-nsdeletetest-sfmss, resource: bindings, ignored listing per whitelist
Dec  7 07:02:39.767: INFO: namespace e2e-tests-nsdeletetest-sfmss deletion completed in 6.100806053s

• [SLOW TEST:38.458 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:02:39.769: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:02:39.854: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-7gql7" to be "success or failure"
Dec  7 07:02:39.872: INFO: Pod "downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.145659ms
Dec  7 07:02:41.876: INFO: Pod "downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022086856s
STEP: Saw pod success
Dec  7 07:02:41.876: INFO: Pod "downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:02:41.879: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:02:41.944: INFO: Waiting for pod downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:02:41.948: INFO: Pod downwardapi-volume-15d22eef-f9ee-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:02:41.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7gql7" for this suite.
Dec  7 07:02:47.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:02:48.051: INFO: namespace: e2e-tests-downward-api-7gql7, resource: bindings, ignored listing per whitelist
Dec  7 07:02:48.057: INFO: namespace e2e-tests-downward-api-7gql7 deletion completed in 6.105605234s

• [SLOW TEST:8.288 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:02:48.058: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:02:48.191: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-tq7qq" to be "success or failure"
Dec  7 07:02:48.200: INFO: Pod "downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.844563ms
Dec  7 07:02:50.204: INFO: Pod "downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012445669s
STEP: Saw pod success
Dec  7 07:02:50.204: INFO: Pod "downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:02:50.206: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:02:50.235: INFO: Waiting for pod downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:02:50.249: INFO: Pod downwardapi-volume-1acb154d-f9ee-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:02:50.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tq7qq" for this suite.
Dec  7 07:02:56.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:02:56.275: INFO: namespace: e2e-tests-downward-api-tq7qq, resource: bindings, ignored listing per whitelist
Dec  7 07:02:56.357: INFO: namespace e2e-tests-downward-api-tq7qq deletion completed in 6.103012152s

• [SLOW TEST:8.299 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:02:56.359: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  7 07:02:56.438: INFO: Waiting up to 5m0s for pod "pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-4xmft" to be "success or failure"
Dec  7 07:02:56.442: INFO: Pod "pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04598ms
Dec  7 07:02:58.447: INFO: Pod "pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009028175s
STEP: Saw pod success
Dec  7 07:02:58.447: INFO: Pod "pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:02:58.450: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:02:58.476: INFO: Waiting for pod pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:02:58.485: INFO: Pod pod-1fb58f2a-f9ee-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:02:58.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4xmft" for this suite.
Dec  7 07:03:04.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:03:04.560: INFO: namespace: e2e-tests-emptydir-4xmft, resource: bindings, ignored listing per whitelist
Dec  7 07:03:04.595: INFO: namespace e2e-tests-emptydir-4xmft deletion completed in 6.105632155s

• [SLOW TEST:8.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:03:04.596: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  7 07:03:04.652: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  7 07:03:04.669: INFO: Waiting for terminating namespaces to be deleted...
Dec  7 07:03:04.672: INFO: 
Logging pods the kubelet thinks is on node 2gb-pool-qefm5t before test
Dec  7 07:03:04.679: INFO: sonobuoy-e2e-job-f8206d314b644524 from heptio-sonobuoy started at 2018-12-07 06:07:46 +0000 UTC (2 container statuses recorded)
Dec  7 07:03:04.679: INFO: 	Container e2e ready: true, restart count 0
Dec  7 07:03:04.679: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  7 07:03:04.679: INFO: kube-proxy-smrvg from kube-system started at 2018-12-07 05:59:48 +0000 UTC (1 container statuses recorded)
Dec  7 07:03:04.679: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  7 07:03:04.679: INFO: sonobuoy-systemd-logs-daemon-set-ac0c249d5e6f4d1f-5jfhb from heptio-sonobuoy started at 2018-12-07 06:07:46 +0000 UTC (2 container statuses recorded)
Dec  7 07:03:04.680: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  7 07:03:04.680: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  7 07:03:04.680: INFO: pharmer-provisioner-cf7cd8d85-fckbl from kube-system started at 2018-12-07 06:00:17 +0000 UTC (1 container statuses recorded)
Dec  7 07:03:04.680: INFO: 	Container cloud-storage ready: true, restart count 0
Dec  7 07:03:04.680: INFO: pharmer-flex-5ngx4 from kube-system started at 2018-12-07 06:00:17 +0000 UTC (1 container statuses recorded)
Dec  7 07:03:04.680: INFO: 	Container pharmer-flex ready: true, restart count 0
Dec  7 07:03:04.680: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-07 06:07:42 +0000 UTC (1 container statuses recorded)
Dec  7 07:03:04.680: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  7 07:03:04.680: INFO: calico-node-wmv9t from kube-system started at 2018-12-07 05:59:48 +0000 UTC (2 container statuses recorded)
Dec  7 07:03:04.680: INFO: 	Container calico-node ready: true, restart count 0
Dec  7 07:03:04.681: INFO: 	Container install-cni ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod sonobuoy requesting resource cpu=0m on Node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod sonobuoy-e2e-job-f8206d314b644524 requesting resource cpu=0m on Node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod sonobuoy-systemd-logs-daemon-set-ac0c249d5e6f4d1f-5jfhb requesting resource cpu=0m on Node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod calico-node-wmv9t requesting resource cpu=250m on Node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod kube-proxy-smrvg requesting resource cpu=0m on Node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod pharmer-flex-5ngx4 requesting resource cpu=0m on Node 2gb-pool-qefm5t
Dec  7 07:03:04.710: INFO: Pod pharmer-provisioner-cf7cd8d85-fckbl requesting resource cpu=50m on Node 2gb-pool-qefm5t
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24a4bf40-f9ee-11e8-9cb3-16e60f4677a4.156dfaf6b304d0f4], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z7pjq/filler-pod-24a4bf40-f9ee-11e8-9cb3-16e60f4677a4 to 2gb-pool-qefm5t]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24a4bf40-f9ee-11e8-9cb3-16e60f4677a4.156dfaf6e1881766], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24a4bf40-f9ee-11e8-9cb3-16e60f4677a4.156dfaf6e4abb6fc], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24a4bf40-f9ee-11e8-9cb3-16e60f4677a4.156dfaf6ee29eb36], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156dfaf72b9ccbe0], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 2gb-pool-qefm5t
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:03:07.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-z7pjq" for this suite.
Dec  7 07:03:13.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:03:13.853: INFO: namespace: e2e-tests-sched-pred-z7pjq, resource: bindings, ignored listing per whitelist
Dec  7 07:03:13.879: INFO: namespace e2e-tests-sched-pred-z7pjq deletion completed in 6.097330269s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.284 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:03:13.880: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-655hn
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  7 07:03:13.960: INFO: Found 0 stateful pods, waiting for 3
Dec  7 07:03:23.964: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 07:03:23.964: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 07:03:23.964: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 07:03:23.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-655hn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 07:03:24.155: INFO: stderr: ""
Dec  7 07:03:24.155: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 07:03:24.155: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  7 07:03:34.185: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  7 07:03:44.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-655hn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:03:44.404: INFO: stderr: ""
Dec  7 07:03:44.404: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 07:03:44.404: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 07:04:04.424: INFO: Waiting for StatefulSet e2e-tests-statefulset-655hn/ss2 to complete update
Dec  7 07:04:04.424: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec  7 07:04:14.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-655hn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 07:04:14.621: INFO: stderr: ""
Dec  7 07:04:14.621: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 07:04:14.621: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 07:04:24.653: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  7 07:04:34.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-655hn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:04:34.863: INFO: stderr: ""
Dec  7 07:04:34.863: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 07:04:34.863: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 07:04:44.881: INFO: Waiting for StatefulSet e2e-tests-statefulset-655hn/ss2 to complete update
Dec  7 07:04:44.881: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  7 07:04:44.881: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  7 07:04:44.881: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  7 07:04:54.887: INFO: Waiting for StatefulSet e2e-tests-statefulset-655hn/ss2 to complete update
Dec  7 07:04:54.887: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  7 07:04:54.887: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  7 07:05:04.888: INFO: Waiting for StatefulSet e2e-tests-statefulset-655hn/ss2 to complete update
Dec  7 07:05:04.888: INFO: Waiting for Pod e2e-tests-statefulset-655hn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  7 07:05:14.888: INFO: Deleting all statefulset in ns e2e-tests-statefulset-655hn
Dec  7 07:05:14.891: INFO: Scaling statefulset ss2 to 0
Dec  7 07:05:44.908: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 07:05:44.910: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:05:44.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-655hn" for this suite.
Dec  7 07:05:50.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:05:50.990: INFO: namespace: e2e-tests-statefulset-655hn, resource: bindings, ignored listing per whitelist
Dec  7 07:05:51.023: INFO: namespace e2e-tests-statefulset-655hn deletion completed in 6.089363935s

• [SLOW TEST:157.143 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:05:51.024: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:05:51.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hhkr7" for this suite.
Dec  7 07:06:13.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:06:13.173: INFO: namespace: e2e-tests-kubelet-test-hhkr7, resource: bindings, ignored listing per whitelist
Dec  7 07:06:13.218: INFO: namespace e2e-tests-kubelet-test-hhkr7 deletion completed in 22.106730802s

• [SLOW TEST:22.193 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:06:13.218: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-950af426-f9ee-11e8-9cb3-16e60f4677a4
STEP: Creating configMap with name cm-test-opt-upd-950af464-f9ee-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-950af426-f9ee-11e8-9cb3-16e60f4677a4
STEP: Updating configmap cm-test-opt-upd-950af464-f9ee-11e8-9cb3-16e60f4677a4
STEP: Creating configMap with name cm-test-opt-create-950af481-f9ee-11e8-9cb3-16e60f4677a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:06:17.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qncjn" for this suite.
Dec  7 07:06:39.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:06:39.448: INFO: namespace: e2e-tests-projected-qncjn, resource: bindings, ignored listing per whitelist
Dec  7 07:06:39.492: INFO: namespace e2e-tests-projected-qncjn deletion completed in 22.093504849s

• [SLOW TEST:26.274 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:06:39.494: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  7 07:06:39.568: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  7 07:06:44.573: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:06:44.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-mfrzr" for this suite.
Dec  7 07:06:50.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:06:50.691: INFO: namespace: e2e-tests-replication-controller-mfrzr, resource: bindings, ignored listing per whitelist
Dec  7 07:06:50.744: INFO: namespace e2e-tests-replication-controller-mfrzr deletion completed in 6.125271392s

• [SLOW TEST:11.250 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:06:50.744: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  7 07:06:54.891: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  7 07:06:54.899: INFO: Pod pod-with-poststart-http-hook still exists
Dec  7 07:06:56.899: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  7 07:06:56.902: INFO: Pod pod-with-poststart-http-hook still exists
Dec  7 07:06:58.899: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  7 07:06:58.903: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:06:58.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5rc5n" for this suite.
Dec  7 07:07:20.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:07:20.945: INFO: namespace: e2e-tests-container-lifecycle-hook-5rc5n, resource: bindings, ignored listing per whitelist
Dec  7 07:07:20.995: INFO: namespace e2e-tests-container-lifecycle-hook-5rc5n deletion completed in 22.08796372s

• [SLOW TEST:30.251 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:07:20.996: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  7 07:07:21.570: INFO: Waiting up to 5m0s for pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b" in namespace "e2e-tests-svcaccounts-qrcln" to be "success or failure"
Dec  7 07:07:21.578: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.862074ms
Dec  7 07:07:23.582: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011823876s
Dec  7 07:07:25.586: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015692284s
STEP: Saw pod success
Dec  7 07:07:25.586: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b" satisfied condition "success or failure"
Dec  7 07:07:25.588: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b container token-test: <nil>
STEP: delete the pod
Dec  7 07:07:25.609: INFO: Waiting for pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b to disappear
Dec  7 07:07:25.613: INFO: Pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-ztb9b no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  7 07:07:25.617: INFO: Waiting up to 5m0s for pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4" in namespace "e2e-tests-svcaccounts-qrcln" to be "success or failure"
Dec  7 07:07:25.620: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.151281ms
Dec  7 07:07:27.627: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009947984s
Dec  7 07:07:29.631: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013452296s
STEP: Saw pod success
Dec  7 07:07:29.631: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4" satisfied condition "success or failure"
Dec  7 07:07:29.633: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4 container root-ca-test: <nil>
STEP: delete the pod
Dec  7 07:07:29.664: INFO: Waiting for pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4 to disappear
Dec  7 07:07:29.667: INFO: Pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-llrd4 no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  7 07:07:29.675: INFO: Waiting up to 5m0s for pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx" in namespace "e2e-tests-svcaccounts-qrcln" to be "success or failure"
Dec  7 07:07:29.689: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052173ms
Dec  7 07:07:31.692: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017729604s
Dec  7 07:07:33.696: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020968337s
STEP: Saw pod success
Dec  7 07:07:33.696: INFO: Pod "pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx" satisfied condition "success or failure"
Dec  7 07:07:33.698: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx container namespace-test: <nil>
STEP: delete the pod
Dec  7 07:07:33.723: INFO: Waiting for pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx to disappear
Dec  7 07:07:33.727: INFO: Pod pod-service-account-bdbd83e8-f9ee-11e8-9cb3-16e60f4677a4-fcrvx no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:07:33.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qrcln" for this suite.
Dec  7 07:07:39.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:07:39.816: INFO: namespace: e2e-tests-svcaccounts-qrcln, resource: bindings, ignored listing per whitelist
Dec  7 07:07:39.928: INFO: namespace e2e-tests-svcaccounts-qrcln deletion completed in 6.195447113s

• [SLOW TEST:18.932 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:07:39.928: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  7 07:07:42.552: INFO: Successfully updated pod "annotationupdatec8ba4cd1-f9ee-11e8-9cb3-16e60f4677a4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:07:46.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pxg9x" for this suite.
Dec  7 07:08:08.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:08:08.648: INFO: namespace: e2e-tests-downward-api-pxg9x, resource: bindings, ignored listing per whitelist
Dec  7 07:08:08.678: INFO: namespace e2e-tests-downward-api-pxg9x deletion completed in 22.089700057s

• [SLOW TEST:28.751 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:08:08.679: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:08:08.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-w69kc" to be "success or failure"
Dec  7 07:08:08.761: INFO: Pod "downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.956149ms
Dec  7 07:08:10.765: INFO: Pod "downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01133896s
STEP: Saw pod success
Dec  7 07:08:10.765: INFO: Pod "downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:08:10.767: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:08:10.791: INFO: Waiting for pod downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:08:10.795: INFO: Pod downwardapi-volume-d9dcaf4f-f9ee-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:08:10.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w69kc" for this suite.
Dec  7 07:08:16.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:08:16.846: INFO: namespace: e2e-tests-downward-api-w69kc, resource: bindings, ignored listing per whitelist
Dec  7 07:08:16.891: INFO: namespace e2e-tests-downward-api-w69kc deletion completed in 6.093365221s

• [SLOW TEST:8.213 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:08:16.892: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  7 07:08:16.961: INFO: Waiting up to 5m0s for pod "pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-8rdvp" to be "success or failure"
Dec  7 07:08:16.966: INFO: Pod "pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.92126ms
Dec  7 07:08:18.970: INFO: Pod "pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007858121s
STEP: Saw pod success
Dec  7 07:08:18.970: INFO: Pod "pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:08:18.972: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:08:18.993: INFO: Waiting for pod pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:08:18.999: INFO: Pod pod-dec14b29-f9ee-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:08:18.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8rdvp" for this suite.
Dec  7 07:08:25.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:08:25.029: INFO: namespace: e2e-tests-emptydir-8rdvp, resource: bindings, ignored listing per whitelist
Dec  7 07:08:25.106: INFO: namespace e2e-tests-emptydir-8rdvp deletion completed in 6.100753564s

• [SLOW TEST:8.214 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:08:25.110: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:08:25.173: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:08:27.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r79z7" for this suite.
Dec  7 07:09:05.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:09:05.340: INFO: namespace: e2e-tests-pods-r79z7, resource: bindings, ignored listing per whitelist
Dec  7 07:09:05.375: INFO: namespace e2e-tests-pods-r79z7 deletion completed in 38.096539995s

• [SLOW TEST:40.265 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:09:05.375: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fba7faf6-f9ee-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:09:05.451: INFO: Waiting up to 5m0s for pod "pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-pgsg2" to be "success or failure"
Dec  7 07:09:05.457: INFO: Pod "pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.940668ms
Dec  7 07:09:07.461: INFO: Pod "pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009934479s
STEP: Saw pod success
Dec  7 07:09:07.461: INFO: Pod "pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:09:07.464: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:09:07.488: INFO: Waiting for pod pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:09:07.509: INFO: Pod pod-configmaps-fba86b1a-f9ee-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:09:07.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pgsg2" for this suite.
Dec  7 07:09:13.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:09:13.549: INFO: namespace: e2e-tests-configmap-pgsg2, resource: bindings, ignored listing per whitelist
Dec  7 07:09:13.610: INFO: namespace e2e-tests-configmap-pgsg2 deletion completed in 6.096509712s

• [SLOW TEST:8.235 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:09:13.613: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-pn6g
STEP: Creating a pod to test atomic-volume-subpath
Dec  7 07:09:13.688: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pn6g" in namespace "e2e-tests-subpath-dtnms" to be "success or failure"
Dec  7 07:09:13.696: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Pending", Reason="", readiness=false. Elapsed: 7.712068ms
Dec  7 07:09:15.700: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011614039s
Dec  7 07:09:17.704: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 4.015545339s
Dec  7 07:09:19.708: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 6.019286792s
Dec  7 07:09:21.711: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 8.022971267s
Dec  7 07:09:23.715: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 10.026239678s
Dec  7 07:09:25.718: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 12.02945521s
Dec  7 07:09:27.721: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 14.032885628s
Dec  7 07:09:29.725: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 16.036302356s
Dec  7 07:09:31.728: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 18.039968862s
Dec  7 07:09:33.732: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 20.043307349s
Dec  7 07:09:35.735: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Running", Reason="", readiness=false. Elapsed: 22.047109049s
Dec  7 07:09:37.739: INFO: Pod "pod-subpath-test-configmap-pn6g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050868686s
STEP: Saw pod success
Dec  7 07:09:37.739: INFO: Pod "pod-subpath-test-configmap-pn6g" satisfied condition "success or failure"
Dec  7 07:09:37.742: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-subpath-test-configmap-pn6g container test-container-subpath-configmap-pn6g: <nil>
STEP: delete the pod
Dec  7 07:09:37.764: INFO: Waiting for pod pod-subpath-test-configmap-pn6g to disappear
Dec  7 07:09:37.771: INFO: Pod pod-subpath-test-configmap-pn6g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pn6g
Dec  7 07:09:37.771: INFO: Deleting pod "pod-subpath-test-configmap-pn6g" in namespace "e2e-tests-subpath-dtnms"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:09:37.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dtnms" for this suite.
Dec  7 07:09:43.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:09:43.818: INFO: namespace: e2e-tests-subpath-dtnms, resource: bindings, ignored listing per whitelist
Dec  7 07:09:43.884: INFO: namespace e2e-tests-subpath-dtnms deletion completed in 6.092200837s

• [SLOW TEST:30.271 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:09:43.884: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  7 07:09:43.955: INFO: Waiting up to 5m0s for pod "var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-var-expansion-ftrzb" to be "success or failure"
Dec  7 07:09:43.958: INFO: Pod "var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.720252ms
Dec  7 07:09:45.962: INFO: Pod "var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007289108s
STEP: Saw pod success
Dec  7 07:09:45.962: INFO: Pod "var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:09:45.965: INFO: Trying to get logs from node 2gb-pool-qefm5t pod var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 07:09:45.986: INFO: Waiting for pod var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:09:46.000: INFO: Pod var-expansion-129be60f-f9ef-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:09:46.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ftrzb" for this suite.
Dec  7 07:09:52.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:09:52.039: INFO: namespace: e2e-tests-var-expansion-ftrzb, resource: bindings, ignored listing per whitelist
Dec  7 07:09:52.099: INFO: namespace e2e-tests-var-expansion-ftrzb deletion completed in 6.088550357s

• [SLOW TEST:8.215 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:09:52.099: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:09:52.163: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-r6mzh" to be "success or failure"
Dec  7 07:09:52.166: INFO: Pod "downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.897467ms
Dec  7 07:09:54.169: INFO: Pod "downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006122656s
STEP: Saw pod success
Dec  7 07:09:54.170: INFO: Pod "downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:09:54.172: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:09:54.193: INFO: Waiting for pod downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:09:54.195: INFO: Pod downwardapi-volume-1780218b-f9ef-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:09:54.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r6mzh" for this suite.
Dec  7 07:10:00.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:10:00.256: INFO: namespace: e2e-tests-downward-api-r6mzh, resource: bindings, ignored listing per whitelist
Dec  7 07:10:00.290: INFO: namespace e2e-tests-downward-api-r6mzh deletion completed in 6.089283144s

• [SLOW TEST:8.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:10:00.290: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zzlhk
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-zzlhk
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-zzlhk
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-zzlhk
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-zzlhk
Dec  7 07:10:02.402: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zzlhk, name: ss-0, uid: 1d5eb0cf-f9ef-11e8-bee8-5a54dcfa39ab, status phase: Pending. Waiting for statefulset controller to delete.
Dec  7 07:10:02.982: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zzlhk, name: ss-0, uid: 1d5eb0cf-f9ef-11e8-bee8-5a54dcfa39ab, status phase: Failed. Waiting for statefulset controller to delete.
Dec  7 07:10:02.996: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zzlhk, name: ss-0, uid: 1d5eb0cf-f9ef-11e8-bee8-5a54dcfa39ab, status phase: Failed. Waiting for statefulset controller to delete.
Dec  7 07:10:03.004: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-zzlhk
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-zzlhk
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-zzlhk and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  7 07:10:05.055: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zzlhk
Dec  7 07:10:05.058: INFO: Scaling statefulset ss to 0
Dec  7 07:10:25.084: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 07:10:25.088: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:10:25.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zzlhk" for this suite.
Dec  7 07:10:31.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:10:31.128: INFO: namespace: e2e-tests-statefulset-zzlhk, resource: bindings, ignored listing per whitelist
Dec  7 07:10:31.214: INFO: namespace e2e-tests-statefulset-zzlhk deletion completed in 6.109057125s

• [SLOW TEST:30.924 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:10:31.214: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  7 07:10:31.288: INFO: Waiting up to 5m0s for pod "downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-v8pbl" to be "success or failure"
Dec  7 07:10:31.293: INFO: Pod "downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.86895ms
Dec  7 07:10:33.297: INFO: Pod "downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008193292s
STEP: Saw pod success
Dec  7 07:10:33.297: INFO: Pod "downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:10:33.300: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 07:10:33.320: INFO: Waiting for pod downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:10:33.334: INFO: Pod downward-api-2ed1e27b-f9ef-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:10:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v8pbl" for this suite.
Dec  7 07:10:39.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:10:39.417: INFO: namespace: e2e-tests-downward-api-v8pbl, resource: bindings, ignored listing per whitelist
Dec  7 07:10:39.443: INFO: namespace e2e-tests-downward-api-v8pbl deletion completed in 6.104728292s

• [SLOW TEST:8.229 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:10:39.443: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zbkv7
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-zbkv7
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-zbkv7
Dec  7 07:10:39.518: INFO: Found 0 stateful pods, waiting for 1
Dec  7 07:10:49.521: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  7 07:10:49.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 07:10:49.712: INFO: stderr: ""
Dec  7 07:10:49.712: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 07:10:49.712: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 07:10:49.715: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  7 07:10:59.719: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 07:10:59.719: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 07:10:59.735: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999964s
Dec  7 07:11:00.738: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993946705s
Dec  7 07:11:01.742: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990213029s
Dec  7 07:11:02.745: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987043664s
Dec  7 07:11:03.749: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983320021s
Dec  7 07:11:04.753: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979487384s
Dec  7 07:11:05.756: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975727153s
Dec  7 07:11:06.761: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972245435s
Dec  7 07:11:07.765: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.967699003s
Dec  7 07:11:08.769: INFO: Verifying statefulset ss doesn't scale past 1 for another 963.176504ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-zbkv7
Dec  7 07:11:09.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:11:09.968: INFO: stderr: ""
Dec  7 07:11:09.968: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 07:11:09.968: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 07:11:09.972: INFO: Found 1 stateful pods, waiting for 3
Dec  7 07:11:19.977: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 07:11:19.977: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  7 07:11:19.977: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  7 07:11:19.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 07:11:20.176: INFO: stderr: ""
Dec  7 07:11:20.176: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 07:11:20.176: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 07:11:20.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 07:11:20.388: INFO: stderr: ""
Dec  7 07:11:20.388: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 07:11:20.388: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 07:11:20.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  7 07:11:20.601: INFO: stderr: ""
Dec  7 07:11:20.601: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  7 07:11:20.602: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  7 07:11:20.602: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 07:11:20.605: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  7 07:11:30.612: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 07:11:30.612: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 07:11:30.612: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  7 07:11:30.623: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999622s
Dec  7 07:11:31.628: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994191652s
Dec  7 07:11:32.632: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989281562s
Dec  7 07:11:33.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985030506s
Dec  7 07:11:34.641: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980617354s
Dec  7 07:11:35.645: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976329047s
Dec  7 07:11:36.649: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972371433s
Dec  7 07:11:37.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968438538s
Dec  7 07:11:38.656: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964448504s
Dec  7 07:11:39.661: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.868557ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-zbkv7
Dec  7 07:11:40.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:11:40.828: INFO: stderr: ""
Dec  7 07:11:40.828: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 07:11:40.828: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 07:11:40.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:11:41.028: INFO: stderr: ""
Dec  7 07:11:41.028: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  7 07:11:41.028: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  7 07:11:41.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:11:41.258: INFO: rc: 1
Dec  7 07:11:41.258: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (a0af01a915e72918553154ba4ccb4b23e89a9d002d47694b0d8cbea85978d53d)
 [] <nil> 0xc0011997a0 exit status 1 <nil> <nil> true [0xc0028697b0 0xc0028697c8 0xc0028697e0] [0xc0028697b0 0xc0028697c8 0xc0028697e0] [0xc0028697c0 0xc0028697d8] [0x92f8e0 0x92f8e0] 0xc001a42240 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (a0af01a915e72918553154ba4ccb4b23e89a9d002d47694b0d8cbea85978d53d)

error:
exit status 1

Dec  7 07:11:51.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:11:51.350: INFO: rc: 1
Dec  7 07:11:51.350: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ec04e0 exit status 1 <nil> <nil> true [0xc000951968 0xc000951980 0xc000951998] [0xc000951968 0xc000951980 0xc000951998] [0xc000951978 0xc000951990] [0x92f8e0 0x92f8e0] 0xc001c663c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:12:01.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:12:01.433: INFO: rc: 1
Dec  7 07:12:01.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ec08d0 exit status 1 <nil> <nil> true [0xc0009519a0 0xc0009519b8 0xc0009519d0] [0xc0009519a0 0xc0009519b8 0xc0009519d0] [0xc0009519b0 0xc0009519c8] [0x92f8e0 0x92f8e0] 0xc001c66840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:12:11.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:12:11.517: INFO: rc: 1
Dec  7 07:12:11.517: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001199b60 exit status 1 <nil> <nil> true [0xc0028697e8 0xc002869800 0xc002869818] [0xc0028697e8 0xc002869800 0xc002869818] [0xc0028697f8 0xc002869810] [0x92f8e0 0x92f8e0] 0xc001a42840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:12:21.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:12:21.615: INFO: rc: 1
Dec  7 07:12:21.615: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ec0ed0 exit status 1 <nil> <nil> true [0xc0009519d8 0xc000951a00 0xc000951a18] [0xc0009519d8 0xc000951a00 0xc000951a18] [0xc0009519f0 0xc000951a10] [0x92f8e0 0x92f8e0] 0xc001c66d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:12:31.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:12:31.708: INFO: rc: 1
Dec  7 07:12:31.708: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0420 exit status 1 <nil> <nil> true [0xc000950008 0xc000950020 0xc000950038] [0xc000950008 0xc000950020 0xc000950038] [0xc000950018 0xc000950030] [0x92f8e0 0x92f8e0] 0xc002886240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:12:41.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:12:41.795: INFO: rc: 1
Dec  7 07:12:41.795: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b07e0 exit status 1 <nil> <nil> true [0xc000950040 0xc000950058 0xc000950070] [0xc000950040 0xc000950058 0xc000950070] [0xc000950050 0xc000950068] [0x92f8e0 0x92f8e0] 0xc002886540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:12:51.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:12:51.894: INFO: rc: 1
Dec  7 07:12:51.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce0f60 exit status 1 <nil> <nil> true [0xc002868000 0xc002868018 0xc002868030] [0xc002868000 0xc002868018 0xc002868030] [0xc002868010 0xc002868028] [0x92f8e0 0x92f8e0] 0xc00171a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:13:01.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:13:01.987: INFO: rc: 1
Dec  7 07:13:01.987: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0ba0 exit status 1 <nil> <nil> true [0xc000950078 0xc000950090 0xc0009500a8] [0xc000950078 0xc000950090 0xc0009500a8] [0xc000950088 0xc0009500a0] [0x92f8e0 0x92f8e0] 0xc002886840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:13:11.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:13:12.072: INFO: rc: 1
Dec  7 07:13:12.072: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce1320 exit status 1 <nil> <nil> true [0xc002868038 0xc002868050 0xc002868068] [0xc002868038 0xc002868050 0xc002868068] [0xc002868048 0xc002868060] [0x92f8e0 0x92f8e0] 0xc00171ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:13:22.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:13:22.161: INFO: rc: 1
Dec  7 07:13:22.161: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0f90 exit status 1 <nil> <nil> true [0xc0009500b0 0xc0009500c8 0xc0009500e0] [0xc0009500b0 0xc0009500c8 0xc0009500e0] [0xc0009500c0 0xc0009500d8] [0x92f8e0 0x92f8e0] 0xc002886b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:13:32.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:13:32.262: INFO: rc: 1
Dec  7 07:13:32.262: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b1a10 exit status 1 <nil> <nil> true [0xc0009500e8 0xc000950100 0xc000950118] [0xc0009500e8 0xc000950100 0xc000950118] [0xc0009500f8 0xc000950110] [0x92f8e0 0x92f8e0] 0xc002886ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:13:42.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:13:42.354: INFO: rc: 1
Dec  7 07:13:42.354: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b1ec0 exit status 1 <nil> <nil> true [0xc000950120 0xc000950138 0xc000950150] [0xc000950120 0xc000950138 0xc000950150] [0xc000950130 0xc000950148] [0x92f8e0 0x92f8e0] 0xc002887680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:13:52.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:13:52.441: INFO: rc: 1
Dec  7 07:13:52.441: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce1710 exit status 1 <nil> <nil> true [0xc002868070 0xc002868088 0xc0028680a0] [0xc002868070 0xc002868088 0xc0028680a0] [0xc002868080 0xc002868098] [0x92f8e0 0x92f8e0] 0xc00171b3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:14:02.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:14:02.556: INFO: rc: 1
Dec  7 07:14:02.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce1ad0 exit status 1 <nil> <nil> true [0xc0028680a8 0xc0028680c0 0xc0028680d8] [0xc0028680a8 0xc0028680c0 0xc0028680d8] [0xc0028680b8 0xc0028680d0] [0x92f8e0 0x92f8e0] 0xc00171b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:14:12.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:14:12.643: INFO: rc: 1
Dec  7 07:14:12.643: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3c0f0 exit status 1 <nil> <nil> true [0xc0028680e0 0xc0028680f8 0xc002868110] [0xc0028680e0 0xc0028680f8 0xc002868110] [0xc0028680f0 0xc002868108] [0x92f8e0 0x92f8e0] 0xc00171bd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:14:22.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:14:22.760: INFO: rc: 1
Dec  7 07:14:22.760: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3c570 exit status 1 <nil> <nil> true [0xc002868118 0xc002868130 0xc002868148] [0xc002868118 0xc002868130 0xc002868148] [0xc002868128 0xc002868140] [0x92f8e0 0x92f8e0] 0xc00154c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:14:32.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:14:32.867: INFO: rc: 1
Dec  7 07:14:32.868: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3c960 exit status 1 <nil> <nil> true [0xc002868158 0xc002868170 0xc002868188] [0xc002868158 0xc002868170 0xc002868188] [0xc002868168 0xc002868180] [0x92f8e0 0x92f8e0] 0xc00154c720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:14:42.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:14:42.967: INFO: rc: 1
Dec  7 07:14:42.967: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce1290 exit status 1 <nil> <nil> true [0xc002868000 0xc002868018 0xc002868030] [0xc002868000 0xc002868018 0xc002868030] [0xc002868010 0xc002868028] [0x92f8e0 0x92f8e0] 0xc00171a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:14:52.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:14:53.099: INFO: rc: 1
Dec  7 07:14:53.099: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3c060 exit status 1 <nil> <nil> true [0xc000950000 0xc000950018 0xc000950030] [0xc000950000 0xc000950018 0xc000950030] [0xc000950010 0xc000950028] [0x92f8e0 0x92f8e0] 0xc00154c960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:15:03.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:15:03.186: INFO: rc: 1
Dec  7 07:15:03.186: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce16b0 exit status 1 <nil> <nil> true [0xc002868038 0xc002868050 0xc002868068] [0xc002868038 0xc002868050 0xc002868068] [0xc002868048 0xc002868060] [0x92f8e0 0x92f8e0] 0xc00171ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:15:13.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:15:13.283: INFO: rc: 1
Dec  7 07:15:13.283: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3c5a0 exit status 1 <nil> <nil> true [0xc000950038 0xc000950050 0xc000950068] [0xc000950038 0xc000950050 0xc000950068] [0xc000950048 0xc000950060] [0x92f8e0 0x92f8e0] 0xc00154ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:15:23.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:15:23.379: INFO: rc: 1
Dec  7 07:15:23.379: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce1a70 exit status 1 <nil> <nil> true [0xc002868070 0xc002868088 0xc0028680a0] [0xc002868070 0xc002868088 0xc0028680a0] [0xc002868080 0xc002868098] [0x92f8e0 0x92f8e0] 0xc00171b3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:15:33.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:15:33.470: INFO: rc: 1
Dec  7 07:15:33.470: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3d0b0 exit status 1 <nil> <nil> true [0xc000950070 0xc000950088 0xc0009500a0] [0xc000950070 0xc000950088 0xc0009500a0] [0xc000950080 0xc000950098] [0x92f8e0 0x92f8e0] 0xc00154d200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:15:43.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:15:43.552: INFO: rc: 1
Dec  7 07:15:43.553: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0090 exit status 1 <nil> <nil> true [0xc0028680a8 0xc0028680c0 0xc0028680d8] [0xc0028680a8 0xc0028680c0 0xc0028680d8] [0xc0028680b8 0xc0028680d0] [0x92f8e0 0x92f8e0] 0xc00171b980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:15:53.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:15:53.635: INFO: rc: 1
Dec  7 07:15:53.636: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0510 exit status 1 <nil> <nil> true [0xc0028680e0 0xc0028680f8 0xc002868110] [0xc0028680e0 0xc0028680f8 0xc002868110] [0xc0028680f0 0xc002868108] [0x92f8e0 0x92f8e0] 0xc00171bd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:16:03.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:16:03.758: INFO: rc: 1
Dec  7 07:16:03.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0010b0900 exit status 1 <nil> <nil> true [0xc002868118 0xc002868130 0xc002868148] [0xc002868118 0xc002868130 0xc002868148] [0xc002868128 0xc002868140] [0x92f8e0 0x92f8e0] 0xc0028860c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:16:13.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:16:13.885: INFO: rc: 1
Dec  7 07:16:13.886: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3d470 exit status 1 <nil> <nil> true [0xc0009500a8 0xc0009500c0 0xc0009500d8] [0xc0009500a8 0xc0009500c0 0xc0009500d8] [0xc0009500b8 0xc0009500d0] [0x92f8e0 0x92f8e0] 0xc00154d560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:16:23.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:16:23.976: INFO: rc: 1
Dec  7 07:16:23.976: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000a3d830 exit status 1 <nil> <nil> true [0xc0009500e0 0xc0009500f8 0xc000950110] [0xc0009500e0 0xc0009500f8 0xc000950110] [0xc0009500f0 0xc000950108] [0x92f8e0 0x92f8e0] 0xc00154d860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:16:33.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:16:34.072: INFO: rc: 1
Dec  7 07:16:34.072: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ce0f60 exit status 1 <nil> <nil> true [0xc000950008 0xc000950020 0xc000950038] [0xc000950008 0xc000950020 0xc000950038] [0xc000950018 0xc000950030] [0x92f8e0 0x92f8e0] 0xc00171a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec  7 07:16:44.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 exec --namespace=e2e-tests-statefulset-zbkv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  7 07:16:44.165: INFO: rc: 1
Dec  7 07:16:44.165: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec  7 07:16:44.165: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  7 07:16:44.175: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zbkv7
Dec  7 07:16:44.177: INFO: Scaling statefulset ss to 0
Dec  7 07:16:44.183: INFO: Waiting for statefulset status.replicas updated to 0
Dec  7 07:16:44.185: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:16:44.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zbkv7" for this suite.
Dec  7 07:16:50.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:16:50.233: INFO: namespace: e2e-tests-statefulset-zbkv7, resource: bindings, ignored listing per whitelist
Dec  7 07:16:50.308: INFO: namespace e2e-tests-statefulset-zbkv7 deletion completed in 6.101032883s

• [SLOW TEST:370.865 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:16:50.309: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  7 07:16:50.403: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gh6ln,SelfLink:/api/v1/namespaces/e2e-tests-watch-gh6ln/configmaps/e2e-watch-test-label-changed,UID:10c95373-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14540,Generation:0,CreationTimestamp:2018-12-07 07:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  7 07:16:50.403: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gh6ln,SelfLink:/api/v1/namespaces/e2e-tests-watch-gh6ln/configmaps/e2e-watch-test-label-changed,UID:10c95373-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14541,Generation:0,CreationTimestamp:2018-12-07 07:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  7 07:16:50.403: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gh6ln,SelfLink:/api/v1/namespaces/e2e-tests-watch-gh6ln/configmaps/e2e-watch-test-label-changed,UID:10c95373-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14542,Generation:0,CreationTimestamp:2018-12-07 07:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  7 07:17:00.429: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gh6ln,SelfLink:/api/v1/namespaces/e2e-tests-watch-gh6ln/configmaps/e2e-watch-test-label-changed,UID:10c95373-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14557,Generation:0,CreationTimestamp:2018-12-07 07:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  7 07:17:00.429: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gh6ln,SelfLink:/api/v1/namespaces/e2e-tests-watch-gh6ln/configmaps/e2e-watch-test-label-changed,UID:10c95373-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14558,Generation:0,CreationTimestamp:2018-12-07 07:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  7 07:17:00.429: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gh6ln,SelfLink:/api/v1/namespaces/e2e-tests-watch-gh6ln/configmaps/e2e-watch-test-label-changed,UID:10c95373-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14559,Generation:0,CreationTimestamp:2018-12-07 07:16:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:17:00.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gh6ln" for this suite.
Dec  7 07:17:06.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:17:06.469: INFO: namespace: e2e-tests-watch-gh6ln, resource: bindings, ignored listing per whitelist
Dec  7 07:17:06.555: INFO: namespace e2e-tests-watch-gh6ln deletion completed in 6.122375801s

• [SLOW TEST:16.246 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:17:06.558: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  7 07:17:06.638: INFO: Waiting up to 5m0s for pod "pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-2ztcz" to be "success or failure"
Dec  7 07:17:06.652: INFO: Pod "pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.962042ms
Dec  7 07:17:08.656: INFO: Pod "pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017716849s
STEP: Saw pod success
Dec  7 07:17:08.656: INFO: Pod "pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:17:08.658: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:17:08.677: INFO: Waiting for pod pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:17:08.680: INFO: Pod pod-1a77a2b4-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:17:08.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2ztcz" for this suite.
Dec  7 07:17:14.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:17:14.791: INFO: namespace: e2e-tests-emptydir-2ztcz, resource: bindings, ignored listing per whitelist
Dec  7 07:17:14.797: INFO: namespace e2e-tests-emptydir-2ztcz deletion completed in 6.109151132s

• [SLOW TEST:8.239 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:17:14.800: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1f606902-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:17:14.877: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-5nrhd" to be "success or failure"
Dec  7 07:17:14.884: INFO: Pod "pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.579549ms
Dec  7 07:17:16.887: INFO: Pod "pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010231344s
STEP: Saw pod success
Dec  7 07:17:16.888: INFO: Pod "pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:17:16.890: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:17:16.910: INFO: Waiting for pod pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:17:16.912: INFO: Pod pod-projected-configmaps-1f60f4ba-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:17:16.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5nrhd" for this suite.
Dec  7 07:17:22.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:17:22.987: INFO: namespace: e2e-tests-projected-5nrhd, resource: bindings, ignored listing per whitelist
Dec  7 07:17:23.008: INFO: namespace e2e-tests-projected-5nrhd deletion completed in 6.089221927s

• [SLOW TEST:8.208 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:17:23.008: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-24445561-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 07:17:23.083: INFO: Waiting up to 5m0s for pod "pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-j4qq7" to be "success or failure"
Dec  7 07:17:23.094: INFO: Pod "pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.515689ms
Dec  7 07:17:25.097: INFO: Pod "pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013809148s
STEP: Saw pod success
Dec  7 07:17:25.097: INFO: Pod "pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:17:25.100: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  7 07:17:25.126: INFO: Waiting for pod pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:17:25.130: INFO: Pod pod-secrets-2444cf47-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:17:25.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j4qq7" for this suite.
Dec  7 07:17:31.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:17:31.209: INFO: namespace: e2e-tests-secrets-j4qq7, resource: bindings, ignored listing per whitelist
Dec  7 07:17:31.242: INFO: namespace e2e-tests-secrets-j4qq7 deletion completed in 6.105155647s

• [SLOW TEST:8.234 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:17:31.243: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-292c57c8-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:17:31.319: INFO: Waiting up to 5m0s for pod "pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-89br9" to be "success or failure"
Dec  7 07:17:31.331: INFO: Pod "pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.207345ms
Dec  7 07:17:33.336: INFO: Pod "pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016182648s
STEP: Saw pod success
Dec  7 07:17:33.336: INFO: Pod "pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:17:33.338: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:17:33.360: INFO: Waiting for pod pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:17:33.363: INFO: Pod pod-configmaps-292ce7e9-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:17:33.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-89br9" for this suite.
Dec  7 07:17:39.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:17:39.571: INFO: namespace: e2e-tests-configmap-89br9, resource: bindings, ignored listing per whitelist
Dec  7 07:17:39.574: INFO: namespace e2e-tests-configmap-89br9 deletion completed in 6.208284521s

• [SLOW TEST:8.331 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:17:39.574: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2e2433ee-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating secret with name s-test-opt-upd-2e243434-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2e2433ee-f9f0-11e8-9cb3-16e60f4677a4
STEP: Updating secret s-test-opt-upd-2e243434-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating secret with name s-test-opt-create-2e243451-f9f0-11e8-9cb3-16e60f4677a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:17:43.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kd5rr" for this suite.
Dec  7 07:18:05.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:18:05.822: INFO: namespace: e2e-tests-secrets-kd5rr, resource: bindings, ignored listing per whitelist
Dec  7 07:18:05.863: INFO: namespace e2e-tests-secrets-kd5rr deletion completed in 22.111270185s

• [SLOW TEST:26.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:18:05.863: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:18:05.934: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  7 07:18:10.938: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  7 07:18:10.938: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  7 07:18:12.941: INFO: Creating deployment "test-rollover-deployment"
Dec  7 07:18:12.948: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  7 07:18:14.955: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  7 07:18:14.961: INFO: Ensure that both replica sets have 1 created replica
Dec  7 07:18:14.966: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  7 07:18:14.973: INFO: Updating deployment test-rollover-deployment
Dec  7 07:18:14.973: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  7 07:18:16.988: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  7 07:18:16.994: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  7 07:18:17.000: INFO: all replica sets need to contain the pod-template-hash label
Dec  7 07:18:17.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763896, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  7 07:18:19.007: INFO: all replica sets need to contain the pod-template-hash label
Dec  7 07:18:19.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763896, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  7 07:18:21.007: INFO: all replica sets need to contain the pod-template-hash label
Dec  7 07:18:21.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763896, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  7 07:18:23.007: INFO: all replica sets need to contain the pod-template-hash label
Dec  7 07:18:23.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763896, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  7 07:18:25.007: INFO: all replica sets need to contain the pod-template-hash label
Dec  7 07:18:25.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763896, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679763892, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  7 07:18:27.010: INFO: 
Dec  7 07:18:27.010: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  7 07:18:27.016: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-szsm8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-szsm8/deployments/test-rollover-deployment,UID:41fe1f2a-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14907,Generation:2,CreationTimestamp:2018-12-07 07:18:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-07 07:18:12 +0000 UTC 2018-12-07 07:18:12 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-07 07:18:26 +0000 UTC 2018-12-07 07:18:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  7 07:18:27.019: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-szsm8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-szsm8/replicasets/test-rollover-deployment-6b7f9d6597,UID:4333da6c-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14898,Generation:2,CreationTimestamp:2018-12-07 07:18:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 41fe1f2a-f9f0-11e8-bee8-5a54dcfa39ab 0xc001ed9e67 0xc001ed9e68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  7 07:18:27.019: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  7 07:18:27.020: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-szsm8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-szsm8/replicasets/test-rollover-controller,UID:3dcfdca0-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14906,Generation:2,CreationTimestamp:2018-12-07 07:18:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 41fe1f2a-f9f0-11e8-bee8-5a54dcfa39ab 0xc001ed9cd7 0xc001ed9cd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  7 07:18:27.020: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-szsm8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-szsm8/replicasets/test-rollover-deployment-6586df867b,UID:42008bdc-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14872,Generation:2,CreationTimestamp:2018-12-07 07:18:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 41fe1f2a-f9f0-11e8-bee8-5a54dcfa39ab 0xc001ed9d97 0xc001ed9d98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  7 07:18:27.023: INFO: Pod "test-rollover-deployment-6b7f9d6597-xzwnb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-xzwnb,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-szsm8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-szsm8/pods/test-rollover-deployment-6b7f9d6597-xzwnb,UID:4337b3d8-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:14882,Generation:0,CreationTimestamp:2018-12-07 07:18:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.227/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 4333da6c-f9f0-11e8-bee8-5a54dcfa39ab 0xc001dcf6b7 0xc001dcf6b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-77ktg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-77ktg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-77ktg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:2gb-pool-qefm5t,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dcf730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dcf750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 07:18:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 07:18:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 07:18:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-07 07:18:15 +0000 UTC  }],Message:,Reason:,HostIP:10.132.155.16,PodIP:192.168.1.227,StartTime:2018-12-07 07:18:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-07 07:18:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0bd54e2a1b4d417c9fe635fb339bd045708a70ced3fb6a623219789bef08063a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:18:27.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-szsm8" for this suite.
Dec  7 07:18:33.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:18:33.051: INFO: namespace: e2e-tests-deployment-szsm8, resource: bindings, ignored listing per whitelist
Dec  7 07:18:33.117: INFO: namespace e2e-tests-deployment-szsm8 deletion completed in 6.09102998s

• [SLOW TEST:27.255 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:18:33.118: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4e0dbb07-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating secret with name secret-projected-all-test-volume-4e0dbadc-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  7 07:18:33.189: INFO: Waiting up to 5m0s for pod "projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-vl2qp" to be "success or failure"
Dec  7 07:18:33.194: INFO: Pod "projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.262056ms
Dec  7 07:18:35.200: INFO: Pod "projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010464963s
STEP: Saw pod success
Dec  7 07:18:35.200: INFO: Pod "projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:18:35.203: INFO: Trying to get logs from node 2gb-pool-qefm5t pod projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  7 07:18:35.234: INFO: Waiting for pod projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:18:35.237: INFO: Pod projected-volume-4e0dba85-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:18:35.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vl2qp" for this suite.
Dec  7 07:18:41.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:18:41.283: INFO: namespace: e2e-tests-projected-vl2qp, resource: bindings, ignored listing per whitelist
Dec  7 07:18:41.328: INFO: namespace e2e-tests-projected-vl2qp deletion completed in 6.086584854s

• [SLOW TEST:8.210 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:18:41.328: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:18:41.398: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-mghrg" to be "success or failure"
Dec  7 07:18:41.402: INFO: Pod "downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.392172ms
Dec  7 07:18:43.405: INFO: Pod "downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006719363s
STEP: Saw pod success
Dec  7 07:18:43.405: INFO: Pod "downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:18:43.407: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:18:43.432: INFO: Waiting for pod downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:18:43.436: INFO: Pod downwardapi-volume-52f2c26b-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:18:43.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mghrg" for this suite.
Dec  7 07:18:49.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:18:49.551: INFO: namespace: e2e-tests-downward-api-mghrg, resource: bindings, ignored listing per whitelist
Dec  7 07:18:49.585: INFO: namespace e2e-tests-downward-api-mghrg deletion completed in 6.144537126s

• [SLOW TEST:8.257 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:18:49.587: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-8gmp7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  7 07:18:49.645: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  7 07:19:09.699: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.1.230:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-8gmp7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:19:09.699: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:19:09.804: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:19:09.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-8gmp7" for this suite.
Dec  7 07:19:31.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:19:31.892: INFO: namespace: e2e-tests-pod-network-test-8gmp7, resource: bindings, ignored listing per whitelist
Dec  7 07:19:31.896: INFO: namespace e2e-tests-pod-network-test-8gmp7 deletion completed in 22.089501838s

• [SLOW TEST:42.309 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:19:31.896: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:19:53.995: INFO: Container started at 2018-12-07 07:19:32 +0000 UTC, pod became ready at 2018-12-07 07:19:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:19:53.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6mvdw" for this suite.
Dec  7 07:20:16.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:20:16.046: INFO: namespace: e2e-tests-container-probe-6mvdw, resource: bindings, ignored listing per whitelist
Dec  7 07:20:16.108: INFO: namespace e2e-tests-container-probe-6mvdw deletion completed in 22.110075474s

• [SLOW TEST:44.212 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:20:16.109: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-57hn
STEP: Creating a pod to test atomic-volume-subpath
Dec  7 07:20:16.201: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-57hn" in namespace "e2e-tests-subpath-9c8gq" to be "success or failure"
Dec  7 07:20:16.205: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.899958ms
Dec  7 07:20:18.208: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007295156s
Dec  7 07:20:20.212: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 4.010971109s
Dec  7 07:20:22.216: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 6.014663556s
Dec  7 07:20:24.219: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 8.018228065s
Dec  7 07:20:26.223: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 10.021696366s
Dec  7 07:20:28.227: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 12.025362459s
Dec  7 07:20:30.230: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 14.029348149s
Dec  7 07:20:32.238: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 16.03713581s
Dec  7 07:20:34.242: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 18.040627705s
Dec  7 07:20:36.246: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 20.044457483s
Dec  7 07:20:38.250: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Running", Reason="", readiness=false. Elapsed: 22.048668176s
Dec  7 07:20:40.254: INFO: Pod "pod-subpath-test-projected-57hn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052567167s
STEP: Saw pod success
Dec  7 07:20:40.254: INFO: Pod "pod-subpath-test-projected-57hn" satisfied condition "success or failure"
Dec  7 07:20:40.256: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-subpath-test-projected-57hn container test-container-subpath-projected-57hn: <nil>
STEP: delete the pod
Dec  7 07:20:40.275: INFO: Waiting for pod pod-subpath-test-projected-57hn to disappear
Dec  7 07:20:40.287: INFO: Pod pod-subpath-test-projected-57hn no longer exists
STEP: Deleting pod pod-subpath-test-projected-57hn
Dec  7 07:20:40.287: INFO: Deleting pod "pod-subpath-test-projected-57hn" in namespace "e2e-tests-subpath-9c8gq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:20:40.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9c8gq" for this suite.
Dec  7 07:20:46.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:20:46.341: INFO: namespace: e2e-tests-subpath-9c8gq, resource: bindings, ignored listing per whitelist
Dec  7 07:20:46.396: INFO: namespace e2e-tests-subpath-9c8gq deletion completed in 6.102060122s

• [SLOW TEST:30.287 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:20:46.396: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-9d7e6f55-f9f0-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 07:20:46.465: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-ff25k" to be "success or failure"
Dec  7 07:20:46.470: INFO: Pod "pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.173292ms
Dec  7 07:20:48.474: INFO: Pod "pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008416596s
STEP: Saw pod success
Dec  7 07:20:48.474: INFO: Pod "pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:20:48.477: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  7 07:20:48.531: INFO: Waiting for pod pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:20:48.535: INFO: Pod pod-projected-secrets-9d7ed854-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:20:48.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ff25k" for this suite.
Dec  7 07:20:54.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:20:54.585: INFO: namespace: e2e-tests-projected-ff25k, resource: bindings, ignored listing per whitelist
Dec  7 07:20:54.632: INFO: namespace e2e-tests-projected-ff25k deletion completed in 6.091176171s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:20:54.634: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:20:54.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-ns5md" to be "success or failure"
Dec  7 07:20:54.711: INFO: Pod "downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.16302ms
Dec  7 07:20:56.715: INFO: Pod "downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013511529s
STEP: Saw pod success
Dec  7 07:20:56.715: INFO: Pod "downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:20:56.717: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:20:56.742: INFO: Waiting for pod downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:20:56.749: INFO: Pod downwardapi-volume-a2676594-f9f0-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:20:56.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ns5md" for this suite.
Dec  7 07:21:02.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:21:02.782: INFO: namespace: e2e-tests-projected-ns5md, resource: bindings, ignored listing per whitelist
Dec  7 07:21:02.868: INFO: namespace e2e-tests-projected-ns5md deletion completed in 6.115924351s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:21:02.874: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  7 07:21:02.964: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sd5s7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sd5s7/configmaps/e2e-watch-test-watch-closed,UID:a753e5cb-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:15382,Generation:0,CreationTimestamp:2018-12-07 07:21:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  7 07:21:02.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sd5s7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sd5s7/configmaps/e2e-watch-test-watch-closed,UID:a753e5cb-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:15383,Generation:0,CreationTimestamp:2018-12-07 07:21:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  7 07:21:02.985: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sd5s7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sd5s7/configmaps/e2e-watch-test-watch-closed,UID:a753e5cb-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:15384,Generation:0,CreationTimestamp:2018-12-07 07:21:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  7 07:21:02.985: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-sd5s7,SelfLink:/api/v1/namespaces/e2e-tests-watch-sd5s7/configmaps/e2e-watch-test-watch-closed,UID:a753e5cb-f9f0-11e8-bee8-5a54dcfa39ab,ResourceVersion:15385,Generation:0,CreationTimestamp:2018-12-07 07:21:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:21:02.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-sd5s7" for this suite.
Dec  7 07:21:09.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:21:09.087: INFO: namespace: e2e-tests-watch-sd5s7, resource: bindings, ignored listing per whitelist
Dec  7 07:21:09.100: INFO: namespace e2e-tests-watch-sd5s7 deletion completed in 6.110791452s

• [SLOW TEST:6.226 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:21:09.103: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec  7 07:21:09.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:09.563: INFO: stderr: ""
Dec  7 07:21:09.563: INFO: stdout: "pod/pause created\n"
Dec  7 07:21:09.563: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  7 07:21:09.563: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-lflvj" to be "running and ready"
Dec  7 07:21:09.568: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.412712ms
Dec  7 07:21:11.573: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01040933s
Dec  7 07:21:11.573: INFO: Pod "pause" satisfied condition "running and ready"
Dec  7 07:21:11.573: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  7 07:21:11.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:11.690: INFO: stderr: ""
Dec  7 07:21:11.690: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  7 07:21:11.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pod pause -L testing-label --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:11.812: INFO: stderr: ""
Dec  7 07:21:11.812: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  7 07:21:11.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 label pods pause testing-label- --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:11.920: INFO: stderr: ""
Dec  7 07:21:11.921: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  7 07:21:11.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pod pause -L testing-label --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:12.024: INFO: stderr: ""
Dec  7 07:21:12.024: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec  7 07:21:12.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:12.148: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 07:21:12.148: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  7 07:21:12.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-lflvj'
Dec  7 07:21:12.314: INFO: stderr: "No resources found.\n"
Dec  7 07:21:12.314: INFO: stdout: ""
Dec  7 07:21:12.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -l name=pause --namespace=e2e-tests-kubectl-lflvj -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  7 07:21:12.423: INFO: stderr: ""
Dec  7 07:21:12.423: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:21:12.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lflvj" for this suite.
Dec  7 07:21:18.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:21:18.467: INFO: namespace: e2e-tests-kubectl-lflvj, resource: bindings, ignored listing per whitelist
Dec  7 07:21:18.543: INFO: namespace e2e-tests-kubectl-lflvj deletion completed in 6.115747911s

• [SLOW TEST:9.440 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:21:18.545: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-n2jz4
Dec  7 07:21:20.663: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-n2jz4
STEP: checking the pod's current state and verifying that restartCount is present
Dec  7 07:21:20.665: INFO: Initial restart count of pod liveness-http is 0
Dec  7 07:21:32.692: INFO: Restart count of pod e2e-tests-container-probe-n2jz4/liveness-http is now 1 (12.02629298s elapsed)
Dec  7 07:21:52.732: INFO: Restart count of pod e2e-tests-container-probe-n2jz4/liveness-http is now 2 (32.06633873s elapsed)
Dec  7 07:22:12.775: INFO: Restart count of pod e2e-tests-container-probe-n2jz4/liveness-http is now 3 (52.10960926s elapsed)
Dec  7 07:22:32.814: INFO: Restart count of pod e2e-tests-container-probe-n2jz4/liveness-http is now 4 (1m12.148893031s elapsed)
Dec  7 07:23:42.945: INFO: Restart count of pod e2e-tests-container-probe-n2jz4/liveness-http is now 5 (2m22.279902534s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:23:42.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n2jz4" for this suite.
Dec  7 07:23:48.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:23:49.013: INFO: namespace: e2e-tests-container-probe-n2jz4, resource: bindings, ignored listing per whitelist
Dec  7 07:23:49.068: INFO: namespace e2e-tests-container-probe-n2jz4 deletion completed in 6.09539169s

• [SLOW TEST:150.523 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:23:49.070: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec  7 07:23:49.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-xdjgc'
Dec  7 07:23:49.325: INFO: stderr: ""
Dec  7 07:23:49.325: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  7 07:23:50.329: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 07:23:50.329: INFO: Found 0 / 1
Dec  7 07:23:51.329: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 07:23:51.329: INFO: Found 1 / 1
Dec  7 07:23:51.329: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  7 07:23:51.332: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 07:23:51.332: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  7 07:23:51.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 logs redis-master-ntklk redis-master --namespace=e2e-tests-kubectl-xdjgc'
Dec  7 07:23:51.455: INFO: stderr: ""
Dec  7 07:23:51.455: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Dec 07:23:50.298 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Dec 07:23:50.298 # Server started, Redis version 3.2.12\n1:M 07 Dec 07:23:50.298 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Dec 07:23:50.299 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  7 07:23:51.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 log redis-master-ntklk redis-master --namespace=e2e-tests-kubectl-xdjgc --tail=1'
Dec  7 07:23:51.567: INFO: stderr: ""
Dec  7 07:23:51.567: INFO: stdout: "1:M 07 Dec 07:23:50.299 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  7 07:23:51.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 log redis-master-ntklk redis-master --namespace=e2e-tests-kubectl-xdjgc --limit-bytes=1'
Dec  7 07:23:51.682: INFO: stderr: ""
Dec  7 07:23:51.682: INFO: stdout: " "
STEP: exposing timestamps
Dec  7 07:23:51.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 log redis-master-ntklk redis-master --namespace=e2e-tests-kubectl-xdjgc --tail=1 --timestamps'
Dec  7 07:23:51.817: INFO: stderr: ""
Dec  7 07:23:51.817: INFO: stdout: "2018-12-07T07:23:50.304162581Z 1:M 07 Dec 07:23:50.299 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  7 07:23:54.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 log redis-master-ntklk redis-master --namespace=e2e-tests-kubectl-xdjgc --since=1s'
Dec  7 07:23:54.428: INFO: stderr: ""
Dec  7 07:23:54.428: INFO: stdout: ""
Dec  7 07:23:54.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 log redis-master-ntklk redis-master --namespace=e2e-tests-kubectl-xdjgc --since=24h'
Dec  7 07:23:54.539: INFO: stderr: ""
Dec  7 07:23:54.539: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 07 Dec 07:23:50.298 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Dec 07:23:50.298 # Server started, Redis version 3.2.12\n1:M 07 Dec 07:23:50.298 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 07 Dec 07:23:50.299 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec  7 07:23:54.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xdjgc'
Dec  7 07:23:54.647: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  7 07:23:54.647: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  7 07:23:54.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-xdjgc'
Dec  7 07:23:54.807: INFO: stderr: "No resources found.\n"
Dec  7 07:23:54.807: INFO: stdout: ""
Dec  7 07:23:54.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -l name=nginx --namespace=e2e-tests-kubectl-xdjgc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  7 07:23:54.955: INFO: stderr: ""
Dec  7 07:23:54.955: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:23:54.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xdjgc" for this suite.
Dec  7 07:24:16.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:24:17.050: INFO: namespace: e2e-tests-kubectl-xdjgc, resource: bindings, ignored listing per whitelist
Dec  7 07:24:17.100: INFO: namespace e2e-tests-kubectl-xdjgc deletion completed in 22.140096527s

• [SLOW TEST:28.030 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:24:17.101: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  7 07:24:17.362: INFO: Pod name wrapped-volume-race-1b31cc80-f9f1-11e8-9cb3-16e60f4677a4: Found 0 pods out of 5
Dec  7 07:24:22.368: INFO: Pod name wrapped-volume-race-1b31cc80-f9f1-11e8-9cb3-16e60f4677a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1b31cc80-f9f1-11e8-9cb3-16e60f4677a4 in namespace e2e-tests-emptydir-wrapper-tj6l4, will wait for the garbage collector to delete the pods
Dec  7 07:24:32.451: INFO: Deleting ReplicationController wrapped-volume-race-1b31cc80-f9f1-11e8-9cb3-16e60f4677a4 took: 12.080983ms
Dec  7 07:24:32.552: INFO: Terminating ReplicationController wrapped-volume-race-1b31cc80-f9f1-11e8-9cb3-16e60f4677a4 pods took: 100.29603ms
STEP: Creating RC which spawns configmap-volume pods
Dec  7 07:25:09.768: INFO: Pod name wrapped-volume-race-3a6e0874-f9f1-11e8-9cb3-16e60f4677a4: Found 0 pods out of 5
Dec  7 07:25:14.774: INFO: Pod name wrapped-volume-race-3a6e0874-f9f1-11e8-9cb3-16e60f4677a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3a6e0874-f9f1-11e8-9cb3-16e60f4677a4 in namespace e2e-tests-emptydir-wrapper-tj6l4, will wait for the garbage collector to delete the pods
Dec  7 07:25:24.868: INFO: Deleting ReplicationController wrapped-volume-race-3a6e0874-f9f1-11e8-9cb3-16e60f4677a4 took: 11.247364ms
Dec  7 07:25:24.969: INFO: Terminating ReplicationController wrapped-volume-race-3a6e0874-f9f1-11e8-9cb3-16e60f4677a4 pods took: 100.328234ms
STEP: Creating RC which spawns configmap-volume pods
Dec  7 07:26:07.911: INFO: Pod name wrapped-volume-race-5d11fd37-f9f1-11e8-9cb3-16e60f4677a4: Found 0 pods out of 5
Dec  7 07:26:12.926: INFO: Pod name wrapped-volume-race-5d11fd37-f9f1-11e8-9cb3-16e60f4677a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5d11fd37-f9f1-11e8-9cb3-16e60f4677a4 in namespace e2e-tests-emptydir-wrapper-tj6l4, will wait for the garbage collector to delete the pods
Dec  7 07:26:23.005: INFO: Deleting ReplicationController wrapped-volume-race-5d11fd37-f9f1-11e8-9cb3-16e60f4677a4 took: 7.912301ms
Dec  7 07:26:23.105: INFO: Terminating ReplicationController wrapped-volume-race-5d11fd37-f9f1-11e8-9cb3-16e60f4677a4 pods took: 100.410081ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:27:09.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-tj6l4" for this suite.
Dec  7 07:27:15.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:27:15.128: INFO: namespace: e2e-tests-emptydir-wrapper-tj6l4, resource: bindings, ignored listing per whitelist
Dec  7 07:27:15.169: INFO: namespace e2e-tests-emptydir-wrapper-tj6l4 deletion completed in 6.095981679s

• [SLOW TEST:178.068 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:27:15.169: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  7 07:27:15.234: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:27:19.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jlk2t" for this suite.
Dec  7 07:27:25.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:27:25.155: INFO: namespace: e2e-tests-init-container-jlk2t, resource: bindings, ignored listing per whitelist
Dec  7 07:27:25.205: INFO: namespace e2e-tests-init-container-jlk2t deletion completed in 6.10641218s

• [SLOW TEST:10.036 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:27:25.205: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:27:25.291: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  7 07:27:25.300: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:25.302: INFO: Number of nodes with available pods: 0
Dec  7 07:27:25.302: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:27:26.715: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:26.724: INFO: Number of nodes with available pods: 0
Dec  7 07:27:26.724: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:27:27.307: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:27.311: INFO: Number of nodes with available pods: 1
Dec  7 07:27:27.311: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  7 07:27:27.338: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:27.342: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:28.347: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:28.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:29.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:29.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:30.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:30.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:31.347: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:31.351: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:32.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:32.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:33.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:33.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:34.347: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:34.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:35.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:35.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:36.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:36.348: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:37.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:37.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:38.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:38.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:39.411: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:39.415: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:40.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:40.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:41.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:41.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:42.347: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:42.351: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:43.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:43.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:44.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:44.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:45.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:45.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:46.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:46.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:47.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:47.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:48.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:48.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:49.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:49.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:50.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:50.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:51.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:51.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:52.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:52.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:53.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:53.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:54.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:54.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:55.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:55.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:56.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:56.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:57.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:57.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:58.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:58.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:27:59.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:27:59.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:00.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:00.346: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:00.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:01.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:01.346: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:01.349: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:02.347: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:02.347: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:02.351: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:03.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:03.346: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:03.348: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:04.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:04.346: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:04.350: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:05.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:05.346: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:05.348: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:06.346: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:06.346: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:06.348: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:07.354: INFO: Wrong image for pod: daemon-set-mv262. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  7 07:28:07.354: INFO: Pod daemon-set-mv262 is not available
Dec  7 07:28:07.361: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:08.348: INFO: Pod daemon-set-lvwrg is not available
Dec  7 07:28:08.352: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  7 07:28:08.355: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:08.358: INFO: Number of nodes with available pods: 0
Dec  7 07:28:08.358: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:28:09.362: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:28:09.364: INFO: Number of nodes with available pods: 1
Dec  7 07:28:09.365: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vvfv6, will wait for the garbage collector to delete the pods
Dec  7 07:28:09.443: INFO: Deleting DaemonSet.extensions daemon-set took: 9.678266ms
Dec  7 07:28:09.543: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.291573ms
Dec  7 07:28:17.747: INFO: Number of nodes with available pods: 0
Dec  7 07:28:17.747: INFO: Number of running nodes: 0, number of available pods: 0
Dec  7 07:28:17.749: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vvfv6/daemonsets","resourceVersion":"17028"},"items":null}

Dec  7 07:28:17.751: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vvfv6/pods","resourceVersion":"17028"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:28:17.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vvfv6" for this suite.
Dec  7 07:28:23.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:28:23.791: INFO: namespace: e2e-tests-daemonsets-vvfv6, resource: bindings, ignored listing per whitelist
Dec  7 07:28:23.868: INFO: namespace e2e-tests-daemonsets-vvfv6 deletion completed in 6.108801248s

• [SLOW TEST:58.663 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:28:23.869: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  7 07:28:27.972: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  7 07:28:27.976: INFO: Pod pod-with-prestop-http-hook still exists
Dec  7 07:28:29.976: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  7 07:28:29.979: INFO: Pod pod-with-prestop-http-hook still exists
Dec  7 07:28:31.976: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  7 07:28:31.979: INFO: Pod pod-with-prestop-http-hook still exists
Dec  7 07:28:33.976: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  7 07:28:33.980: INFO: Pod pod-with-prestop-http-hook still exists
Dec  7 07:28:35.976: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  7 07:28:35.980: INFO: Pod pod-with-prestop-http-hook still exists
Dec  7 07:28:37.976: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  7 07:28:37.979: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:28:37.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bprnh" for this suite.
Dec  7 07:29:00.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:29:00.100: INFO: namespace: e2e-tests-container-lifecycle-hook-bprnh, resource: bindings, ignored listing per whitelist
Dec  7 07:29:00.102: INFO: namespace e2e-tests-container-lifecycle-hook-bprnh deletion completed in 22.111545046s

• [SLOW TEST:36.233 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:29:00.103: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  7 07:29:00.172: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-542553880 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:29:00.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hkltw" for this suite.
Dec  7 07:29:06.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:29:06.324: INFO: namespace: e2e-tests-kubectl-hkltw, resource: bindings, ignored listing per whitelist
Dec  7 07:29:06.351: INFO: namespace e2e-tests-kubectl-hkltw deletion completed in 6.095285671s

• [SLOW TEST:6.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:29:06.352: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c77e9b2c-f9f1-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c77e9b2c-f9f1-11e8-9cb3-16e60f4677a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:29:10.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zspg" for this suite.
Dec  7 07:29:32.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:29:32.582: INFO: namespace: e2e-tests-projected-9zspg, resource: bindings, ignored listing per whitelist
Dec  7 07:29:32.610: INFO: namespace e2e-tests-projected-9zspg deletion completed in 22.129714989s

• [SLOW TEST:26.259 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:29:32.611: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  7 07:29:32.684: INFO: Waiting up to 5m0s for pod "pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-b8ll6" to be "success or failure"
Dec  7 07:29:32.691: INFO: Pod "pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.730957ms
Dec  7 07:29:34.695: INFO: Pod "pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011142492s
STEP: Saw pod success
Dec  7 07:29:34.695: INFO: Pod "pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:29:34.698: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:29:34.724: INFO: Waiting for pod pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:29:34.727: INFO: Pod pod-d7254fc6-f9f1-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:29:34.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b8ll6" for this suite.
Dec  7 07:29:40.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:29:40.770: INFO: namespace: e2e-tests-emptydir-b8ll6, resource: bindings, ignored listing per whitelist
Dec  7 07:29:40.833: INFO: namespace e2e-tests-emptydir-b8ll6 deletion completed in 6.102300226s

• [SLOW TEST:8.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:29:40.834: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  7 07:29:40.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:41.125: INFO: stderr: ""
Dec  7 07:29:41.125: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  7 07:29:41.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:41.265: INFO: stderr: ""
Dec  7 07:29:41.265: INFO: stdout: "update-demo-nautilus-8g4f8 update-demo-nautilus-wcptm "
Dec  7 07:29:41.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-8g4f8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:41.373: INFO: stderr: ""
Dec  7 07:29:41.373: INFO: stdout: ""
Dec  7 07:29:41.373: INFO: update-demo-nautilus-8g4f8 is created but not running
Dec  7 07:29:46.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:46.475: INFO: stderr: ""
Dec  7 07:29:46.475: INFO: stdout: "update-demo-nautilus-8g4f8 update-demo-nautilus-wcptm "
Dec  7 07:29:46.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-8g4f8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:46.577: INFO: stderr: ""
Dec  7 07:29:46.577: INFO: stdout: "true"
Dec  7 07:29:46.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-8g4f8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:46.679: INFO: stderr: ""
Dec  7 07:29:46.679: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 07:29:46.679: INFO: validating pod update-demo-nautilus-8g4f8
Dec  7 07:29:46.688: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 07:29:46.688: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 07:29:46.688: INFO: update-demo-nautilus-8g4f8 is verified up and running
Dec  7 07:29:46.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-wcptm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:46.805: INFO: stderr: ""
Dec  7 07:29:46.805: INFO: stdout: "true"
Dec  7 07:29:46.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-nautilus-wcptm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:29:46.904: INFO: stderr: ""
Dec  7 07:29:46.904: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  7 07:29:46.904: INFO: validating pod update-demo-nautilus-wcptm
Dec  7 07:29:46.909: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  7 07:29:46.910: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  7 07:29:46.910: INFO: update-demo-nautilus-wcptm is verified up and running
STEP: rolling-update to new replication controller
Dec  7 07:29:46.912: INFO: scanned /root for discovery docs: <nil>
Dec  7 07:29:46.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:30:08.452: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  7 07:30:08.452: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  7 07:30:08.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:30:08.561: INFO: stderr: ""
Dec  7 07:30:08.561: INFO: stdout: "update-demo-kitten-cwdrr update-demo-kitten-nrf4b "
Dec  7 07:30:08.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-kitten-cwdrr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:30:08.671: INFO: stderr: ""
Dec  7 07:30:08.671: INFO: stdout: "true"
Dec  7 07:30:08.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-kitten-cwdrr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:30:08.769: INFO: stderr: ""
Dec  7 07:30:08.769: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  7 07:30:08.769: INFO: validating pod update-demo-kitten-cwdrr
Dec  7 07:30:08.776: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  7 07:30:08.776: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  7 07:30:08.776: INFO: update-demo-kitten-cwdrr is verified up and running
Dec  7 07:30:08.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-kitten-nrf4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:30:08.874: INFO: stderr: ""
Dec  7 07:30:08.875: INFO: stdout: "true"
Dec  7 07:30:08.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 get pods update-demo-kitten-nrf4b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nqc7v'
Dec  7 07:30:08.977: INFO: stderr: ""
Dec  7 07:30:08.977: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  7 07:30:08.977: INFO: validating pod update-demo-kitten-nrf4b
Dec  7 07:30:08.983: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  7 07:30:08.983: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  7 07:30:08.983: INFO: update-demo-kitten-nrf4b is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:30:08.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nqc7v" for this suite.
Dec  7 07:30:30.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:30:31.037: INFO: namespace: e2e-tests-kubectl-nqc7v, resource: bindings, ignored listing per whitelist
Dec  7 07:30:31.084: INFO: namespace e2e-tests-kubectl-nqc7v deletion completed in 22.098441939s

• [SLOW TEST:50.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:30:31.084: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  7 07:30:31.147: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  7 07:30:31.154: INFO: Waiting for terminating namespaces to be deleted...
Dec  7 07:30:31.157: INFO: 
Logging pods the kubelet thinks is on node 2gb-pool-qefm5t before test
Dec  7 07:30:31.164: INFO: sonobuoy-e2e-job-f8206d314b644524 from heptio-sonobuoy started at 2018-12-07 06:07:46 +0000 UTC (2 container statuses recorded)
Dec  7 07:30:31.164: INFO: 	Container e2e ready: true, restart count 0
Dec  7 07:30:31.164: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  7 07:30:31.164: INFO: kube-proxy-smrvg from kube-system started at 2018-12-07 05:59:48 +0000 UTC (1 container statuses recorded)
Dec  7 07:30:31.164: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  7 07:30:31.164: INFO: sonobuoy-systemd-logs-daemon-set-ac0c249d5e6f4d1f-5jfhb from heptio-sonobuoy started at 2018-12-07 06:07:46 +0000 UTC (2 container statuses recorded)
Dec  7 07:30:31.164: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  7 07:30:31.165: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  7 07:30:31.165: INFO: pharmer-provisioner-cf7cd8d85-fckbl from kube-system started at 2018-12-07 06:00:17 +0000 UTC (1 container statuses recorded)
Dec  7 07:30:31.165: INFO: 	Container cloud-storage ready: true, restart count 0
Dec  7 07:30:31.165: INFO: pharmer-flex-5ngx4 from kube-system started at 2018-12-07 06:00:17 +0000 UTC (1 container statuses recorded)
Dec  7 07:30:31.165: INFO: 	Container pharmer-flex ready: true, restart count 0
Dec  7 07:30:31.165: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-07 06:07:42 +0000 UTC (1 container statuses recorded)
Dec  7 07:30:31.165: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  7 07:30:31.165: INFO: calico-node-wmv9t from kube-system started at 2018-12-07 05:59:48 +0000 UTC (2 container statuses recorded)
Dec  7 07:30:31.165: INFO: 	Container calico-node ready: true, restart count 0
Dec  7 07:30:31.165: INFO: 	Container install-cni ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fb389b5d-f9f1-11e8-9cb3-16e60f4677a4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fb389b5d-f9f1-11e8-9cb3-16e60f4677a4 off the node 2gb-pool-qefm5t
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fb389b5d-f9f1-11e8-9cb3-16e60f4677a4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:30:35.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2dj2c" for this suite.
Dec  7 07:30:43.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:30:43.360: INFO: namespace: e2e-tests-sched-pred-2dj2c, resource: bindings, ignored listing per whitelist
Dec  7 07:30:43.410: INFO: namespace e2e-tests-sched-pred-2dj2c deletion completed in 8.115647125s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.325 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:30:43.410: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  7 07:31:14.038: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:31:14.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wfm9z" for this suite.
Dec  7 07:31:20.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:31:20.087: INFO: namespace: e2e-tests-gc-wfm9z, resource: bindings, ignored listing per whitelist
Dec  7 07:31:20.152: INFO: namespace e2e-tests-gc-wfm9z deletion completed in 6.111220085s

• [SLOW TEST:36.743 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:31:20.153: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  7 07:31:30.346: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:31:30.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xnl4p" for this suite.
Dec  7 07:31:36.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:31:36.423: INFO: namespace: e2e-tests-gc-xnl4p, resource: bindings, ignored listing per whitelist
Dec  7 07:31:36.471: INFO: namespace e2e-tests-gc-xnl4p deletion completed in 6.122413268s

• [SLOW TEST:16.318 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:31:36.472: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  7 07:31:36.559: INFO: Waiting up to 5m0s for pod "downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-c8ck8" to be "success or failure"
Dec  7 07:31:36.565: INFO: Pod "downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854145ms
Dec  7 07:31:38.568: INFO: Pod "downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009183128s
STEP: Saw pod success
Dec  7 07:31:38.568: INFO: Pod "downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:31:38.571: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 07:31:38.624: INFO: Waiting for pod downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:31:38.631: INFO: Pod downward-api-20fb3a49-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:31:38.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c8ck8" for this suite.
Dec  7 07:31:44.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:31:44.721: INFO: namespace: e2e-tests-downward-api-c8ck8, resource: bindings, ignored listing per whitelist
Dec  7 07:31:44.730: INFO: namespace e2e-tests-downward-api-c8ck8 deletion completed in 6.094349111s

• [SLOW TEST:8.259 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:31:44.732: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:31:44.802: INFO: (0) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.552716ms)
Dec  7 07:31:44.806: INFO: (1) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.6893ms)
Dec  7 07:31:44.810: INFO: (2) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.787306ms)
Dec  7 07:31:44.814: INFO: (3) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.353305ms)
Dec  7 07:31:44.817: INFO: (4) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.115138ms)
Dec  7 07:31:44.821: INFO: (5) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.991189ms)
Dec  7 07:31:44.825: INFO: (6) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.703702ms)
Dec  7 07:31:44.828: INFO: (7) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.358108ms)
Dec  7 07:31:44.832: INFO: (8) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.505734ms)
Dec  7 07:31:44.835: INFO: (9) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.373668ms)
Dec  7 07:31:44.839: INFO: (10) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.016203ms)
Dec  7 07:31:44.843: INFO: (11) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.761074ms)
Dec  7 07:31:44.847: INFO: (12) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.893714ms)
Dec  7 07:31:44.852: INFO: (13) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.306506ms)
Dec  7 07:31:44.855: INFO: (14) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.859967ms)
Dec  7 07:31:44.859: INFO: (15) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.586974ms)
Dec  7 07:31:44.863: INFO: (16) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.589709ms)
Dec  7 07:31:44.867: INFO: (17) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.952502ms)
Dec  7 07:31:44.871: INFO: (18) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.956115ms)
Dec  7 07:31:44.876: INFO: (19) /api/v1/nodes/2gb-pool-qefm5t/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.892872ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:31:44.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6fs5n" for this suite.
Dec  7 07:31:50.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:31:50.912: INFO: namespace: e2e-tests-proxy-6fs5n, resource: bindings, ignored listing per whitelist
Dec  7 07:31:50.965: INFO: namespace e2e-tests-proxy-6fs5n deletion completed in 6.084686978s

• [SLOW TEST:6.232 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:31:50.966: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:31:51.033: INFO: Waiting up to 5m0s for pod "downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-xrckh" to be "success or failure"
Dec  7 07:31:51.044: INFO: Pod "downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.853057ms
Dec  7 07:31:53.048: INFO: Pod "downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014946166s
STEP: Saw pod success
Dec  7 07:31:53.048: INFO: Pod "downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:31:53.050: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:31:53.072: INFO: Waiting for pod downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:31:53.074: INFO: Pod downwardapi-volume-299bc5fe-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:31:53.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xrckh" for this suite.
Dec  7 07:31:59.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:31:59.114: INFO: namespace: e2e-tests-projected-xrckh, resource: bindings, ignored listing per whitelist
Dec  7 07:31:59.197: INFO: namespace e2e-tests-projected-xrckh deletion completed in 6.118125023s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:31:59.197: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-vll5t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vll5t to expose endpoints map[]
Dec  7 07:31:59.276: INFO: Get endpoints failed (4.910256ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  7 07:32:00.280: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vll5t exposes endpoints map[] (1.008214455s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-vll5t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vll5t to expose endpoints map[pod1:[80]]
Dec  7 07:32:02.311: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vll5t exposes endpoints map[pod1:[80]] (2.026053034s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-vll5t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vll5t to expose endpoints map[pod1:[80] pod2:[80]]
Dec  7 07:32:04.346: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vll5t exposes endpoints map[pod1:[80] pod2:[80]] (2.028403426s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-vll5t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vll5t to expose endpoints map[pod2:[80]]
Dec  7 07:32:04.364: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vll5t exposes endpoints map[pod2:[80]] (10.614017ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-vll5t
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vll5t to expose endpoints map[]
Dec  7 07:32:04.388: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vll5t exposes endpoints map[] (7.404607ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:32:04.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vll5t" for this suite.
Dec  7 07:32:26.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:32:26.510: INFO: namespace: e2e-tests-services-vll5t, resource: bindings, ignored listing per whitelist
Dec  7 07:32:26.545: INFO: namespace e2e-tests-services-vll5t deletion completed in 22.121421999s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.347 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:32:26.545: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  7 07:32:26.629: INFO: Waiting up to 5m0s for pod "pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-rbxnw" to be "success or failure"
Dec  7 07:32:26.633: INFO: Pod "pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.353387ms
Dec  7 07:32:28.638: INFO: Pod "pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009047902s
STEP: Saw pod success
Dec  7 07:32:28.638: INFO: Pod "pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:32:28.641: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:32:28.668: INFO: Waiting for pod pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:32:28.679: INFO: Pod pod-3ed31524-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:32:28.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rbxnw" for this suite.
Dec  7 07:32:34.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:32:34.716: INFO: namespace: e2e-tests-emptydir-rbxnw, resource: bindings, ignored listing per whitelist
Dec  7 07:32:34.779: INFO: namespace e2e-tests-emptydir-rbxnw deletion completed in 6.095522568s

• [SLOW TEST:8.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:32:34.780: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  7 07:32:34.891: INFO: Waiting up to 5m0s for pod "pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-lxkqg" to be "success or failure"
Dec  7 07:32:34.896: INFO: Pod "pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.440294ms
Dec  7 07:32:36.900: INFO: Pod "pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4": Phase="Running", Reason="", readiness=true. Elapsed: 2.008520156s
Dec  7 07:32:38.903: INFO: Pod "pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012125472s
STEP: Saw pod success
Dec  7 07:32:38.903: INFO: Pod "pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:32:38.906: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:32:38.935: INFO: Waiting for pod pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:32:38.937: INFO: Pod pod-43bf7499-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:32:38.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lxkqg" for this suite.
Dec  7 07:32:44.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:32:44.967: INFO: namespace: e2e-tests-emptydir-lxkqg, resource: bindings, ignored listing per whitelist
Dec  7 07:32:45.042: INFO: namespace e2e-tests-emptydir-lxkqg deletion completed in 6.101886743s

• [SLOW TEST:10.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:32:45.042: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mxvmt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  7 07:32:45.107: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  7 07:33:05.268: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.1.36 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mxvmt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:33:05.269: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:33:06.365: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:33:06.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mxvmt" for this suite.
Dec  7 07:33:28.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:33:28.422: INFO: namespace: e2e-tests-pod-network-test-mxvmt, resource: bindings, ignored listing per whitelist
Dec  7 07:33:28.479: INFO: namespace e2e-tests-pod-network-test-mxvmt deletion completed in 22.109280255s

• [SLOW TEST:43.437 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:33:28.481: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  7 07:33:31.100: INFO: Successfully updated pod "labelsupdate63be159f-f9f2-11e8-9cb3-16e60f4677a4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:33:33.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nfjxq" for this suite.
Dec  7 07:33:55.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:33:55.203: INFO: namespace: e2e-tests-projected-nfjxq, resource: bindings, ignored listing per whitelist
Dec  7 07:33:55.228: INFO: namespace e2e-tests-projected-nfjxq deletion completed in 22.102732682s

• [SLOW TEST:26.748 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:33:55.228: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  7 07:33:55.296: INFO: PodSpec: initContainers in spec.initContainers
Dec  7 07:34:40.053: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-73adc3ef-f9f2-11e8-9cb3-16e60f4677a4", GenerateName:"", Namespace:"e2e-tests-init-container-s2gq7", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-s2gq7/pods/pod-init-73adc3ef-f9f2-11e8-9cb3-16e60f4677a4", UID:"73ae7dba-f9f2-11e8-bee8-5a54dcfa39ab", ResourceVersion:"18394", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679764835, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"296977213"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.39/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jqjt4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001e28380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jqjt4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jqjt4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jqjt4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024da338), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"2gb-pool-qefm5t", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00286c0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024da3c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024da3e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0024da3e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0024da3ec)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679764835, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679764835, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679764835, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679764835, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.132.155.16", PodIP:"192.168.1.39", StartTime:(*v1.Time)(0xc002604120), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001e24460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001e244d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://90077cedc18596027f3f6a3e2d439020c560e91e942d856d950572706178a637"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002604160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002604140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:34:40.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-s2gq7" for this suite.
Dec  7 07:35:02.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:35:02.112: INFO: namespace: e2e-tests-init-container-s2gq7, resource: bindings, ignored listing per whitelist
Dec  7 07:35:02.205: INFO: namespace e2e-tests-init-container-s2gq7 deletion completed in 22.143857544s

• [SLOW TEST:66.976 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:35:02.205: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  7 07:35:05.313: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:35:05.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-d425d" for this suite.
Dec  7 07:35:27.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:35:27.387: INFO: namespace: e2e-tests-replicaset-d425d, resource: bindings, ignored listing per whitelist
Dec  7 07:35:27.441: INFO: namespace e2e-tests-replicaset-d425d deletion completed in 22.091959628s

• [SLOW TEST:25.236 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:35:27.442: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-aaa2e096-f9f2-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:35:27.510: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-55llv" to be "success or failure"
Dec  7 07:35:27.515: INFO: Pod "pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.240666ms
Dec  7 07:35:29.518: INFO: Pod "pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007503s
STEP: Saw pod success
Dec  7 07:35:29.518: INFO: Pod "pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:35:29.521: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:35:29.551: INFO: Waiting for pod pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:35:29.558: INFO: Pod pod-projected-configmaps-aaa36bd2-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:35:29.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-55llv" for this suite.
Dec  7 07:35:35.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:35:35.613: INFO: namespace: e2e-tests-projected-55llv, resource: bindings, ignored listing per whitelist
Dec  7 07:35:35.684: INFO: namespace e2e-tests-projected-55llv deletion completed in 6.12134726s

• [SLOW TEST:8.243 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:35:35.684: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-af91cc16-f9f2-11e8-9cb3-16e60f4677a4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:35:37.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pz5bm" for this suite.
Dec  7 07:35:59.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:35:59.925: INFO: namespace: e2e-tests-configmap-pz5bm, resource: bindings, ignored listing per whitelist
Dec  7 07:35:59.941: INFO: namespace e2e-tests-configmap-pz5bm deletion completed in 22.111950881s

• [SLOW TEST:24.256 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:35:59.941: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  7 07:36:00.023: INFO: Waiting up to 5m0s for pod "var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-var-expansion-dgdlp" to be "success or failure"
Dec  7 07:36:00.036: INFO: Pod "var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.115797ms
Dec  7 07:36:02.040: INFO: Pod "var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016422239s
STEP: Saw pod success
Dec  7 07:36:02.040: INFO: Pod "var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:36:02.043: INFO: Trying to get logs from node 2gb-pool-qefm5t pod var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 07:36:02.065: INFO: Waiting for pod var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:36:02.077: INFO: Pod var-expansion-be02e187-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:36:02.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-dgdlp" for this suite.
Dec  7 07:36:08.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:36:08.153: INFO: namespace: e2e-tests-var-expansion-dgdlp, resource: bindings, ignored listing per whitelist
Dec  7 07:36:08.172: INFO: namespace e2e-tests-var-expansion-dgdlp deletion completed in 6.088675532s

• [SLOW TEST:8.231 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:36:08.174: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:36:12.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xs5hz" for this suite.
Dec  7 07:36:18.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:36:18.358: INFO: namespace: e2e-tests-kubelet-test-xs5hz, resource: bindings, ignored listing per whitelist
Dec  7 07:36:18.364: INFO: namespace e2e-tests-kubelet-test-xs5hz deletion completed in 6.113153015s

• [SLOW TEST:10.190 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:36:18.365: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:36:18.459: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-rvm72" to be "success or failure"
Dec  7 07:36:18.467: INFO: Pod "downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.927427ms
Dec  7 07:36:20.470: INFO: Pod "downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010969014s
STEP: Saw pod success
Dec  7 07:36:20.470: INFO: Pod "downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:36:20.472: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:36:20.491: INFO: Waiting for pod downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:36:20.493: INFO: Pod downwardapi-volume-c9009ed3-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:36:20.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rvm72" for this suite.
Dec  7 07:36:26.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:36:26.542: INFO: namespace: e2e-tests-projected-rvm72, resource: bindings, ignored listing per whitelist
Dec  7 07:36:26.617: INFO: namespace e2e-tests-projected-rvm72 deletion completed in 6.118084783s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:36:26.618: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:36:46.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-sw5wj" for this suite.
Dec  7 07:36:52.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:36:52.935: INFO: namespace: e2e-tests-container-runtime-sw5wj, resource: bindings, ignored listing per whitelist
Dec  7 07:36:53.007: INFO: namespace e2e-tests-container-runtime-sw5wj deletion completed in 6.099841031s

• [SLOW TEST:26.389 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:36:53.008: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:36:53.073: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:36:54.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-stbgz" for this suite.
Dec  7 07:37:00.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:37:00.192: INFO: namespace: e2e-tests-custom-resource-definition-stbgz, resource: bindings, ignored listing per whitelist
Dec  7 07:37:00.253: INFO: namespace e2e-tests-custom-resource-definition-stbgz deletion completed in 6.102773058s

• [SLOW TEST:7.245 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:37:00.254: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e1f69d77-f9f2-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:37:00.334: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-gkktj" to be "success or failure"
Dec  7 07:37:00.337: INFO: Pod "pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.887415ms
Dec  7 07:37:02.341: INFO: Pod "pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007357128s
STEP: Saw pod success
Dec  7 07:37:02.341: INFO: Pod "pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:37:02.343: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:37:02.363: INFO: Waiting for pod pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:37:02.367: INFO: Pod pod-projected-configmaps-e1f742b5-f9f2-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:37:02.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gkktj" for this suite.
Dec  7 07:37:08.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:37:08.479: INFO: namespace: e2e-tests-projected-gkktj, resource: bindings, ignored listing per whitelist
Dec  7 07:37:08.486: INFO: namespace e2e-tests-projected-gkktj deletion completed in 6.108491825s

• [SLOW TEST:8.232 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:37:08.487: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vh7dt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  7 07:37:08.567: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  7 07:37:26.629: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.52:8080/dial?request=hostName&protocol=http&host=192.168.1.51&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-vh7dt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:37:26.629: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:37:26.713: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:37:26.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vh7dt" for this suite.
Dec  7 07:37:48.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:37:48.796: INFO: namespace: e2e-tests-pod-network-test-vh7dt, resource: bindings, ignored listing per whitelist
Dec  7 07:37:48.812: INFO: namespace e2e-tests-pod-network-test-vh7dt deletion completed in 22.094188138s

• [SLOW TEST:40.326 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:37:48.814: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4
Dec  7 07:37:48.884: INFO: Pod name my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4: Found 0 pods out of 1
Dec  7 07:37:53.888: INFO: Pod name my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4: Found 1 pods out of 1
Dec  7 07:37:53.888: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4" are running
Dec  7 07:37:53.891: INFO: Pod "my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4-jvhkp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:37:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:37:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:37:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:37:48 +0000 UTC Reason: Message:}])
Dec  7 07:37:53.891: INFO: Trying to dial the pod
Dec  7 07:37:58.904: INFO: Controller my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4: Got expected result from replica 1 [my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4-jvhkp]: "my-hostname-basic-fee76e25-f9f2-11e8-9cb3-16e60f4677a4-jvhkp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:37:58.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9t4ww" for this suite.
Dec  7 07:38:04.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:38:04.944: INFO: namespace: e2e-tests-replication-controller-9t4ww, resource: bindings, ignored listing per whitelist
Dec  7 07:38:05.016: INFO: namespace e2e-tests-replication-controller-9t4ww deletion completed in 6.108118719s

• [SLOW TEST:16.202 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:38:05.016: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-08906424-f9f3-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 07:38:05.093: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-dp8wd" to be "success or failure"
Dec  7 07:38:05.096: INFO: Pod "pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.965861ms
Dec  7 07:38:07.099: INFO: Pod "pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4": Phase="Running", Reason="", readiness=true. Elapsed: 2.006229311s
Dec  7 07:38:09.103: INFO: Pod "pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009786098s
STEP: Saw pod success
Dec  7 07:38:09.103: INFO: Pod "pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:38:09.105: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  7 07:38:09.126: INFO: Waiting for pod pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:38:09.142: INFO: Pod pod-projected-secrets-0890c9db-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:38:09.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dp8wd" for this suite.
Dec  7 07:38:15.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:38:15.234: INFO: namespace: e2e-tests-projected-dp8wd, resource: bindings, ignored listing per whitelist
Dec  7 07:38:15.244: INFO: namespace e2e-tests-projected-dp8wd deletion completed in 6.098494879s

• [SLOW TEST:10.228 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:38:15.244: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  7 07:38:15.318: INFO: Waiting up to 5m0s for pod "downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-downward-api-dvgrq" to be "success or failure"
Dec  7 07:38:15.322: INFO: Pod "downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.360101ms
Dec  7 07:38:17.326: INFO: Pod "downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007722574s
STEP: Saw pod success
Dec  7 07:38:17.326: INFO: Pod "downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:38:17.329: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4 container dapi-container: <nil>
STEP: delete the pod
Dec  7 07:38:17.349: INFO: Waiting for pod downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:38:17.356: INFO: Pod downward-api-0ea7cf7d-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:38:17.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dvgrq" for this suite.
Dec  7 07:38:23.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:38:23.452: INFO: namespace: e2e-tests-downward-api-dvgrq, resource: bindings, ignored listing per whitelist
Dec  7 07:38:23.466: INFO: namespace e2e-tests-downward-api-dvgrq deletion completed in 6.100882331s

• [SLOW TEST:8.222 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:38:23.467: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  7 07:38:27.580: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:27.585: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:29.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:29.591: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:31.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:31.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:33.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:33.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:35.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:35.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:37.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:37.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:39.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:39.592: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:41.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:41.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:43.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:43.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:45.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:45.589: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  7 07:38:47.585: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  7 07:38:47.589: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:38:47.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-v9t2f" for this suite.
Dec  7 07:39:09.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:39:09.709: INFO: namespace: e2e-tests-container-lifecycle-hook-v9t2f, resource: bindings, ignored listing per whitelist
Dec  7 07:39:09.724: INFO: namespace e2e-tests-container-lifecycle-hook-v9t2f deletion completed in 22.123523684s

• [SLOW TEST:46.257 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:39:09.724: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-ddsqn;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-ddsqn.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 198.146.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.146.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.146.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.146.198_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-ddsqn;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-ddsqn.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-ddsqn.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-ddsqn.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 198.146.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.146.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.146.107.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.107.146.198_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  7 07:39:13.851: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.855: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.878: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.881: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.907: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.910: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.914: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.917: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.920: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.924: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.927: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.931: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:13.963: INFO: Lookups using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-ddsqn jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc]

Dec  7 07:39:18.968: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:18.972: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:18.984: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:18.987: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.012: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.015: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.018: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.022: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.026: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.029: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.033: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.037: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:19.061: INFO: Lookups using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-ddsqn jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc]

Dec  7 07:39:23.968: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:23.973: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:23.986: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:23.989: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.015: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.018: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.022: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.025: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.027: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.031: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.034: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.036: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:24.058: INFO: Lookups using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-ddsqn jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc]

Dec  7 07:39:28.969: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:28.973: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:28.988: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:28.991: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.021: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.024: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.027: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.031: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.034: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.037: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.041: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.044: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:29.064: INFO: Lookups using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-ddsqn jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc]

Dec  7 07:39:33.974: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:33.977: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:33.992: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:33.997: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.029: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.032: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.035: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.038: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.042: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.045: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.049: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.052: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:34.074: INFO: Lookups using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-ddsqn jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc]

Dec  7 07:39:38.971: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:38.976: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:38.992: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.000: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.040: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.044: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.047: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.050: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.053: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.057: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.059: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.063: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc from pod e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4: the server could not find the requested resource (get pods dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4)
Dec  7 07:39:39.083: INFO: Lookups using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-ddsqn jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn jessie_udp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@dns-test-service.e2e-tests-dns-ddsqn.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-ddsqn.svc]

Dec  7 07:39:44.066: INFO: DNS probes using e2e-tests-dns-ddsqn/dns-test-2f26ac56-f9f3-11e8-9cb3-16e60f4677a4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:39:44.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-ddsqn" for this suite.
Dec  7 07:39:50.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:39:50.206: INFO: namespace: e2e-tests-dns-ddsqn, resource: bindings, ignored listing per whitelist
Dec  7 07:39:50.275: INFO: namespace e2e-tests-dns-ddsqn deletion completed in 6.101333238s

• [SLOW TEST:40.551 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:39:50.277: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  7 07:39:50.344: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  7 07:39:50.351: INFO: Waiting for terminating namespaces to be deleted...
Dec  7 07:39:50.353: INFO: 
Logging pods the kubelet thinks is on node 2gb-pool-qefm5t before test
Dec  7 07:39:50.362: INFO: calico-node-wmv9t from kube-system started at 2018-12-07 05:59:48 +0000 UTC (2 container statuses recorded)
Dec  7 07:39:50.362: INFO: 	Container calico-node ready: true, restart count 0
Dec  7 07:39:50.363: INFO: 	Container install-cni ready: true, restart count 0
Dec  7 07:39:50.363: INFO: sonobuoy-e2e-job-f8206d314b644524 from heptio-sonobuoy started at 2018-12-07 06:07:46 +0000 UTC (2 container statuses recorded)
Dec  7 07:39:50.363: INFO: 	Container e2e ready: true, restart count 0
Dec  7 07:39:50.363: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  7 07:39:50.363: INFO: kube-proxy-smrvg from kube-system started at 2018-12-07 05:59:48 +0000 UTC (1 container statuses recorded)
Dec  7 07:39:50.363: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  7 07:39:50.363: INFO: sonobuoy-systemd-logs-daemon-set-ac0c249d5e6f4d1f-5jfhb from heptio-sonobuoy started at 2018-12-07 06:07:46 +0000 UTC (2 container statuses recorded)
Dec  7 07:39:50.363: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  7 07:39:50.363: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  7 07:39:50.364: INFO: pharmer-provisioner-cf7cd8d85-fckbl from kube-system started at 2018-12-07 06:00:17 +0000 UTC (1 container statuses recorded)
Dec  7 07:39:50.364: INFO: 	Container cloud-storage ready: true, restart count 0
Dec  7 07:39:50.364: INFO: pharmer-flex-5ngx4 from kube-system started at 2018-12-07 06:00:17 +0000 UTC (1 container statuses recorded)
Dec  7 07:39:50.364: INFO: 	Container pharmer-flex ready: true, restart count 0
Dec  7 07:39:50.364: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-07 06:07:42 +0000 UTC (1 container statuses recorded)
Dec  7 07:39:50.364: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156dfcf83e20800f], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:39:51.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lx82p" for this suite.
Dec  7 07:39:57.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:39:57.422: INFO: namespace: e2e-tests-sched-pred-lx82p, resource: bindings, ignored listing per whitelist
Dec  7 07:39:57.487: INFO: namespace e2e-tests-sched-pred-lx82p deletion completed in 6.097067582s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.211 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:39:57.488: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  7 07:39:57.570: INFO: Waiting up to 5m0s for pod "pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-emptydir-t78r7" to be "success or failure"
Dec  7 07:39:57.579: INFO: Pod "pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.802575ms
Dec  7 07:39:59.583: INFO: Pod "pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012231153s
STEP: Saw pod success
Dec  7 07:39:59.583: INFO: Pod "pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:39:59.585: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4 container test-container: <nil>
STEP: delete the pod
Dec  7 07:39:59.616: INFO: Waiting for pod pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:39:59.622: INFO: Pod pod-4b9b1211-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:39:59.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t78r7" for this suite.
Dec  7 07:40:05.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:40:05.653: INFO: namespace: e2e-tests-emptydir-t78r7, resource: bindings, ignored listing per whitelist
Dec  7 07:40:05.727: INFO: namespace e2e-tests-emptydir-t78r7 deletion completed in 6.097928493s

• [SLOW TEST:8.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:40:05.730: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  7 07:40:05.819: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-dmt4h" to be "success or failure"
Dec  7 07:40:05.828: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.607628ms
Dec  7 07:40:07.832: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013512859s
Dec  7 07:40:09.837: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01845064s
STEP: Saw pod success
Dec  7 07:40:09.837: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  7 07:40:09.840: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  7 07:40:09.865: INFO: Waiting for pod pod-host-path-test to disappear
Dec  7 07:40:09.889: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:40:09.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-dmt4h" for this suite.
Dec  7 07:40:15.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:40:16.005: INFO: namespace: e2e-tests-hostpath-dmt4h, resource: bindings, ignored listing per whitelist
Dec  7 07:40:16.005: INFO: namespace e2e-tests-hostpath-dmt4h deletion completed in 6.112396859s

• [SLOW TEST:10.274 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:40:16.005: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  7 07:40:16.074: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-542553880 proxy --unix-socket=/tmp/kubectl-proxy-unix701649815/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:40:16.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-59qjj" for this suite.
Dec  7 07:40:22.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:40:22.208: INFO: namespace: e2e-tests-kubectl-59qjj, resource: bindings, ignored listing per whitelist
Dec  7 07:40:22.290: INFO: namespace e2e-tests-kubectl-59qjj deletion completed in 6.121741532s

• [SLOW TEST:6.285 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:40:22.293: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  7 07:40:22.395: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:40:22.399: INFO: Number of nodes with available pods: 0
Dec  7 07:40:22.399: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:40:23.403: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:40:23.406: INFO: Number of nodes with available pods: 0
Dec  7 07:40:23.406: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:40:24.404: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:40:24.407: INFO: Number of nodes with available pods: 1
Dec  7 07:40:24.407: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  7 07:40:24.424: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:40:24.429: INFO: Number of nodes with available pods: 0
Dec  7 07:40:24.429: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:40:25.434: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:40:25.437: INFO: Number of nodes with available pods: 0
Dec  7 07:40:25.437: INFO: Node 2gb-pool-qefm5t is running more than one daemon pod
Dec  7 07:40:26.434: INFO: DaemonSet pods can't tolerate node d113c-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec  7 07:40:26.437: INFO: Number of nodes with available pods: 1
Dec  7 07:40:26.437: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cwnt9, will wait for the garbage collector to delete the pods
Dec  7 07:40:26.506: INFO: Deleting DaemonSet.extensions daemon-set took: 10.771514ms
Dec  7 07:40:26.608: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.685111ms
Dec  7 07:41:00.512: INFO: Number of nodes with available pods: 0
Dec  7 07:41:00.512: INFO: Number of running nodes: 0, number of available pods: 0
Dec  7 07:41:00.528: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cwnt9/daemonsets","resourceVersion":"19580"},"items":null}

Dec  7 07:41:00.534: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cwnt9/pods","resourceVersion":"19580"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:41:00.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cwnt9" for this suite.
Dec  7 07:41:06.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:41:06.625: INFO: namespace: e2e-tests-daemonsets-cwnt9, resource: bindings, ignored listing per whitelist
Dec  7 07:41:06.663: INFO: namespace e2e-tests-daemonsets-cwnt9 deletion completed in 6.118498116s

• [SLOW TEST:44.370 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:41:06.663: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:41:06.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 version --client'
Dec  7 07:41:06.811: INFO: stderr: ""
Dec  7 07:41:06.811: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  7 07:41:06.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-pscrl'
Dec  7 07:41:07.172: INFO: stderr: ""
Dec  7 07:41:07.172: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  7 07:41:07.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 create -f - --namespace=e2e-tests-kubectl-pscrl'
Dec  7 07:41:07.416: INFO: stderr: ""
Dec  7 07:41:07.416: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  7 07:41:08.420: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 07:41:08.420: INFO: Found 0 / 1
Dec  7 07:41:09.421: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 07:41:09.421: INFO: Found 1 / 1
Dec  7 07:41:09.421: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  7 07:41:09.424: INFO: Selector matched 1 pods for map[app:redis]
Dec  7 07:41:09.424: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  7 07:41:09.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 describe pod redis-master-thbtk --namespace=e2e-tests-kubectl-pscrl'
Dec  7 07:41:09.547: INFO: stderr: ""
Dec  7 07:41:09.547: INFO: stdout: "Name:               redis-master-thbtk\nNamespace:          e2e-tests-kubectl-pscrl\nPriority:           0\nPriorityClassName:  <none>\nNode:               2gb-pool-qefm5t/10.132.155.16\nStart Time:         Fri, 07 Dec 2018 07:41:07 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.1.63/32\nStatus:             Running\nIP:                 192.168.1.63\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d8736ca211ceb407384bbbd721c6ff6a32d31c8ddae8fa5e041028fe363e8914\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 07 Dec 2018 07:41:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-sl7qx (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-sl7qx:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-sl7qx\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                      Message\n  ----    ------     ----  ----                      -------\n  Normal  Scheduled  2s    default-scheduler         Successfully assigned e2e-tests-kubectl-pscrl/redis-master-thbtk to 2gb-pool-qefm5t\n  Normal  Pulled     2s    kubelet, 2gb-pool-qefm5t  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 2gb-pool-qefm5t  Created container\n  Normal  Started    1s    kubelet, 2gb-pool-qefm5t  Started container\n"
Dec  7 07:41:09.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 describe rc redis-master --namespace=e2e-tests-kubectl-pscrl'
Dec  7 07:41:09.679: INFO: stderr: ""
Dec  7 07:41:09.679: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-pscrl\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-thbtk\n"
Dec  7 07:41:09.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 describe service redis-master --namespace=e2e-tests-kubectl-pscrl'
Dec  7 07:41:09.803: INFO: stderr: ""
Dec  7 07:41:09.803: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-pscrl\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.104.156.137\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.1.63:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  7 07:41:09.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 describe node 2gb-pool-qefm5t'
Dec  7 07:41:09.925: INFO: stderr: ""
Dec  7 07:41:09.925: INFO: stdout: "Name:               2gb-pool-qefm5t\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=2gb\n                    beta.kubernetes.io/os=linux\n                    cloud.appscode.com/pool=2gb-pool\n                    failure-domain.beta.kubernetes.io/region=nyc3\n                    kubernetes.io/hostname=2gb-pool-qefm5t\n                    node-role.kubernetes.io/node=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.132.155.16/16\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 07 Dec 2018 05:59:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 07 Dec 2018 07:41:08 +0000   Fri, 07 Dec 2018 05:59:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 07 Dec 2018 07:41:08 +0000   Fri, 07 Dec 2018 05:59:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 07 Dec 2018 07:41:08 +0000   Fri, 07 Dec 2018 05:59:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 07 Dec 2018 07:41:08 +0000   Fri, 07 Dec 2018 06:00:17 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    2gb-pool-qefm5t\n  InternalIP:  10.132.155.16\n  ExternalIP:  159.89.184.59\nCapacity:\n cpu:                2\n ephemeral-storage:  40470828Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2048056Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37297915024\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1945656Ki\n pods:               110\nSystem Info:\n Machine ID:                 7cbcc0486bd0412e94ee63756661b71a\n System UUID:                7CBCC048-6BD0-412E-94EE-63756661B71A\n Boot ID:                    62f4ba60-b2f7-44dc-af65-8311715aa4ae\n Kernel Version:             4.4.0-138-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nPodCIDR:                     192.168.1.0/24\nProviderID:                  digitalocean://122208964\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-pscrl    redis-master-thbtk                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  heptio-sonobuoy            sonobuoy-e2e-job-f8206d314b644524                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-ac0c249d5e6f4d1f-5jfhb    0 (0%)        0 (0%)      0 (0%)           0 (0%)         93m\n  kube-system                calico-node-wmv9t                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         101m\n  kube-system                kube-proxy-smrvg                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         101m\n  kube-system                pharmer-flex-5ngx4                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         100m\n  kube-system                pharmer-provisioner-cf7cd8d85-fckbl                        50m (2%)      50m (2%)    64Mi (3%)        64Mi (3%)      102m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                300m (15%)  50m (2%)\n  memory             64Mi (3%)   64Mi (3%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Dec  7 07:41:09.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-542553880 describe namespace e2e-tests-kubectl-pscrl'
Dec  7 07:41:10.047: INFO: stderr: ""
Dec  7 07:41:10.048: INFO: stdout: "Name:         e2e-tests-kubectl-pscrl\nLabels:       e2e-framework=kubectl\n              e2e-run=7fda7ca2-f9e6-11e8-9cb3-16e60f4677a4\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:41:10.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pscrl" for this suite.
Dec  7 07:41:32.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:41:32.076: INFO: namespace: e2e-tests-kubectl-pscrl, resource: bindings, ignored listing per whitelist
Dec  7 07:41:32.150: INFO: namespace e2e-tests-kubectl-pscrl deletion completed in 22.097681143s

• [SLOW TEST:25.487 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:41:32.153: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-84090e19-f9f3-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 07:41:32.246: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-xdm8p" to be "success or failure"
Dec  7 07:41:32.258: INFO: Pod "pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.626939ms
Dec  7 07:41:34.261: INFO: Pod "pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014807715s
STEP: Saw pod success
Dec  7 07:41:34.261: INFO: Pod "pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:41:34.264: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  7 07:41:34.289: INFO: Waiting for pod pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:41:34.295: INFO: Pod pod-projected-secrets-8409cf28-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:41:34.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xdm8p" for this suite.
Dec  7 07:41:40.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:41:40.365: INFO: namespace: e2e-tests-projected-xdm8p, resource: bindings, ignored listing per whitelist
Dec  7 07:41:40.388: INFO: namespace e2e-tests-projected-xdm8p deletion completed in 6.088801832s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:41:40.389: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  7 07:41:44.507: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:44.507: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:44.604: INFO: Exec stderr: ""
Dec  7 07:41:44.604: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:44.604: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:44.708: INFO: Exec stderr: ""
Dec  7 07:41:44.708: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:44.708: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:44.818: INFO: Exec stderr: ""
Dec  7 07:41:44.818: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:44.818: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:44.914: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  7 07:41:44.915: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:44.915: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:45.009: INFO: Exec stderr: ""
Dec  7 07:41:45.009: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:45.009: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:45.088: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  7 07:41:45.088: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:45.088: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:45.178: INFO: Exec stderr: ""
Dec  7 07:41:45.179: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:45.179: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:45.276: INFO: Exec stderr: ""
Dec  7 07:41:45.276: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:45.276: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:45.373: INFO: Exec stderr: ""
Dec  7 07:41:45.373: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4tf9b PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  7 07:41:45.374: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
Dec  7 07:41:45.469: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:41:45.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-4tf9b" for this suite.
Dec  7 07:42:23.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:42:23.498: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-4tf9b, resource: bindings, ignored listing per whitelist
Dec  7 07:42:23.581: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-4tf9b deletion completed in 38.108209219s

• [SLOW TEST:43.193 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:42:23.584: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  7 07:42:23.655: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:42:26.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8n6vq" for this suite.
Dec  7 07:42:32.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:42:32.564: INFO: namespace: e2e-tests-init-container-8n6vq, resource: bindings, ignored listing per whitelist
Dec  7 07:42:32.586: INFO: namespace e2e-tests-init-container-8n6vq deletion completed in 6.105952121s

• [SLOW TEST:9.003 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:42:32.587: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:42:32.654: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-gzf4p" to be "success or failure"
Dec  7 07:42:32.660: INFO: Pod "downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.528524ms
Dec  7 07:42:34.664: INFO: Pod "downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009708996s
STEP: Saw pod success
Dec  7 07:42:34.664: INFO: Pod "downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:42:34.667: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:42:34.694: INFO: Waiting for pod downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:42:34.698: INFO: Pod downwardapi-volume-a80b2046-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:42:34.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gzf4p" for this suite.
Dec  7 07:42:40.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:42:40.779: INFO: namespace: e2e-tests-projected-gzf4p, resource: bindings, ignored listing per whitelist
Dec  7 07:42:40.797: INFO: namespace e2e-tests-projected-gzf4p deletion completed in 6.091872974s

• [SLOW TEST:8.210 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:42:40.797: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  7 07:42:40.865: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-projected-t9zbb" to be "success or failure"
Dec  7 07:42:40.871: INFO: Pod "downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.852162ms
Dec  7 07:42:42.875: INFO: Pod "downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009872348s
STEP: Saw pod success
Dec  7 07:42:42.875: INFO: Pod "downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:42:42.880: INFO: Trying to get logs from node 2gb-pool-qefm5t pod downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4 container client-container: <nil>
STEP: delete the pod
Dec  7 07:42:42.913: INFO: Waiting for pod downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:42:42.916: INFO: Pod downwardapi-volume-acf04fb1-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:42:42.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t9zbb" for this suite.
Dec  7 07:42:48.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:42:49.010: INFO: namespace: e2e-tests-projected-t9zbb, resource: bindings, ignored listing per whitelist
Dec  7 07:42:49.016: INFO: namespace e2e-tests-projected-t9zbb deletion completed in 6.094467134s

• [SLOW TEST:8.219 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:42:49.016: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:42:49.085: INFO: Creating ReplicaSet my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4
Dec  7 07:42:49.095: INFO: Pod name my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4: Found 0 pods out of 1
Dec  7 07:42:54.099: INFO: Pod name my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4: Found 1 pods out of 1
Dec  7 07:42:54.099: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4" is running
Dec  7 07:42:54.101: INFO: Pod "my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4-ckw62" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:42:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:42:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:42:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-07 07:42:49 +0000 UTC Reason: Message:}])
Dec  7 07:42:54.101: INFO: Trying to dial the pod
Dec  7 07:42:59.113: INFO: Controller my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4: Got expected result from replica 1 [my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4-ckw62]: "my-hostname-basic-b1d75d20-f9f3-11e8-9cb3-16e60f4677a4-ckw62", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:42:59.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mfdt8" for this suite.
Dec  7 07:43:05.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:43:05.238: INFO: namespace: e2e-tests-replicaset-mfdt8, resource: bindings, ignored listing per whitelist
Dec  7 07:43:05.239: INFO: namespace e2e-tests-replicaset-mfdt8 deletion completed in 6.122502928s

• [SLOW TEST:16.222 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:43:05.240: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-bb85a8b6-f9f3-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:43:05.338: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-hmfng" to be "success or failure"
Dec  7 07:43:05.350: INFO: Pod "pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.372062ms
Dec  7 07:43:07.354: INFO: Pod "pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015719447s
STEP: Saw pod success
Dec  7 07:43:07.354: INFO: Pod "pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:43:07.356: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:43:07.390: INFO: Waiting for pod pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:43:07.403: INFO: Pod pod-configmaps-bb863667-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:43:07.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hmfng" for this suite.
Dec  7 07:43:13.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:43:13.440: INFO: namespace: e2e-tests-configmap-hmfng, resource: bindings, ignored listing per whitelist
Dec  7 07:43:13.501: INFO: namespace e2e-tests-configmap-hmfng deletion completed in 6.092935912s

• [SLOW TEST:8.262 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:43:13.502: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c06ff1ec-f9f3-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume secrets
Dec  7 07:43:13.585: INFO: Waiting up to 5m0s for pod "pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-secrets-696vr" to be "success or failure"
Dec  7 07:43:13.594: INFO: Pod "pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.8143ms
Dec  7 07:43:15.598: INFO: Pod "pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012902112s
STEP: Saw pod success
Dec  7 07:43:15.598: INFO: Pod "pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:43:15.600: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4 container secret-env-test: <nil>
STEP: delete the pod
Dec  7 07:43:15.621: INFO: Waiting for pod pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:43:15.628: INFO: Pod pod-secrets-c070819c-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:43:15.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-696vr" for this suite.
Dec  7 07:43:21.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:43:21.678: INFO: namespace: e2e-tests-secrets-696vr, resource: bindings, ignored listing per whitelist
Dec  7 07:43:21.741: INFO: namespace e2e-tests-secrets-696vr deletion completed in 6.109833203s

• [SLOW TEST:8.239 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:43:21.742: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c55a6b71-f9f3-11e8-9cb3-16e60f4677a4
STEP: Creating a pod to test consume configMaps
Dec  7 07:43:21.828: INFO: Waiting up to 5m0s for pod "pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4" in namespace "e2e-tests-configmap-wxqc8" to be "success or failure"
Dec  7 07:43:21.837: INFO: Pod "pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.431832ms
Dec  7 07:43:23.840: INFO: Pod "pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011628245s
STEP: Saw pod success
Dec  7 07:43:23.840: INFO: Pod "pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4" satisfied condition "success or failure"
Dec  7 07:43:23.842: INFO: Trying to get logs from node 2gb-pool-qefm5t pod pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  7 07:43:23.860: INFO: Waiting for pod pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4 to disappear
Dec  7 07:43:23.863: INFO: Pod pod-configmaps-c55acab6-f9f3-11e8-9cb3-16e60f4677a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:43:23.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wxqc8" for this suite.
Dec  7 07:43:29.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:43:29.962: INFO: namespace: e2e-tests-configmap-wxqc8, resource: bindings, ignored listing per whitelist
Dec  7 07:43:29.968: INFO: namespace e2e-tests-configmap-wxqc8 deletion completed in 6.101162189s

• [SLOW TEST:8.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  7 07:43:29.969: INFO: >>> kubeConfig: /tmp/kubeconfig-542553880
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  7 07:43:30.054: INFO: (0) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.420463ms)
Dec  7 07:43:30.059: INFO: (1) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.869535ms)
Dec  7 07:43:30.064: INFO: (2) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.511941ms)
Dec  7 07:43:30.068: INFO: (3) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.251691ms)
Dec  7 07:43:30.072: INFO: (4) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.361163ms)
Dec  7 07:43:30.076: INFO: (5) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.500068ms)
Dec  7 07:43:30.084: INFO: (6) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.151368ms)
Dec  7 07:43:30.088: INFO: (7) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.136132ms)
Dec  7 07:43:30.092: INFO: (8) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.2004ms)
Dec  7 07:43:30.097: INFO: (9) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.293762ms)
Dec  7 07:43:30.100: INFO: (10) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.664856ms)
Dec  7 07:43:30.104: INFO: (11) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.819706ms)
Dec  7 07:43:30.108: INFO: (12) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.914412ms)
Dec  7 07:43:30.112: INFO: (13) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.224339ms)
Dec  7 07:43:30.116: INFO: (14) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.810565ms)
Dec  7 07:43:30.125: INFO: (15) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.962616ms)
Dec  7 07:43:30.129: INFO: (16) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.901787ms)
Dec  7 07:43:30.133: INFO: (17) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.775775ms)
Dec  7 07:43:30.136: INFO: (18) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.784637ms)
Dec  7 07:43:30.142: INFO: (19) /api/v1/nodes/2gb-pool-qefm5t:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.142509ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  7 07:43:30.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xh4rt" for this suite.
Dec  7 07:43:36.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  7 07:43:36.221: INFO: namespace: e2e-tests-proxy-xh4rt, resource: bindings, ignored listing per whitelist
Dec  7 07:43:36.240: INFO: namespace e2e-tests-proxy-xh4rt deletion completed in 6.095258176s

• [SLOW TEST:6.271 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSDec  7 07:43:36.240: INFO: Running AfterSuite actions on all nodes
Dec  7 07:43:36.241: INFO: Running AfterSuite actions on node 1
Dec  7 07:43:36.241: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5713.430 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h35m14.603871956s
Test Suite Passed
